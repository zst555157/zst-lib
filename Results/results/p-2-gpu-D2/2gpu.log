nohup: ignoring input
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
using world size: 2, data-parallel size: 2, context-parallel size: 1 tensor-model-parallel size: 1, pipeline-model-parallel size: 1 
WARNING: Setting args.overlap_p2p_comm to False since non-interleaved schedule does not support overlapping p2p communication
WARNING: Setting args.check_for_nan_in_loss_and_grad to False since dynamic loss scaling is being used
using torch.float16 for parameters ...
------------------------print arguments ------------------------
  accumulate_allreduce_grads_in_fp32 .............. False
  adam_beta1 ...................................... 0.9
  adam_beta2 ...................................... 0.999
  adam_eps ........................................ 1e-08
  add_bias_linear ................................. True
  add_position_embedding .......................... True
  add_qkv_bias .................................... False
  adlr_autoresume ................................. False
  adlr_autoresume_interval ........................ 1000
  apply_layernorm_1p .............................. False
  apply_query_key_layer_scaling ................... False
  apply_residual_connection_post_layernorm ........ False
  apply_rope_fusion ............................... True
  async_tensor_model_parallel_allreduce ........... True
  attention_dropout ............................... 0.1
  attention_softmax_in_fp32 ....................... False
  auto_detect_ckpt_format ......................... False
  barrier_with_L1_time ............................ True
  bert_binary_head ................................ True
  bert_embedder_type .............................. megatron
  bert_load ....................................... None
  bf16 ............................................ False
  bias_dropout_fusion ............................. True
  bias_gelu_fusion ................................ True
  bias_swiglu_fusion .............................. True
  biencoder_projection_dim ........................ 0
  biencoder_shared_query_context_model ............ False
  block_data_path ................................. None
  check_for_nan_in_loss_and_grad .................. False
  ckpt_fully_parallel_save ........................ False
  ckpt_step ....................................... None
  classes_fraction ................................ 1.0
  clip_grad ....................................... 1.0
  clone_scatter_output_in_embedding ............... True
  consumed_train_samples .......................... 0
  consumed_valid_samples .......................... 0
  context_parallel_size ........................... 1
  create_attention_mask_in_dataloader ............. True
  data_cache_path ................................. None
  data_parallel_random_init ....................... False
  data_parallel_size .............................. 2
  data_path ....................................... ['/Zhushitong/workspace/Models/gpt-2/data/meg-gpt2_text_document']
  data_per_class_fraction ......................... 1.0
  data_sharding ................................... True
  dataloader_type ................................. single
  ddp_bucket_size ................................. None
  decoder_num_layers .............................. None
  decoder_seq_length .............................. None
  decoupled_lr .................................... None
  decoupled_min_lr ................................ None
  delay_grad_reduce ............................... True
  delay_param_gather .............................. False
  dino_bottleneck_size ............................ 256
  dino_freeze_last_layer .......................... 1
  dino_head_hidden_size ........................... 2048
  dino_local_crops_number ......................... 10
  dino_local_img_size ............................. 96
  dino_norm_last_layer ............................ False
  dino_teacher_temp ............................... 0.07
  dino_warmup_teacher_temp ........................ 0.04
  dino_warmup_teacher_temp_epochs ................. 30
  disable_straggler_on_startup .................... False
  dist_ckpt_format ................................ torch_dist
  distribute_saved_activations .................... False
  distributed_backend ............................. nccl
  distributed_timeout_minutes ..................... 10
  embedding_path .................................. None
  empty_unused_memory_level ....................... 0
  enable_one_logger ............................... False
  encoder_num_layers .............................. 24
  encoder_seq_length .............................. 1024
  end_weight_decay ................................ 0.01
  eod_mask_loss ................................... False
  eval_interval ................................... 1000
  eval_iters ...................................... 10
  evidence_data_path .............................. None
  exit_duration_in_mins ........................... None
  exit_interval ................................... None
  exit_on_missing_checkpoint ...................... False
  exit_signal_handler ............................. False
  expert_model_parallel_size ...................... 1
  ffn_hidden_size ................................. 3072
  finetune ........................................ False
  fp16 ............................................ True
  fp16_lm_cross_entropy ........................... False
  fp32_residual_connection ........................ False
  fp8 ............................................. None
  fp8_amax_compute_algo ........................... most_recent
  fp8_amax_history_len ............................ 1
  fp8_interval .................................... 1
  fp8_margin ...................................... 0
  fp8_wgrad ....................................... True
  global_batch_size ............................... 64
  gradient_accumulation_fusion .................... True
  group_query_attention ........................... False
  head_lr_mult .................................... 1.0
  hidden_dropout .................................. 0.1
  hidden_size ..................................... 768
  hysteresis ...................................... 2
  ict_head_size ................................... None
  ict_load ........................................ None
  img_h ........................................... 224
  img_w ........................................... 224
  indexer_batch_size .............................. 128
  indexer_log_interval ............................ 1000
  inference_batch_times_seqlen_threshold .......... 512
  init_method_std ................................. 0.02
  init_method_xavier_uniform ...................... False
  initial_loss_scale .............................. 4294967296
  iter_per_epoch .................................. 1250
  kv_channels ..................................... 32
  lazy_mpu_init ................................... None
  load ............................................ /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-distribution
  local_rank ...................................... None
  log_batch_size_to_tensorboard ................... False
  log_interval .................................... 100
  log_learning_rate_to_tensorboard ................ True
  log_loss_scale_to_tensorboard ................... True
  log_memory_to_tensorboard ....................... False
  log_num_zeros_in_grad ........................... False
  log_params_norm ................................. False
  log_progress .................................... False
  log_straggler ................................... False
  log_throughput .................................. False
  log_timers_to_tensorboard ....................... False
  log_validation_ppl_to_tensorboard ............... False
  log_world_size_to_tensorboard ................... False
  loss_scale ...................................... None
  loss_scale_window ............................... 1000
  lr .............................................. 0.00015
  lr_decay_iters .................................. 320000
  lr_decay_samples ................................ None
  lr_decay_style .................................. cosine
  lr_warmup_fraction .............................. 0.01
  lr_warmup_init .................................. 0.0
  lr_warmup_iters ................................. 0
  lr_warmup_samples ............................... 0
  make_vocab_size_divisible_by .................... 128
  manual_gc ....................................... False
  manual_gc_eval .................................. True
  manual_gc_interval .............................. 0
  mask_factor ..................................... 1.0
  mask_prob ....................................... 0.15
  mask_type ....................................... random
  masked_softmax_fusion ........................... True
  max_position_embeddings ......................... 1024
  max_tokens_to_oom ............................... 12000
  merge_file ...................................... /Zhushitong/workspace/Models/gpt-2/data/gpt2-merges.txt
  micro_batch_size ................................ 8
  min_loss_scale .................................. 1.0
  min_lr .......................................... 1e-05
  mmap_bin_files .................................. True
  mock_data ....................................... False
  moe_aux_loss_coeff .............................. 0.0
  moe_grouped_gemm ................................ False
  moe_input_jitter_eps ............................ None
  moe_per_layer_logging ........................... False
  moe_router_load_balancing_type .................. aux_loss
  moe_router_topk ................................. 2
  moe_token_dispatcher_type ....................... allgather
  moe_token_dropping .............................. False
  moe_z_loss_coeff ................................ None
  nccl_communicator_config_path ................... None
  no_load_optim ................................... None
  no_load_rng ..................................... None
  no_persist_layer_norm ........................... False
  no_save_optim ................................... None
  no_save_rng ..................................... None
  norm_epsilon .................................... 1e-05
  normalization ................................... LayerNorm
  num_attention_heads ............................. 24
  num_channels .................................... 3
  num_classes ..................................... 1000
  num_experts ..................................... None
  num_layers ...................................... 24
  num_layers_per_virtual_pipeline_stage ........... None
  num_query_groups ................................ 1
  num_workers ..................................... 2
  one_logger_entity ............................... hwinf_dcm
  one_logger_project .............................. e2e-tracking
  one_logger_run_name ............................. None
  onnx_safe ....................................... None
  openai_gelu ..................................... False
  optimizer ....................................... adam
  output_bert_embeddings .......................... False
  overlap_grad_reduce ............................. False
  overlap_p2p_comm ................................ False
  overlap_param_gather ............................ False
  override_opt_param_scheduler .................... False
  params_dtype .................................... torch.float16
  patch_dim ....................................... 16
  perform_initialization .......................... True
  pipeline_model_parallel_size .................... 1
  pipeline_model_parallel_split_rank .............. None
  position_embedding_type ......................... learned_absolute
  pretrained_checkpoint ........................... None
  profile ......................................... False
  profile_ranks ................................... [0]
  profile_step_end ................................ 12
  profile_step_start .............................. 10
  qk_layernorm .................................... False
  query_in_block_prob ............................. 0.1
  rampup_batch_size ............................... None
  rank ............................................ 0
  recompute_granularity ........................... None
  recompute_method ................................ None
  recompute_num_layers ............................ None
  reset_attention_mask ............................ False
  reset_position_ids .............................. False
  retriever_report_topk_accuracies ................ []
  retriever_score_scaling ......................... False
  retriever_seq_length ............................ 256
  retro_add_retriever ............................. False
  retro_attention_gate ............................ 1
  retro_cyclic_train_iters ........................ None
  retro_encoder_attention_dropout ................. 0.1
  retro_encoder_hidden_dropout .................... 0.1
  retro_encoder_layers ............................ 2
  retro_num_neighbors ............................. 2
  retro_num_retrieved_chunks ...................... 2
  retro_project_dir ............................... None
  retro_verify_neighbor_count ..................... True
  rotary_interleaved .............................. False
  rotary_percent .................................. 1.0
  rotary_seq_len_interpolation_factor ............. None
  sample_rate ..................................... 1.0
  save ............................................ /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-distribution
  save_interval ................................... 10000
  scatter_gather_tensors_in_pipeline .............. True
  seed ............................................ 1234
  seq_length ...................................... 1024
  sequence_parallel ............................... False
  sgd_momentum .................................... 0.9
  short_seq_prob .................................. 0.1
  skip_train ...................................... False
  spec ............................................ None
  split ........................................... 949,50,1
  squared_relu .................................... False
  standalone_embedding_stage ...................... False
  start_weight_decay .............................. 0.01
  straggler_ctrlr_port ............................ 65535
  straggler_minmax_count .......................... 1
  swiglu .......................................... False
  swin_backbone_type .............................. tiny
  tensor_model_parallel_size ...................... 1
  tensorboard_dir ................................. None
  tensorboard_log_interval ........................ 1
  tensorboard_queue_size .......................... 1000
  test_data_path .................................. None
  test_mode ....................................... False
  timing_log_level ................................ 0
  timing_log_option ............................... minmax
  titles_data_path ................................ None
  tokenizer_model ................................. None
  tokenizer_type .................................. GPT2BPETokenizer
  tp_comm_bulk_dgrad .............................. True
  tp_comm_bulk_wgrad .............................. True
  tp_comm_overlap ................................. False
  tp_comm_overlap_ag .............................. True
  tp_comm_overlap_cfg ............................. None
  tp_comm_overlap_rs .............................. True
  tp_comm_overlap_rs_dgrad ........................ False
  tp_comm_split_ag ................................ True
  tp_comm_split_rs ................................ True
  train_data_path ................................. None
  train_iters ..................................... 500000
  train_samples ................................... None
  transformer_impl ................................ transformer_engine
  transformer_pipeline_model_parallel_size ........ 1
  untie_embeddings_and_output_weights ............. False
  use_checkpoint_args ............................. False
  use_checkpoint_opt_param_scheduler .............. False
  use_cpu_initialization .......................... None
  use_dist_ckpt ................................... False
  use_distributed_optimizer ....................... False
  use_flash_attn .................................. False
  use_mcore_models ................................ False
  use_one_sent_docs ............................... False
  use_ring_exchange_p2p ........................... False
  use_rotary_position_embeddings .................. False
  use_tp_pp_dp_mapping ............................ False
  valid_data_path ................................. None
  variable_seq_lengths ............................ False
  virtual_pipeline_model_parallel_size ............ None
  vision_backbone_type ............................ vit
  vision_pretraining .............................. False
  vision_pretraining_type ......................... classify
  vocab_extra_ids ................................. 0
  vocab_file ...................................... /Zhushitong/workspace/Models/gpt-2/data/gpt2-vocab.json
  vocab_size ...................................... None
  wandb_exp_name .................................. 
  wandb_project ................................... 
  wandb_save_dir .................................. 
  weight_decay .................................... 0.01
  weight_decay_incr_style ......................... constant
  world_size ...................................... 2
  yaml_cfg ........................................ None
-------------------- end of arguments ---------------------
setting number of micro-batches to constant 4
> building GPT2BPETokenizer tokenizer ...
 > padded vocab (size: 50257) with 47 dummy tokens (new size: 50304)
> initializing torch distributed ...
> initialized tensor model parallel with size 1
> initialized pipeline model parallel with size 1
> setting random seeds to 1234 ...
> compiling dataset index builder ...
make: Entering directory '/Zhushitong/workspace/Git/Megatron-LM/megatron/core/datasets'
make: Nothing to be done for 'default'.
make: Leaving directory '/Zhushitong/workspace/Git/Megatron-LM/megatron/core/datasets'
>>> done with dataset index builder. Compilation time: 0.086 seconds
> compiling and loading fused kernels ...
>>> done with compiling and loading fused kernels. Compilation time: 0.741 seconds
time to initialize megatron (seconds): 2.061
[after megatron is initialized] datetime: 2024-06-24 03:40:56 
building GPT model ...
/usr/local/lib/python3.8/dist-packages/transformer_engine/pytorch/transformer.py:967: DeprecationWarning: Arguments `attention_softmax_in_fp32` and `apply_query_key_layer_scaling`are deprecated and will be fully removed in future releases.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/transformer_engine/pytorch/transformer.py:967: DeprecationWarning: Arguments `attention_softmax_in_fp32` and `apply_query_key_layer_scaling`are deprecated and will be fully removed in future releases.
  warnings.warn(
 > number of parameters on (tensor, pipeline) model parallel rank (0, 0): 209530368
INFO:megatron.core.distributed.distributed_data_parallel:Setting up DistributedDataParallel with DistributedDataParallelConfig: DistributedDataParallelConfig(grad_reduce_in_fp32=False, overlap_grad_reduce=False, use_distributed_optimizer=False, check_for_nan_in_grad=False, bucket_size=None)
INFO:megatron.core.distributed.param_and_grad_buffer:Number of buckets for gradient all-reduce / reduce-scatter: 1
INFO:megatron.core.distributed.param_and_grad_buffer:Params for bucket 1 (209530368 elements):
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.20.layernorm_mlp.fc1_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.18.layernorm_mlp.fc2_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.17.self_attention.layernorm_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.9.self_attention.layernorm_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.3.layernorm_mlp.fc1_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.1.self_attention.proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.21.self_attention.layernorm_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.15.self_attention.proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.11.layernorm_mlp.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.9.layernorm_mlp.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.5.layernorm_mlp.fc2_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.18.self_attention.layernorm_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.21.layernorm_mlp.fc1_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.19.layernorm_mlp.fc2_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.10.self_attention.layernorm_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.4.layernorm_mlp.fc1_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.2.self_attention.proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.0.self_attention.layernorm_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.0.layernorm_mlp.fc1_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.22.self_attention.layernorm_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.16.layernorm_mlp.fc1_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.14.self_attention.proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.10.layernorm_mlp.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.8.layernorm_mlp.fc1_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.4.layernorm_mlp.fc2_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.1.self_attention.layernorm_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.6.layernorm_mlp.fc2_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.final_norm.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.22.layernorm_mlp.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.18.layernorm_mlp.fc2_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.13.self_attention.layernorm_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.9.self_attention.layernorm_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.3.self_attention.proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.23.self_attention.layernorm_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.17.layernorm_mlp.fc1_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.15.self_attention.proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.9.layernorm_mlp.fc1_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.7.layernorm_mlp.fc2_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.6.self_attention.layernorm_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.embedding.word_embeddings.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.4.self_attention.proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.23.layernorm_mlp.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.19.layernorm_mlp.fc2_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.14.self_attention.layernorm_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.10.self_attention.layernorm_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.0.self_attention.proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.embedding.position_embeddings.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.1.self_attention.layernorm_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.0.self_attention.layernorm_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.22.self_attention.layernorm_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.16.self_attention.proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.12.layernorm_mlp.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.10.layernorm_mlp.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.8.layernorm_mlp.fc1_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.6.layernorm_mlp.fc2_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.22.layernorm_mlp.fc1_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.20.layernorm_mlp.fc2_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.19.self_attention.layernorm_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.11.self_attention.layernorm_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.5.layernorm_mlp.fc1_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.3.self_attention.proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.23.self_attention.layernorm_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.17.self_attention.proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.13.layernorm_mlp.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.11.layernorm_mlp.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.7.layernorm_mlp.fc2_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.2.self_attention.layernorm_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.0.layernorm_mlp.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.20.self_attention.layernorm_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.23.layernorm_mlp.fc1_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.21.layernorm_mlp.fc2_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.12.self_attention.layernorm_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.6.layernorm_mlp.fc1_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.4.self_attention.proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.18.layernorm_mlp.fc1_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.16.self_attention.proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.10.layernorm_mlp.fc1_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.8.layernorm_mlp.fc2_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.7.self_attention.layernorm_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.3.self_attention.layernorm_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.1.layernorm_mlp.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.20.layernorm_mlp.fc2_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.15.self_attention.layernorm_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.11.self_attention.layernorm_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.5.self_attention.proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.19.layernorm_mlp.fc1_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.17.self_attention.proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.11.layernorm_mlp.fc1_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.9.layernorm_mlp.fc2_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.8.self_attention.layernorm_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.21.layernorm_mlp.fc2_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.16.self_attention.layernorm_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.12.self_attention.layernorm_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.6.self_attention.proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.2.layernorm_mlp.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.0.layernorm_mlp.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.18.self_attention.proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.14.layernorm_mlp.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.12.layernorm_mlp.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.10.layernorm_mlp.fc1_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.8.layernorm_mlp.fc2_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.3.self_attention.layernorm_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.22.layernorm_mlp.fc2_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.21.self_attention.layernorm_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.13.self_attention.layernorm_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.7.layernorm_mlp.fc1_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.5.self_attention.proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.19.self_attention.proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.15.layernorm_mlp.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.13.layernorm_mlp.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.9.layernorm_mlp.fc2_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.4.self_attention.layernorm_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.23.layernorm_mlp.fc2_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.22.self_attention.layernorm_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.14.self_attention.layernorm_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.6.self_attention.proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.0.layernorm_mlp.fc1_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.1.self_attention.layernorm_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.20.layernorm_mlp.fc1_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.18.self_attention.proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.12.layernorm_mlp.fc1_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.10.layernorm_mlp.fc2_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.9.self_attention.layernorm_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.5.self_attention.layernorm_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.22.layernorm_mlp.fc2_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.17.self_attention.layernorm_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.13.self_attention.layernorm_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.7.self_attention.proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.3.layernorm_mlp.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.1.layernorm_mlp.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.21.layernorm_mlp.fc1_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.19.self_attention.proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.13.layernorm_mlp.fc1_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.11.layernorm_mlp.fc2_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.10.self_attention.layernorm_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.2.self_attention.layernorm_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.2.layernorm_mlp.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.23.layernorm_mlp.fc2_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.18.self_attention.layernorm_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.14.self_attention.layernorm_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.8.self_attention.proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.4.layernorm_mlp.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.1.self_attention.layernorm_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.5.self_attention.layernorm_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.20.self_attention.proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.16.layernorm_mlp.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.14.layernorm_mlp.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.12.layernorm_mlp.fc1_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.10.layernorm_mlp.fc2_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.23.self_attention.layernorm_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.15.self_attention.layernorm_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.9.layernorm_mlp.fc1_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.7.self_attention.proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.1.layernorm_mlp.fc1_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.21.self_attention.proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.17.layernorm_mlp.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.15.layernorm_mlp.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.11.layernorm_mlp.fc2_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.6.self_attention.layernorm_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.2.self_attention.layernorm_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.16.self_attention.layernorm_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.8.self_attention.proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.2.layernorm_mlp.fc1_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.0.layernorm_mlp.fc2_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.22.layernorm_mlp.fc1_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.20.self_attention.proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.14.layernorm_mlp.fc1_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.12.layernorm_mlp.fc2_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.11.self_attention.layernorm_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.3.self_attention.layernorm_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.19.self_attention.layernorm_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.15.self_attention.layernorm_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.9.self_attention.proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.5.layernorm_mlp.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.3.layernorm_mlp.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.23.layernorm_mlp.fc1_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.21.self_attention.proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.15.layernorm_mlp.fc1_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.13.layernorm_mlp.fc2_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.12.self_attention.layernorm_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.4.self_attention.layernorm_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.0.layernorm_mlp.fc2_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.20.self_attention.layernorm_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.16.self_attention.layernorm_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.10.self_attention.proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.6.layernorm_mlp.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.4.layernorm_mlp.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.22.self_attention.proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.18.layernorm_mlp.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.16.layernorm_mlp.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.14.layernorm_mlp.fc1_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.12.layernorm_mlp.fc2_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.7.self_attention.layernorm_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.3.self_attention.layernorm_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.17.self_attention.layernorm_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.11.layernorm_mlp.fc1_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.9.self_attention.proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.3.layernorm_mlp.fc1_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.1.layernorm_mlp.fc2_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.23.self_attention.proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.19.layernorm_mlp.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.17.layernorm_mlp.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.13.layernorm_mlp.fc2_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.8.self_attention.layernorm_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.4.self_attention.layernorm_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.18.self_attention.layernorm_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.10.self_attention.proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.4.layernorm_mlp.fc1_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.2.layernorm_mlp.fc2_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.22.self_attention.proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.16.layernorm_mlp.fc1_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.14.layernorm_mlp.fc2_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.13.self_attention.layernorm_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.5.self_attention.layernorm_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.21.self_attention.layernorm_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.17.self_attention.layernorm_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.11.self_attention.proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.7.layernorm_mlp.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.5.layernorm_mlp.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.1.layernorm_mlp.fc2_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.0.self_attention.layernorm_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.23.self_attention.proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.17.layernorm_mlp.fc1_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.15.layernorm_mlp.fc2_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.14.self_attention.layernorm_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.6.self_attention.layernorm_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.2.layernorm_mlp.fc2_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.18.self_attention.layernorm_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.final_norm.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.22.self_attention.layernorm_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.12.self_attention.proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.8.layernorm_mlp.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.6.layernorm_mlp.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.20.layernorm_mlp.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.18.layernorm_mlp.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.14.layernorm_mlp.fc2_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.9.self_attention.layernorm_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.5.self_attention.layernorm_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.19.self_attention.layernorm_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.13.layernorm_mlp.fc1_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.11.self_attention.proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.5.layernorm_mlp.fc1_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.3.layernorm_mlp.fc2_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.2.self_attention.layernorm_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.0.self_attention.layernorm_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.21.layernorm_mlp.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.19.layernorm_mlp.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.15.layernorm_mlp.fc2_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.10.self_attention.layernorm_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.6.self_attention.layernorm_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.20.self_attention.layernorm_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.12.self_attention.proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.6.layernorm_mlp.fc1_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.18.layernorm_mlp.fc1_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.16.layernorm_mlp.fc2_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.15.self_attention.layernorm_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.7.self_attention.layernorm_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.1.layernorm_mlp.fc1_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.23.self_attention.layernorm_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.19.self_attention.layernorm_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.13.self_attention.proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.9.layernorm_mlp.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.7.layernorm_mlp.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.3.layernorm_mlp.fc2_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.2.layernorm_mlp.fc1_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.19.layernorm_mlp.fc1_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.17.layernorm_mlp.fc2_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.16.self_attention.layernorm_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.8.self_attention.layernorm_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.20.self_attention.layernorm_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.14.self_attention.proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.8.layernorm_mlp.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.4.layernorm_mlp.fc2_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.1.self_attention.proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.22.layernorm_mlp.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.20.layernorm_mlp.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.16.layernorm_mlp.fc2_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.11.self_attention.layernorm_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.7.self_attention.layernorm_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.21.self_attention.layernorm_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.15.layernorm_mlp.fc1_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.13.self_attention.proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.7.layernorm_mlp.fc1_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.5.layernorm_mlp.fc2_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.4.self_attention.layernorm_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.2.self_attention.proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.0.self_attention.proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.23.layernorm_mlp.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.21.layernorm_mlp.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.17.layernorm_mlp.fc2_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.12.self_attention.layernorm_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.8.self_attention.layernorm_qkv.bias
INFO:megatron.core.optimizer:Setting up optimizer with OptimizerConfig: OptimizerConfig(optimizer='adam', lr=0.00015, min_lr=1e-05, decoupled_lr=None, decoupled_min_lr=None, weight_decay=0.01, fp16=True, bf16=False, params_dtype=torch.float16, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, adam_beta1=0.9, adam_beta2=0.999, adam_eps=1e-08, sgd_momentum=0.9, use_distributed_optimizer=False, overlap_grad_reduce=False, overlap_param_gather=False, clip_grad=1.0, log_num_zeros_in_grad=False, barrier_with_L1_time=True, timers=<megatron.core.timers.Timers object at 0x7f600e1368e0>)
> learning rate decay style: cosine
WARNING: could not find the metadata file /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-distribution/latest_checkpointed_iteration.txt 
    will not load any checkpoints and will start from random
/usr/local/lib/python3.8/dist-packages/torch/distributed/distributed_c10d.py:2603: UserWarning: torch.distributed._all_gather_base is a private function and will be deprecated. Please use torch.distributed.all_gather_into_tensor instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/distributed/distributed_c10d.py:2603: UserWarning: torch.distributed._all_gather_base is a private function and will be deprecated. Please use torch.distributed.all_gather_into_tensor instead.
  warnings.warn(
(min, max) time across ranks (ms):
    load-checkpoint ................................: (0.25, 0.36)
[after model, optimizer, and learning rate scheduler are built] datetime: 2024-06-24 03:40:59 
> building train, validation, and test datasets ...
 > datasets target sizes (minimum size):
    train:      32000000
    validation: 320640
    test:       640
INFO:megatron.core.datasets.blended_megatron_dataset_config:mock = False
INFO:megatron.core.datasets.blended_megatron_dataset_config:Let split_matrix = [(0, 0.949), (0.949, 0.999), (0.999, 1.0)]
> building train, validation, and test datasets for GPT ...
WARNING:megatron.core.datasets.blended_megatron_dataset_builder:Building dataset splits with cls=GPTDataset, sizes=(32000000, 320640, 640), and config=GPTDatasetConfig(random_seed=1234, sequence_length=1024, blend=(['/Zhushitong/workspace/Models/gpt-2/data/meg-gpt2_text_document'], None), blend_per_split=[None, None, None], split='949,50,1', split_matrix=[(0, 0.949), (0.949, 0.999), (0.999, 1.0)], path_to_cache=None, mmap_bin_files=True, mock=False, tokenizer=<megatron.training.tokenizer.tokenizer._GPT2BPETokenizer object at 0x7f600e0169d0>, reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, create_attention_mask=True)
INFO:megatron.core.datasets.indexed_dataset:Load the _IndexReader from /Zhushitong/workspace/Models/gpt-2/data/meg-gpt2_text_document.idx
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence lengths
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence pointers
INFO:megatron.core.datasets.indexed_dataset:	Extract the document indices
INFO:megatron.core.datasets.indexed_dataset:> total number of sequences: 79000
INFO:megatron.core.datasets.indexed_dataset:> total number of documents: 79000
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset train indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 8d72db0c6782af1b2c5e8b01dd7ba483-GPTDataset-train-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 8d72db0c6782af1b2c5e8b01dd7ba483-GPTDataset-train-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 8d72db0c6782af1b2c5e8b01dd7ba483-GPTDataset-train-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 32100553
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset valid indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 5202e2cc65752523555220b6fc4facd0-GPTDataset-valid-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 5202e2cc65752523555220b6fc4facd0-GPTDataset-valid-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 5202e2cc65752523555220b6fc4facd0-GPTDataset-valid-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 324329
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset test indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 3da4a34cd21c907ca248e476d105ccf5-GPTDataset-test-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 3da4a34cd21c907ca248e476d105ccf5-GPTDataset-test-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 3da4a34cd21c907ca248e476d105ccf5-GPTDataset-test-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 736
> finished creating GPT datasets ...
[after dataloaders are built] datetime: 2024-06-24 03:41:00 
done with setup ...
(min, max) time across ranks (ms):
    model-and-optimizer-setup ......................: (3272.36, 3310.00)
    train/valid/test-data-iterators-setup ..........: (838.50, 841.91)
training ...
[before the start of training step] datetime: 2024-06-24 03:41:00 
 [2024-06-24 03:42:04] iteration      100/  500000 | consumed samples:         6400 | elapsed time per iteration (ms): 641.9 | learning rate: 3.984375E-06 | global batch size:    64 | lm loss: 9.981622E+00 | loss scale: 262144.0 | grad norm: 2.023 | number of skipped iterations:  15 | number of nan iterations:   0 |Number of parameters in transformer layers in billions:  0.17

Number of parameters in embedding layers in billions: 0.04
Total number of parameters in billions: 0.21
Number of parameters in most loaded shard in billions: 0.2086
Theoretical memory footprints: weight and optimizer=3580.48 MB
[Rank 0] (after 100 iterations) memory (MB) | allocated: 4080.89501953125 | max allocated: 20509.49658203125 | reserved: 22092.0 | max reserved: 22092.0
 [2024-06-24 03:43:06] iteration      200/  500000 | consumed samples:        12800 | elapsed time per iteration (ms): 622.8 | learning rate: 8.671875E-06 | global batch size:    64 | lm loss: 8.997157E+00 | loss scale: 262144.0 | grad norm: 1.749 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 03:44:08] iteration      300/  500000 | consumed samples:        19200 | elapsed time per iteration (ms): 621.6 | learning rate: 1.335937E-05 | global batch size:    64 | lm loss: 8.213046E+00 | loss scale: 262144.0 | grad norm: 1.602 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 03:45:11] iteration      400/  500000 | consumed samples:        25600 | elapsed time per iteration (ms): 622.6 | learning rate: 1.804687E-05 | global batch size:    64 | lm loss: 7.512871E+00 | loss scale: 262144.0 | grad norm: 1.006 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 03:46:13] iteration      500/  500000 | consumed samples:        32000 | elapsed time per iteration (ms): 620.6 | learning rate: 2.273437E-05 | global batch size:    64 | lm loss: 7.110026E+00 | loss scale: 262144.0 | grad norm: 1.105 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 03:47:15] iteration      600/  500000 | consumed samples:        38400 | elapsed time per iteration (ms): 621.8 | learning rate: 2.742187E-05 | global batch size:    64 | lm loss: 6.877109E+00 | loss scale: 262144.0 | grad norm: 1.326 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 03:48:17] iteration      700/  500000 | consumed samples:        44800 | elapsed time per iteration (ms): 620.5 | learning rate: 3.210937E-05 | global batch size:    64 | lm loss: 6.718818E+00 | loss scale: 262144.0 | grad norm: 1.033 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 03:49:19] iteration      800/  500000 | consumed samples:        51200 | elapsed time per iteration (ms): 619.9 | learning rate: 3.679687E-05 | global batch size:    64 | lm loss: 6.610398E+00 | loss scale: 262144.0 | grad norm: 0.943 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 03:50:21] iteration      900/  500000 | consumed samples:        57600 | elapsed time per iteration (ms): 621.2 | learning rate: 4.148437E-05 | global batch size:    64 | lm loss: 6.498967E+00 | loss scale: 262144.0 | grad norm: 1.252 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 03:51:23] iteration     1000/  500000 | consumed samples:        64000 | elapsed time per iteration (ms): 623.0 | learning rate: 4.617187E-05 | global batch size:    64 | lm loss: 6.400698E+00 | loss scale: 262144.0 | grad norm: 1.218 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2641.03, 2641.27)
------------------------------------------------------------------------------------------------
 validation loss at iteration 1000 | lm loss value: 6.309464E+00 | lm loss PPL: 5.497505E+02 | 
------------------------------------------------------------------------------------------------
 [2024-06-24 03:52:28] iteration     1100/  500000 | consumed samples:        70400 | elapsed time per iteration (ms): 619.7 | learning rate: 5.085937E-05 | global batch size:    64 | lm loss: 6.314901E+00 | loss scale: 524288.0 | grad norm: 1.378 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 03:53:30] iteration     1200/  500000 | consumed samples:        76800 | elapsed time per iteration (ms): 620.9 | learning rate: 5.554688E-05 | global batch size:    64 | lm loss: 6.210903E+00 | loss scale: 524288.0 | grad norm: 1.314 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 03:54:32] iteration     1300/  500000 | consumed samples:        83200 | elapsed time per iteration (ms): 620.6 | learning rate: 6.023437E-05 | global batch size:    64 | lm loss: 6.120530E+00 | loss scale: 524288.0 | grad norm: 1.346 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 03:55:34] iteration     1400/  500000 | consumed samples:        89600 | elapsed time per iteration (ms): 622.1 | learning rate: 6.492187E-05 | global batch size:    64 | lm loss: 6.015392E+00 | loss scale: 524288.0 | grad norm: 1.152 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 03:56:36] iteration     1500/  500000 | consumed samples:        96000 | elapsed time per iteration (ms): 620.1 | learning rate: 6.960937E-05 | global batch size:    64 | lm loss: 5.913723E+00 | loss scale: 524288.0 | grad norm: 1.263 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 03:57:38] iteration     1600/  500000 | consumed samples:       102400 | elapsed time per iteration (ms): 619.7 | learning rate: 7.429687E-05 | global batch size:    64 | lm loss: 5.847018E+00 | loss scale: 524288.0 | grad norm: 1.240 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 03:58:41] iteration     1700/  500000 | consumed samples:       108800 | elapsed time per iteration (ms): 622.6 | learning rate: 7.898437E-05 | global batch size:    64 | lm loss: 5.746920E+00 | loss scale: 524288.0 | grad norm: 1.052 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 03:59:43] iteration     1800/  500000 | consumed samples:       115200 | elapsed time per iteration (ms): 620.7 | learning rate: 8.367187E-05 | global batch size:    64 | lm loss: 5.660649E+00 | loss scale: 524288.0 | grad norm: 0.964 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 04:00:45] iteration     1900/  500000 | consumed samples:       121600 | elapsed time per iteration (ms): 621.2 | learning rate: 8.835938E-05 | global batch size:    64 | lm loss: 5.588517E+00 | loss scale: 524288.0 | grad norm: 0.961 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 04:01:47] iteration     2000/  500000 | consumed samples:       128000 | elapsed time per iteration (ms): 622.9 | learning rate: 9.304687E-05 | global batch size:    64 | lm loss: 5.517626E+00 | loss scale: 524288.0 | grad norm: 0.933 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2463.03, 2463.21)
------------------------------------------------------------------------------------------------
 validation loss at iteration 2000 | lm loss value: 5.399709E+00 | lm loss PPL: 2.213419E+02 | 
------------------------------------------------------------------------------------------------
 [2024-06-24 04:02:52] iteration     2100/  500000 | consumed samples:       134400 | elapsed time per iteration (ms): 619.7 | learning rate: 9.773437E-05 | global batch size:    64 | lm loss: 5.439864E+00 | loss scale: 1048576.0 | grad norm: 1.184 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 04:03:54] iteration     2200/  500000 | consumed samples:       140800 | elapsed time per iteration (ms): 620.7 | learning rate: 1.023281E-04 | global batch size:    64 | lm loss: 5.371357E+00 | loss scale: 524288.0 | grad norm: 0.882 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-24 04:04:56] iteration     2300/  500000 | consumed samples:       147200 | elapsed time per iteration (ms): 619.9 | learning rate: 1.070156E-04 | global batch size:    64 | lm loss: 5.303557E+00 | loss scale: 524288.0 | grad norm: 1.563 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 04:05:58] iteration     2400/  500000 | consumed samples:       153600 | elapsed time per iteration (ms): 620.0 | learning rate: 1.117031E-04 | global batch size:    64 | lm loss: 5.238051E+00 | loss scale: 524288.0 | grad norm: 0.831 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 04:07:00] iteration     2500/  500000 | consumed samples:       160000 | elapsed time per iteration (ms): 621.5 | learning rate: 1.163437E-04 | global batch size:    64 | lm loss: 5.155461E+00 | loss scale: 262144.0 | grad norm: 0.954 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-24 04:08:02] iteration     2600/  500000 | consumed samples:       166400 | elapsed time per iteration (ms): 621.5 | learning rate: 1.210312E-04 | global batch size:    64 | lm loss: 5.093358E+00 | loss scale: 262144.0 | grad norm: 0.938 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 04:09:04] iteration     2700/  500000 | consumed samples:       172800 | elapsed time per iteration (ms): 620.1 | learning rate: 1.257187E-04 | global batch size:    64 | lm loss: 5.032516E+00 | loss scale: 262144.0 | grad norm: 0.847 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 04:10:06] iteration     2800/  500000 | consumed samples:       179200 | elapsed time per iteration (ms): 618.3 | learning rate: 1.304062E-04 | global batch size:    64 | lm loss: 4.962145E+00 | loss scale: 262144.0 | grad norm: 0.855 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 04:11:08] iteration     2900/  500000 | consumed samples:       185600 | elapsed time per iteration (ms): 619.5 | learning rate: 1.350937E-04 | global batch size:    64 | lm loss: 4.897830E+00 | loss scale: 262144.0 | grad norm: 0.846 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 04:12:10] iteration     3000/  500000 | consumed samples:       192000 | elapsed time per iteration (ms): 619.5 | learning rate: 1.397812E-04 | global batch size:    64 | lm loss: 4.865759E+00 | loss scale: 262144.0 | grad norm: 0.866 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2462.64, 2462.70)
------------------------------------------------------------------------------------------------
 validation loss at iteration 3000 | lm loss value: 4.821876E+00 | lm loss PPL: 1.241979E+02 | 
------------------------------------------------------------------------------------------------
 [2024-06-24 04:13:14] iteration     3100/  500000 | consumed samples:       198400 | elapsed time per iteration (ms): 622.7 | learning rate: 1.444687E-04 | global batch size:    64 | lm loss: 4.819268E+00 | loss scale: 262144.0 | grad norm: 0.785 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 04:14:16] iteration     3200/  500000 | consumed samples:       204800 | elapsed time per iteration (ms): 619.6 | learning rate: 1.491562E-04 | global batch size:    64 | lm loss: 4.751300E+00 | loss scale: 262144.0 | grad norm: 0.720 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 04:15:19] iteration     3300/  500000 | consumed samples:       211200 | elapsed time per iteration (ms): 621.5 | learning rate: 1.500000E-04 | global batch size:    64 | lm loss: 4.728753E+00 | loss scale: 262144.0 | grad norm: 0.767 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 04:16:20] iteration     3400/  500000 | consumed samples:       217600 | elapsed time per iteration (ms): 618.5 | learning rate: 1.499999E-04 | global batch size:    64 | lm loss: 4.689355E+00 | loss scale: 262144.0 | grad norm: 0.738 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 04:17:22] iteration     3500/  500000 | consumed samples:       224000 | elapsed time per iteration (ms): 620.2 | learning rate: 1.499997E-04 | global batch size:    64 | lm loss: 4.647142E+00 | loss scale: 524288.0 | grad norm: 0.658 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 04:18:24] iteration     3600/  500000 | consumed samples:       230400 | elapsed time per iteration (ms): 620.7 | learning rate: 1.499995E-04 | global batch size:    64 | lm loss: 4.615738E+00 | loss scale: 524288.0 | grad norm: 0.658 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 04:19:26] iteration     3700/  500000 | consumed samples:       236800 | elapsed time per iteration (ms): 620.5 | learning rate: 1.499992E-04 | global batch size:    64 | lm loss: 4.581727E+00 | loss scale: 524288.0 | grad norm: 0.665 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-24 04:20:28] iteration     3800/  500000 | consumed samples:       243200 | elapsed time per iteration (ms): 619.4 | learning rate: 1.499988E-04 | global batch size:    64 | lm loss: 4.560628E+00 | loss scale: 524288.0 | grad norm: 0.703 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 04:21:30] iteration     3900/  500000 | consumed samples:       249600 | elapsed time per iteration (ms): 619.5 | learning rate: 1.499984E-04 | global batch size:    64 | lm loss: 4.519672E+00 | loss scale: 262144.0 | grad norm: 0.786 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-24 04:22:32] iteration     4000/  500000 | consumed samples:       256000 | elapsed time per iteration (ms): 620.4 | learning rate: 1.499979E-04 | global batch size:    64 | lm loss: 4.514915E+00 | loss scale: 262144.0 | grad norm: 0.613 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2463.19, 2463.26)
------------------------------------------------------------------------------------------------
 validation loss at iteration 4000 | lm loss value: 4.497440E+00 | lm loss PPL: 8.978701E+01 | 
------------------------------------------------------------------------------------------------
 [2024-06-24 04:23:37] iteration     4100/  500000 | consumed samples:       262400 | elapsed time per iteration (ms): 620.2 | learning rate: 1.499973E-04 | global batch size:    64 | lm loss: 4.500928E+00 | loss scale: 262144.0 | grad norm: 0.689 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 04:24:39] iteration     4200/  500000 | consumed samples:       268800 | elapsed time per iteration (ms): 620.4 | learning rate: 1.499967E-04 | global batch size:    64 | lm loss: 4.476141E+00 | loss scale: 262144.0 | grad norm: 0.628 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 04:25:41] iteration     4300/  500000 | consumed samples:       275200 | elapsed time per iteration (ms): 619.9 | learning rate: 1.499960E-04 | global batch size:    64 | lm loss: 4.438718E+00 | loss scale: 262144.0 | grad norm: 0.598 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 04:26:43] iteration     4400/  500000 | consumed samples:       281600 | elapsed time per iteration (ms): 619.2 | learning rate: 1.499952E-04 | global batch size:    64 | lm loss: 4.411100E+00 | loss scale: 262144.0 | grad norm: 0.634 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 04:27:45] iteration     4500/  500000 | consumed samples:       288000 | elapsed time per iteration (ms): 618.8 | learning rate: 1.499944E-04 | global batch size:    64 | lm loss: 4.382272E+00 | loss scale: 262144.0 | grad norm: 0.571 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 04:28:47] iteration     4600/  500000 | consumed samples:       294400 | elapsed time per iteration (ms): 618.4 | learning rate: 1.499934E-04 | global batch size:    64 | lm loss: 4.380196E+00 | loss scale: 262144.0 | grad norm: 0.578 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 04:29:49] iteration     4700/  500000 | consumed samples:       300800 | elapsed time per iteration (ms): 620.6 | learning rate: 1.499925E-04 | global batch size:    64 | lm loss: 4.361300E+00 | loss scale: 262144.0 | grad norm: 0.568 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 04:30:51] iteration     4800/  500000 | consumed samples:       307200 | elapsed time per iteration (ms): 619.6 | learning rate: 1.499914E-04 | global batch size:    64 | lm loss: 4.345904E+00 | loss scale: 262144.0 | grad norm: 0.558 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 04:31:53] iteration     4900/  500000 | consumed samples:       313600 | elapsed time per iteration (ms): 621.8 | learning rate: 1.499903E-04 | global batch size:    64 | lm loss: 4.328424E+00 | loss scale: 524288.0 | grad norm: 0.582 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 04:32:55] iteration     5000/  500000 | consumed samples:       320000 | elapsed time per iteration (ms): 620.9 | learning rate: 1.499891E-04 | global batch size:    64 | lm loss: 4.321538E+00 | loss scale: 262144.0 | grad norm: 0.581 | number of skipped iterations:   2 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2461.79, 2462.03)
------------------------------------------------------------------------------------------------
 validation loss at iteration 5000 | lm loss value: 4.336661E+00 | lm loss PPL: 7.645183E+01 | 
------------------------------------------------------------------------------------------------
 [2024-06-24 04:33:59] iteration     5100/  500000 | consumed samples:       326400 | elapsed time per iteration (ms): 618.0 | learning rate: 1.499879E-04 | global batch size:    64 | lm loss: 4.314051E+00 | loss scale: 262144.0 | grad norm: 0.539 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 04:35:01] iteration     5200/  500000 | consumed samples:       332800 | elapsed time per iteration (ms): 619.9 | learning rate: 1.499865E-04 | global batch size:    64 | lm loss: 4.307270E+00 | loss scale: 262144.0 | grad norm: 0.615 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 04:36:03] iteration     5300/  500000 | consumed samples:       339200 | elapsed time per iteration (ms): 621.6 | learning rate: 1.499851E-04 | global batch size:    64 | lm loss: 4.267147E+00 | loss scale: 262144.0 | grad norm: 0.571 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 04:37:05] iteration     5400/  500000 | consumed samples:       345600 | elapsed time per iteration (ms): 621.5 | learning rate: 1.499837E-04 | global batch size:    64 | lm loss: 4.262789E+00 | loss scale: 262144.0 | grad norm: 0.579 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 04:38:07] iteration     5500/  500000 | consumed samples:       352000 | elapsed time per iteration (ms): 619.6 | learning rate: 1.499822E-04 | global batch size:    64 | lm loss: 4.253978E+00 | loss scale: 131072.0 | grad norm: 1.864 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-24 04:39:09] iteration     5600/  500000 | consumed samples:       358400 | elapsed time per iteration (ms): 618.7 | learning rate: 1.499806E-04 | global batch size:    64 | lm loss: 4.241721E+00 | loss scale: 131072.0 | grad norm: 0.546 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 04:40:11] iteration     5700/  500000 | consumed samples:       364800 | elapsed time per iteration (ms): 621.9 | learning rate: 1.499789E-04 | global batch size:    64 | lm loss: 4.227987E+00 | loss scale: 131072.0 | grad norm: 0.573 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 04:41:13] iteration     5800/  500000 | consumed samples:       371200 | elapsed time per iteration (ms): 618.4 | learning rate: 1.499771E-04 | global batch size:    64 | lm loss: 4.221840E+00 | loss scale: 131072.0 | grad norm: 0.546 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 04:42:15] iteration     5900/  500000 | consumed samples:       377600 | elapsed time per iteration (ms): 618.4 | learning rate: 1.499753E-04 | global batch size:    64 | lm loss: 4.201751E+00 | loss scale: 131072.0 | grad norm: 0.560 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 04:43:17] iteration     6000/  500000 | consumed samples:       384000 | elapsed time per iteration (ms): 620.3 | learning rate: 1.499735E-04 | global batch size:    64 | lm loss: 4.205803E+00 | loss scale: 131072.0 | grad norm: 0.583 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2462.86, 2462.87)
------------------------------------------------------------------------------------------------
 validation loss at iteration 6000 | lm loss value: 4.229220E+00 | lm loss PPL: 6.866365E+01 | 
------------------------------------------------------------------------------------------------
 [2024-06-24 04:44:21] iteration     6100/  500000 | consumed samples:       390400 | elapsed time per iteration (ms): 616.9 | learning rate: 1.499715E-04 | global batch size:    64 | lm loss: 4.187653E+00 | loss scale: 131072.0 | grad norm: 0.568 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 04:45:23] iteration     6200/  500000 | consumed samples:       396800 | elapsed time per iteration (ms): 618.9 | learning rate: 1.499695E-04 | global batch size:    64 | lm loss: 4.182967E+00 | loss scale: 131072.0 | grad norm: 0.523 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 04:46:25] iteration     6300/  500000 | consumed samples:       403200 | elapsed time per iteration (ms): 619.6 | learning rate: 1.499674E-04 | global batch size:    64 | lm loss: 4.178764E+00 | loss scale: 131072.0 | grad norm: 0.557 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 04:47:27] iteration     6400/  500000 | consumed samples:       409600 | elapsed time per iteration (ms): 618.6 | learning rate: 1.499653E-04 | global batch size:    64 | lm loss: 4.165695E+00 | loss scale: 131072.0 | grad norm: 0.520 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 04:48:29] iteration     6500/  500000 | consumed samples:       416000 | elapsed time per iteration (ms): 619.9 | learning rate: 1.499630E-04 | global batch size:    64 | lm loss: 4.158712E+00 | loss scale: 262144.0 | grad norm: 0.560 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 04:49:31] iteration     6600/  500000 | consumed samples:       422400 | elapsed time per iteration (ms): 619.8 | learning rate: 1.499608E-04 | global batch size:    64 | lm loss: 4.151262E+00 | loss scale: 262144.0 | grad norm: 0.515 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 04:50:33] iteration     6700/  500000 | consumed samples:       428800 | elapsed time per iteration (ms): 618.7 | learning rate: 1.499584E-04 | global batch size:    64 | lm loss: 4.136761E+00 | loss scale: 262144.0 | grad norm: 0.519 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 04:51:35] iteration     6800/  500000 | consumed samples:       435200 | elapsed time per iteration (ms): 618.1 | learning rate: 1.499560E-04 | global batch size:    64 | lm loss: 4.126097E+00 | loss scale: 262144.0 | grad norm: 0.495 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 04:52:37] iteration     6900/  500000 | consumed samples:       441600 | elapsed time per iteration (ms): 619.3 | learning rate: 1.499535E-04 | global batch size:    64 | lm loss: 4.105219E+00 | loss scale: 262144.0 | grad norm: 0.536 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 04:53:39] iteration     7000/  500000 | consumed samples:       448000 | elapsed time per iteration (ms): 619.3 | learning rate: 1.499509E-04 | global batch size:    64 | lm loss: 4.110244E+00 | loss scale: 262144.0 | grad norm: 0.476 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2466.10, 2466.16)
------------------------------------------------------------------------------------------------
 validation loss at iteration 7000 | lm loss value: 4.171340E+00 | lm loss PPL: 6.480226E+01 | 
------------------------------------------------------------------------------------------------
 [2024-06-24 04:54:43] iteration     7100/  500000 | consumed samples:       454400 | elapsed time per iteration (ms): 619.5 | learning rate: 1.499483E-04 | global batch size:    64 | lm loss: 4.095023E+00 | loss scale: 262144.0 | grad norm: 0.526 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 04:55:45] iteration     7200/  500000 | consumed samples:       460800 | elapsed time per iteration (ms): 620.6 | learning rate: 1.499456E-04 | global batch size:    64 | lm loss: 4.093892E+00 | loss scale: 262144.0 | grad norm: 0.501 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 04:56:47] iteration     7300/  500000 | consumed samples:       467200 | elapsed time per iteration (ms): 619.3 | learning rate: 1.499428E-04 | global batch size:    64 | lm loss: 4.073100E+00 | loss scale: 262144.0 | grad norm: 0.498 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 04:57:49] iteration     7400/  500000 | consumed samples:       473600 | elapsed time per iteration (ms): 618.1 | learning rate: 1.499400E-04 | global batch size:    64 | lm loss: 4.068763E+00 | loss scale: 262144.0 | grad norm: 0.522 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 04:58:51] iteration     7500/  500000 | consumed samples:       480000 | elapsed time per iteration (ms): 618.1 | learning rate: 1.499371E-04 | global batch size:    64 | lm loss: 4.085768E+00 | loss scale: 262144.0 | grad norm: 0.489 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-24 04:59:52] iteration     7600/  500000 | consumed samples:       486400 | elapsed time per iteration (ms): 618.7 | learning rate: 1.499341E-04 | global batch size:    64 | lm loss: 4.046864E+00 | loss scale: 262144.0 | grad norm: 0.506 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 05:00:54] iteration     7700/  500000 | consumed samples:       492800 | elapsed time per iteration (ms): 619.7 | learning rate: 1.499311E-04 | global batch size:    64 | lm loss: 4.040305E+00 | loss scale: 262144.0 | grad norm: 0.506 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 05:01:56] iteration     7800/  500000 | consumed samples:       499200 | elapsed time per iteration (ms): 618.6 | learning rate: 1.499280E-04 | global batch size:    64 | lm loss: 4.047677E+00 | loss scale: 262144.0 | grad norm: 0.513 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 05:02:58] iteration     7900/  500000 | consumed samples:       505600 | elapsed time per iteration (ms): 620.2 | learning rate: 1.499248E-04 | global batch size:    64 | lm loss: 4.023401E+00 | loss scale: 262144.0 | grad norm: 0.486 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 05:04:00] iteration     8000/  500000 | consumed samples:       512000 | elapsed time per iteration (ms): 618.0 | learning rate: 1.499215E-04 | global batch size:    64 | lm loss: 4.044982E+00 | loss scale: 262144.0 | grad norm: 0.496 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2463.69, 2464.31)
------------------------------------------------------------------------------------------------
 validation loss at iteration 8000 | lm loss value: 4.094097E+00 | lm loss PPL: 5.998513E+01 | 
------------------------------------------------------------------------------------------------
 [2024-06-24 05:05:04] iteration     8100/  500000 | consumed samples:       518400 | elapsed time per iteration (ms): 619.0 | learning rate: 1.499182E-04 | global batch size:    64 | lm loss: 4.027440E+00 | loss scale: 262144.0 | grad norm: 0.483 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 05:06:06] iteration     8200/  500000 | consumed samples:       524800 | elapsed time per iteration (ms): 619.3 | learning rate: 1.499148E-04 | global batch size:    64 | lm loss: 4.024128E+00 | loss scale: 262144.0 | grad norm: 0.470 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 05:07:08] iteration     8300/  500000 | consumed samples:       531200 | elapsed time per iteration (ms): 619.7 | learning rate: 1.499114E-04 | global batch size:    64 | lm loss: 4.025295E+00 | loss scale: 262144.0 | grad norm: 0.507 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 05:08:10] iteration     8400/  500000 | consumed samples:       537600 | elapsed time per iteration (ms): 620.1 | learning rate: 1.499078E-04 | global batch size:    64 | lm loss: 4.012750E+00 | loss scale: 262144.0 | grad norm: 0.474 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 05:09:12] iteration     8500/  500000 | consumed samples:       544000 | elapsed time per iteration (ms): 619.6 | learning rate: 1.499042E-04 | global batch size:    64 | lm loss: 3.995869E+00 | loss scale: 524288.0 | grad norm: 0.464 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 05:10:14] iteration     8600/  500000 | consumed samples:       550400 | elapsed time per iteration (ms): 619.9 | learning rate: 1.499006E-04 | global batch size:    64 | lm loss: 3.988057E+00 | loss scale: 524288.0 | grad norm: 0.473 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 05:11:16] iteration     8700/  500000 | consumed samples:       556800 | elapsed time per iteration (ms): 617.3 | learning rate: 1.498969E-04 | global batch size:    64 | lm loss: 4.000978E+00 | loss scale: 524288.0 | grad norm: 0.469 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 05:12:18] iteration     8800/  500000 | consumed samples:       563200 | elapsed time per iteration (ms): 620.7 | learning rate: 1.498931E-04 | global batch size:    64 | lm loss: 3.987967E+00 | loss scale: 524288.0 | grad norm: 0.467 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 05:13:20] iteration     8900/  500000 | consumed samples:       569600 | elapsed time per iteration (ms): 617.3 | learning rate: 1.498892E-04 | global batch size:    64 | lm loss: 3.981055E+00 | loss scale: 524288.0 | grad norm: 0.467 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 05:14:22] iteration     9000/  500000 | consumed samples:       576000 | elapsed time per iteration (ms): 619.5 | learning rate: 1.498852E-04 | global batch size:    64 | lm loss: 3.968641E+00 | loss scale: 524288.0 | grad norm: 0.489 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2463.63, 2463.70)
------------------------------------------------------------------------------------------------
 validation loss at iteration 9000 | lm loss value: 4.024293E+00 | lm loss PPL: 5.594074E+01 | 
------------------------------------------------------------------------------------------------
 [2024-06-24 05:15:26] iteration     9100/  500000 | consumed samples:       582400 | elapsed time per iteration (ms): 619.8 | learning rate: 1.498812E-04 | global batch size:    64 | lm loss: 3.970355E+00 | loss scale: 524288.0 | grad norm: 0.468 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 05:16:28] iteration     9200/  500000 | consumed samples:       588800 | elapsed time per iteration (ms): 620.1 | learning rate: 1.498772E-04 | global batch size:    64 | lm loss: 3.962033E+00 | loss scale: 524288.0 | grad norm: 0.507 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 05:17:30] iteration     9300/  500000 | consumed samples:       595200 | elapsed time per iteration (ms): 620.5 | learning rate: 1.498730E-04 | global batch size:    64 | lm loss: 3.975399E+00 | loss scale: 524288.0 | grad norm: 0.479 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 05:18:32] iteration     9400/  500000 | consumed samples:       601600 | elapsed time per iteration (ms): 619.0 | learning rate: 1.498688E-04 | global batch size:    64 | lm loss: 3.951188E+00 | loss scale: 524288.0 | grad norm: 0.464 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 05:19:34] iteration     9500/  500000 | consumed samples:       608000 | elapsed time per iteration (ms): 620.7 | learning rate: 1.498646E-04 | global batch size:    64 | lm loss: 3.953452E+00 | loss scale: 1048576.0 | grad norm: 0.471 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-24 05:20:36] iteration     9600/  500000 | consumed samples:       614400 | elapsed time per iteration (ms): 619.8 | learning rate: 1.498602E-04 | global batch size:    64 | lm loss: 3.931212E+00 | loss scale: 1048576.0 | grad norm: 0.475 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 05:21:38] iteration     9700/  500000 | consumed samples:       620800 | elapsed time per iteration (ms): 618.2 | learning rate: 1.498558E-04 | global batch size:    64 | lm loss: 3.930895E+00 | loss scale: 524288.0 | grad norm: 0.470 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-24 05:22:40] iteration     9800/  500000 | consumed samples:       627200 | elapsed time per iteration (ms): 618.3 | learning rate: 1.498513E-04 | global batch size:    64 | lm loss: 3.931153E+00 | loss scale: 524288.0 | grad norm: 0.454 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 05:23:42] iteration     9900/  500000 | consumed samples:       633600 | elapsed time per iteration (ms): 619.5 | learning rate: 1.498468E-04 | global batch size:    64 | lm loss: 3.919875E+00 | loss scale: 524288.0 | grad norm: 0.456 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 05:24:44] iteration    10000/  500000 | consumed samples:       640000 | elapsed time per iteration (ms): 620.3 | learning rate: 1.498422E-04 | global batch size:    64 | lm loss: 3.922446E+00 | loss scale: 524288.0 | grad norm: 0.444 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2463.17, 2463.43)
-------------------------------------------------------------------------------------------------
 validation loss at iteration 10000 | lm loss value: 4.024572E+00 | lm loss PPL: 5.595635E+01 | 
-------------------------------------------------------------------------------------------------
saving checkpoint at iteration   10000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-distribution in torch format
  successfully saved checkpoint at iteration   10000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-distribution
(min, max) time across ranks (ms):
    save-checkpoint ................................: (2245.23, 2245.23)
 [2024-06-24 05:25:50] iteration    10100/  500000 | consumed samples:       646400 | elapsed time per iteration (ms): 616.8 | learning rate: 1.498375E-04 | global batch size:    64 | lm loss: 3.922714E+00 | loss scale: 524288.0 | grad norm: 0.435 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 05:26:52] iteration    10200/  500000 | consumed samples:       652800 | elapsed time per iteration (ms): 620.3 | learning rate: 1.498327E-04 | global batch size:    64 | lm loss: 3.906166E+00 | loss scale: 524288.0 | grad norm: 0.461 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 05:27:54] iteration    10300/  500000 | consumed samples:       659200 | elapsed time per iteration (ms): 619.0 | learning rate: 1.498279E-04 | global batch size:    64 | lm loss: 3.912113E+00 | loss scale: 524288.0 | grad norm: 0.462 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 05:28:56] iteration    10400/  500000 | consumed samples:       665600 | elapsed time per iteration (ms): 618.4 | learning rate: 1.498230E-04 | global batch size:    64 | lm loss: 3.906402E+00 | loss scale: 524288.0 | grad norm: 0.444 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 05:29:58] iteration    10500/  500000 | consumed samples:       672000 | elapsed time per iteration (ms): 619.4 | learning rate: 1.498180E-04 | global batch size:    64 | lm loss: 3.897081E+00 | loss scale: 524288.0 | grad norm: 0.446 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 05:31:00] iteration    10600/  500000 | consumed samples:       678400 | elapsed time per iteration (ms): 619.7 | learning rate: 1.498130E-04 | global batch size:    64 | lm loss: 3.904094E+00 | loss scale: 524288.0 | grad norm: 0.455 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 05:32:02] iteration    10700/  500000 | consumed samples:       684800 | elapsed time per iteration (ms): 617.7 | learning rate: 1.498080E-04 | global batch size:    64 | lm loss: 3.897694E+00 | loss scale: 131072.0 | grad norm: 0.461 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-24 05:33:04] iteration    10800/  500000 | consumed samples:       691200 | elapsed time per iteration (ms): 618.5 | learning rate: 1.498028E-04 | global batch size:    64 | lm loss: 3.887893E+00 | loss scale: 131072.0 | grad norm: 0.440 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 05:34:06] iteration    10900/  500000 | consumed samples:       697600 | elapsed time per iteration (ms): 620.6 | learning rate: 1.497976E-04 | global batch size:    64 | lm loss: 3.901095E+00 | loss scale: 131072.0 | grad norm: 0.448 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 05:35:08] iteration    11000/  500000 | consumed samples:       704000 | elapsed time per iteration (ms): 620.0 | learning rate: 1.497923E-04 | global batch size:    64 | lm loss: 3.874860E+00 | loss scale: 131072.0 | grad norm: 0.466 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2463.08, 2463.13)
-------------------------------------------------------------------------------------------------
 validation loss at iteration 11000 | lm loss value: 3.923682E+00 | lm loss PPL: 5.058638E+01 | 
-------------------------------------------------------------------------------------------------
 [2024-06-24 05:36:12] iteration    11100/  500000 | consumed samples:       710400 | elapsed time per iteration (ms): 616.6 | learning rate: 1.497869E-04 | global batch size:    64 | lm loss: 3.890690E+00 | loss scale: 131072.0 | grad norm: 0.475 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 05:37:14] iteration    11200/  500000 | consumed samples:       716800 | elapsed time per iteration (ms): 621.4 | learning rate: 1.497814E-04 | global batch size:    64 | lm loss: 3.884563E+00 | loss scale: 131072.0 | grad norm: 0.442 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 05:38:16] iteration    11300/  500000 | consumed samples:       723200 | elapsed time per iteration (ms): 620.1 | learning rate: 1.497759E-04 | global batch size:    64 | lm loss: 3.877013E+00 | loss scale: 131072.0 | grad norm: 0.461 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 05:39:18] iteration    11400/  500000 | consumed samples:       729600 | elapsed time per iteration (ms): 620.4 | learning rate: 1.497704E-04 | global batch size:    64 | lm loss: 3.883149E+00 | loss scale: 65536.0 | grad norm: 0.439 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-24 05:40:20] iteration    11500/  500000 | consumed samples:       736000 | elapsed time per iteration (ms): 618.4 | learning rate: 1.497648E-04 | global batch size:    64 | lm loss: 3.870662E+00 | loss scale: 16384.0 | grad norm: 0.439 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-24 05:41:22] iteration    11600/  500000 | consumed samples:       742400 | elapsed time per iteration (ms): 619.2 | learning rate: 1.497591E-04 | global batch size:    64 | lm loss: 3.861969E+00 | loss scale: 16384.0 | grad norm: 0.460 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 05:42:24] iteration    11700/  500000 | consumed samples:       748800 | elapsed time per iteration (ms): 620.9 | learning rate: 1.497533E-04 | global batch size:    64 | lm loss: 3.864969E+00 | loss scale: 16384.0 | grad norm: 0.435 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 05:43:26] iteration    11800/  500000 | consumed samples:       755200 | elapsed time per iteration (ms): 618.0 | learning rate: 1.497475E-04 | global batch size:    64 | lm loss: 3.876833E+00 | loss scale: 16384.0 | grad norm: 0.443 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 05:44:28] iteration    11900/  500000 | consumed samples:       761600 | elapsed time per iteration (ms): 619.6 | learning rate: 1.497416E-04 | global batch size:    64 | lm loss: 3.843987E+00 | loss scale: 16384.0 | grad norm: 0.452 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 05:45:29] iteration    12000/  500000 | consumed samples:       768000 | elapsed time per iteration (ms): 619.4 | learning rate: 1.497356E-04 | global batch size:    64 | lm loss: 3.856032E+00 | loss scale: 16384.0 | grad norm: 0.444 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2463.56, 2463.78)
-------------------------------------------------------------------------------------------------
 validation loss at iteration 12000 | lm loss value: 3.953235E+00 | lm loss PPL: 5.210365E+01 | 
-------------------------------------------------------------------------------------------------
 [2024-06-24 05:46:34] iteration    12100/  500000 | consumed samples:       774400 | elapsed time per iteration (ms): 620.0 | learning rate: 1.497295E-04 | global batch size:    64 | lm loss: 3.839918E+00 | loss scale: 16384.0 | grad norm: 0.453 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 05:47:36] iteration    12200/  500000 | consumed samples:       780800 | elapsed time per iteration (ms): 622.0 | learning rate: 1.497234E-04 | global batch size:    64 | lm loss: 3.835770E+00 | loss scale: 16384.0 | grad norm: 0.436 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 05:48:38] iteration    12300/  500000 | consumed samples:       787200 | elapsed time per iteration (ms): 619.0 | learning rate: 1.497172E-04 | global batch size:    64 | lm loss: 3.838079E+00 | loss scale: 16384.0 | grad norm: 0.432 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 05:49:40] iteration    12400/  500000 | consumed samples:       793600 | elapsed time per iteration (ms): 618.2 | learning rate: 1.497109E-04 | global batch size:    64 | lm loss: 3.838022E+00 | loss scale: 16384.0 | grad norm: 0.434 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 05:50:42] iteration    12500/  500000 | consumed samples:       800000 | elapsed time per iteration (ms): 621.2 | learning rate: 1.497046E-04 | global batch size:    64 | lm loss: 3.827526E+00 | loss scale: 32768.0 | grad norm: 0.433 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 05:51:44] iteration    12600/  500000 | consumed samples:       806400 | elapsed time per iteration (ms): 619.3 | learning rate: 1.496982E-04 | global batch size:    64 | lm loss: 3.826988E+00 | loss scale: 32768.0 | grad norm: 0.425 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 05:52:46] iteration    12700/  500000 | consumed samples:       812800 | elapsed time per iteration (ms): 616.7 | learning rate: 1.496917E-04 | global batch size:    64 | lm loss: 3.827928E+00 | loss scale: 32768.0 | grad norm: 0.438 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 05:53:48] iteration    12800/  500000 | consumed samples:       819200 | elapsed time per iteration (ms): 619.2 | learning rate: 1.496851E-04 | global batch size:    64 | lm loss: 3.826278E+00 | loss scale: 32768.0 | grad norm: 0.456 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 05:54:49] iteration    12900/  500000 | consumed samples:       825600 | elapsed time per iteration (ms): 619.0 | learning rate: 1.496785E-04 | global batch size:    64 | lm loss: 3.800697E+00 | loss scale: 32768.0 | grad norm: 0.428 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 05:55:51] iteration    13000/  500000 | consumed samples:       832000 | elapsed time per iteration (ms): 618.7 | learning rate: 1.496719E-04 | global batch size:    64 | lm loss: 3.825589E+00 | loss scale: 32768.0 | grad norm: 0.430 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2464.44, 2464.45)
-------------------------------------------------------------------------------------------------
 validation loss at iteration 13000 | lm loss value: 3.912379E+00 | lm loss PPL: 5.001780E+01 | 
-------------------------------------------------------------------------------------------------
 [2024-06-24 05:56:56] iteration    13100/  500000 | consumed samples:       838400 | elapsed time per iteration (ms): 618.7 | learning rate: 1.496651E-04 | global batch size:    64 | lm loss: 3.812159E+00 | loss scale: 32768.0 | grad norm: 0.426 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 05:57:58] iteration    13200/  500000 | consumed samples:       844800 | elapsed time per iteration (ms): 619.5 | learning rate: 1.496583E-04 | global batch size:    64 | lm loss: 3.803469E+00 | loss scale: 32768.0 | grad norm: 0.417 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 05:59:00] iteration    13300/  500000 | consumed samples:       851200 | elapsed time per iteration (ms): 620.9 | learning rate: 1.496514E-04 | global batch size:    64 | lm loss: 3.795317E+00 | loss scale: 32768.0 | grad norm: 0.435 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 06:00:01] iteration    13400/  500000 | consumed samples:       857600 | elapsed time per iteration (ms): 618.0 | learning rate: 1.496445E-04 | global batch size:    64 | lm loss: 3.788752E+00 | loss scale: 32768.0 | grad norm: 0.442 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 06:01:03] iteration    13500/  500000 | consumed samples:       864000 | elapsed time per iteration (ms): 619.1 | learning rate: 1.496374E-04 | global batch size:    64 | lm loss: 3.789951E+00 | loss scale: 65536.0 | grad norm: 0.433 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 06:02:05] iteration    13600/  500000 | consumed samples:       870400 | elapsed time per iteration (ms): 619.0 | learning rate: 1.496303E-04 | global batch size:    64 | lm loss: 3.796043E+00 | loss scale: 65536.0 | grad norm: 0.443 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 06:03:07] iteration    13700/  500000 | consumed samples:       876800 | elapsed time per iteration (ms): 619.4 | learning rate: 1.496232E-04 | global batch size:    64 | lm loss: 3.797480E+00 | loss scale: 65536.0 | grad norm: 0.416 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 06:04:09] iteration    13800/  500000 | consumed samples:       883200 | elapsed time per iteration (ms): 621.7 | learning rate: 1.496160E-04 | global batch size:    64 | lm loss: 3.792424E+00 | loss scale: 65536.0 | grad norm: 0.424 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 06:05:11] iteration    13900/  500000 | consumed samples:       889600 | elapsed time per iteration (ms): 619.8 | learning rate: 1.496087E-04 | global batch size:    64 | lm loss: 3.803120E+00 | loss scale: 65536.0 | grad norm: 0.812 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 06:06:13] iteration    14000/  500000 | consumed samples:       896000 | elapsed time per iteration (ms): 619.2 | learning rate: 1.496013E-04 | global batch size:    64 | lm loss: 3.789776E+00 | loss scale: 65536.0 | grad norm: 0.426 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2464.79, 2464.84)
-------------------------------------------------------------------------------------------------
 validation loss at iteration 14000 | lm loss value: 3.896695E+00 | lm loss PPL: 4.923944E+01 | 
-------------------------------------------------------------------------------------------------
 [2024-06-24 06:07:18] iteration    14100/  500000 | consumed samples:       902400 | elapsed time per iteration (ms): 619.5 | learning rate: 1.495939E-04 | global batch size:    64 | lm loss: 3.787048E+00 | loss scale: 65536.0 | grad norm: 0.421 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 06:08:20] iteration    14200/  500000 | consumed samples:       908800 | elapsed time per iteration (ms): 620.8 | learning rate: 1.495864E-04 | global batch size:    64 | lm loss: 3.763009E+00 | loss scale: 65536.0 | grad norm: 0.434 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 06:09:22] iteration    14300/  500000 | consumed samples:       915200 | elapsed time per iteration (ms): 621.4 | learning rate: 1.495788E-04 | global batch size:    64 | lm loss: 3.778280E+00 | loss scale: 65536.0 | grad norm: 0.424 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 06:10:24] iteration    14400/  500000 | consumed samples:       921600 | elapsed time per iteration (ms): 620.3 | learning rate: 1.495712E-04 | global batch size:    64 | lm loss: 3.773398E+00 | loss scale: 65536.0 | grad norm: 0.522 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 06:11:26] iteration    14500/  500000 | consumed samples:       928000 | elapsed time per iteration (ms): 617.3 | learning rate: 1.495634E-04 | global batch size:    64 | lm loss: 3.772501E+00 | loss scale: 131072.0 | grad norm: 0.423 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 06:12:28] iteration    14600/  500000 | consumed samples:       934400 | elapsed time per iteration (ms): 619.2 | learning rate: 1.495557E-04 | global batch size:    64 | lm loss: 3.765585E+00 | loss scale: 131072.0 | grad norm: 0.417 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 06:13:30] iteration    14700/  500000 | consumed samples:       940800 | elapsed time per iteration (ms): 619.1 | learning rate: 1.495478E-04 | global batch size:    64 | lm loss: 3.772775E+00 | loss scale: 131072.0 | grad norm: 0.436 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 06:14:32] iteration    14800/  500000 | consumed samples:       947200 | elapsed time per iteration (ms): 620.0 | learning rate: 1.495399E-04 | global batch size:    64 | lm loss: 3.760121E+00 | loss scale: 131072.0 | grad norm: 0.438 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 06:15:33] iteration    14900/  500000 | consumed samples:       953600 | elapsed time per iteration (ms): 619.6 | learning rate: 1.495319E-04 | global batch size:    64 | lm loss: 3.751893E+00 | loss scale: 131072.0 | grad norm: 0.412 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 06:16:35] iteration    15000/  500000 | consumed samples:       960000 | elapsed time per iteration (ms): 617.4 | learning rate: 1.495239E-04 | global batch size:    64 | lm loss: 3.751236E+00 | loss scale: 131072.0 | grad norm: 0.417 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2462.23, 2462.35)
-------------------------------------------------------------------------------------------------
 validation loss at iteration 15000 | lm loss value: 3.909597E+00 | lm loss PPL: 4.987883E+01 | 
-------------------------------------------------------------------------------------------------
 [2024-06-24 06:17:40] iteration    15100/  500000 | consumed samples:       966400 | elapsed time per iteration (ms): 619.8 | learning rate: 1.495158E-04 | global batch size:    64 | lm loss: 3.750788E+00 | loss scale: 131072.0 | grad norm: 0.438 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 06:18:42] iteration    15200/  500000 | consumed samples:       972800 | elapsed time per iteration (ms): 620.5 | learning rate: 1.495076E-04 | global batch size:    64 | lm loss: 3.740374E+00 | loss scale: 131072.0 | grad norm: 0.423 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 06:19:44] iteration    15300/  500000 | consumed samples:       979200 | elapsed time per iteration (ms): 620.7 | learning rate: 1.494993E-04 | global batch size:    64 | lm loss: 3.744810E+00 | loss scale: 131072.0 | grad norm: 0.424 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 06:20:46] iteration    15400/  500000 | consumed samples:       985600 | elapsed time per iteration (ms): 617.7 | learning rate: 1.494910E-04 | global batch size:    64 | lm loss: 3.742200E+00 | loss scale: 131072.0 | grad norm: 0.411 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 06:21:47] iteration    15500/  500000 | consumed samples:       992000 | elapsed time per iteration (ms): 618.5 | learning rate: 1.494826E-04 | global batch size:    64 | lm loss: 3.735407E+00 | loss scale: 262144.0 | grad norm: 0.420 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 06:22:49] iteration    15600/  500000 | consumed samples:       998400 | elapsed time per iteration (ms): 619.0 | learning rate: 1.494742E-04 | global batch size:    64 | lm loss: 3.734611E+00 | loss scale: 262144.0 | grad norm: 0.434 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 06:23:51] iteration    15700/  500000 | consumed samples:      1004800 | elapsed time per iteration (ms): 619.1 | learning rate: 1.494656E-04 | global batch size:    64 | lm loss: 3.729902E+00 | loss scale: 262144.0 | grad norm: 0.418 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 06:24:53] iteration    15800/  500000 | consumed samples:      1011200 | elapsed time per iteration (ms): 620.7 | learning rate: 1.494570E-04 | global batch size:    64 | lm loss: 3.740816E+00 | loss scale: 262144.0 | grad norm: 0.406 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 06:25:55] iteration    15900/  500000 | consumed samples:      1017600 | elapsed time per iteration (ms): 621.3 | learning rate: 1.494484E-04 | global batch size:    64 | lm loss: 3.744315E+00 | loss scale: 262144.0 | grad norm: 0.417 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 06:26:57] iteration    16000/  500000 | consumed samples:      1024000 | elapsed time per iteration (ms): 618.5 | learning rate: 1.494396E-04 | global batch size:    64 | lm loss: 3.739802E+00 | loss scale: 262144.0 | grad norm: 0.407 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2464.17, 2464.24)
-------------------------------------------------------------------------------------------------
 validation loss at iteration 16000 | lm loss value: 3.840644E+00 | lm loss PPL: 4.655543E+01 | 
-------------------------------------------------------------------------------------------------
 [2024-06-24 06:28:02] iteration    16100/  500000 | consumed samples:      1030400 | elapsed time per iteration (ms): 618.2 | learning rate: 1.494308E-04 | global batch size:    64 | lm loss: 3.712108E+00 | loss scale: 262144.0 | grad norm: 0.422 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 06:29:04] iteration    16200/  500000 | consumed samples:      1036800 | elapsed time per iteration (ms): 620.7 | learning rate: 1.494220E-04 | global batch size:    64 | lm loss: 3.729245E+00 | loss scale: 262144.0 | grad norm: 0.422 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 06:30:06] iteration    16300/  500000 | consumed samples:      1043200 | elapsed time per iteration (ms): 620.8 | learning rate: 1.494130E-04 | global batch size:    64 | lm loss: 3.714333E+00 | loss scale: 262144.0 | grad norm: 0.423 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 06:31:07] iteration    16400/  500000 | consumed samples:      1049600 | elapsed time per iteration (ms): 617.6 | learning rate: 1.494040E-04 | global batch size:    64 | lm loss: 3.725972E+00 | loss scale: 262144.0 | grad norm: 0.407 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 06:32:09] iteration    16500/  500000 | consumed samples:      1056000 | elapsed time per iteration (ms): 619.7 | learning rate: 1.493950E-04 | global batch size:    64 | lm loss: 3.712525E+00 | loss scale: 524288.0 | grad norm: 0.407 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 06:33:11] iteration    16600/  500000 | consumed samples:      1062400 | elapsed time per iteration (ms): 619.6 | learning rate: 1.493858E-04 | global batch size:    64 | lm loss: 3.717813E+00 | loss scale: 524288.0 | grad norm: 0.437 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 06:34:13] iteration    16700/  500000 | consumed samples:      1068800 | elapsed time per iteration (ms): 618.9 | learning rate: 1.493766E-04 | global batch size:    64 | lm loss: 3.721132E+00 | loss scale: 524288.0 | grad norm: 0.424 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 06:35:15] iteration    16800/  500000 | consumed samples:      1075200 | elapsed time per iteration (ms): 617.0 | learning rate: 1.493673E-04 | global batch size:    64 | lm loss: 3.695381E+00 | loss scale: 524288.0 | grad norm: 0.432 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 06:36:17] iteration    16900/  500000 | consumed samples:      1081600 | elapsed time per iteration (ms): 618.7 | learning rate: 1.493580E-04 | global batch size:    64 | lm loss: 3.723278E+00 | loss scale: 524288.0 | grad norm: 0.418 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 06:37:19] iteration    17000/  500000 | consumed samples:      1088000 | elapsed time per iteration (ms): 617.5 | learning rate: 1.493486E-04 | global batch size:    64 | lm loss: 3.703542E+00 | loss scale: 524288.0 | grad norm: 0.403 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2464.18, 2464.32)
-------------------------------------------------------------------------------------------------
 validation loss at iteration 17000 | lm loss value: 3.822290E+00 | lm loss PPL: 4.570877E+01 | 
-------------------------------------------------------------------------------------------------
 [2024-06-24 06:38:23] iteration    17100/  500000 | consumed samples:      1094400 | elapsed time per iteration (ms): 621.2 | learning rate: 1.493391E-04 | global batch size:    64 | lm loss: 3.691902E+00 | loss scale: 524288.0 | grad norm: 0.419 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 06:39:25] iteration    17200/  500000 | consumed samples:      1100800 | elapsed time per iteration (ms): 620.1 | learning rate: 1.493295E-04 | global batch size:    64 | lm loss: 3.702524E+00 | loss scale: 524288.0 | grad norm: 0.418 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 06:40:27] iteration    17300/  500000 | consumed samples:      1107200 | elapsed time per iteration (ms): 620.9 | learning rate: 1.493199E-04 | global batch size:    64 | lm loss: 3.708013E+00 | loss scale: 524288.0 | grad norm: 0.410 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 06:41:29] iteration    17400/  500000 | consumed samples:      1113600 | elapsed time per iteration (ms): 617.9 | learning rate: 1.493102E-04 | global batch size:    64 | lm loss: 3.686098E+00 | loss scale: 524288.0 | grad norm: 0.414 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 06:42:31] iteration    17500/  500000 | consumed samples:      1120000 | elapsed time per iteration (ms): 620.2 | learning rate: 1.493005E-04 | global batch size:    64 | lm loss: 3.710978E+00 | loss scale: 1048576.0 | grad norm: 0.412 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 06:43:33] iteration    17600/  500000 | consumed samples:      1126400 | elapsed time per iteration (ms): 618.8 | learning rate: 1.492907E-04 | global batch size:    64 | lm loss: 3.687410E+00 | loss scale: 1048576.0 | grad norm: 0.411 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 06:44:35] iteration    17700/  500000 | consumed samples:      1132800 | elapsed time per iteration (ms): 619.0 | learning rate: 1.492808E-04 | global batch size:    64 | lm loss: 3.694703E+00 | loss scale: 1048576.0 | grad norm: 0.416 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 06:45:37] iteration    17800/  500000 | consumed samples:      1139200 | elapsed time per iteration (ms): 620.7 | learning rate: 1.492709E-04 | global batch size:    64 | lm loss: 3.697888E+00 | loss scale: 1048576.0 | grad norm: 0.427 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-24 06:46:39] iteration    17900/  500000 | consumed samples:      1145600 | elapsed time per iteration (ms): 619.0 | learning rate: 1.492609E-04 | global batch size:    64 | lm loss: 3.688952E+00 | loss scale: 1048576.0 | grad norm: 0.421 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 06:47:41] iteration    18000/  500000 | consumed samples:      1152000 | elapsed time per iteration (ms): 618.5 | learning rate: 1.492508E-04 | global batch size:    64 | lm loss: 3.680009E+00 | loss scale: 1048576.0 | grad norm: 0.443 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2463.93, 2464.07)
-------------------------------------------------------------------------------------------------
 validation loss at iteration 18000 | lm loss value: 3.829227E+00 | lm loss PPL: 4.602693E+01 | 
-------------------------------------------------------------------------------------------------
 [2024-06-24 06:48:45] iteration    18100/  500000 | consumed samples:      1158400 | elapsed time per iteration (ms): 620.2 | learning rate: 1.492406E-04 | global batch size:    64 | lm loss: 3.678862E+00 | loss scale: 1048576.0 | grad norm: 0.415 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 06:49:47] iteration    18200/  500000 | consumed samples:      1164800 | elapsed time per iteration (ms): 620.5 | learning rate: 1.492305E-04 | global batch size:    64 | lm loss: 3.688956E+00 | loss scale: 524288.0 | grad norm: 0.413 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-24 06:50:49] iteration    18300/  500000 | consumed samples:      1171200 | elapsed time per iteration (ms): 620.0 | learning rate: 1.492202E-04 | global batch size:    64 | lm loss: 3.669120E+00 | loss scale: 524288.0 | grad norm: 0.414 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 06:51:51] iteration    18400/  500000 | consumed samples:      1177600 | elapsed time per iteration (ms): 619.1 | learning rate: 1.492098E-04 | global batch size:    64 | lm loss: 3.685335E+00 | loss scale: 524288.0 | grad norm: 0.417 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 06:52:53] iteration    18500/  500000 | consumed samples:      1184000 | elapsed time per iteration (ms): 620.0 | learning rate: 1.491994E-04 | global batch size:    64 | lm loss: 3.681744E+00 | loss scale: 524288.0 | grad norm: 0.416 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 06:53:55] iteration    18600/  500000 | consumed samples:      1190400 | elapsed time per iteration (ms): 618.4 | learning rate: 1.491889E-04 | global batch size:    64 | lm loss: 3.667362E+00 | loss scale: 524288.0 | grad norm: 0.408 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 06:54:57] iteration    18700/  500000 | consumed samples:      1196800 | elapsed time per iteration (ms): 617.4 | learning rate: 1.491783E-04 | global batch size:    64 | lm loss: 3.682399E+00 | loss scale: 524288.0 | grad norm: 0.418 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 06:55:58] iteration    18800/  500000 | consumed samples:      1203200 | elapsed time per iteration (ms): 617.6 | learning rate: 1.491677E-04 | global batch size:    64 | lm loss: 3.669833E+00 | loss scale: 524288.0 | grad norm: 0.413 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 06:57:00] iteration    18900/  500000 | consumed samples:      1209600 | elapsed time per iteration (ms): 618.9 | learning rate: 1.491570E-04 | global batch size:    64 | lm loss: 3.667233E+00 | loss scale: 524288.0 | grad norm: 0.416 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 06:58:02] iteration    19000/  500000 | consumed samples:      1216000 | elapsed time per iteration (ms): 618.2 | learning rate: 1.491462E-04 | global batch size:    64 | lm loss: 3.655436E+00 | loss scale: 524288.0 | grad norm: 0.401 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2465.18, 2465.29)
-------------------------------------------------------------------------------------------------
 validation loss at iteration 19000 | lm loss value: 3.778744E+00 | lm loss PPL: 4.376106E+01 | 
-------------------------------------------------------------------------------------------------
 [2024-06-24 06:59:07] iteration    19100/  500000 | consumed samples:      1222400 | elapsed time per iteration (ms): 620.2 | learning rate: 1.491354E-04 | global batch size:    64 | lm loss: 3.665211E+00 | loss scale: 524288.0 | grad norm: 0.408 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 07:00:09] iteration    19200/  500000 | consumed samples:      1228800 | elapsed time per iteration (ms): 619.4 | learning rate: 1.491244E-04 | global batch size:    64 | lm loss: 3.653199E+00 | loss scale: 1048576.0 | grad norm: 0.390 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 07:01:11] iteration    19300/  500000 | consumed samples:      1235200 | elapsed time per iteration (ms): 619.5 | learning rate: 1.491136E-04 | global batch size:    64 | lm loss: 3.647030E+00 | loss scale: 1048576.0 | grad norm: 0.409 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-24 07:02:12] iteration    19400/  500000 | consumed samples:      1241600 | elapsed time per iteration (ms): 618.4 | learning rate: 1.491025E-04 | global batch size:    64 | lm loss: 3.649985E+00 | loss scale: 1048576.0 | grad norm: 0.395 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 07:03:14] iteration    19500/  500000 | consumed samples:      1248000 | elapsed time per iteration (ms): 619.8 | learning rate: 1.490914E-04 | global batch size:    64 | lm loss: 3.654850E+00 | loss scale: 1048576.0 | grad norm: 0.411 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 07:04:16] iteration    19600/  500000 | consumed samples:      1254400 | elapsed time per iteration (ms): 620.8 | learning rate: 1.490803E-04 | global batch size:    64 | lm loss: 3.653681E+00 | loss scale: 524288.0 | grad norm: 0.414 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-24 07:05:18] iteration    19700/  500000 | consumed samples:      1260800 | elapsed time per iteration (ms): 618.3 | learning rate: 1.490691E-04 | global batch size:    64 | lm loss: 3.650818E+00 | loss scale: 524288.0 | grad norm: 0.405 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 07:06:20] iteration    19800/  500000 | consumed samples:      1267200 | elapsed time per iteration (ms): 621.0 | learning rate: 1.490578E-04 | global batch size:    64 | lm loss: 3.649446E+00 | loss scale: 524288.0 | grad norm: 0.398 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 07:07:22] iteration    19900/  500000 | consumed samples:      1273600 | elapsed time per iteration (ms): 617.7 | learning rate: 1.490464E-04 | global batch size:    64 | lm loss: 3.635151E+00 | loss scale: 524288.0 | grad norm: 0.420 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 07:08:24] iteration    20000/  500000 | consumed samples:      1280000 | elapsed time per iteration (ms): 618.8 | learning rate: 1.490349E-04 | global batch size:    64 | lm loss: 3.631895E+00 | loss scale: 524288.0 | grad norm: 0.400 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2463.55, 2463.58)
-------------------------------------------------------------------------------------------------
 validation loss at iteration 20000 | lm loss value: 3.782274E+00 | lm loss PPL: 4.391579E+01 | 
-------------------------------------------------------------------------------------------------
saving checkpoint at iteration   20000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-distribution in torch format
  successfully saved checkpoint at iteration   20000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-distribution
(min, max) time across ranks (ms):
    save-checkpoint ................................: (2368.78, 2368.79)
 [2024-06-24 07:09:31] iteration    20100/  500000 | consumed samples:      1286400 | elapsed time per iteration (ms): 618.6 | learning rate: 1.490234E-04 | global batch size:    64 | lm loss: 3.645965E+00 | loss scale: 524288.0 | grad norm: 0.410 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 07:10:33] iteration    20200/  500000 | consumed samples:      1292800 | elapsed time per iteration (ms): 618.1 | learning rate: 1.490118E-04 | global batch size:    64 | lm loss: 3.646870E+00 | loss scale: 524288.0 | grad norm: 0.410 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 07:11:34] iteration    20300/  500000 | consumed samples:      1299200 | elapsed time per iteration (ms): 619.3 | learning rate: 1.490002E-04 | global batch size:    64 | lm loss: 3.636232E+00 | loss scale: 524288.0 | grad norm: 0.407 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 07:12:36] iteration    20400/  500000 | consumed samples:      1305600 | elapsed time per iteration (ms): 619.4 | learning rate: 1.489885E-04 | global batch size:    64 | lm loss: 3.635950E+00 | loss scale: 524288.0 | grad norm: 0.408 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 07:13:38] iteration    20500/  500000 | consumed samples:      1312000 | elapsed time per iteration (ms): 619.6 | learning rate: 1.489767E-04 | global batch size:    64 | lm loss: 3.653690E+00 | loss scale: 524288.0 | grad norm: 0.419 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 07:14:40] iteration    20600/  500000 | consumed samples:      1318400 | elapsed time per iteration (ms): 618.7 | learning rate: 1.489648E-04 | global batch size:    64 | lm loss: 3.627903E+00 | loss scale: 1048576.0 | grad norm: 0.412 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 07:15:42] iteration    20700/  500000 | consumed samples:      1324800 | elapsed time per iteration (ms): 619.3 | learning rate: 1.489529E-04 | global batch size:    64 | lm loss: 3.645932E+00 | loss scale: 1048576.0 | grad norm: 0.420 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 07:16:44] iteration    20800/  500000 | consumed samples:      1331200 | elapsed time per iteration (ms): 618.6 | learning rate: 1.489409E-04 | global batch size:    64 | lm loss: 3.635648E+00 | loss scale: 1048576.0 | grad norm: 0.392 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 07:17:46] iteration    20900/  500000 | consumed samples:      1337600 | elapsed time per iteration (ms): 621.8 | learning rate: 1.489288E-04 | global batch size:    64 | lm loss: 3.639250E+00 | loss scale: 1048576.0 | grad norm: 0.404 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 07:18:48] iteration    21000/  500000 | consumed samples:      1344000 | elapsed time per iteration (ms): 618.5 | learning rate: 1.489167E-04 | global batch size:    64 | lm loss: 3.619922E+00 | loss scale: 1048576.0 | grad norm: 0.401 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2463.14, 2463.33)
-------------------------------------------------------------------------------------------------
 validation loss at iteration 21000 | lm loss value: 3.792513E+00 | lm loss PPL: 4.436774E+01 | 
-------------------------------------------------------------------------------------------------
 [2024-06-24 07:19:53] iteration    21100/  500000 | consumed samples:      1350400 | elapsed time per iteration (ms): 620.9 | learning rate: 1.489045E-04 | global batch size:    64 | lm loss: 3.631893E+00 | loss scale: 1048576.0 | grad norm: 0.399 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 07:20:55] iteration    21200/  500000 | consumed samples:      1356800 | elapsed time per iteration (ms): 621.0 | learning rate: 1.488922E-04 | global batch size:    64 | lm loss: 3.611365E+00 | loss scale: 1048576.0 | grad norm: 0.398 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 07:21:57] iteration    21300/  500000 | consumed samples:      1363200 | elapsed time per iteration (ms): 619.8 | learning rate: 1.488800E-04 | global batch size:    64 | lm loss: 3.624402E+00 | loss scale: 1048576.0 | grad norm: 0.398 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-24 07:22:59] iteration    21400/  500000 | consumed samples:      1369600 | elapsed time per iteration (ms): 618.8 | learning rate: 1.488676E-04 | global batch size:    64 | lm loss: 3.629709E+00 | loss scale: 1048576.0 | grad norm: 0.414 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 07:24:00] iteration    21500/  500000 | consumed samples:      1376000 | elapsed time per iteration (ms): 618.8 | learning rate: 1.488553E-04 | global batch size:    64 | lm loss: 3.621171E+00 | loss scale: 524288.0 | grad norm: 0.395 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-24 07:25:02] iteration    21600/  500000 | consumed samples:      1382400 | elapsed time per iteration (ms): 619.1 | learning rate: 1.488427E-04 | global batch size:    64 | lm loss: 3.625407E+00 | loss scale: 524288.0 | grad norm: 0.413 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 07:26:04] iteration    21700/  500000 | consumed samples:      1388800 | elapsed time per iteration (ms): 620.1 | learning rate: 1.488301E-04 | global batch size:    64 | lm loss: 3.609237E+00 | loss scale: 524288.0 | grad norm: 0.400 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 07:27:06] iteration    21800/  500000 | consumed samples:      1395200 | elapsed time per iteration (ms): 618.4 | learning rate: 1.488176E-04 | global batch size:    64 | lm loss: 3.622549E+00 | loss scale: 262144.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-24 07:28:08] iteration    21900/  500000 | consumed samples:      1401600 | elapsed time per iteration (ms): 620.6 | learning rate: 1.488048E-04 | global batch size:    64 | lm loss: 3.617218E+00 | loss scale: 262144.0 | grad norm: 0.403 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 07:29:10] iteration    22000/  500000 | consumed samples:      1408000 | elapsed time per iteration (ms): 620.0 | learning rate: 1.487920E-04 | global batch size:    64 | lm loss: 3.608719E+00 | loss scale: 262144.0 | grad norm: 0.406 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2463.26, 2463.28)
-------------------------------------------------------------------------------------------------
 validation loss at iteration 22000 | lm loss value: 3.830856E+00 | lm loss PPL: 4.610199E+01 | 
-------------------------------------------------------------------------------------------------
 [2024-06-24 07:30:15] iteration    22100/  500000 | consumed samples:      1414400 | elapsed time per iteration (ms): 620.9 | learning rate: 1.487792E-04 | global batch size:    64 | lm loss: 3.609758E+00 | loss scale: 262144.0 | grad norm: 0.395 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 07:31:17] iteration    22200/  500000 | consumed samples:      1420800 | elapsed time per iteration (ms): 620.8 | learning rate: 1.487662E-04 | global batch size:    64 | lm loss: 3.608762E+00 | loss scale: 262144.0 | grad norm: 0.400 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 07:32:19] iteration    22300/  500000 | consumed samples:      1427200 | elapsed time per iteration (ms): 619.4 | learning rate: 1.487532E-04 | global batch size:    64 | lm loss: 3.611685E+00 | loss scale: 262144.0 | grad norm: 0.397 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 07:33:21] iteration    22400/  500000 | consumed samples:      1433600 | elapsed time per iteration (ms): 618.9 | learning rate: 1.487401E-04 | global batch size:    64 | lm loss: 3.610609E+00 | loss scale: 262144.0 | grad norm: 0.405 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 07:34:23] iteration    22500/  500000 | consumed samples:      1440000 | elapsed time per iteration (ms): 619.4 | learning rate: 1.487270E-04 | global batch size:    64 | lm loss: 3.609997E+00 | loss scale: 262144.0 | grad norm: 0.401 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 07:35:25] iteration    22600/  500000 | consumed samples:      1446400 | elapsed time per iteration (ms): 619.4 | learning rate: 1.487138E-04 | global batch size:    64 | lm loss: 3.596108E+00 | loss scale: 262144.0 | grad norm: 0.397 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 07:36:27] iteration    22700/  500000 | consumed samples:      1452800 | elapsed time per iteration (ms): 618.8 | learning rate: 1.487005E-04 | global batch size:    64 | lm loss: 3.601938E+00 | loss scale: 262144.0 | grad norm: 0.414 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 07:37:28] iteration    22800/  500000 | consumed samples:      1459200 | elapsed time per iteration (ms): 618.2 | learning rate: 1.486871E-04 | global batch size:    64 | lm loss: 3.605704E+00 | loss scale: 524288.0 | grad norm: 0.419 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 07:38:30] iteration    22900/  500000 | consumed samples:      1465600 | elapsed time per iteration (ms): 618.9 | learning rate: 1.486737E-04 | global batch size:    64 | lm loss: 3.600184E+00 | loss scale: 524288.0 | grad norm: 0.413 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 07:39:32] iteration    23000/  500000 | consumed samples:      1472000 | elapsed time per iteration (ms): 619.2 | learning rate: 1.486602E-04 | global batch size:    64 | lm loss: 3.596182E+00 | loss scale: 524288.0 | grad norm: 0.397 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2464.25, 2464.33)
-------------------------------------------------------------------------------------------------
 validation loss at iteration 23000 | lm loss value: 3.788361E+00 | lm loss PPL: 4.418391E+01 | 
-------------------------------------------------------------------------------------------------
 [2024-06-24 07:40:36] iteration    23100/  500000 | consumed samples:      1478400 | elapsed time per iteration (ms): 618.7 | learning rate: 1.486467E-04 | global batch size:    64 | lm loss: 3.587202E+00 | loss scale: 524288.0 | grad norm: 0.390 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 07:41:38] iteration    23200/  500000 | consumed samples:      1484800 | elapsed time per iteration (ms): 619.1 | learning rate: 1.486331E-04 | global batch size:    64 | lm loss: 3.582146E+00 | loss scale: 524288.0 | grad norm: 0.400 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 07:42:40] iteration    23300/  500000 | consumed samples:      1491200 | elapsed time per iteration (ms): 619.1 | learning rate: 1.486195E-04 | global batch size:    64 | lm loss: 3.589714E+00 | loss scale: 524288.0 | grad norm: 0.609 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-24 07:43:42] iteration    23400/  500000 | consumed samples:      1497600 | elapsed time per iteration (ms): 619.8 | learning rate: 1.486059E-04 | global batch size:    64 | lm loss: 3.615633E+00 | loss scale: 262144.0 | grad norm: 0.398 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-24 07:44:44] iteration    23500/  500000 | consumed samples:      1504000 | elapsed time per iteration (ms): 618.4 | learning rate: 1.485921E-04 | global batch size:    64 | lm loss: 3.603588E+00 | loss scale: 262144.0 | grad norm: 0.416 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 07:45:46] iteration    23600/  500000 | consumed samples:      1510400 | elapsed time per iteration (ms): 620.3 | learning rate: 1.485782E-04 | global batch size:    64 | lm loss: 3.589847E+00 | loss scale: 262144.0 | grad norm: 0.405 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 07:46:48] iteration    23700/  500000 | consumed samples:      1516800 | elapsed time per iteration (ms): 619.1 | learning rate: 1.485643E-04 | global batch size:    64 | lm loss: 3.584243E+00 | loss scale: 262144.0 | grad norm: 0.412 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 07:47:50] iteration    23800/  500000 | consumed samples:      1523200 | elapsed time per iteration (ms): 619.1 | learning rate: 1.485502E-04 | global batch size:    64 | lm loss: 3.581405E+00 | loss scale: 262144.0 | grad norm: 0.405 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 07:48:52] iteration    23900/  500000 | consumed samples:      1529600 | elapsed time per iteration (ms): 618.9 | learning rate: 1.485362E-04 | global batch size:    64 | lm loss: 3.577026E+00 | loss scale: 262144.0 | grad norm: 0.408 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 07:49:54] iteration    24000/  500000 | consumed samples:      1536000 | elapsed time per iteration (ms): 618.1 | learning rate: 1.485220E-04 | global batch size:    64 | lm loss: 3.591407E+00 | loss scale: 262144.0 | grad norm: 0.413 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2462.98, 2463.11)
-------------------------------------------------------------------------------------------------
 validation loss at iteration 24000 | lm loss value: 3.796786E+00 | lm loss PPL: 4.455775E+01 | 
-------------------------------------------------------------------------------------------------
 [2024-06-24 07:50:58] iteration    24100/  500000 | consumed samples:      1542400 | elapsed time per iteration (ms): 618.0 | learning rate: 1.485078E-04 | global batch size:    64 | lm loss: 3.584561E+00 | loss scale: 262144.0 | grad norm: 0.403 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 07:52:00] iteration    24200/  500000 | consumed samples:      1548800 | elapsed time per iteration (ms): 618.7 | learning rate: 1.484935E-04 | global batch size:    64 | lm loss: 3.595514E+00 | loss scale: 262144.0 | grad norm: 0.417 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 07:53:02] iteration    24300/  500000 | consumed samples:      1555200 | elapsed time per iteration (ms): 620.5 | learning rate: 1.484791E-04 | global batch size:    64 | lm loss: 3.579089E+00 | loss scale: 262144.0 | grad norm: 0.393 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 07:54:04] iteration    24400/  500000 | consumed samples:      1561600 | elapsed time per iteration (ms): 621.1 | learning rate: 1.484647E-04 | global batch size:    64 | lm loss: 3.578793E+00 | loss scale: 524288.0 | grad norm: 0.399 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 07:55:06] iteration    24500/  500000 | consumed samples:      1568000 | elapsed time per iteration (ms): 621.3 | learning rate: 1.484502E-04 | global batch size:    64 | lm loss: 3.571696E+00 | loss scale: 524288.0 | grad norm: 0.409 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 07:56:08] iteration    24600/  500000 | consumed samples:      1574400 | elapsed time per iteration (ms): 621.8 | learning rate: 1.484356E-04 | global batch size:    64 | lm loss: 3.569736E+00 | loss scale: 524288.0 | grad norm: 0.401 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 07:57:10] iteration    24700/  500000 | consumed samples:      1580800 | elapsed time per iteration (ms): 621.5 | learning rate: 1.484210E-04 | global batch size:    64 | lm loss: 3.575243E+00 | loss scale: 524288.0 | grad norm: 0.397 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 07:58:12] iteration    24800/  500000 | consumed samples:      1587200 | elapsed time per iteration (ms): 620.4 | learning rate: 1.484063E-04 | global batch size:    64 | lm loss: 3.547853E+00 | loss scale: 524288.0 | grad norm: 0.402 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 07:59:14] iteration    24900/  500000 | consumed samples:      1593600 | elapsed time per iteration (ms): 620.3 | learning rate: 1.483916E-04 | global batch size:    64 | lm loss: 3.570126E+00 | loss scale: 524288.0 | grad norm: 0.401 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 08:00:16] iteration    25000/  500000 | consumed samples:      1600000 | elapsed time per iteration (ms): 619.9 | learning rate: 1.483767E-04 | global batch size:    64 | lm loss: 3.562472E+00 | loss scale: 524288.0 | grad norm: 0.422 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2464.75, 2464.87)
-------------------------------------------------------------------------------------------------
 validation loss at iteration 25000 | lm loss value: 3.794242E+00 | lm loss PPL: 4.444452E+01 | 
-------------------------------------------------------------------------------------------------
 [2024-06-24 08:01:21] iteration    25100/  500000 | consumed samples:      1606400 | elapsed time per iteration (ms): 618.7 | learning rate: 1.483618E-04 | global batch size:    64 | lm loss: 3.569100E+00 | loss scale: 524288.0 | grad norm: 0.399 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 08:02:23] iteration    25200/  500000 | consumed samples:      1612800 | elapsed time per iteration (ms): 620.1 | learning rate: 1.483469E-04 | global batch size:    64 | lm loss: 3.573225E+00 | loss scale: 524288.0 | grad norm: 0.410 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 08:03:25] iteration    25300/  500000 | consumed samples:      1619200 | elapsed time per iteration (ms): 621.0 | learning rate: 1.483318E-04 | global batch size:    64 | lm loss: 3.568140E+00 | loss scale: 524288.0 | grad norm: 0.402 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 08:04:27] iteration    25400/  500000 | consumed samples:      1625600 | elapsed time per iteration (ms): 620.1 | learning rate: 1.483167E-04 | global batch size:    64 | lm loss: 3.555336E+00 | loss scale: 1048576.0 | grad norm: 0.401 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 08:05:29] iteration    25500/  500000 | consumed samples:      1632000 | elapsed time per iteration (ms): 620.6 | learning rate: 1.483017E-04 | global batch size:    64 | lm loss: 3.565439E+00 | loss scale: 1048576.0 | grad norm: 0.395 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-24 08:06:31] iteration    25600/  500000 | consumed samples:      1638400 | elapsed time per iteration (ms): 618.7 | learning rate: 1.482865E-04 | global batch size:    64 | lm loss: 3.566483E+00 | loss scale: 1048576.0 | grad norm: 0.399 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 08:07:33] iteration    25700/  500000 | consumed samples:      1644800 | elapsed time per iteration (ms): 620.7 | learning rate: 1.482712E-04 | global batch size:    64 | lm loss: 3.555947E+00 | loss scale: 1048576.0 | grad norm: 0.386 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 08:08:35] iteration    25800/  500000 | consumed samples:      1651200 | elapsed time per iteration (ms): 618.0 | learning rate: 1.482560E-04 | global batch size:    64 | lm loss: 3.571833E+00 | loss scale: 524288.0 | grad norm: 0.393 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-24 08:09:37] iteration    25900/  500000 | consumed samples:      1657600 | elapsed time per iteration (ms): 619.8 | learning rate: 1.482406E-04 | global batch size:    64 | lm loss: 3.553711E+00 | loss scale: 524288.0 | grad norm: 0.392 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 08:10:38] iteration    26000/  500000 | consumed samples:      1664000 | elapsed time per iteration (ms): 616.6 | learning rate: 1.482251E-04 | global batch size:    64 | lm loss: 3.562376E+00 | loss scale: 524288.0 | grad norm: 0.401 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2465.47, 2465.61)
-------------------------------------------------------------------------------------------------
 validation loss at iteration 26000 | lm loss value: 3.745172E+00 | lm loss PPL: 4.231628E+01 | 
-------------------------------------------------------------------------------------------------
 [2024-06-24 08:11:43] iteration    26100/  500000 | consumed samples:      1670400 | elapsed time per iteration (ms): 619.5 | learning rate: 1.482095E-04 | global batch size:    64 | lm loss: 3.542975E+00 | loss scale: 524288.0 | grad norm: 0.399 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 08:12:45] iteration    26200/  500000 | consumed samples:      1676800 | elapsed time per iteration (ms): 620.5 | learning rate: 1.481939E-04 | global batch size:    64 | lm loss: 3.546523E+00 | loss scale: 524288.0 | grad norm: 0.400 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 08:13:47] iteration    26300/  500000 | consumed samples:      1683200 | elapsed time per iteration (ms): 619.0 | learning rate: 1.481782E-04 | global batch size:    64 | lm loss: 3.563390E+00 | loss scale: 524288.0 | grad norm: 0.383 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 08:14:49] iteration    26400/  500000 | consumed samples:      1689600 | elapsed time per iteration (ms): 620.3 | learning rate: 1.481624E-04 | global batch size:    64 | lm loss: 3.540667E+00 | loss scale: 524288.0 | grad norm: 0.397 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 08:15:51] iteration    26500/  500000 | consumed samples:      1696000 | elapsed time per iteration (ms): 620.0 | learning rate: 1.481466E-04 | global batch size:    64 | lm loss: 3.549220E+00 | loss scale: 524288.0 | grad norm: 0.405 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 08:16:53] iteration    26600/  500000 | consumed samples:      1702400 | elapsed time per iteration (ms): 623.3 | learning rate: 1.481307E-04 | global batch size:    64 | lm loss: 3.557301E+00 | loss scale: 524288.0 | grad norm: 0.389 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 08:17:55] iteration    26700/  500000 | consumed samples:      1708800 | elapsed time per iteration (ms): 619.8 | learning rate: 1.481147E-04 | global batch size:    64 | lm loss: 3.554406E+00 | loss scale: 524288.0 | grad norm: 0.397 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 08:18:57] iteration    26800/  500000 | consumed samples:      1715200 | elapsed time per iteration (ms): 621.8 | learning rate: 1.480987E-04 | global batch size:    64 | lm loss: 3.551935E+00 | loss scale: 1048576.0 | grad norm: 0.407 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 08:19:59] iteration    26900/  500000 | consumed samples:      1721600 | elapsed time per iteration (ms): 619.9 | learning rate: 1.480826E-04 | global batch size:    64 | lm loss: 3.559457E+00 | loss scale: 1048576.0 | grad norm: 0.400 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 08:21:01] iteration    27000/  500000 | consumed samples:      1728000 | elapsed time per iteration (ms): 618.6 | learning rate: 1.480664E-04 | global batch size:    64 | lm loss: 3.549346E+00 | loss scale: 1048576.0 | grad norm: 0.396 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2471.16, 2471.29)
-------------------------------------------------------------------------------------------------
 validation loss at iteration 27000 | lm loss value: 3.743819E+00 | lm loss PPL: 4.225909E+01 | 
-------------------------------------------------------------------------------------------------
 [2024-06-24 08:22:05] iteration    27100/  500000 | consumed samples:      1734400 | elapsed time per iteration (ms): 618.4 | learning rate: 1.480501E-04 | global batch size:    64 | lm loss: 3.549073E+00 | loss scale: 1048576.0 | grad norm: 0.415 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 08:23:07] iteration    27200/  500000 | consumed samples:      1740800 | elapsed time per iteration (ms): 617.8 | learning rate: 1.480338E-04 | global batch size:    64 | lm loss: 3.549260E+00 | loss scale: 1048576.0 | grad norm: 0.410 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 08:24:09] iteration    27300/  500000 | consumed samples:      1747200 | elapsed time per iteration (ms): 619.3 | learning rate: 1.480175E-04 | global batch size:    64 | lm loss: 3.543590E+00 | loss scale: 1048576.0 | grad norm: 0.398 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 08:25:11] iteration    27400/  500000 | consumed samples:      1753600 | elapsed time per iteration (ms): 618.9 | learning rate: 1.480010E-04 | global batch size:    64 | lm loss: 3.539017E+00 | loss scale: 1048576.0 | grad norm: 0.415 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 08:26:13] iteration    27500/  500000 | consumed samples:      1760000 | elapsed time per iteration (ms): 620.7 | learning rate: 1.479845E-04 | global batch size:    64 | lm loss: 3.538454E+00 | loss scale: 1048576.0 | grad norm: 0.407 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 08:27:15] iteration    27600/  500000 | consumed samples:      1766400 | elapsed time per iteration (ms): 619.3 | learning rate: 1.479680E-04 | global batch size:    64 | lm loss: 3.542819E+00 | loss scale: 1048576.0 | grad norm: 0.392 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 08:28:17] iteration    27700/  500000 | consumed samples:      1772800 | elapsed time per iteration (ms): 621.2 | learning rate: 1.479513E-04 | global batch size:    64 | lm loss: 3.526351E+00 | loss scale: 1048576.0 | grad norm: 0.396 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 08:29:19] iteration    27800/  500000 | consumed samples:      1779200 | elapsed time per iteration (ms): 619.1 | learning rate: 1.479346E-04 | global batch size:    64 | lm loss: 3.545046E+00 | loss scale: 2097152.0 | grad norm: 0.395 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 08:30:21] iteration    27900/  500000 | consumed samples:      1785600 | elapsed time per iteration (ms): 621.1 | learning rate: 1.479178E-04 | global batch size:    64 | lm loss: 3.527478E+00 | loss scale: 2097152.0 | grad norm: 0.393 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 08:31:23] iteration    28000/  500000 | consumed samples:      1792000 | elapsed time per iteration (ms): 619.2 | learning rate: 1.479010E-04 | global batch size:    64 | lm loss: 3.532353E+00 | loss scale: 2097152.0 | grad norm: 0.404 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2466.48, 2466.50)
-------------------------------------------------------------------------------------------------
 validation loss at iteration 28000 | lm loss value: 3.757703E+00 | lm loss PPL: 4.284989E+01 | 
-------------------------------------------------------------------------------------------------
 [2024-06-24 08:32:28] iteration    28100/  500000 | consumed samples:      1798400 | elapsed time per iteration (ms): 619.7 | learning rate: 1.478841E-04 | global batch size:    64 | lm loss: 3.530866E+00 | loss scale: 2097152.0 | grad norm: 0.402 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 08:33:30] iteration    28200/  500000 | consumed samples:      1804800 | elapsed time per iteration (ms): 620.1 | learning rate: 1.478673E-04 | global batch size:    64 | lm loss: 3.531590E+00 | loss scale: 2097152.0 | grad norm: 0.397 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-24 08:34:31] iteration    28300/  500000 | consumed samples:      1811200 | elapsed time per iteration (ms): 618.9 | learning rate: 1.478504E-04 | global batch size:    64 | lm loss: 3.523920E+00 | loss scale: 1048576.0 | grad norm: 0.416 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-24 08:35:33] iteration    28400/  500000 | consumed samples:      1817600 | elapsed time per iteration (ms): 620.1 | learning rate: 1.478333E-04 | global batch size:    64 | lm loss: 3.520491E+00 | loss scale: 1048576.0 | grad norm: 0.400 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 08:36:36] iteration    28500/  500000 | consumed samples:      1824000 | elapsed time per iteration (ms): 621.0 | learning rate: 1.478162E-04 | global batch size:    64 | lm loss: 3.519303E+00 | loss scale: 1048576.0 | grad norm: 0.400 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 08:37:37] iteration    28600/  500000 | consumed samples:      1830400 | elapsed time per iteration (ms): 618.8 | learning rate: 1.477989E-04 | global batch size:    64 | lm loss: 3.530401E+00 | loss scale: 1048576.0 | grad norm: 0.388 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 08:38:39] iteration    28700/  500000 | consumed samples:      1836800 | elapsed time per iteration (ms): 619.4 | learning rate: 1.477816E-04 | global batch size:    64 | lm loss: 3.526716E+00 | loss scale: 1048576.0 | grad norm: 0.427 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 08:39:41] iteration    28800/  500000 | consumed samples:      1843200 | elapsed time per iteration (ms): 619.7 | learning rate: 1.477642E-04 | global batch size:    64 | lm loss: 3.528138E+00 | loss scale: 1048576.0 | grad norm: 0.399 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 08:40:43] iteration    28900/  500000 | consumed samples:      1849600 | elapsed time per iteration (ms): 621.6 | learning rate: 1.477468E-04 | global batch size:    64 | lm loss: 3.525157E+00 | loss scale: 1048576.0 | grad norm: 0.401 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 08:41:45] iteration    29000/  500000 | consumed samples:      1856000 | elapsed time per iteration (ms): 619.3 | learning rate: 1.477293E-04 | global batch size:    64 | lm loss: 3.529132E+00 | loss scale: 1048576.0 | grad norm: 0.389 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2463.82, 2464.00)
-------------------------------------------------------------------------------------------------
 validation loss at iteration 29000 | lm loss value: 3.761862E+00 | lm loss PPL: 4.302846E+01 | 
-------------------------------------------------------------------------------------------------
 [2024-06-24 08:42:50] iteration    29100/  500000 | consumed samples:      1862400 | elapsed time per iteration (ms): 620.0 | learning rate: 1.477117E-04 | global batch size:    64 | lm loss: 3.510191E+00 | loss scale: 1048576.0 | grad norm: 0.396 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 08:43:52] iteration    29200/  500000 | consumed samples:      1868800 | elapsed time per iteration (ms): 621.2 | learning rate: 1.476941E-04 | global batch size:    64 | lm loss: 3.508652E+00 | loss scale: 1048576.0 | grad norm: 0.391 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 08:44:54] iteration    29300/  500000 | consumed samples:      1875200 | elapsed time per iteration (ms): 619.4 | learning rate: 1.476764E-04 | global batch size:    64 | lm loss: 3.532803E+00 | loss scale: 2097152.0 | grad norm: 0.386 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 08:45:56] iteration    29400/  500000 | consumed samples:      1881600 | elapsed time per iteration (ms): 618.4 | learning rate: 1.476590E-04 | global batch size:    64 | lm loss: 3.523778E+00 | loss scale: 1048576.0 | grad norm: 0.394 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-24 08:46:58] iteration    29500/  500000 | consumed samples:      1888000 | elapsed time per iteration (ms): 618.5 | learning rate: 1.476411E-04 | global batch size:    64 | lm loss: 3.520304E+00 | loss scale: 1048576.0 | grad norm: 0.394 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 08:48:00] iteration    29600/  500000 | consumed samples:      1894400 | elapsed time per iteration (ms): 620.1 | learning rate: 1.476232E-04 | global batch size:    64 | lm loss: 3.527782E+00 | loss scale: 1048576.0 | grad norm: 0.404 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 08:49:02] iteration    29700/  500000 | consumed samples:      1900800 | elapsed time per iteration (ms): 620.5 | learning rate: 1.476053E-04 | global batch size:    64 | lm loss: 3.524301E+00 | loss scale: 1048576.0 | grad norm: 1.029 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 08:50:04] iteration    29800/  500000 | consumed samples:      1907200 | elapsed time per iteration (ms): 620.0 | learning rate: 1.475874E-04 | global batch size:    64 | lm loss: 3.522984E+00 | loss scale: 524288.0 | grad norm: 0.392 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-24 08:51:06] iteration    29900/  500000 | consumed samples:      1913600 | elapsed time per iteration (ms): 619.7 | learning rate: 1.475693E-04 | global batch size:    64 | lm loss: 3.519849E+00 | loss scale: 524288.0 | grad norm: 0.400 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 08:52:08] iteration    30000/  500000 | consumed samples:      1920000 | elapsed time per iteration (ms): 618.8 | learning rate: 1.475513E-04 | global batch size:    64 | lm loss: 3.518408E+00 | loss scale: 262144.0 | grad norm: 0.398 | number of skipped iterations:   1 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2462.95, 2462.98)
-------------------------------------------------------------------------------------------------
 validation loss at iteration 30000 | lm loss value: 3.789849E+00 | lm loss PPL: 4.424971E+01 | 
-------------------------------------------------------------------------------------------------
saving checkpoint at iteration   30000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-distribution in torch format
  successfully saved checkpoint at iteration   30000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-distribution
(min, max) time across ranks (ms):
    save-checkpoint ................................: (2225.41, 2225.43)
 [2024-06-24 08:53:14] iteration    30100/  500000 | consumed samples:      1926400 | elapsed time per iteration (ms): 620.1 | learning rate: 1.475331E-04 | global batch size:    64 | lm loss: 3.518376E+00 | loss scale: 262144.0 | grad norm: 0.404 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 08:54:16] iteration    30200/  500000 | consumed samples:      1932800 | elapsed time per iteration (ms): 619.9 | learning rate: 1.475148E-04 | global batch size:    64 | lm loss: 3.507152E+00 | loss scale: 262144.0 | grad norm: 0.386 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 08:55:18] iteration    30300/  500000 | consumed samples:      1939200 | elapsed time per iteration (ms): 618.8 | learning rate: 1.474964E-04 | global batch size:    64 | lm loss: 3.508113E+00 | loss scale: 262144.0 | grad norm: 0.400 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 08:56:20] iteration    30400/  500000 | consumed samples:      1945600 | elapsed time per iteration (ms): 618.4 | learning rate: 1.474780E-04 | global batch size:    64 | lm loss: 3.512313E+00 | loss scale: 262144.0 | grad norm: 0.398 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 08:57:22] iteration    30500/  500000 | consumed samples:      1952000 | elapsed time per iteration (ms): 618.2 | learning rate: 1.474595E-04 | global batch size:    64 | lm loss: 3.510877E+00 | loss scale: 262144.0 | grad norm: 0.392 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 08:58:24] iteration    30600/  500000 | consumed samples:      1958400 | elapsed time per iteration (ms): 619.2 | learning rate: 1.474409E-04 | global batch size:    64 | lm loss: 3.517154E+00 | loss scale: 262144.0 | grad norm: 0.402 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 08:59:26] iteration    30700/  500000 | consumed samples:      1964800 | elapsed time per iteration (ms): 618.3 | learning rate: 1.474223E-04 | global batch size:    64 | lm loss: 3.515099E+00 | loss scale: 262144.0 | grad norm: 0.397 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 09:00:28] iteration    30800/  500000 | consumed samples:      1971200 | elapsed time per iteration (ms): 620.1 | learning rate: 1.474036E-04 | global batch size:    64 | lm loss: 3.524439E+00 | loss scale: 262144.0 | grad norm: 0.406 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 09:01:30] iteration    30900/  500000 | consumed samples:      1977600 | elapsed time per iteration (ms): 621.3 | learning rate: 1.473849E-04 | global batch size:    64 | lm loss: 3.497093E+00 | loss scale: 262144.0 | grad norm: 0.393 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 09:02:32] iteration    31000/  500000 | consumed samples:      1984000 | elapsed time per iteration (ms): 619.3 | learning rate: 1.473660E-04 | global batch size:    64 | lm loss: 3.500849E+00 | loss scale: 524288.0 | grad norm: 0.405 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2463.50, 2463.57)
-------------------------------------------------------------------------------------------------
 validation loss at iteration 31000 | lm loss value: 3.749756E+00 | lm loss PPL: 4.251072E+01 | 
-------------------------------------------------------------------------------------------------
 [2024-06-24 09:03:36] iteration    31100/  500000 | consumed samples:      1990400 | elapsed time per iteration (ms): 621.1 | learning rate: 1.473471E-04 | global batch size:    64 | lm loss: 3.509953E+00 | loss scale: 524288.0 | grad norm: 0.395 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 09:04:38] iteration    31200/  500000 | consumed samples:      1996800 | elapsed time per iteration (ms): 620.2 | learning rate: 1.473282E-04 | global batch size:    64 | lm loss: 3.494234E+00 | loss scale: 524288.0 | grad norm: 0.419 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 09:05:40] iteration    31300/  500000 | consumed samples:      2003200 | elapsed time per iteration (ms): 620.3 | learning rate: 1.473091E-04 | global batch size:    64 | lm loss: 3.503928E+00 | loss scale: 524288.0 | grad norm: 0.393 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 09:06:42] iteration    31400/  500000 | consumed samples:      2009600 | elapsed time per iteration (ms): 619.5 | learning rate: 1.472900E-04 | global batch size:    64 | lm loss: 3.482091E+00 | loss scale: 524288.0 | grad norm: 0.396 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 09:07:44] iteration    31500/  500000 | consumed samples:      2016000 | elapsed time per iteration (ms): 620.0 | learning rate: 1.472709E-04 | global batch size:    64 | lm loss: 3.490963E+00 | loss scale: 524288.0 | grad norm: 0.398 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 09:08:46] iteration    31600/  500000 | consumed samples:      2022400 | elapsed time per iteration (ms): 620.9 | learning rate: 1.472517E-04 | global batch size:    64 | lm loss: 3.479745E+00 | loss scale: 524288.0 | grad norm: 0.418 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 09:09:48] iteration    31700/  500000 | consumed samples:      2028800 | elapsed time per iteration (ms): 620.4 | learning rate: 1.472324E-04 | global batch size:    64 | lm loss: 3.502407E+00 | loss scale: 524288.0 | grad norm: 0.399 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 09:10:50] iteration    31800/  500000 | consumed samples:      2035200 | elapsed time per iteration (ms): 619.6 | learning rate: 1.472130E-04 | global batch size:    64 | lm loss: 3.488863E+00 | loss scale: 524288.0 | grad norm: 0.397 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 09:11:52] iteration    31900/  500000 | consumed samples:      2041600 | elapsed time per iteration (ms): 617.6 | learning rate: 1.471936E-04 | global batch size:    64 | lm loss: 3.492167E+00 | loss scale: 524288.0 | grad norm: 0.390 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 09:12:54] iteration    32000/  500000 | consumed samples:      2048000 | elapsed time per iteration (ms): 619.0 | learning rate: 1.471741E-04 | global batch size:    64 | lm loss: 3.488545E+00 | loss scale: 1048576.0 | grad norm: 0.422 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2464.12, 2464.17)
-------------------------------------------------------------------------------------------------
 validation loss at iteration 32000 | lm loss value: 3.756265E+00 | lm loss PPL: 4.278833E+01 | 
-------------------------------------------------------------------------------------------------
 [2024-06-24 09:13:58] iteration    32100/  500000 | consumed samples:      2054400 | elapsed time per iteration (ms): 619.6 | learning rate: 1.471547E-04 | global batch size:    64 | lm loss: 3.487495E+00 | loss scale: 1048576.0 | grad norm: 0.390 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-24 09:15:00] iteration    32200/  500000 | consumed samples:      2060800 | elapsed time per iteration (ms): 619.5 | learning rate: 1.471353E-04 | global batch size:    64 | lm loss: 3.497375E+00 | loss scale: 524288.0 | grad norm: 0.406 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-24 09:16:02] iteration    32300/  500000 | consumed samples:      2067200 | elapsed time per iteration (ms): 619.4 | learning rate: 1.471156E-04 | global batch size:    64 | lm loss: 3.498074E+00 | loss scale: 524288.0 | grad norm: 0.409 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 09:17:04] iteration    32400/  500000 | consumed samples:      2073600 | elapsed time per iteration (ms): 616.1 | learning rate: 1.470959E-04 | global batch size:    64 | lm loss: 3.484691E+00 | loss scale: 524288.0 | grad norm: 0.381 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 09:18:06] iteration    32500/  500000 | consumed samples:      2080000 | elapsed time per iteration (ms): 618.1 | learning rate: 1.470760E-04 | global batch size:    64 | lm loss: 3.489293E+00 | loss scale: 524288.0 | grad norm: 0.391 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 09:19:08] iteration    32600/  500000 | consumed samples:      2086400 | elapsed time per iteration (ms): 619.4 | learning rate: 1.470561E-04 | global batch size:    64 | lm loss: 3.489175E+00 | loss scale: 524288.0 | grad norm: 0.387 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 09:20:09] iteration    32700/  500000 | consumed samples:      2092800 | elapsed time per iteration (ms): 619.2 | learning rate: 1.470362E-04 | global batch size:    64 | lm loss: 3.499597E+00 | loss scale: 524288.0 | grad norm: 0.397 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 09:21:11] iteration    32800/  500000 | consumed samples:      2099200 | elapsed time per iteration (ms): 619.7 | learning rate: 1.470162E-04 | global batch size:    64 | lm loss: 3.492447E+00 | loss scale: 524288.0 | grad norm: 0.407 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 09:22:13] iteration    32900/  500000 | consumed samples:      2105600 | elapsed time per iteration (ms): 619.3 | learning rate: 1.469961E-04 | global batch size:    64 | lm loss: 3.492116E+00 | loss scale: 524288.0 | grad norm: 0.388 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 09:23:15] iteration    33000/  500000 | consumed samples:      2112000 | elapsed time per iteration (ms): 618.5 | learning rate: 1.469759E-04 | global batch size:    64 | lm loss: 3.484772E+00 | loss scale: 524288.0 | grad norm: 0.390 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2462.98, 2463.03)
-------------------------------------------------------------------------------------------------
 validation loss at iteration 33000 | lm loss value: 3.729076E+00 | lm loss PPL: 4.164063E+01 | 
-------------------------------------------------------------------------------------------------
 [2024-06-24 09:24:20] iteration    33100/  500000 | consumed samples:      2118400 | elapsed time per iteration (ms): 621.0 | learning rate: 1.469557E-04 | global batch size:    64 | lm loss: 3.475369E+00 | loss scale: 524288.0 | grad norm: 0.649 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 09:25:22] iteration    33200/  500000 | consumed samples:      2124800 | elapsed time per iteration (ms): 622.6 | learning rate: 1.469354E-04 | global batch size:    64 | lm loss: 3.473119E+00 | loss scale: 1048576.0 | grad norm: 0.391 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 09:26:24] iteration    33300/  500000 | consumed samples:      2131200 | elapsed time per iteration (ms): 619.2 | learning rate: 1.469151E-04 | global batch size:    64 | lm loss: 3.476433E+00 | loss scale: 1048576.0 | grad norm: 0.394 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 09:27:26] iteration    33400/  500000 | consumed samples:      2137600 | elapsed time per iteration (ms): 620.6 | learning rate: 1.468947E-04 | global batch size:    64 | lm loss: 3.481998E+00 | loss scale: 1048576.0 | grad norm: 0.411 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 09:28:28] iteration    33500/  500000 | consumed samples:      2144000 | elapsed time per iteration (ms): 620.8 | learning rate: 1.468742E-04 | global batch size:    64 | lm loss: 3.474753E+00 | loss scale: 1048576.0 | grad norm: 0.392 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 09:29:30] iteration    33600/  500000 | consumed samples:      2150400 | elapsed time per iteration (ms): 618.9 | learning rate: 1.468539E-04 | global batch size:    64 | lm loss: 3.486679E+00 | loss scale: 1048576.0 | grad norm: 0.405 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-24 09:30:32] iteration    33700/  500000 | consumed samples:      2156800 | elapsed time per iteration (ms): 619.1 | learning rate: 1.468333E-04 | global batch size:    64 | lm loss: 3.475377E+00 | loss scale: 1048576.0 | grad norm: 0.394 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 09:31:34] iteration    33800/  500000 | consumed samples:      2163200 | elapsed time per iteration (ms): 620.9 | learning rate: 1.468126E-04 | global batch size:    64 | lm loss: 3.477578E+00 | loss scale: 1048576.0 | grad norm: 0.397 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 09:32:36] iteration    33900/  500000 | consumed samples:      2169600 | elapsed time per iteration (ms): 620.0 | learning rate: 1.467918E-04 | global batch size:    64 | lm loss: 3.478604E+00 | loss scale: 1048576.0 | grad norm: 0.397 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 09:33:38] iteration    34000/  500000 | consumed samples:      2176000 | elapsed time per iteration (ms): 618.3 | learning rate: 1.467712E-04 | global batch size:    64 | lm loss: 3.473189E+00 | loss scale: 524288.0 | grad norm: 0.406 | number of skipped iterations:   1 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2465.73, 2465.81)
-------------------------------------------------------------------------------------------------
 validation loss at iteration 34000 | lm loss value: 3.689370E+00 | lm loss PPL: 4.001964E+01 | 
-------------------------------------------------------------------------------------------------
 [2024-06-24 09:34:42] iteration    34100/  500000 | consumed samples:      2182400 | elapsed time per iteration (ms): 619.8 | learning rate: 1.467504E-04 | global batch size:    64 | lm loss: 3.467450E+00 | loss scale: 524288.0 | grad norm: 0.397 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 09:35:44] iteration    34200/  500000 | consumed samples:      2188800 | elapsed time per iteration (ms): 620.6 | learning rate: 1.467294E-04 | global batch size:    64 | lm loss: 3.468498E+00 | loss scale: 524288.0 | grad norm: 0.412 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 09:36:46] iteration    34300/  500000 | consumed samples:      2195200 | elapsed time per iteration (ms): 620.3 | learning rate: 1.467084E-04 | global batch size:    64 | lm loss: 3.476200E+00 | loss scale: 524288.0 | grad norm: 0.390 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 09:37:49] iteration    34400/  500000 | consumed samples:      2201600 | elapsed time per iteration (ms): 621.5 | learning rate: 1.466874E-04 | global batch size:    64 | lm loss: 3.463052E+00 | loss scale: 524288.0 | grad norm: 0.407 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 09:38:51] iteration    34500/  500000 | consumed samples:      2208000 | elapsed time per iteration (ms): 621.3 | learning rate: 1.466662E-04 | global batch size:    64 | lm loss: 3.476922E+00 | loss scale: 524288.0 | grad norm: 0.395 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 09:39:53] iteration    34600/  500000 | consumed samples:      2214400 | elapsed time per iteration (ms): 618.8 | learning rate: 1.466450E-04 | global batch size:    64 | lm loss: 3.467138E+00 | loss scale: 524288.0 | grad norm: 0.404 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 09:40:55] iteration    34700/  500000 | consumed samples:      2220800 | elapsed time per iteration (ms): 619.7 | learning rate: 1.466238E-04 | global batch size:    64 | lm loss: 3.489231E+00 | loss scale: 524288.0 | grad norm: 0.409 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 09:41:57] iteration    34800/  500000 | consumed samples:      2227200 | elapsed time per iteration (ms): 620.0 | learning rate: 1.466024E-04 | global batch size:    64 | lm loss: 3.471337E+00 | loss scale: 524288.0 | grad norm: 0.394 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 09:42:58] iteration    34900/  500000 | consumed samples:      2233600 | elapsed time per iteration (ms): 618.2 | learning rate: 1.465810E-04 | global batch size:    64 | lm loss: 3.469191E+00 | loss scale: 524288.0 | grad norm: 0.389 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 09:44:00] iteration    35000/  500000 | consumed samples:      2240000 | elapsed time per iteration (ms): 619.6 | learning rate: 1.465596E-04 | global batch size:    64 | lm loss: 3.463354E+00 | loss scale: 1048576.0 | grad norm: 0.406 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2465.80, 2465.81)
-------------------------------------------------------------------------------------------------
 validation loss at iteration 35000 | lm loss value: 3.681801E+00 | lm loss PPL: 3.971786E+01 | 
-------------------------------------------------------------------------------------------------
 [2024-06-24 09:45:05] iteration    35100/  500000 | consumed samples:      2246400 | elapsed time per iteration (ms): 620.4 | learning rate: 1.465380E-04 | global batch size:    64 | lm loss: 3.463321E+00 | loss scale: 1048576.0 | grad norm: 0.408 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 09:46:07] iteration    35200/  500000 | consumed samples:      2252800 | elapsed time per iteration (ms): 619.6 | learning rate: 1.465164E-04 | global batch size:    64 | lm loss: 3.470696E+00 | loss scale: 1048576.0 | grad norm: 0.394 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 09:47:09] iteration    35300/  500000 | consumed samples:      2259200 | elapsed time per iteration (ms): 618.4 | learning rate: 1.464948E-04 | global batch size:    64 | lm loss: 3.451912E+00 | loss scale: 1048576.0 | grad norm: 0.396 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 09:48:10] iteration    35400/  500000 | consumed samples:      2265600 | elapsed time per iteration (ms): 618.0 | learning rate: 1.464731E-04 | global batch size:    64 | lm loss: 3.464987E+00 | loss scale: 1048576.0 | grad norm: 0.397 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 09:49:12] iteration    35500/  500000 | consumed samples:      2272000 | elapsed time per iteration (ms): 620.6 | learning rate: 1.464513E-04 | global batch size:    64 | lm loss: 3.469156E+00 | loss scale: 1048576.0 | grad norm: 0.399 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 09:50:14] iteration    35600/  500000 | consumed samples:      2278400 | elapsed time per iteration (ms): 618.6 | learning rate: 1.464294E-04 | global batch size:    64 | lm loss: 3.450612E+00 | loss scale: 1048576.0 | grad norm: 0.394 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 09:51:16] iteration    35700/  500000 | consumed samples:      2284800 | elapsed time per iteration (ms): 620.2 | learning rate: 1.464075E-04 | global batch size:    64 | lm loss: 3.454458E+00 | loss scale: 1048576.0 | grad norm: 0.389 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 09:52:18] iteration    35800/  500000 | consumed samples:      2291200 | elapsed time per iteration (ms): 618.8 | learning rate: 1.463855E-04 | global batch size:    64 | lm loss: 3.454799E+00 | loss scale: 1048576.0 | grad norm: 0.415 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 09:53:20] iteration    35900/  500000 | consumed samples:      2297600 | elapsed time per iteration (ms): 618.9 | learning rate: 1.463635E-04 | global batch size:    64 | lm loss: 3.446839E+00 | loss scale: 1048576.0 | grad norm: 0.410 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 09:54:22] iteration    36000/  500000 | consumed samples:      2304000 | elapsed time per iteration (ms): 616.5 | learning rate: 1.463418E-04 | global batch size:    64 | lm loss: 3.459822E+00 | loss scale: 1048576.0 | grad norm: 0.394 | number of skipped iterations:   2 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2467.50, 2467.53)
-------------------------------------------------------------------------------------------------
 validation loss at iteration 36000 | lm loss value: 3.781612E+00 | lm loss PPL: 4.388675E+01 | 
-------------------------------------------------------------------------------------------------
 [2024-06-24 09:55:26] iteration    36100/  500000 | consumed samples:      2310400 | elapsed time per iteration (ms): 619.1 | learning rate: 1.463196E-04 | global batch size:    64 | lm loss: 3.452613E+00 | loss scale: 1048576.0 | grad norm: 0.408 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 09:56:28] iteration    36200/  500000 | consumed samples:      2316800 | elapsed time per iteration (ms): 618.3 | learning rate: 1.462974E-04 | global batch size:    64 | lm loss: 3.458944E+00 | loss scale: 1048576.0 | grad norm: 0.395 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 09:57:30] iteration    36300/  500000 | consumed samples:      2323200 | elapsed time per iteration (ms): 618.7 | learning rate: 1.462751E-04 | global batch size:    64 | lm loss: 3.465221E+00 | loss scale: 1048576.0 | grad norm: 0.391 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 09:58:32] iteration    36400/  500000 | consumed samples:      2329600 | elapsed time per iteration (ms): 617.5 | learning rate: 1.462527E-04 | global batch size:    64 | lm loss: 3.449132E+00 | loss scale: 1048576.0 | grad norm: 0.398 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 09:59:33] iteration    36500/  500000 | consumed samples:      2336000 | elapsed time per iteration (ms): 617.0 | learning rate: 1.462302E-04 | global batch size:    64 | lm loss: 3.445074E+00 | loss scale: 1048576.0 | grad norm: 0.398 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 10:00:35] iteration    36600/  500000 | consumed samples:      2342400 | elapsed time per iteration (ms): 618.8 | learning rate: 1.462077E-04 | global batch size:    64 | lm loss: 3.452143E+00 | loss scale: 1048576.0 | grad norm: 0.394 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 10:01:37] iteration    36700/  500000 | consumed samples:      2348800 | elapsed time per iteration (ms): 617.4 | learning rate: 1.461852E-04 | global batch size:    64 | lm loss: 3.448316E+00 | loss scale: 1048576.0 | grad norm: 0.396 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 10:02:39] iteration    36800/  500000 | consumed samples:      2355200 | elapsed time per iteration (ms): 618.7 | learning rate: 1.461625E-04 | global batch size:    64 | lm loss: 3.450790E+00 | loss scale: 1048576.0 | grad norm: 0.405 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 10:03:41] iteration    36900/  500000 | consumed samples:      2361600 | elapsed time per iteration (ms): 617.8 | learning rate: 1.461398E-04 | global batch size:    64 | lm loss: 3.445601E+00 | loss scale: 1048576.0 | grad norm: 0.398 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 10:04:43] iteration    37000/  500000 | consumed samples:      2368000 | elapsed time per iteration (ms): 619.9 | learning rate: 1.461171E-04 | global batch size:    64 | lm loss: 3.451092E+00 | loss scale: 2097152.0 | grad norm: 0.406 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2463.28, 2463.36)
-------------------------------------------------------------------------------------------------
 validation loss at iteration 37000 | lm loss value: 3.719285E+00 | lm loss PPL: 4.123489E+01 | 
-------------------------------------------------------------------------------------------------
 [2024-06-24 10:05:47] iteration    37100/  500000 | consumed samples:      2374400 | elapsed time per iteration (ms): 620.8 | learning rate: 1.460942E-04 | global batch size:    64 | lm loss: 3.454345E+00 | loss scale: 2097152.0 | grad norm: 0.393 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 10:06:49] iteration    37200/  500000 | consumed samples:      2380800 | elapsed time per iteration (ms): 618.4 | learning rate: 1.460713E-04 | global batch size:    64 | lm loss: 3.438102E+00 | loss scale: 2097152.0 | grad norm: 0.408 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 10:07:51] iteration    37300/  500000 | consumed samples:      2387200 | elapsed time per iteration (ms): 620.2 | learning rate: 1.460486E-04 | global batch size:    64 | lm loss: 3.460871E+00 | loss scale: 2097152.0 | grad norm: 0.392 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-24 10:08:53] iteration    37400/  500000 | consumed samples:      2393600 | elapsed time per iteration (ms): 617.7 | learning rate: 1.460256E-04 | global batch size:    64 | lm loss: 3.452755E+00 | loss scale: 2097152.0 | grad norm: 0.398 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 10:09:55] iteration    37500/  500000 | consumed samples:      2400000 | elapsed time per iteration (ms): 620.1 | learning rate: 1.460025E-04 | global batch size:    64 | lm loss: 3.449430E+00 | loss scale: 2097152.0 | grad norm: 0.392 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 10:10:57] iteration    37600/  500000 | consumed samples:      2406400 | elapsed time per iteration (ms): 619.3 | learning rate: 1.459793E-04 | global batch size:    64 | lm loss: 3.435032E+00 | loss scale: 2097152.0 | grad norm: 0.414 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 10:11:58] iteration    37700/  500000 | consumed samples:      2412800 | elapsed time per iteration (ms): 618.0 | learning rate: 1.459564E-04 | global batch size:    64 | lm loss: 3.448948E+00 | loss scale: 1048576.0 | grad norm: 0.393 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-24 10:13:00] iteration    37800/  500000 | consumed samples:      2419200 | elapsed time per iteration (ms): 619.2 | learning rate: 1.459331E-04 | global batch size:    64 | lm loss: 3.436991E+00 | loss scale: 1048576.0 | grad norm: 0.414 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 10:14:02] iteration    37900/  500000 | consumed samples:      2425600 | elapsed time per iteration (ms): 619.1 | learning rate: 1.459097E-04 | global batch size:    64 | lm loss: 3.438574E+00 | loss scale: 1048576.0 | grad norm: 0.402 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 10:15:04] iteration    38000/  500000 | consumed samples:      2432000 | elapsed time per iteration (ms): 618.7 | learning rate: 1.458863E-04 | global batch size:    64 | lm loss: 3.441569E+00 | loss scale: 1048576.0 | grad norm: 0.403 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2463.14, 2463.22)
-------------------------------------------------------------------------------------------------
 validation loss at iteration 38000 | lm loss value: 3.708181E+00 | lm loss PPL: 4.077957E+01 | 
-------------------------------------------------------------------------------------------------
 [2024-06-24 10:16:09] iteration    38100/  500000 | consumed samples:      2438400 | elapsed time per iteration (ms): 618.8 | learning rate: 1.458628E-04 | global batch size:    64 | lm loss: 3.447192E+00 | loss scale: 1048576.0 | grad norm: 0.383 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 10:17:11] iteration    38200/  500000 | consumed samples:      2444800 | elapsed time per iteration (ms): 620.9 | learning rate: 1.458393E-04 | global batch size:    64 | lm loss: 3.438918E+00 | loss scale: 1048576.0 | grad norm: 0.417 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 10:18:13] iteration    38300/  500000 | consumed samples:      2451200 | elapsed time per iteration (ms): 621.2 | learning rate: 1.458157E-04 | global batch size:    64 | lm loss: 3.445069E+00 | loss scale: 1048576.0 | grad norm: 0.405 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 10:19:15] iteration    38400/  500000 | consumed samples:      2457600 | elapsed time per iteration (ms): 621.0 | learning rate: 1.457920E-04 | global batch size:    64 | lm loss: 3.437596E+00 | loss scale: 1048576.0 | grad norm: 0.401 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 10:20:17] iteration    38500/  500000 | consumed samples:      2464000 | elapsed time per iteration (ms): 621.2 | learning rate: 1.457683E-04 | global batch size:    64 | lm loss: 3.425529E+00 | loss scale: 1048576.0 | grad norm: 0.408 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 10:21:19] iteration    38600/  500000 | consumed samples:      2470400 | elapsed time per iteration (ms): 619.3 | learning rate: 1.457445E-04 | global batch size:    64 | lm loss: 3.432601E+00 | loss scale: 1048576.0 | grad norm: 0.394 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 10:22:21] iteration    38700/  500000 | consumed samples:      2476800 | elapsed time per iteration (ms): 619.7 | learning rate: 1.457206E-04 | global batch size:    64 | lm loss: 3.446766E+00 | loss scale: 2097152.0 | grad norm: 0.397 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 10:23:23] iteration    38800/  500000 | consumed samples:      2483200 | elapsed time per iteration (ms): 619.3 | learning rate: 1.456967E-04 | global batch size:    64 | lm loss: 3.430298E+00 | loss scale: 2097152.0 | grad norm: 0.399 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 10:24:25] iteration    38900/  500000 | consumed samples:      2489600 | elapsed time per iteration (ms): 621.1 | learning rate: 1.456727E-04 | global batch size:    64 | lm loss: 3.429136E+00 | loss scale: 2097152.0 | grad norm: 0.392 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 10:25:27] iteration    39000/  500000 | consumed samples:      2496000 | elapsed time per iteration (ms): 620.6 | learning rate: 1.456486E-04 | global batch size:    64 | lm loss: 3.445744E+00 | loss scale: 2097152.0 | grad norm: 0.403 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2464.29, 2464.35)
-------------------------------------------------------------------------------------------------
 validation loss at iteration 39000 | lm loss value: 3.694958E+00 | lm loss PPL: 4.024389E+01 | 
-------------------------------------------------------------------------------------------------
 [2024-06-24 10:26:32] iteration    39100/  500000 | consumed samples:      2502400 | elapsed time per iteration (ms): 621.3 | learning rate: 1.456247E-04 | global batch size:    64 | lm loss: 3.450090E+00 | loss scale: 2097152.0 | grad norm: 0.386 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-24 10:27:34] iteration    39200/  500000 | consumed samples:      2508800 | elapsed time per iteration (ms): 621.2 | learning rate: 1.456005E-04 | global batch size:    64 | lm loss: 3.433051E+00 | loss scale: 2097152.0 | grad norm: 0.391 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 10:28:36] iteration    39300/  500000 | consumed samples:      2515200 | elapsed time per iteration (ms): 620.9 | learning rate: 1.455765E-04 | global batch size:    64 | lm loss: 3.431528E+00 | loss scale: 1048576.0 | grad norm: 0.399 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-24 10:29:38] iteration    39400/  500000 | consumed samples:      2521600 | elapsed time per iteration (ms): 619.9 | learning rate: 1.455522E-04 | global batch size:    64 | lm loss: 3.427250E+00 | loss scale: 1048576.0 | grad norm: 0.396 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 10:30:40] iteration    39500/  500000 | consumed samples:      2528000 | elapsed time per iteration (ms): 617.9 | learning rate: 1.455278E-04 | global batch size:    64 | lm loss: 3.436793E+00 | loss scale: 1048576.0 | grad norm: 0.389 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 10:31:41] iteration    39600/  500000 | consumed samples:      2534400 | elapsed time per iteration (ms): 618.9 | learning rate: 1.455034E-04 | global batch size:    64 | lm loss: 3.443519E+00 | loss scale: 1048576.0 | grad norm: 0.399 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 10:32:43] iteration    39700/  500000 | consumed samples:      2540800 | elapsed time per iteration (ms): 619.3 | learning rate: 1.454789E-04 | global batch size:    64 | lm loss: 3.432348E+00 | loss scale: 1048576.0 | grad norm: 0.395 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 10:33:45] iteration    39800/  500000 | consumed samples:      2547200 | elapsed time per iteration (ms): 618.3 | learning rate: 1.454543E-04 | global batch size:    64 | lm loss: 3.415699E+00 | loss scale: 1048576.0 | grad norm: 0.405 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 10:34:47] iteration    39900/  500000 | consumed samples:      2553600 | elapsed time per iteration (ms): 619.9 | learning rate: 1.454297E-04 | global batch size:    64 | lm loss: 3.417616E+00 | loss scale: 1048576.0 | grad norm: 0.386 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 10:35:49] iteration    40000/  500000 | consumed samples:      2560000 | elapsed time per iteration (ms): 618.3 | learning rate: 1.454050E-04 | global batch size:    64 | lm loss: 3.427434E+00 | loss scale: 1048576.0 | grad norm: 0.393 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2464.43, 2464.46)
-------------------------------------------------------------------------------------------------
 validation loss at iteration 40000 | lm loss value: 3.724700E+00 | lm loss PPL: 4.145878E+01 | 
-------------------------------------------------------------------------------------------------
saving checkpoint at iteration   40000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-distribution in torch format
  successfully saved checkpoint at iteration   40000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-distribution
(min, max) time across ranks (ms):
    save-checkpoint ................................: (2259.60, 2259.61)
 [2024-06-24 10:36:55] iteration    40100/  500000 | consumed samples:      2566400 | elapsed time per iteration (ms): 617.1 | learning rate: 1.453802E-04 | global batch size:    64 | lm loss: 3.426736E+00 | loss scale: 1048576.0 | grad norm: 0.383 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 10:37:57] iteration    40200/  500000 | consumed samples:      2572800 | elapsed time per iteration (ms): 618.8 | learning rate: 1.453554E-04 | global batch size:    64 | lm loss: 3.423738E+00 | loss scale: 1048576.0 | grad norm: 0.387 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 10:38:59] iteration    40300/  500000 | consumed samples:      2579200 | elapsed time per iteration (ms): 619.5 | learning rate: 1.453305E-04 | global batch size:    64 | lm loss: 3.427397E+00 | loss scale: 2097152.0 | grad norm: 0.412 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 10:40:01] iteration    40400/  500000 | consumed samples:      2585600 | elapsed time per iteration (ms): 619.9 | learning rate: 1.453055E-04 | global batch size:    64 | lm loss: 3.434716E+00 | loss scale: 2097152.0 | grad norm: 0.397 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 10:41:03] iteration    40500/  500000 | consumed samples:      2592000 | elapsed time per iteration (ms): 618.3 | learning rate: 1.452805E-04 | global batch size:    64 | lm loss: 3.442613E+00 | loss scale: 2097152.0 | grad norm: 0.397 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 10:42:05] iteration    40600/  500000 | consumed samples:      2598400 | elapsed time per iteration (ms): 618.8 | learning rate: 1.452554E-04 | global batch size:    64 | lm loss: 3.411524E+00 | loss scale: 2097152.0 | grad norm: 0.396 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 10:43:07] iteration    40700/  500000 | consumed samples:      2604800 | elapsed time per iteration (ms): 619.7 | learning rate: 1.452302E-04 | global batch size:    64 | lm loss: 3.415665E+00 | loss scale: 2097152.0 | grad norm: 0.413 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 10:44:09] iteration    40800/  500000 | consumed samples:      2611200 | elapsed time per iteration (ms): 618.5 | learning rate: 1.452050E-04 | global batch size:    64 | lm loss: 3.430864E+00 | loss scale: 2097152.0 | grad norm: 0.407 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 10:45:11] iteration    40900/  500000 | consumed samples:      2617600 | elapsed time per iteration (ms): 619.4 | learning rate: 1.451797E-04 | global batch size:    64 | lm loss: 3.423660E+00 | loss scale: 2097152.0 | grad norm: 0.396 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 10:46:13] iteration    41000/  500000 | consumed samples:      2624000 | elapsed time per iteration (ms): 618.6 | learning rate: 1.451544E-04 | global batch size:    64 | lm loss: 3.429334E+00 | loss scale: 2097152.0 | grad norm: 0.389 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2464.93, 2465.16)
-------------------------------------------------------------------------------------------------
 validation loss at iteration 41000 | lm loss value: 3.693455E+00 | lm loss PPL: 4.018345E+01 | 
-------------------------------------------------------------------------------------------------
 [2024-06-24 10:47:17] iteration    41100/  500000 | consumed samples:      2630400 | elapsed time per iteration (ms): 621.4 | learning rate: 1.451290E-04 | global batch size:    64 | lm loss: 3.406820E+00 | loss scale: 2097152.0 | grad norm: 0.384 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 10:48:19] iteration    41200/  500000 | consumed samples:      2636800 | elapsed time per iteration (ms): 619.4 | learning rate: 1.451035E-04 | global batch size:    64 | lm loss: 3.404368E+00 | loss scale: 2097152.0 | grad norm: 0.405 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 10:49:21] iteration    41300/  500000 | consumed samples:      2643200 | elapsed time per iteration (ms): 618.7 | learning rate: 1.450785E-04 | global batch size:    64 | lm loss: 3.405432E+00 | loss scale: 2097152.0 | grad norm: 0.396 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-24 10:50:23] iteration    41400/  500000 | consumed samples:      2649600 | elapsed time per iteration (ms): 620.4 | learning rate: 1.450529E-04 | global batch size:    64 | lm loss: 3.420572E+00 | loss scale: 2097152.0 | grad norm: 0.391 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 10:51:25] iteration    41500/  500000 | consumed samples:      2656000 | elapsed time per iteration (ms): 617.4 | learning rate: 1.450275E-04 | global batch size:    64 | lm loss: 3.431252E+00 | loss scale: 1048576.0 | grad norm: 0.392 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-24 10:52:27] iteration    41600/  500000 | consumed samples:      2662400 | elapsed time per iteration (ms): 618.3 | learning rate: 1.450017E-04 | global batch size:    64 | lm loss: 3.424795E+00 | loss scale: 1048576.0 | grad norm: 0.400 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 10:53:28] iteration    41700/  500000 | consumed samples:      2668800 | elapsed time per iteration (ms): 618.2 | learning rate: 1.449759E-04 | global batch size:    64 | lm loss: 3.418227E+00 | loss scale: 1048576.0 | grad norm: 0.408 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 10:54:30] iteration    41800/  500000 | consumed samples:      2675200 | elapsed time per iteration (ms): 620.5 | learning rate: 1.449501E-04 | global batch size:    64 | lm loss: 3.407717E+00 | loss scale: 1048576.0 | grad norm: 0.394 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 10:55:32] iteration    41900/  500000 | consumed samples:      2681600 | elapsed time per iteration (ms): 618.9 | learning rate: 1.449242E-04 | global batch size:    64 | lm loss: 3.411801E+00 | loss scale: 1048576.0 | grad norm: 0.416 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 10:56:34] iteration    42000/  500000 | consumed samples:      2688000 | elapsed time per iteration (ms): 619.9 | learning rate: 1.448982E-04 | global batch size:    64 | lm loss: 3.408644E+00 | loss scale: 1048576.0 | grad norm: 0.404 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2463.29, 2463.59)
-------------------------------------------------------------------------------------------------
 validation loss at iteration 42000 | lm loss value: 3.719906E+00 | lm loss PPL: 4.126050E+01 | 
-------------------------------------------------------------------------------------------------
 [2024-06-24 10:57:39] iteration    42100/  500000 | consumed samples:      2694400 | elapsed time per iteration (ms): 620.8 | learning rate: 1.448721E-04 | global batch size:    64 | lm loss: 3.422416E+00 | loss scale: 1048576.0 | grad norm: 0.390 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 10:58:41] iteration    42200/  500000 | consumed samples:      2700800 | elapsed time per iteration (ms): 619.2 | learning rate: 1.448460E-04 | global batch size:    64 | lm loss: 3.411009E+00 | loss scale: 1048576.0 | grad norm: 0.386 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 10:59:43] iteration    42300/  500000 | consumed samples:      2707200 | elapsed time per iteration (ms): 620.0 | learning rate: 1.448199E-04 | global batch size:    64 | lm loss: 3.412336E+00 | loss scale: 1048576.0 | grad norm: 0.389 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 11:00:45] iteration    42400/  500000 | consumed samples:      2713600 | elapsed time per iteration (ms): 619.3 | learning rate: 1.447936E-04 | global batch size:    64 | lm loss: 3.393291E+00 | loss scale: 1048576.0 | grad norm: 0.394 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 11:01:47] iteration    42500/  500000 | consumed samples:      2720000 | elapsed time per iteration (ms): 618.9 | learning rate: 1.447673E-04 | global batch size:    64 | lm loss: 3.414981E+00 | loss scale: 2097152.0 | grad norm: 0.398 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 11:02:49] iteration    42600/  500000 | consumed samples:      2726400 | elapsed time per iteration (ms): 619.7 | learning rate: 1.447409E-04 | global batch size:    64 | lm loss: 3.407476E+00 | loss scale: 2097152.0 | grad norm: 0.377 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 11:03:51] iteration    42700/  500000 | consumed samples:      2732800 | elapsed time per iteration (ms): 619.8 | learning rate: 1.447145E-04 | global batch size:    64 | lm loss: 3.422531E+00 | loss scale: 2097152.0 | grad norm: 0.392 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 11:04:53] iteration    42800/  500000 | consumed samples:      2739200 | elapsed time per iteration (ms): 619.9 | learning rate: 1.446880E-04 | global batch size:    64 | lm loss: 3.400696E+00 | loss scale: 2097152.0 | grad norm: 0.403 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 11:05:55] iteration    42900/  500000 | consumed samples:      2745600 | elapsed time per iteration (ms): 619.6 | learning rate: 1.446617E-04 | global batch size:    64 | lm loss: 3.402071E+00 | loss scale: 2097152.0 | grad norm: 0.409 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-24 11:06:56] iteration    43000/  500000 | consumed samples:      2752000 | elapsed time per iteration (ms): 619.1 | learning rate: 1.446351E-04 | global batch size:    64 | lm loss: 3.412748E+00 | loss scale: 2097152.0 | grad norm: 0.418 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2463.79, 2463.84)
-------------------------------------------------------------------------------------------------
 validation loss at iteration 43000 | lm loss value: 3.689313E+00 | lm loss PPL: 4.001733E+01 | 
-------------------------------------------------------------------------------------------------
 [2024-06-24 11:08:01] iteration    43100/  500000 | consumed samples:      2758400 | elapsed time per iteration (ms): 617.7 | learning rate: 1.446084E-04 | global batch size:    64 | lm loss: 3.417261E+00 | loss scale: 2097152.0 | grad norm: 0.388 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 11:09:03] iteration    43200/  500000 | consumed samples:      2764800 | elapsed time per iteration (ms): 620.1 | learning rate: 1.445817E-04 | global batch size:    64 | lm loss: 3.414234E+00 | loss scale: 2097152.0 | grad norm: 0.409 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 11:10:05] iteration    43300/  500000 | consumed samples:      2771200 | elapsed time per iteration (ms): 619.6 | learning rate: 1.445549E-04 | global batch size:    64 | lm loss: 3.400036E+00 | loss scale: 2097152.0 | grad norm: 0.388 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 11:11:07] iteration    43400/  500000 | consumed samples:      2777600 | elapsed time per iteration (ms): 620.5 | learning rate: 1.445283E-04 | global batch size:    64 | lm loss: 3.412157E+00 | loss scale: 1048576.0 | grad norm: 0.396 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-24 11:12:09] iteration    43500/  500000 | consumed samples:      2784000 | elapsed time per iteration (ms): 619.0 | learning rate: 1.445013E-04 | global batch size:    64 | lm loss: 3.404837E+00 | loss scale: 1048576.0 | grad norm: 0.387 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 11:13:11] iteration    43600/  500000 | consumed samples:      2790400 | elapsed time per iteration (ms): 620.5 | learning rate: 1.444743E-04 | global batch size:    64 | lm loss: 3.397123E+00 | loss scale: 1048576.0 | grad norm: 0.405 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 11:14:13] iteration    43700/  500000 | consumed samples:      2796800 | elapsed time per iteration (ms): 622.4 | learning rate: 1.444473E-04 | global batch size:    64 | lm loss: 3.406878E+00 | loss scale: 1048576.0 | grad norm: 0.385 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 11:15:15] iteration    43800/  500000 | consumed samples:      2803200 | elapsed time per iteration (ms): 619.9 | learning rate: 1.444201E-04 | global batch size:    64 | lm loss: 3.408426E+00 | loss scale: 1048576.0 | grad norm: 0.403 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 11:16:17] iteration    43900/  500000 | consumed samples:      2809600 | elapsed time per iteration (ms): 620.6 | learning rate: 1.443930E-04 | global batch size:    64 | lm loss: 3.410516E+00 | loss scale: 1048576.0 | grad norm: 0.397 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 11:17:19] iteration    44000/  500000 | consumed samples:      2816000 | elapsed time per iteration (ms): 621.9 | learning rate: 1.443657E-04 | global batch size:    64 | lm loss: 3.399438E+00 | loss scale: 1048576.0 | grad norm: 0.407 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2464.94, 2464.99)
-------------------------------------------------------------------------------------------------
 validation loss at iteration 44000 | lm loss value: 3.707443E+00 | lm loss PPL: 4.074949E+01 | 
-------------------------------------------------------------------------------------------------
 [2024-06-24 11:18:24] iteration    44100/  500000 | consumed samples:      2822400 | elapsed time per iteration (ms): 622.4 | learning rate: 1.443384E-04 | global batch size:    64 | lm loss: 3.387237E+00 | loss scale: 1048576.0 | grad norm: 0.392 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 11:19:26] iteration    44200/  500000 | consumed samples:      2828800 | elapsed time per iteration (ms): 617.7 | learning rate: 1.443110E-04 | global batch size:    64 | lm loss: 3.413157E+00 | loss scale: 1048576.0 | grad norm: 0.402 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 11:20:28] iteration    44300/  500000 | consumed samples:      2835200 | elapsed time per iteration (ms): 619.6 | learning rate: 1.442836E-04 | global batch size:    64 | lm loss: 3.409289E+00 | loss scale: 1048576.0 | grad norm: 0.393 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 11:21:30] iteration    44400/  500000 | consumed samples:      2841600 | elapsed time per iteration (ms): 619.7 | learning rate: 1.442560E-04 | global batch size:    64 | lm loss: 3.398502E+00 | loss scale: 2097152.0 | grad norm: 0.397 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 11:22:32] iteration    44500/  500000 | consumed samples:      2848000 | elapsed time per iteration (ms): 620.6 | learning rate: 1.442285E-04 | global batch size:    64 | lm loss: 3.390015E+00 | loss scale: 2097152.0 | grad norm: 0.407 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 11:23:33] iteration    44600/  500000 | consumed samples:      2854400 | elapsed time per iteration (ms): 618.7 | learning rate: 1.442008E-04 | global batch size:    64 | lm loss: 3.389269E+00 | loss scale: 2097152.0 | grad norm: 0.392 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 11:24:35] iteration    44700/  500000 | consumed samples:      2860800 | elapsed time per iteration (ms): 619.5 | learning rate: 1.441734E-04 | global batch size:    64 | lm loss: 3.408025E+00 | loss scale: 2097152.0 | grad norm: 0.401 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-24 11:25:37] iteration    44800/  500000 | consumed samples:      2867200 | elapsed time per iteration (ms): 618.3 | learning rate: 1.441459E-04 | global batch size:    64 | lm loss: 3.398441E+00 | loss scale: 1048576.0 | grad norm: 0.386 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-24 11:26:39] iteration    44900/  500000 | consumed samples:      2873600 | elapsed time per iteration (ms): 619.5 | learning rate: 1.441181E-04 | global batch size:    64 | lm loss: 3.385580E+00 | loss scale: 1048576.0 | grad norm: 0.429 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 11:27:41] iteration    45000/  500000 | consumed samples:      2880000 | elapsed time per iteration (ms): 619.3 | learning rate: 1.440902E-04 | global batch size:    64 | lm loss: 3.403814E+00 | loss scale: 1048576.0 | grad norm: 0.388 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2464.64, 2464.86)
-------------------------------------------------------------------------------------------------
 validation loss at iteration 45000 | lm loss value: 3.696043E+00 | lm loss PPL: 4.028756E+01 | 
-------------------------------------------------------------------------------------------------
 [2024-06-24 11:28:45] iteration    45100/  500000 | consumed samples:      2886400 | elapsed time per iteration (ms): 618.2 | learning rate: 1.440623E-04 | global batch size:    64 | lm loss: 3.397377E+00 | loss scale: 1048576.0 | grad norm: 0.412 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 11:29:47] iteration    45200/  500000 | consumed samples:      2892800 | elapsed time per iteration (ms): 618.6 | learning rate: 1.440343E-04 | global batch size:    64 | lm loss: 3.391209E+00 | loss scale: 1048576.0 | grad norm: 0.394 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 11:30:49] iteration    45300/  500000 | consumed samples:      2899200 | elapsed time per iteration (ms): 619.3 | learning rate: 1.440062E-04 | global batch size:    64 | lm loss: 3.391304E+00 | loss scale: 1048576.0 | grad norm: 0.378 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 11:31:51] iteration    45400/  500000 | consumed samples:      2905600 | elapsed time per iteration (ms): 620.4 | learning rate: 1.439781E-04 | global batch size:    64 | lm loss: 3.388404E+00 | loss scale: 1048576.0 | grad norm: 0.390 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 11:32:53] iteration    45500/  500000 | consumed samples:      2912000 | elapsed time per iteration (ms): 620.1 | learning rate: 1.439499E-04 | global batch size:    64 | lm loss: 3.384911E+00 | loss scale: 1048576.0 | grad norm: 0.378 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 11:33:55] iteration    45600/  500000 | consumed samples:      2918400 | elapsed time per iteration (ms): 619.1 | learning rate: 1.439216E-04 | global batch size:    64 | lm loss: 3.400500E+00 | loss scale: 1048576.0 | grad norm: 0.412 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 11:34:57] iteration    45700/  500000 | consumed samples:      2924800 | elapsed time per iteration (ms): 619.5 | learning rate: 1.438933E-04 | global batch size:    64 | lm loss: 3.401451E+00 | loss scale: 1048576.0 | grad norm: 0.399 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 11:35:59] iteration    45800/  500000 | consumed samples:      2931200 | elapsed time per iteration (ms): 619.6 | learning rate: 1.438649E-04 | global batch size:    64 | lm loss: 3.385737E+00 | loss scale: 2097152.0 | grad norm: 0.402 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 11:37:01] iteration    45900/  500000 | consumed samples:      2937600 | elapsed time per iteration (ms): 618.2 | learning rate: 1.438365E-04 | global batch size:    64 | lm loss: 3.386575E+00 | loss scale: 2097152.0 | grad norm: 0.395 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 11:38:03] iteration    46000/  500000 | consumed samples:      2944000 | elapsed time per iteration (ms): 618.9 | learning rate: 1.438079E-04 | global batch size:    64 | lm loss: 3.396424E+00 | loss scale: 2097152.0 | grad norm: 0.396 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2464.84, 2464.95)
-------------------------------------------------------------------------------------------------
 validation loss at iteration 46000 | lm loss value: 3.702064E+00 | lm loss PPL: 4.053087E+01 | 
-------------------------------------------------------------------------------------------------
 [2024-06-24 11:39:07] iteration    46100/  500000 | consumed samples:      2950400 | elapsed time per iteration (ms): 618.5 | learning rate: 1.437794E-04 | global batch size:    64 | lm loss: 3.385515E+00 | loss scale: 2097152.0 | grad norm: 0.395 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 11:40:09] iteration    46200/  500000 | consumed samples:      2956800 | elapsed time per iteration (ms): 619.9 | learning rate: 1.437507E-04 | global batch size:    64 | lm loss: 3.386201E+00 | loss scale: 2097152.0 | grad norm: 0.391 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 11:41:11] iteration    46300/  500000 | consumed samples:      2963200 | elapsed time per iteration (ms): 618.4 | learning rate: 1.437220E-04 | global batch size:    64 | lm loss: 3.382200E+00 | loss scale: 2097152.0 | grad norm: 0.382 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 11:42:13] iteration    46400/  500000 | consumed samples:      2969600 | elapsed time per iteration (ms): 618.1 | learning rate: 1.436933E-04 | global batch size:    64 | lm loss: 3.398130E+00 | loss scale: 2097152.0 | grad norm: 0.398 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 11:43:15] iteration    46500/  500000 | consumed samples:      2976000 | elapsed time per iteration (ms): 619.0 | learning rate: 1.436644E-04 | global batch size:    64 | lm loss: 3.391320E+00 | loss scale: 2097152.0 | grad norm: 0.386 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 11:44:17] iteration    46600/  500000 | consumed samples:      2982400 | elapsed time per iteration (ms): 618.9 | learning rate: 1.436358E-04 | global batch size:    64 | lm loss: 3.387764E+00 | loss scale: 2097152.0 | grad norm: 0.414 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-24 11:45:18] iteration    46700/  500000 | consumed samples:      2988800 | elapsed time per iteration (ms): 618.2 | learning rate: 1.436072E-04 | global batch size:    64 | lm loss: 3.373826E+00 | loss scale: 1048576.0 | grad norm: 0.407 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-24 11:46:20] iteration    46800/  500000 | consumed samples:      2995200 | elapsed time per iteration (ms): 618.3 | learning rate: 1.435782E-04 | global batch size:    64 | lm loss: 3.387982E+00 | loss scale: 1048576.0 | grad norm: 0.394 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 11:47:22] iteration    46900/  500000 | consumed samples:      3001600 | elapsed time per iteration (ms): 617.9 | learning rate: 1.435491E-04 | global batch size:    64 | lm loss: 3.387324E+00 | loss scale: 1048576.0 | grad norm: 0.399 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 11:48:24] iteration    47000/  500000 | consumed samples:      3008000 | elapsed time per iteration (ms): 617.8 | learning rate: 1.435199E-04 | global batch size:    64 | lm loss: 3.392265E+00 | loss scale: 1048576.0 | grad norm: 0.392 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2462.48, 2462.63)
-------------------------------------------------------------------------------------------------
 validation loss at iteration 47000 | lm loss value: 3.728199E+00 | lm loss PPL: 4.160411E+01 | 
-------------------------------------------------------------------------------------------------
 [2024-06-24 11:49:28] iteration    47100/  500000 | consumed samples:      3014400 | elapsed time per iteration (ms): 620.4 | learning rate: 1.434907E-04 | global batch size:    64 | lm loss: 3.381401E+00 | loss scale: 1048576.0 | grad norm: 0.391 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 11:50:30] iteration    47200/  500000 | consumed samples:      3020800 | elapsed time per iteration (ms): 619.1 | learning rate: 1.434615E-04 | global batch size:    64 | lm loss: 3.389919E+00 | loss scale: 1048576.0 | grad norm: 0.383 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 11:51:32] iteration    47300/  500000 | consumed samples:      3027200 | elapsed time per iteration (ms): 619.5 | learning rate: 1.434322E-04 | global batch size:    64 | lm loss: 3.389650E+00 | loss scale: 1048576.0 | grad norm: 0.406 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 11:52:34] iteration    47400/  500000 | consumed samples:      3033600 | elapsed time per iteration (ms): 617.4 | learning rate: 1.434028E-04 | global batch size:    64 | lm loss: 3.384487E+00 | loss scale: 1048576.0 | grad norm: 0.408 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 11:53:36] iteration    47500/  500000 | consumed samples:      3040000 | elapsed time per iteration (ms): 618.8 | learning rate: 1.433733E-04 | global batch size:    64 | lm loss: 3.384270E+00 | loss scale: 1048576.0 | grad norm: 0.397 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 11:54:38] iteration    47600/  500000 | consumed samples:      3046400 | elapsed time per iteration (ms): 618.2 | learning rate: 1.433438E-04 | global batch size:    64 | lm loss: 3.375247E+00 | loss scale: 1048576.0 | grad norm: 0.398 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 11:55:40] iteration    47700/  500000 | consumed samples:      3052800 | elapsed time per iteration (ms): 619.8 | learning rate: 1.433142E-04 | global batch size:    64 | lm loss: 3.387123E+00 | loss scale: 2097152.0 | grad norm: 0.404 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 11:56:41] iteration    47800/  500000 | consumed samples:      3059200 | elapsed time per iteration (ms): 618.9 | learning rate: 1.432846E-04 | global batch size:    64 | lm loss: 3.391635E+00 | loss scale: 2097152.0 | grad norm: 0.395 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 11:57:43] iteration    47900/  500000 | consumed samples:      3065600 | elapsed time per iteration (ms): 619.9 | learning rate: 1.432549E-04 | global batch size:    64 | lm loss: 3.389197E+00 | loss scale: 2097152.0 | grad norm: 0.397 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 11:58:45] iteration    48000/  500000 | consumed samples:      3072000 | elapsed time per iteration (ms): 619.2 | learning rate: 1.432254E-04 | global batch size:    64 | lm loss: 3.379515E+00 | loss scale: 2097152.0 | grad norm: 0.381 | number of skipped iterations:   1 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2463.01, 2463.08)
-------------------------------------------------------------------------------------------------
 validation loss at iteration 48000 | lm loss value: 3.639628E+00 | lm loss PPL: 3.807767E+01 | 
-------------------------------------------------------------------------------------------------
 [2024-06-24 11:59:50] iteration    48100/  500000 | consumed samples:      3078400 | elapsed time per iteration (ms): 618.7 | learning rate: 1.431956E-04 | global batch size:    64 | lm loss: 3.376249E+00 | loss scale: 2097152.0 | grad norm: 0.407 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 12:00:52] iteration    48200/  500000 | consumed samples:      3084800 | elapsed time per iteration (ms): 618.8 | learning rate: 1.431660E-04 | global batch size:    64 | lm loss: 3.364265E+00 | loss scale: 1048576.0 | grad norm: 0.406 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-24 12:01:53] iteration    48300/  500000 | consumed samples:      3091200 | elapsed time per iteration (ms): 618.6 | learning rate: 1.431361E-04 | global batch size:    64 | lm loss: 3.384461E+00 | loss scale: 1048576.0 | grad norm: 0.402 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 12:02:55] iteration    48400/  500000 | consumed samples:      3097600 | elapsed time per iteration (ms): 618.3 | learning rate: 1.431061E-04 | global batch size:    64 | lm loss: 3.376278E+00 | loss scale: 1048576.0 | grad norm: 0.389 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 12:03:57] iteration    48500/  500000 | consumed samples:      3104000 | elapsed time per iteration (ms): 619.3 | learning rate: 1.430760E-04 | global batch size:    64 | lm loss: 3.375702E+00 | loss scale: 1048576.0 | grad norm: 0.400 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 12:04:59] iteration    48600/  500000 | consumed samples:      3110400 | elapsed time per iteration (ms): 617.4 | learning rate: 1.430462E-04 | global batch size:    64 | lm loss: 3.376799E+00 | loss scale: 524288.0 | grad norm: 0.388 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-24 12:06:01] iteration    48700/  500000 | consumed samples:      3116800 | elapsed time per iteration (ms): 621.0 | learning rate: 1.430160E-04 | global batch size:    64 | lm loss: 3.372639E+00 | loss scale: 524288.0 | grad norm: 0.392 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 12:07:03] iteration    48800/  500000 | consumed samples:      3123200 | elapsed time per iteration (ms): 617.8 | learning rate: 1.429857E-04 | global batch size:    64 | lm loss: 3.377109E+00 | loss scale: 524288.0 | grad norm: 0.391 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 12:08:05] iteration    48900/  500000 | consumed samples:      3129600 | elapsed time per iteration (ms): 619.8 | learning rate: 1.429554E-04 | global batch size:    64 | lm loss: 3.376703E+00 | loss scale: 524288.0 | grad norm: 0.398 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 12:09:07] iteration    49000/  500000 | consumed samples:      3136000 | elapsed time per iteration (ms): 619.3 | learning rate: 1.429250E-04 | global batch size:    64 | lm loss: 3.366880E+00 | loss scale: 524288.0 | grad norm: 0.378 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2462.90, 2462.92)
-------------------------------------------------------------------------------------------------
 validation loss at iteration 49000 | lm loss value: 3.697212E+00 | lm loss PPL: 4.033469E+01 | 
-------------------------------------------------------------------------------------------------
 [2024-06-24 12:10:11] iteration    49100/  500000 | consumed samples:      3142400 | elapsed time per iteration (ms): 619.5 | learning rate: 1.428946E-04 | global batch size:    64 | lm loss: 3.378019E+00 | loss scale: 524288.0 | grad norm: 0.402 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 12:11:13] iteration    49200/  500000 | consumed samples:      3148800 | elapsed time per iteration (ms): 618.7 | learning rate: 1.428641E-04 | global batch size:    64 | lm loss: 3.357409E+00 | loss scale: 524288.0 | grad norm: 0.400 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 12:12:15] iteration    49300/  500000 | consumed samples:      3155200 | elapsed time per iteration (ms): 617.1 | learning rate: 1.428335E-04 | global batch size:    64 | lm loss: 3.379189E+00 | loss scale: 524288.0 | grad norm: 0.400 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 12:13:17] iteration    49400/  500000 | consumed samples:      3161600 | elapsed time per iteration (ms): 620.7 | learning rate: 1.428029E-04 | global batch size:    64 | lm loss: 3.365209E+00 | loss scale: 524288.0 | grad norm: 0.401 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 12:14:19] iteration    49500/  500000 | consumed samples:      3168000 | elapsed time per iteration (ms): 620.1 | learning rate: 1.427722E-04 | global batch size:    64 | lm loss: 3.381095E+00 | loss scale: 524288.0 | grad norm: 0.381 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 12:15:21] iteration    49600/  500000 | consumed samples:      3174400 | elapsed time per iteration (ms): 620.4 | learning rate: 1.427414E-04 | global batch size:    64 | lm loss: 3.357267E+00 | loss scale: 1048576.0 | grad norm: 0.411 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 12:16:23] iteration    49700/  500000 | consumed samples:      3180800 | elapsed time per iteration (ms): 621.1 | learning rate: 1.427106E-04 | global batch size:    64 | lm loss: 3.394421E+00 | loss scale: 1048576.0 | grad norm: 0.387 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 12:17:25] iteration    49800/  500000 | consumed samples:      3187200 | elapsed time per iteration (ms): 619.6 | learning rate: 1.426797E-04 | global batch size:    64 | lm loss: 3.372005E+00 | loss scale: 1048576.0 | grad norm: 0.399 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 12:18:27] iteration    49900/  500000 | consumed samples:      3193600 | elapsed time per iteration (ms): 619.4 | learning rate: 1.426488E-04 | global batch size:    64 | lm loss: 3.371185E+00 | loss scale: 1048576.0 | grad norm: 0.388 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 12:19:29] iteration    50000/  500000 | consumed samples:      3200000 | elapsed time per iteration (ms): 618.1 | learning rate: 1.426178E-04 | global batch size:    64 | lm loss: 3.365366E+00 | loss scale: 1048576.0 | grad norm: 0.399 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2463.80, 2463.82)
-------------------------------------------------------------------------------------------------
 validation loss at iteration 50000 | lm loss value: 3.679359E+00 | lm loss PPL: 3.962100E+01 | 
-------------------------------------------------------------------------------------------------
saving checkpoint at iteration   50000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-distribution in torch format
  successfully saved checkpoint at iteration   50000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-distribution
(min, max) time across ranks (ms):
    save-checkpoint ................................: (2367.55, 2367.63)
 [2024-06-24 12:20:35] iteration    50100/  500000 | consumed samples:      3206400 | elapsed time per iteration (ms): 620.0 | learning rate: 1.425868E-04 | global batch size:    64 | lm loss: 3.368580E+00 | loss scale: 1048576.0 | grad norm: 0.381 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 12:21:37] iteration    50200/  500000 | consumed samples:      3212800 | elapsed time per iteration (ms): 619.0 | learning rate: 1.425556E-04 | global batch size:    64 | lm loss: 3.379631E+00 | loss scale: 1048576.0 | grad norm: 0.396 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 12:22:39] iteration    50300/  500000 | consumed samples:      3219200 | elapsed time per iteration (ms): 620.8 | learning rate: 1.425245E-04 | global batch size:    64 | lm loss: 3.354798E+00 | loss scale: 1048576.0 | grad norm: 0.384 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 12:23:42] iteration    50400/  500000 | consumed samples:      3225600 | elapsed time per iteration (ms): 622.1 | learning rate: 1.424932E-04 | global batch size:    64 | lm loss: 3.372688E+00 | loss scale: 1048576.0 | grad norm: 0.399 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 12:24:44] iteration    50500/  500000 | consumed samples:      3232000 | elapsed time per iteration (ms): 619.5 | learning rate: 1.424619E-04 | global batch size:    64 | lm loss: 3.379905E+00 | loss scale: 1048576.0 | grad norm: 0.404 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 12:25:46] iteration    50600/  500000 | consumed samples:      3238400 | elapsed time per iteration (ms): 619.1 | learning rate: 1.424309E-04 | global batch size:    64 | lm loss: 3.369407E+00 | loss scale: 2097152.0 | grad norm: 0.395 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-24 12:26:47] iteration    50700/  500000 | consumed samples:      3244800 | elapsed time per iteration (ms): 618.6 | learning rate: 1.423994E-04 | global batch size:    64 | lm loss: 3.352061E+00 | loss scale: 2097152.0 | grad norm: 0.399 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 12:27:49] iteration    50800/  500000 | consumed samples:      3251200 | elapsed time per iteration (ms): 618.6 | learning rate: 1.423679E-04 | global batch size:    64 | lm loss: 3.362239E+00 | loss scale: 2097152.0 | grad norm: 0.419 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 12:28:51] iteration    50900/  500000 | consumed samples:      3257600 | elapsed time per iteration (ms): 619.9 | learning rate: 1.423364E-04 | global batch size:    64 | lm loss: 3.355042E+00 | loss scale: 2097152.0 | grad norm: 0.378 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 12:29:53] iteration    51000/  500000 | consumed samples:      3264000 | elapsed time per iteration (ms): 617.8 | learning rate: 1.423048E-04 | global batch size:    64 | lm loss: 3.369838E+00 | loss scale: 2097152.0 | grad norm: 0.398 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2462.54, 2462.57)
-------------------------------------------------------------------------------------------------
 validation loss at iteration 51000 | lm loss value: 3.744951E+00 | lm loss PPL: 4.230694E+01 | 
-------------------------------------------------------------------------------------------------
 [2024-06-24 12:30:57] iteration    51100/  500000 | consumed samples:      3270400 | elapsed time per iteration (ms): 619.6 | learning rate: 1.422731E-04 | global batch size:    64 | lm loss: 3.369880E+00 | loss scale: 2097152.0 | grad norm: 0.389 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 12:31:59] iteration    51200/  500000 | consumed samples:      3276800 | elapsed time per iteration (ms): 617.5 | learning rate: 1.422414E-04 | global batch size:    64 | lm loss: 3.360435E+00 | loss scale: 2097152.0 | grad norm: 0.400 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 12:33:01] iteration    51300/  500000 | consumed samples:      3283200 | elapsed time per iteration (ms): 617.8 | learning rate: 1.422096E-04 | global batch size:    64 | lm loss: 3.356681E+00 | loss scale: 2097152.0 | grad norm: 0.410 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 12:34:03] iteration    51400/  500000 | consumed samples:      3289600 | elapsed time per iteration (ms): 621.5 | learning rate: 1.421780E-04 | global batch size:    64 | lm loss: 3.363669E+00 | loss scale: 1048576.0 | grad norm: 0.399 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-24 12:35:05] iteration    51500/  500000 | consumed samples:      3296000 | elapsed time per iteration (ms): 620.3 | learning rate: 1.421461E-04 | global batch size:    64 | lm loss: 3.365797E+00 | loss scale: 1048576.0 | grad norm: 0.405 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 12:36:07] iteration    51600/  500000 | consumed samples:      3302400 | elapsed time per iteration (ms): 618.4 | learning rate: 1.421141E-04 | global batch size:    64 | lm loss: 3.365180E+00 | loss scale: 1048576.0 | grad norm: 0.392 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 12:37:09] iteration    51700/  500000 | consumed samples:      3308800 | elapsed time per iteration (ms): 620.1 | learning rate: 1.420821E-04 | global batch size:    64 | lm loss: 3.365758E+00 | loss scale: 1048576.0 | grad norm: 0.396 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 12:38:11] iteration    51800/  500000 | consumed samples:      3315200 | elapsed time per iteration (ms): 620.1 | learning rate: 1.420500E-04 | global batch size:    64 | lm loss: 3.368080E+00 | loss scale: 1048576.0 | grad norm: 0.398 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 12:39:13] iteration    51900/  500000 | consumed samples:      3321600 | elapsed time per iteration (ms): 618.2 | learning rate: 1.420178E-04 | global batch size:    64 | lm loss: 3.360540E+00 | loss scale: 1048576.0 | grad norm: 0.389 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 12:40:15] iteration    52000/  500000 | consumed samples:      3328000 | elapsed time per iteration (ms): 617.4 | learning rate: 1.419856E-04 | global batch size:    64 | lm loss: 3.363236E+00 | loss scale: 1048576.0 | grad norm: 0.385 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2463.29, 2463.35)
-------------------------------------------------------------------------------------------------
 validation loss at iteration 52000 | lm loss value: 3.707165E+00 | lm loss PPL: 4.073814E+01 | 
-------------------------------------------------------------------------------------------------
 [2024-06-24 12:41:19] iteration    52100/  500000 | consumed samples:      3334400 | elapsed time per iteration (ms): 617.3 | learning rate: 1.419533E-04 | global batch size:    64 | lm loss: 3.346402E+00 | loss scale: 1048576.0 | grad norm: 0.394 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 12:42:21] iteration    52200/  500000 | consumed samples:      3340800 | elapsed time per iteration (ms): 620.0 | learning rate: 1.419210E-04 | global batch size:    64 | lm loss: 3.362347E+00 | loss scale: 1048576.0 | grad norm: 0.399 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 12:43:23] iteration    52300/  500000 | consumed samples:      3347200 | elapsed time per iteration (ms): 619.5 | learning rate: 1.418886E-04 | global batch size:    64 | lm loss: 3.349175E+00 | loss scale: 1048576.0 | grad norm: 0.385 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 12:44:25] iteration    52400/  500000 | consumed samples:      3353600 | elapsed time per iteration (ms): 620.0 | learning rate: 1.418561E-04 | global batch size:    64 | lm loss: 3.362533E+00 | loss scale: 2097152.0 | grad norm: 0.396 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 12:45:27] iteration    52500/  500000 | consumed samples:      3360000 | elapsed time per iteration (ms): 619.3 | learning rate: 1.418239E-04 | global batch size:    64 | lm loss: 3.359279E+00 | loss scale: 2097152.0 | grad norm: 0.399 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-24 12:46:29] iteration    52600/  500000 | consumed samples:      3366400 | elapsed time per iteration (ms): 619.3 | learning rate: 1.417913E-04 | global batch size:    64 | lm loss: 3.359526E+00 | loss scale: 2097152.0 | grad norm: 0.398 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 12:47:31] iteration    52700/  500000 | consumed samples:      3372800 | elapsed time per iteration (ms): 619.6 | learning rate: 1.417587E-04 | global batch size:    64 | lm loss: 3.342923E+00 | loss scale: 2097152.0 | grad norm: 0.412 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 12:48:32] iteration    52800/  500000 | consumed samples:      3379200 | elapsed time per iteration (ms): 619.2 | learning rate: 1.417260E-04 | global batch size:    64 | lm loss: 3.366954E+00 | loss scale: 2097152.0 | grad norm: 0.405 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 12:49:34] iteration    52900/  500000 | consumed samples:      3385600 | elapsed time per iteration (ms): 619.3 | learning rate: 1.416932E-04 | global batch size:    64 | lm loss: 3.359294E+00 | loss scale: 2097152.0 | grad norm: 0.390 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 12:50:36] iteration    53000/  500000 | consumed samples:      3392000 | elapsed time per iteration (ms): 619.0 | learning rate: 1.416604E-04 | global batch size:    64 | lm loss: 3.340272E+00 | loss scale: 2097152.0 | grad norm: 0.401 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2462.70, 2462.82)
-------------------------------------------------------------------------------------------------
 validation loss at iteration 53000 | lm loss value: 3.762678E+00 | lm loss PPL: 4.306359E+01 | 
-------------------------------------------------------------------------------------------------
 [2024-06-24 12:51:41] iteration    53100/  500000 | consumed samples:      3398400 | elapsed time per iteration (ms): 619.8 | learning rate: 1.416275E-04 | global batch size:    64 | lm loss: 3.354114E+00 | loss scale: 2097152.0 | grad norm: 0.391 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 12:52:43] iteration    53200/  500000 | consumed samples:      3404800 | elapsed time per iteration (ms): 619.9 | learning rate: 1.415945E-04 | global batch size:    64 | lm loss: 3.354177E+00 | loss scale: 2097152.0 | grad norm: 0.402 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 12:53:44] iteration    53300/  500000 | consumed samples:      3411200 | elapsed time per iteration (ms): 617.8 | learning rate: 1.415619E-04 | global batch size:    64 | lm loss: 3.352247E+00 | loss scale: 1048576.0 | grad norm: 0.394 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-24 12:54:46] iteration    53400/  500000 | consumed samples:      3417600 | elapsed time per iteration (ms): 619.1 | learning rate: 1.415288E-04 | global batch size:    64 | lm loss: 3.364389E+00 | loss scale: 1048576.0 | grad norm: 0.403 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 12:55:48] iteration    53500/  500000 | consumed samples:      3424000 | elapsed time per iteration (ms): 618.0 | learning rate: 1.414957E-04 | global batch size:    64 | lm loss: 3.340688E+00 | loss scale: 1048576.0 | grad norm: 0.396 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 12:56:50] iteration    53600/  500000 | consumed samples:      3430400 | elapsed time per iteration (ms): 617.8 | learning rate: 1.414625E-04 | global batch size:    64 | lm loss: 3.359998E+00 | loss scale: 1048576.0 | grad norm: 0.398 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 12:57:52] iteration    53700/  500000 | consumed samples:      3436800 | elapsed time per iteration (ms): 617.7 | learning rate: 1.414292E-04 | global batch size:    64 | lm loss: 3.344644E+00 | loss scale: 1048576.0 | grad norm: 0.399 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 12:58:54] iteration    53800/  500000 | consumed samples:      3443200 | elapsed time per iteration (ms): 620.1 | learning rate: 1.413959E-04 | global batch size:    64 | lm loss: 3.353331E+00 | loss scale: 1048576.0 | grad norm: 0.393 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 12:59:56] iteration    53900/  500000 | consumed samples:      3449600 | elapsed time per iteration (ms): 620.4 | learning rate: 1.413625E-04 | global batch size:    64 | lm loss: 3.348464E+00 | loss scale: 1048576.0 | grad norm: 0.402 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 13:00:58] iteration    54000/  500000 | consumed samples:      3456000 | elapsed time per iteration (ms): 619.3 | learning rate: 1.413291E-04 | global batch size:    64 | lm loss: 3.338844E+00 | loss scale: 1048576.0 | grad norm: 0.397 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2463.26, 2464.72)
-------------------------------------------------------------------------------------------------
 validation loss at iteration 54000 | lm loss value: 3.691751E+00 | lm loss PPL: 4.011502E+01 | 
-------------------------------------------------------------------------------------------------
 [2024-06-24 13:02:02] iteration    54100/  500000 | consumed samples:      3462400 | elapsed time per iteration (ms): 619.9 | learning rate: 1.412956E-04 | global batch size:    64 | lm loss: 3.363608E+00 | loss scale: 1048576.0 | grad norm: 0.394 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 13:03:04] iteration    54200/  500000 | consumed samples:      3468800 | elapsed time per iteration (ms): 620.0 | learning rate: 1.412620E-04 | global batch size:    64 | lm loss: 3.342708E+00 | loss scale: 1048576.0 | grad norm: 0.401 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 13:04:06] iteration    54300/  500000 | consumed samples:      3475200 | elapsed time per iteration (ms): 618.6 | learning rate: 1.412284E-04 | global batch size:    64 | lm loss: 3.363549E+00 | loss scale: 2097152.0 | grad norm: 0.402 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 13:05:08] iteration    54400/  500000 | consumed samples:      3481600 | elapsed time per iteration (ms): 618.3 | learning rate: 1.411948E-04 | global batch size:    64 | lm loss: 3.351208E+00 | loss scale: 2097152.0 | grad norm: 0.402 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 13:06:10] iteration    54500/  500000 | consumed samples:      3488000 | elapsed time per iteration (ms): 619.5 | learning rate: 1.411614E-04 | global batch size:    64 | lm loss: 3.365733E+00 | loss scale: 2097152.0 | grad norm: 0.394 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-24 13:07:12] iteration    54600/  500000 | consumed samples:      3494400 | elapsed time per iteration (ms): 619.4 | learning rate: 1.411279E-04 | global batch size:    64 | lm loss: 3.354088E+00 | loss scale: 1048576.0 | grad norm: 0.385 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-24 13:08:14] iteration    54700/  500000 | consumed samples:      3500800 | elapsed time per iteration (ms): 619.2 | learning rate: 1.410940E-04 | global batch size:    64 | lm loss: 3.325169E+00 | loss scale: 1048576.0 | grad norm: 0.413 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 13:09:16] iteration    54800/  500000 | consumed samples:      3507200 | elapsed time per iteration (ms): 619.5 | learning rate: 1.410601E-04 | global batch size:    64 | lm loss: 3.345864E+00 | loss scale: 1048576.0 | grad norm: 0.394 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 13:10:18] iteration    54900/  500000 | consumed samples:      3513600 | elapsed time per iteration (ms): 620.2 | learning rate: 1.410262E-04 | global batch size:    64 | lm loss: 3.338452E+00 | loss scale: 1048576.0 | grad norm: 0.390 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 13:11:20] iteration    55000/  500000 | consumed samples:      3520000 | elapsed time per iteration (ms): 620.6 | learning rate: 1.409921E-04 | global batch size:    64 | lm loss: 3.338037E+00 | loss scale: 1048576.0 | grad norm: 0.404 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2461.41, 2461.53)
-------------------------------------------------------------------------------------------------
 validation loss at iteration 55000 | lm loss value: 3.709514E+00 | lm loss PPL: 4.083395E+01 | 
-------------------------------------------------------------------------------------------------
 [2024-06-24 13:12:24] iteration    55100/  500000 | consumed samples:      3526400 | elapsed time per iteration (ms): 619.6 | learning rate: 1.409580E-04 | global batch size:    64 | lm loss: 3.349256E+00 | loss scale: 1048576.0 | grad norm: 0.402 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 13:13:26] iteration    55200/  500000 | consumed samples:      3532800 | elapsed time per iteration (ms): 619.5 | learning rate: 1.409239E-04 | global batch size:    64 | lm loss: 3.342051E+00 | loss scale: 1048576.0 | grad norm: 0.411 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 13:14:28] iteration    55300/  500000 | consumed samples:      3539200 | elapsed time per iteration (ms): 617.7 | learning rate: 1.408897E-04 | global batch size:    64 | lm loss: 3.344934E+00 | loss scale: 1048576.0 | grad norm: 0.400 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 13:15:30] iteration    55400/  500000 | consumed samples:      3545600 | elapsed time per iteration (ms): 619.4 | learning rate: 1.408554E-04 | global batch size:    64 | lm loss: 3.344124E+00 | loss scale: 1048576.0 | grad norm: 0.387 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 13:16:32] iteration    55500/  500000 | consumed samples:      3552000 | elapsed time per iteration (ms): 618.7 | learning rate: 1.408211E-04 | global batch size:    64 | lm loss: 3.324151E+00 | loss scale: 1048576.0 | grad norm: 0.379 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 13:17:34] iteration    55600/  500000 | consumed samples:      3558400 | elapsed time per iteration (ms): 618.4 | learning rate: 1.407867E-04 | global batch size:    64 | lm loss: 3.332871E+00 | loss scale: 2097152.0 | grad norm: 0.406 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 13:18:36] iteration    55700/  500000 | consumed samples:      3564800 | elapsed time per iteration (ms): 620.6 | learning rate: 1.407522E-04 | global batch size:    64 | lm loss: 3.359385E+00 | loss scale: 2097152.0 | grad norm: 0.407 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 13:19:37] iteration    55800/  500000 | consumed samples:      3571200 | elapsed time per iteration (ms): 618.3 | learning rate: 1.407177E-04 | global batch size:    64 | lm loss: 3.356330E+00 | loss scale: 2097152.0 | grad norm: 0.391 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 13:20:39] iteration    55900/  500000 | consumed samples:      3577600 | elapsed time per iteration (ms): 620.1 | learning rate: 1.406831E-04 | global batch size:    64 | lm loss: 3.344609E+00 | loss scale: 2097152.0 | grad norm: 0.411 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 13:21:41] iteration    56000/  500000 | consumed samples:      3584000 | elapsed time per iteration (ms): 619.2 | learning rate: 1.406485E-04 | global batch size:    64 | lm loss: 3.346159E+00 | loss scale: 2097152.0 | grad norm: 0.387 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2461.79, 2461.91)
-------------------------------------------------------------------------------------------------
 validation loss at iteration 56000 | lm loss value: 3.640573E+00 | lm loss PPL: 3.811368E+01 | 
-------------------------------------------------------------------------------------------------
 [2024-06-24 13:22:46] iteration    56100/  500000 | consumed samples:      3590400 | elapsed time per iteration (ms): 619.4 | learning rate: 1.406138E-04 | global batch size:    64 | lm loss: 3.332375E+00 | loss scale: 2097152.0 | grad norm: 0.388 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 13:23:48] iteration    56200/  500000 | consumed samples:      3596800 | elapsed time per iteration (ms): 619.3 | learning rate: 1.405790E-04 | global batch size:    64 | lm loss: 3.340060E+00 | loss scale: 2097152.0 | grad norm: 0.381 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 13:24:49] iteration    56300/  500000 | consumed samples:      3603200 | elapsed time per iteration (ms): 617.6 | learning rate: 1.405442E-04 | global batch size:    64 | lm loss: 3.327814E+00 | loss scale: 2097152.0 | grad norm: 0.400 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 13:25:51] iteration    56400/  500000 | consumed samples:      3609600 | elapsed time per iteration (ms): 619.4 | learning rate: 1.405094E-04 | global batch size:    64 | lm loss: 3.335691E+00 | loss scale: 2097152.0 | grad norm: 0.393 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 13:26:53] iteration    56500/  500000 | consumed samples:      3616000 | elapsed time per iteration (ms): 619.0 | learning rate: 1.404744E-04 | global batch size:    64 | lm loss: 3.345461E+00 | loss scale: 2097152.0 | grad norm: 0.393 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 13:27:55] iteration    56600/  500000 | consumed samples:      3622400 | elapsed time per iteration (ms): 619.1 | learning rate: 1.404394E-04 | global batch size:    64 | lm loss: 3.332748E+00 | loss scale: 4194304.0 | grad norm: 0.406 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 13:28:57] iteration    56700/  500000 | consumed samples:      3628800 | elapsed time per iteration (ms): 618.6 | learning rate: 1.404044E-04 | global batch size:    64 | lm loss: 3.328419E+00 | loss scale: 4194304.0 | grad norm: 0.415 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 13:29:59] iteration    56800/  500000 | consumed samples:      3635200 | elapsed time per iteration (ms): 618.6 | learning rate: 1.403700E-04 | global batch size:    64 | lm loss: 3.322501E+00 | loss scale: 2097152.0 | grad norm: 0.407 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-24 13:31:01] iteration    56900/  500000 | consumed samples:      3641600 | elapsed time per iteration (ms): 619.0 | learning rate: 1.403348E-04 | global batch size:    64 | lm loss: 3.327219E+00 | loss scale: 2097152.0 | grad norm: 0.398 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 13:32:03] iteration    57000/  500000 | consumed samples:      3648000 | elapsed time per iteration (ms): 619.0 | learning rate: 1.402996E-04 | global batch size:    64 | lm loss: 3.323214E+00 | loss scale: 2097152.0 | grad norm: 0.404 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2465.13, 2465.13)
-------------------------------------------------------------------------------------------------
 validation loss at iteration 57000 | lm loss value: 3.704084E+00 | lm loss PPL: 4.061285E+01 | 
-------------------------------------------------------------------------------------------------
 [2024-06-24 13:33:07] iteration    57100/  500000 | consumed samples:      3654400 | elapsed time per iteration (ms): 620.1 | learning rate: 1.402643E-04 | global batch size:    64 | lm loss: 3.310216E+00 | loss scale: 2097152.0 | grad norm: 0.392 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 13:34:09] iteration    57200/  500000 | consumed samples:      3660800 | elapsed time per iteration (ms): 620.0 | learning rate: 1.402293E-04 | global batch size:    64 | lm loss: 3.337508E+00 | loss scale: 1048576.0 | grad norm: 0.399 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-24 13:35:11] iteration    57300/  500000 | consumed samples:      3667200 | elapsed time per iteration (ms): 616.6 | learning rate: 1.401939E-04 | global batch size:    64 | lm loss: 3.327787E+00 | loss scale: 1048576.0 | grad norm: 0.389 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 13:36:13] iteration    57400/  500000 | consumed samples:      3673600 | elapsed time per iteration (ms): 618.7 | learning rate: 1.401584E-04 | global batch size:    64 | lm loss: 3.330502E+00 | loss scale: 1048576.0 | grad norm: 0.415 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 13:37:14] iteration    57500/  500000 | consumed samples:      3680000 | elapsed time per iteration (ms): 617.1 | learning rate: 1.401229E-04 | global batch size:    64 | lm loss: 3.324450E+00 | loss scale: 1048576.0 | grad norm: 0.395 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 13:38:16] iteration    57600/  500000 | consumed samples:      3686400 | elapsed time per iteration (ms): 618.2 | learning rate: 1.400873E-04 | global batch size:    64 | lm loss: 3.337433E+00 | loss scale: 1048576.0 | grad norm: 0.394 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 13:39:18] iteration    57700/  500000 | consumed samples:      3692800 | elapsed time per iteration (ms): 621.8 | learning rate: 1.400517E-04 | global batch size:    64 | lm loss: 3.336436E+00 | loss scale: 1048576.0 | grad norm: 0.406 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 13:40:21] iteration    57800/  500000 | consumed samples:      3699200 | elapsed time per iteration (ms): 621.1 | learning rate: 1.400160E-04 | global batch size:    64 | lm loss: 3.331408E+00 | loss scale: 1048576.0 | grad norm: 0.400 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 13:41:22] iteration    57900/  500000 | consumed samples:      3705600 | elapsed time per iteration (ms): 619.1 | learning rate: 1.399802E-04 | global batch size:    64 | lm loss: 3.336653E+00 | loss scale: 1048576.0 | grad norm: 0.394 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 13:42:24] iteration    58000/  500000 | consumed samples:      3712000 | elapsed time per iteration (ms): 620.6 | learning rate: 1.399444E-04 | global batch size:    64 | lm loss: 3.342601E+00 | loss scale: 1048576.0 | grad norm: 0.410 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2462.01, 2462.10)
-------------------------------------------------------------------------------------------------
 validation loss at iteration 58000 | lm loss value: 3.671633E+00 | lm loss PPL: 3.931604E+01 | 
-------------------------------------------------------------------------------------------------
 [2024-06-24 13:43:29] iteration    58100/  500000 | consumed samples:      3718400 | elapsed time per iteration (ms): 618.3 | learning rate: 1.399086E-04 | global batch size:    64 | lm loss: 3.332300E+00 | loss scale: 1048576.0 | grad norm: 0.409 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 13:44:31] iteration    58200/  500000 | consumed samples:      3724800 | elapsed time per iteration (ms): 619.2 | learning rate: 1.398726E-04 | global batch size:    64 | lm loss: 3.325938E+00 | loss scale: 2097152.0 | grad norm: 0.402 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 13:45:33] iteration    58300/  500000 | consumed samples:      3731200 | elapsed time per iteration (ms): 621.6 | learning rate: 1.398366E-04 | global batch size:    64 | lm loss: 3.322825E+00 | loss scale: 2097152.0 | grad norm: 0.394 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 13:46:35] iteration    58400/  500000 | consumed samples:      3737600 | elapsed time per iteration (ms): 618.4 | learning rate: 1.398013E-04 | global batch size:    64 | lm loss: 3.325561E+00 | loss scale: 1048576.0 | grad norm: 0.399 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-24 13:47:37] iteration    58500/  500000 | consumed samples:      3744000 | elapsed time per iteration (ms): 620.3 | learning rate: 1.397652E-04 | global batch size:    64 | lm loss: 3.335104E+00 | loss scale: 1048576.0 | grad norm: 0.401 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 13:48:39] iteration    58600/  500000 | consumed samples:      3750400 | elapsed time per iteration (ms): 620.7 | learning rate: 1.397290E-04 | global batch size:    64 | lm loss: 3.324105E+00 | loss scale: 1048576.0 | grad norm: 0.406 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 13:49:41] iteration    58700/  500000 | consumed samples:      3756800 | elapsed time per iteration (ms): 619.7 | learning rate: 1.396928E-04 | global batch size:    64 | lm loss: 3.321682E+00 | loss scale: 1048576.0 | grad norm: 0.402 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 13:50:43] iteration    58800/  500000 | consumed samples:      3763200 | elapsed time per iteration (ms): 618.6 | learning rate: 1.396565E-04 | global batch size:    64 | lm loss: 3.336399E+00 | loss scale: 1048576.0 | grad norm: 0.404 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 13:51:45] iteration    58900/  500000 | consumed samples:      3769600 | elapsed time per iteration (ms): 619.5 | learning rate: 1.396202E-04 | global batch size:    64 | lm loss: 3.323198E+00 | loss scale: 1048576.0 | grad norm: 0.409 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 13:52:46] iteration    59000/  500000 | consumed samples:      3776000 | elapsed time per iteration (ms): 618.4 | learning rate: 1.395838E-04 | global batch size:    64 | lm loss: 3.327661E+00 | loss scale: 1048576.0 | grad norm: 0.401 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2461.74, 2461.86)
-------------------------------------------------------------------------------------------------
 validation loss at iteration 59000 | lm loss value: 3.659223E+00 | lm loss PPL: 3.883115E+01 | 
-------------------------------------------------------------------------------------------------
 [2024-06-24 13:53:51] iteration    59100/  500000 | consumed samples:      3782400 | elapsed time per iteration (ms): 618.2 | learning rate: 1.395473E-04 | global batch size:    64 | lm loss: 3.329020E+00 | loss scale: 1048576.0 | grad norm: 0.404 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 13:54:52] iteration    59200/  500000 | consumed samples:      3788800 | elapsed time per iteration (ms): 617.3 | learning rate: 1.395108E-04 | global batch size:    64 | lm loss: 3.312068E+00 | loss scale: 1048576.0 | grad norm: 0.390 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 13:55:54] iteration    59300/  500000 | consumed samples:      3795200 | elapsed time per iteration (ms): 617.1 | learning rate: 1.394742E-04 | global batch size:    64 | lm loss: 3.343492E+00 | loss scale: 1048576.0 | grad norm: 0.391 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 13:56:56] iteration    59400/  500000 | consumed samples:      3801600 | elapsed time per iteration (ms): 617.9 | learning rate: 1.394376E-04 | global batch size:    64 | lm loss: 3.328775E+00 | loss scale: 2097152.0 | grad norm: 0.396 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 13:57:58] iteration    59500/  500000 | consumed samples:      3808000 | elapsed time per iteration (ms): 619.6 | learning rate: 1.394009E-04 | global batch size:    64 | lm loss: 3.324330E+00 | loss scale: 2097152.0 | grad norm: 0.395 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 13:59:00] iteration    59600/  500000 | consumed samples:      3814400 | elapsed time per iteration (ms): 618.0 | learning rate: 1.393641E-04 | global batch size:    64 | lm loss: 3.331778E+00 | loss scale: 2097152.0 | grad norm: 0.397 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 14:00:02] iteration    59700/  500000 | consumed samples:      3820800 | elapsed time per iteration (ms): 618.2 | learning rate: 1.393273E-04 | global batch size:    64 | lm loss: 3.311942E+00 | loss scale: 2097152.0 | grad norm: 0.394 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 14:01:04] iteration    59800/  500000 | consumed samples:      3827200 | elapsed time per iteration (ms): 620.6 | learning rate: 1.392908E-04 | global batch size:    64 | lm loss: 3.310718E+00 | loss scale: 2097152.0 | grad norm: 0.392 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-24 14:02:05] iteration    59900/  500000 | consumed samples:      3833600 | elapsed time per iteration (ms): 617.2 | learning rate: 1.392539E-04 | global batch size:    64 | lm loss: 3.306686E+00 | loss scale: 2097152.0 | grad norm: 0.403 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 14:03:07] iteration    60000/  500000 | consumed samples:      3840000 | elapsed time per iteration (ms): 620.1 | learning rate: 1.392169E-04 | global batch size:    64 | lm loss: 3.323702E+00 | loss scale: 2097152.0 | grad norm: 0.398 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2462.73, 2462.94)
-------------------------------------------------------------------------------------------------
 validation loss at iteration 60000 | lm loss value: 3.687338E+00 | lm loss PPL: 3.993837E+01 | 
-------------------------------------------------------------------------------------------------
saving checkpoint at iteration   60000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-distribution in torch format
  successfully saved checkpoint at iteration   60000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-distribution
(min, max) time across ranks (ms):
    save-checkpoint ................................: (2246.26, 2246.27)
 [2024-06-24 14:04:14] iteration    60100/  500000 | consumed samples:      3846400 | elapsed time per iteration (ms): 619.1 | learning rate: 1.391798E-04 | global batch size:    64 | lm loss: 3.322657E+00 | loss scale: 2097152.0 | grad norm: 0.397 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 14:05:16] iteration    60200/  500000 | consumed samples:      3852800 | elapsed time per iteration (ms): 618.0 | learning rate: 1.391431E-04 | global batch size:    64 | lm loss: 3.317612E+00 | loss scale: 1048576.0 | grad norm: 0.400 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-24 14:06:18] iteration    60300/  500000 | consumed samples:      3859200 | elapsed time per iteration (ms): 617.7 | learning rate: 1.391059E-04 | global batch size:    64 | lm loss: 3.319527E+00 | loss scale: 1048576.0 | grad norm: 0.409 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 14:07:19] iteration    60400/  500000 | consumed samples:      3865600 | elapsed time per iteration (ms): 617.8 | learning rate: 1.390687E-04 | global batch size:    64 | lm loss: 3.320484E+00 | loss scale: 1048576.0 | grad norm: 0.404 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 14:08:21] iteration    60500/  500000 | consumed samples:      3872000 | elapsed time per iteration (ms): 620.4 | learning rate: 1.390314E-04 | global batch size:    64 | lm loss: 3.322491E+00 | loss scale: 1048576.0 | grad norm: 0.389 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 14:09:23] iteration    60600/  500000 | consumed samples:      3878400 | elapsed time per iteration (ms): 618.5 | learning rate: 1.389941E-04 | global batch size:    64 | lm loss: 3.330630E+00 | loss scale: 1048576.0 | grad norm: 0.403 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 14:10:25] iteration    60700/  500000 | consumed samples:      3884800 | elapsed time per iteration (ms): 617.8 | learning rate: 1.389567E-04 | global batch size:    64 | lm loss: 3.315557E+00 | loss scale: 1048576.0 | grad norm: 0.400 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 14:11:27] iteration    60800/  500000 | consumed samples:      3891200 | elapsed time per iteration (ms): 618.5 | learning rate: 1.389193E-04 | global batch size:    64 | lm loss: 3.311012E+00 | loss scale: 1048576.0 | grad norm: 0.406 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 14:12:29] iteration    60900/  500000 | consumed samples:      3897600 | elapsed time per iteration (ms): 618.9 | learning rate: 1.388817E-04 | global batch size:    64 | lm loss: 3.311959E+00 | loss scale: 1048576.0 | grad norm: 0.406 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 14:13:30] iteration    61000/  500000 | consumed samples:      3904000 | elapsed time per iteration (ms): 618.0 | learning rate: 1.388442E-04 | global batch size:    64 | lm loss: 3.325459E+00 | loss scale: 1048576.0 | grad norm: 0.412 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2461.73, 2461.83)
-------------------------------------------------------------------------------------------------
 validation loss at iteration 61000 | lm loss value: 3.705153E+00 | lm loss PPL: 4.065628E+01 | 
-------------------------------------------------------------------------------------------------
 [2024-06-24 14:14:35] iteration    61100/  500000 | consumed samples:      3910400 | elapsed time per iteration (ms): 618.4 | learning rate: 1.388065E-04 | global batch size:    64 | lm loss: 3.333912E+00 | loss scale: 1048576.0 | grad norm: 0.405 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 14:15:37] iteration    61200/  500000 | consumed samples:      3916800 | elapsed time per iteration (ms): 619.4 | learning rate: 1.387689E-04 | global batch size:    64 | lm loss: 3.314703E+00 | loss scale: 2097152.0 | grad norm: 0.392 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 14:16:39] iteration    61300/  500000 | consumed samples:      3923200 | elapsed time per iteration (ms): 620.7 | learning rate: 1.387311E-04 | global batch size:    64 | lm loss: 3.322658E+00 | loss scale: 2097152.0 | grad norm: 0.409 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 14:17:41] iteration    61400/  500000 | consumed samples:      3929600 | elapsed time per iteration (ms): 618.5 | learning rate: 1.386933E-04 | global batch size:    64 | lm loss: 3.309672E+00 | loss scale: 2097152.0 | grad norm: 0.405 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 14:18:43] iteration    61500/  500000 | consumed samples:      3936000 | elapsed time per iteration (ms): 619.1 | learning rate: 1.386558E-04 | global batch size:    64 | lm loss: 3.294416E+00 | loss scale: 2097152.0 | grad norm: 0.409 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-24 14:19:45] iteration    61600/  500000 | consumed samples:      3942400 | elapsed time per iteration (ms): 620.1 | learning rate: 1.386179E-04 | global batch size:    64 | lm loss: 3.307227E+00 | loss scale: 2097152.0 | grad norm: 0.399 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 14:20:47] iteration    61700/  500000 | consumed samples:      3948800 | elapsed time per iteration (ms): 619.3 | learning rate: 1.385800E-04 | global batch size:    64 | lm loss: 3.305116E+00 | loss scale: 2097152.0 | grad norm: 0.397 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 14:21:49] iteration    61800/  500000 | consumed samples:      3955200 | elapsed time per iteration (ms): 620.4 | learning rate: 1.385419E-04 | global batch size:    64 | lm loss: 3.317818E+00 | loss scale: 2097152.0 | grad norm: 0.399 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 14:22:51] iteration    61900/  500000 | consumed samples:      3961600 | elapsed time per iteration (ms): 619.7 | learning rate: 1.385038E-04 | global batch size:    64 | lm loss: 3.315421E+00 | loss scale: 2097152.0 | grad norm: 0.397 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 14:23:52] iteration    62000/  500000 | consumed samples:      3968000 | elapsed time per iteration (ms): 619.3 | learning rate: 1.384657E-04 | global batch size:    64 | lm loss: 3.319566E+00 | loss scale: 2097152.0 | grad norm: 0.404 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2462.89, 2462.92)
-------------------------------------------------------------------------------------------------
 validation loss at iteration 62000 | lm loss value: 3.666321E+00 | lm loss PPL: 3.910776E+01 | 
-------------------------------------------------------------------------------------------------
 [2024-06-24 14:24:57] iteration    62100/  500000 | consumed samples:      3974400 | elapsed time per iteration (ms): 618.4 | learning rate: 1.384275E-04 | global batch size:    64 | lm loss: 3.311137E+00 | loss scale: 2097152.0 | grad norm: 0.400 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 14:25:59] iteration    62200/  500000 | consumed samples:      3980800 | elapsed time per iteration (ms): 620.4 | learning rate: 1.383896E-04 | global batch size:    64 | lm loss: 3.315256E+00 | loss scale: 1048576.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-24 14:27:01] iteration    62300/  500000 | consumed samples:      3987200 | elapsed time per iteration (ms): 620.5 | learning rate: 1.383513E-04 | global batch size:    64 | lm loss: 3.318811E+00 | loss scale: 1048576.0 | grad norm: 0.403 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 14:28:03] iteration    62400/  500000 | consumed samples:      3993600 | elapsed time per iteration (ms): 618.6 | learning rate: 1.383129E-04 | global batch size:    64 | lm loss: 3.304539E+00 | loss scale: 1048576.0 | grad norm: 0.402 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 14:29:05] iteration    62500/  500000 | consumed samples:      4000000 | elapsed time per iteration (ms): 621.9 | learning rate: 1.382745E-04 | global batch size:    64 | lm loss: 3.309483E+00 | loss scale: 1048576.0 | grad norm: 0.397 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 14:30:07] iteration    62600/  500000 | consumed samples:      4006400 | elapsed time per iteration (ms): 621.9 | learning rate: 1.382360E-04 | global batch size:    64 | lm loss: 3.322117E+00 | loss scale: 1048576.0 | grad norm: 0.389 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 14:31:09] iteration    62700/  500000 | consumed samples:      4012800 | elapsed time per iteration (ms): 621.2 | learning rate: 1.381975E-04 | global batch size:    64 | lm loss: 3.312109E+00 | loss scale: 1048576.0 | grad norm: 0.406 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 14:32:11] iteration    62800/  500000 | consumed samples:      4019200 | elapsed time per iteration (ms): 618.8 | learning rate: 1.381589E-04 | global batch size:    64 | lm loss: 3.308028E+00 | loss scale: 1048576.0 | grad norm: 0.391 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 14:33:13] iteration    62900/  500000 | consumed samples:      4025600 | elapsed time per iteration (ms): 620.4 | learning rate: 1.381202E-04 | global batch size:    64 | lm loss: 3.300049E+00 | loss scale: 1048576.0 | grad norm: 0.384 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 14:34:15] iteration    63000/  500000 | consumed samples:      4032000 | elapsed time per iteration (ms): 620.5 | learning rate: 1.380815E-04 | global batch size:    64 | lm loss: 3.294763E+00 | loss scale: 1048576.0 | grad norm: 0.406 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2464.05, 2464.11)
-------------------------------------------------------------------------------------------------
 validation loss at iteration 63000 | lm loss value: 3.707191E+00 | lm loss PPL: 4.073920E+01 | 
-------------------------------------------------------------------------------------------------
 [2024-06-24 14:35:20] iteration    63100/  500000 | consumed samples:      4038400 | elapsed time per iteration (ms): 618.7 | learning rate: 1.380427E-04 | global batch size:    64 | lm loss: 3.303167E+00 | loss scale: 1048576.0 | grad norm: 0.410 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 14:36:21] iteration    63200/  500000 | consumed samples:      4044800 | elapsed time per iteration (ms): 617.8 | learning rate: 1.380039E-04 | global batch size:    64 | lm loss: 3.300245E+00 | loss scale: 2097152.0 | grad norm: 0.385 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 14:37:23] iteration    63300/  500000 | consumed samples:      4051200 | elapsed time per iteration (ms): 619.1 | learning rate: 1.379650E-04 | global batch size:    64 | lm loss: 3.307049E+00 | loss scale: 2097152.0 | grad norm: 0.384 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 14:38:25] iteration    63400/  500000 | consumed samples:      4057600 | elapsed time per iteration (ms): 619.8 | learning rate: 1.379261E-04 | global batch size:    64 | lm loss: 3.314125E+00 | loss scale: 2097152.0 | grad norm: 0.390 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 14:39:27] iteration    63500/  500000 | consumed samples:      4064000 | elapsed time per iteration (ms): 619.1 | learning rate: 1.378871E-04 | global batch size:    64 | lm loss: 3.312892E+00 | loss scale: 2097152.0 | grad norm: 0.401 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 14:40:29] iteration    63600/  500000 | consumed samples:      4070400 | elapsed time per iteration (ms): 620.4 | learning rate: 1.378480E-04 | global batch size:    64 | lm loss: 3.313051E+00 | loss scale: 2097152.0 | grad norm: 0.396 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 14:41:31] iteration    63700/  500000 | consumed samples:      4076800 | elapsed time per iteration (ms): 618.7 | learning rate: 1.378089E-04 | global batch size:    64 | lm loss: 3.292596E+00 | loss scale: 2097152.0 | grad norm: 0.397 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 14:42:33] iteration    63800/  500000 | consumed samples:      4083200 | elapsed time per iteration (ms): 620.0 | learning rate: 1.377697E-04 | global batch size:    64 | lm loss: 3.298248E+00 | loss scale: 2097152.0 | grad norm: 0.411 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 14:43:35] iteration    63900/  500000 | consumed samples:      4089600 | elapsed time per iteration (ms): 618.1 | learning rate: 1.377309E-04 | global batch size:    64 | lm loss: 3.302488E+00 | loss scale: 2097152.0 | grad norm: 0.394 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-24 14:44:37] iteration    64000/  500000 | consumed samples:      4096000 | elapsed time per iteration (ms): 618.6 | learning rate: 1.376916E-04 | global batch size:    64 | lm loss: 3.320874E+00 | loss scale: 2097152.0 | grad norm: 0.397 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2462.27, 2462.37)
-------------------------------------------------------------------------------------------------
 validation loss at iteration 64000 | lm loss value: 3.620942E+00 | lm loss PPL: 3.737277E+01 | 
-------------------------------------------------------------------------------------------------
 [2024-06-24 14:45:41] iteration    64100/  500000 | consumed samples:      4102400 | elapsed time per iteration (ms): 621.2 | learning rate: 1.376526E-04 | global batch size:    64 | lm loss: 3.314920E+00 | loss scale: 1048576.0 | grad norm: 0.395 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-24 14:46:43] iteration    64200/  500000 | consumed samples:      4108800 | elapsed time per iteration (ms): 620.4 | learning rate: 1.376132E-04 | global batch size:    64 | lm loss: 3.289903E+00 | loss scale: 1048576.0 | grad norm: 0.409 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 14:47:46] iteration    64300/  500000 | consumed samples:      4115200 | elapsed time per iteration (ms): 622.5 | learning rate: 1.375738E-04 | global batch size:    64 | lm loss: 3.297175E+00 | loss scale: 1048576.0 | grad norm: 0.419 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 14:48:48] iteration    64400/  500000 | consumed samples:      4121600 | elapsed time per iteration (ms): 624.1 | learning rate: 1.375343E-04 | global batch size:    64 | lm loss: 3.299536E+00 | loss scale: 1048576.0 | grad norm: 0.385 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 14:49:50] iteration    64500/  500000 | consumed samples:      4128000 | elapsed time per iteration (ms): 620.2 | learning rate: 1.374947E-04 | global batch size:    64 | lm loss: 3.301458E+00 | loss scale: 1048576.0 | grad norm: 0.387 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 14:50:52] iteration    64600/  500000 | consumed samples:      4134400 | elapsed time per iteration (ms): 619.1 | learning rate: 1.374551E-04 | global batch size:    64 | lm loss: 3.306389E+00 | loss scale: 1048576.0 | grad norm: 0.397 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 14:51:54] iteration    64700/  500000 | consumed samples:      4140800 | elapsed time per iteration (ms): 619.0 | learning rate: 1.374154E-04 | global batch size:    64 | lm loss: 3.309315E+00 | loss scale: 1048576.0 | grad norm: 0.400 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 14:52:56] iteration    64800/  500000 | consumed samples:      4147200 | elapsed time per iteration (ms): 618.9 | learning rate: 1.373757E-04 | global batch size:    64 | lm loss: 3.293542E+00 | loss scale: 1048576.0 | grad norm: 0.417 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 14:53:58] iteration    64900/  500000 | consumed samples:      4153600 | elapsed time per iteration (ms): 619.2 | learning rate: 1.373359E-04 | global batch size:    64 | lm loss: 3.303140E+00 | loss scale: 1048576.0 | grad norm: 0.408 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 14:54:59] iteration    65000/  500000 | consumed samples:      4160000 | elapsed time per iteration (ms): 617.7 | learning rate: 1.372960E-04 | global batch size:    64 | lm loss: 3.307224E+00 | loss scale: 1048576.0 | grad norm: 0.405 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2465.21, 2465.34)
-------------------------------------------------------------------------------------------------
 validation loss at iteration 65000 | lm loss value: 3.724456E+00 | lm loss PPL: 4.144868E+01 | 
-------------------------------------------------------------------------------------------------
 [2024-06-24 14:56:04] iteration    65100/  500000 | consumed samples:      4166400 | elapsed time per iteration (ms): 620.1 | learning rate: 1.372565E-04 | global batch size:    64 | lm loss: 3.285579E+00 | loss scale: 2097152.0 | grad norm: 0.391 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-24 14:57:06] iteration    65200/  500000 | consumed samples:      4172800 | elapsed time per iteration (ms): 618.1 | learning rate: 1.372165E-04 | global batch size:    64 | lm loss: 3.291900E+00 | loss scale: 2097152.0 | grad norm: 0.387 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 14:58:08] iteration    65300/  500000 | consumed samples:      4179200 | elapsed time per iteration (ms): 620.6 | learning rate: 1.371765E-04 | global batch size:    64 | lm loss: 3.301494E+00 | loss scale: 2097152.0 | grad norm: 0.403 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 14:59:10] iteration    65400/  500000 | consumed samples:      4185600 | elapsed time per iteration (ms): 620.0 | learning rate: 1.371364E-04 | global batch size:    64 | lm loss: 3.309922E+00 | loss scale: 2097152.0 | grad norm: 0.394 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 15:00:12] iteration    65500/  500000 | consumed samples:      4192000 | elapsed time per iteration (ms): 619.2 | learning rate: 1.370963E-04 | global batch size:    64 | lm loss: 3.304994E+00 | loss scale: 2097152.0 | grad norm: 0.392 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 15:01:14] iteration    65600/  500000 | consumed samples:      4198400 | elapsed time per iteration (ms): 619.7 | learning rate: 1.370561E-04 | global batch size:    64 | lm loss: 3.309041E+00 | loss scale: 2097152.0 | grad norm: 0.385 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 15:02:15] iteration    65700/  500000 | consumed samples:      4204800 | elapsed time per iteration (ms): 616.2 | learning rate: 1.370159E-04 | global batch size:    64 | lm loss: 3.296502E+00 | loss scale: 2097152.0 | grad norm: 0.395 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 15:03:17] iteration    65800/  500000 | consumed samples:      4211200 | elapsed time per iteration (ms): 619.9 | learning rate: 1.369756E-04 | global batch size:    64 | lm loss: 3.288366E+00 | loss scale: 2097152.0 | grad norm: 0.412 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 15:04:19] iteration    65900/  500000 | consumed samples:      4217600 | elapsed time per iteration (ms): 620.3 | learning rate: 1.369356E-04 | global batch size:    64 | lm loss: 3.302634E+00 | loss scale: 1048576.0 | grad norm: 0.399 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-24 15:05:21] iteration    66000/  500000 | consumed samples:      4224000 | elapsed time per iteration (ms): 618.1 | learning rate: 1.368952E-04 | global batch size:    64 | lm loss: 3.304868E+00 | loss scale: 1048576.0 | grad norm: 0.385 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2463.00, 2463.10)
-------------------------------------------------------------------------------------------------
 validation loss at iteration 66000 | lm loss value: 3.683392E+00 | lm loss PPL: 3.978111E+01 | 
-------------------------------------------------------------------------------------------------
 [2024-06-24 15:06:26] iteration    66100/  500000 | consumed samples:      4230400 | elapsed time per iteration (ms): 620.6 | learning rate: 1.368548E-04 | global batch size:    64 | lm loss: 3.310735E+00 | loss scale: 1048576.0 | grad norm: 0.399 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 15:07:27] iteration    66200/  500000 | consumed samples:      4236800 | elapsed time per iteration (ms): 619.0 | learning rate: 1.368146E-04 | global batch size:    64 | lm loss: 3.301309E+00 | loss scale: 524288.0 | grad norm: 0.392 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-24 15:08:29] iteration    66300/  500000 | consumed samples:      4243200 | elapsed time per iteration (ms): 618.6 | learning rate: 1.367741E-04 | global batch size:    64 | lm loss: 3.291622E+00 | loss scale: 524288.0 | grad norm: 0.386 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 15:09:31] iteration    66400/  500000 | consumed samples:      4249600 | elapsed time per iteration (ms): 618.7 | learning rate: 1.367334E-04 | global batch size:    64 | lm loss: 3.297221E+00 | loss scale: 524288.0 | grad norm: 0.409 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 15:10:33] iteration    66500/  500000 | consumed samples:      4256000 | elapsed time per iteration (ms): 619.9 | learning rate: 1.366927E-04 | global batch size:    64 | lm loss: 3.296516E+00 | loss scale: 524288.0 | grad norm: 0.397 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 15:11:35] iteration    66600/  500000 | consumed samples:      4262400 | elapsed time per iteration (ms): 618.1 | learning rate: 1.366520E-04 | global batch size:    64 | lm loss: 3.300852E+00 | loss scale: 524288.0 | grad norm: 0.386 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 15:12:37] iteration    66700/  500000 | consumed samples:      4268800 | elapsed time per iteration (ms): 620.7 | learning rate: 1.366112E-04 | global batch size:    64 | lm loss: 3.290709E+00 | loss scale: 524288.0 | grad norm: 0.392 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 15:13:39] iteration    66800/  500000 | consumed samples:      4275200 | elapsed time per iteration (ms): 620.9 | learning rate: 1.365703E-04 | global batch size:    64 | lm loss: 3.297142E+00 | loss scale: 524288.0 | grad norm: 0.405 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 15:14:41] iteration    66900/  500000 | consumed samples:      4281600 | elapsed time per iteration (ms): 620.5 | learning rate: 1.365294E-04 | global batch size:    64 | lm loss: 3.295205E+00 | loss scale: 524288.0 | grad norm: 0.404 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 15:15:43] iteration    67000/  500000 | consumed samples:      4288000 | elapsed time per iteration (ms): 618.8 | learning rate: 1.364885E-04 | global batch size:    64 | lm loss: 3.289431E+00 | loss scale: 524288.0 | grad norm: 0.404 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2465.69, 2465.98)
-------------------------------------------------------------------------------------------------
 validation loss at iteration 67000 | lm loss value: 3.680211E+00 | lm loss PPL: 3.965475E+01 | 
-------------------------------------------------------------------------------------------------
 [2024-06-24 15:16:48] iteration    67100/  500000 | consumed samples:      4294400 | elapsed time per iteration (ms): 623.9 | learning rate: 1.364474E-04 | global batch size:    64 | lm loss: 3.287326E+00 | loss scale: 524288.0 | grad norm: 0.387 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 15:17:50] iteration    67200/  500000 | consumed samples:      4300800 | elapsed time per iteration (ms): 619.7 | learning rate: 1.364063E-04 | global batch size:    64 | lm loss: 3.283571E+00 | loss scale: 1048576.0 | grad norm: 0.432 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 15:18:52] iteration    67300/  500000 | consumed samples:      4307200 | elapsed time per iteration (ms): 619.4 | learning rate: 1.363652E-04 | global batch size:    64 | lm loss: 3.289576E+00 | loss scale: 1048576.0 | grad norm: 0.402 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 15:19:54] iteration    67400/  500000 | consumed samples:      4313600 | elapsed time per iteration (ms): 618.8 | learning rate: 1.363240E-04 | global batch size:    64 | lm loss: 3.293507E+00 | loss scale: 1048576.0 | grad norm: 0.412 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 15:20:56] iteration    67500/  500000 | consumed samples:      4320000 | elapsed time per iteration (ms): 620.9 | learning rate: 1.362828E-04 | global batch size:    64 | lm loss: 3.288176E+00 | loss scale: 1048576.0 | grad norm: 0.407 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 15:21:58] iteration    67600/  500000 | consumed samples:      4326400 | elapsed time per iteration (ms): 620.4 | learning rate: 1.362415E-04 | global batch size:    64 | lm loss: 3.285156E+00 | loss scale: 1048576.0 | grad norm: 0.391 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 15:23:00] iteration    67700/  500000 | consumed samples:      4332800 | elapsed time per iteration (ms): 618.9 | learning rate: 1.362001E-04 | global batch size:    64 | lm loss: 3.289777E+00 | loss scale: 1048576.0 | grad norm: 0.395 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 15:24:02] iteration    67800/  500000 | consumed samples:      4339200 | elapsed time per iteration (ms): 618.5 | learning rate: 1.361587E-04 | global batch size:    64 | lm loss: 3.299399E+00 | loss scale: 1048576.0 | grad norm: 0.391 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 15:25:04] iteration    67900/  500000 | consumed samples:      4345600 | elapsed time per iteration (ms): 619.9 | learning rate: 1.361172E-04 | global batch size:    64 | lm loss: 3.288001E+00 | loss scale: 1048576.0 | grad norm: 0.406 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 15:26:05] iteration    68000/  500000 | consumed samples:      4352000 | elapsed time per iteration (ms): 618.9 | learning rate: 1.360757E-04 | global batch size:    64 | lm loss: 3.288532E+00 | loss scale: 1048576.0 | grad norm: 0.412 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2465.89, 2466.13)
-------------------------------------------------------------------------------------------------
 validation loss at iteration 68000 | lm loss value: 3.665358E+00 | lm loss PPL: 3.907012E+01 | 
-------------------------------------------------------------------------------------------------
 [2024-06-24 15:27:10] iteration    68100/  500000 | consumed samples:      4358400 | elapsed time per iteration (ms): 619.7 | learning rate: 1.360341E-04 | global batch size:    64 | lm loss: 3.287063E+00 | loss scale: 1048576.0 | grad norm: 0.401 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 15:28:12] iteration    68200/  500000 | consumed samples:      4364800 | elapsed time per iteration (ms): 617.9 | learning rate: 1.359925E-04 | global batch size:    64 | lm loss: 3.285326E+00 | loss scale: 2097152.0 | grad norm: 0.404 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 15:29:14] iteration    68300/  500000 | consumed samples:      4371200 | elapsed time per iteration (ms): 618.4 | learning rate: 1.359508E-04 | global batch size:    64 | lm loss: 3.288020E+00 | loss scale: 2097152.0 | grad norm: 0.396 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 15:30:15] iteration    68400/  500000 | consumed samples:      4377600 | elapsed time per iteration (ms): 618.5 | learning rate: 1.359091E-04 | global batch size:    64 | lm loss: 3.291593E+00 | loss scale: 2097152.0 | grad norm: 0.390 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 15:31:17] iteration    68500/  500000 | consumed samples:      4384000 | elapsed time per iteration (ms): 619.7 | learning rate: 1.358673E-04 | global batch size:    64 | lm loss: 3.288338E+00 | loss scale: 2097152.0 | grad norm: 0.402 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 15:32:19] iteration    68600/  500000 | consumed samples:      4390400 | elapsed time per iteration (ms): 618.5 | learning rate: 1.358254E-04 | global batch size:    64 | lm loss: 3.295527E+00 | loss scale: 2097152.0 | grad norm: 0.406 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 15:33:21] iteration    68700/  500000 | consumed samples:      4396800 | elapsed time per iteration (ms): 619.7 | learning rate: 1.357835E-04 | global batch size:    64 | lm loss: 3.296180E+00 | loss scale: 2097152.0 | grad norm: 0.399 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 15:34:23] iteration    68800/  500000 | consumed samples:      4403200 | elapsed time per iteration (ms): 618.1 | learning rate: 1.357416E-04 | global batch size:    64 | lm loss: 3.296380E+00 | loss scale: 2097152.0 | grad norm: 0.403 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 15:35:25] iteration    68900/  500000 | consumed samples:      4409600 | elapsed time per iteration (ms): 619.6 | learning rate: 1.356995E-04 | global batch size:    64 | lm loss: 3.299869E+00 | loss scale: 2097152.0 | grad norm: 0.403 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 15:36:27] iteration    69000/  500000 | consumed samples:      4416000 | elapsed time per iteration (ms): 619.6 | learning rate: 1.356579E-04 | global batch size:    64 | lm loss: 3.295911E+00 | loss scale: 2097152.0 | grad norm: 0.398 | number of skipped iterations:   1 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2463.33, 2463.49)
-------------------------------------------------------------------------------------------------
 validation loss at iteration 69000 | lm loss value: 3.668071E+00 | lm loss PPL: 3.917624E+01 | 
-------------------------------------------------------------------------------------------------
 [2024-06-24 15:37:31] iteration    69100/  500000 | consumed samples:      4422400 | elapsed time per iteration (ms): 620.9 | learning rate: 1.356158E-04 | global batch size:    64 | lm loss: 3.284835E+00 | loss scale: 2097152.0 | grad norm: 0.401 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 15:38:33] iteration    69200/  500000 | consumed samples:      4428800 | elapsed time per iteration (ms): 618.4 | learning rate: 1.355736E-04 | global batch size:    64 | lm loss: 3.285683E+00 | loss scale: 2097152.0 | grad norm: 0.386 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 15:39:35] iteration    69300/  500000 | consumed samples:      4435200 | elapsed time per iteration (ms): 620.6 | learning rate: 1.355314E-04 | global batch size:    64 | lm loss: 3.281036E+00 | loss scale: 2097152.0 | grad norm: 0.391 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 15:40:37] iteration    69400/  500000 | consumed samples:      4441600 | elapsed time per iteration (ms): 620.4 | learning rate: 1.354891E-04 | global batch size:    64 | lm loss: 3.292901E+00 | loss scale: 2097152.0 | grad norm: 0.403 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 15:41:39] iteration    69500/  500000 | consumed samples:      4448000 | elapsed time per iteration (ms): 620.8 | learning rate: 1.354467E-04 | global batch size:    64 | lm loss: 3.278543E+00 | loss scale: 2097152.0 | grad norm: 0.402 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 15:42:41] iteration    69600/  500000 | consumed samples:      4454400 | elapsed time per iteration (ms): 618.3 | learning rate: 1.354043E-04 | global batch size:    64 | lm loss: 3.280589E+00 | loss scale: 2097152.0 | grad norm: 0.404 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 15:43:43] iteration    69700/  500000 | consumed samples:      4460800 | elapsed time per iteration (ms): 618.4 | learning rate: 1.353619E-04 | global batch size:    64 | lm loss: 3.294879E+00 | loss scale: 2097152.0 | grad norm: 0.402 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 15:44:45] iteration    69800/  500000 | consumed samples:      4467200 | elapsed time per iteration (ms): 620.3 | learning rate: 1.353198E-04 | global batch size:    64 | lm loss: 3.285055E+00 | loss scale: 1048576.0 | grad norm: 0.388 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-24 15:45:47] iteration    69900/  500000 | consumed samples:      4473600 | elapsed time per iteration (ms): 620.3 | learning rate: 1.352772E-04 | global batch size:    64 | lm loss: 3.268253E+00 | loss scale: 1048576.0 | grad norm: 0.396 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 15:46:49] iteration    70000/  500000 | consumed samples:      4480000 | elapsed time per iteration (ms): 617.9 | learning rate: 1.352346E-04 | global batch size:    64 | lm loss: 3.270345E+00 | loss scale: 1048576.0 | grad norm: 0.396 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2463.03, 2463.35)
-------------------------------------------------------------------------------------------------
 validation loss at iteration 70000 | lm loss value: 3.675529E+00 | lm loss PPL: 3.946955E+01 | 
-------------------------------------------------------------------------------------------------
saving checkpoint at iteration   70000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-distribution in torch format
  successfully saved checkpoint at iteration   70000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-distribution
(min, max) time across ranks (ms):
    save-checkpoint ................................: (2281.90, 2281.91)
 [2024-06-24 15:47:56] iteration    70100/  500000 | consumed samples:      4486400 | elapsed time per iteration (ms): 618.3 | learning rate: 1.351919E-04 | global batch size:    64 | lm loss: 3.288320E+00 | loss scale: 1048576.0 | grad norm: 0.400 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 15:48:57] iteration    70200/  500000 | consumed samples:      4492800 | elapsed time per iteration (ms): 619.0 | learning rate: 1.351492E-04 | global batch size:    64 | lm loss: 3.271650E+00 | loss scale: 1048576.0 | grad norm: 0.424 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 15:49:59] iteration    70300/  500000 | consumed samples:      4499200 | elapsed time per iteration (ms): 619.9 | learning rate: 1.351064E-04 | global batch size:    64 | lm loss: 3.274202E+00 | loss scale: 1048576.0 | grad norm: 0.399 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 15:51:02] iteration    70400/  500000 | consumed samples:      4505600 | elapsed time per iteration (ms): 620.7 | learning rate: 1.350636E-04 | global batch size:    64 | lm loss: 3.264641E+00 | loss scale: 1048576.0 | grad norm: 0.416 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 15:52:03] iteration    70500/  500000 | consumed samples:      4512000 | elapsed time per iteration (ms): 618.9 | learning rate: 1.350207E-04 | global batch size:    64 | lm loss: 3.285934E+00 | loss scale: 1048576.0 | grad norm: 0.402 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 15:53:05] iteration    70600/  500000 | consumed samples:      4518400 | elapsed time per iteration (ms): 619.7 | learning rate: 1.349778E-04 | global batch size:    64 | lm loss: 3.286106E+00 | loss scale: 1048576.0 | grad norm: 0.392 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 15:54:07] iteration    70700/  500000 | consumed samples:      4524800 | elapsed time per iteration (ms): 618.4 | learning rate: 1.349348E-04 | global batch size:    64 | lm loss: 3.282675E+00 | loss scale: 1048576.0 | grad norm: 0.393 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 15:55:09] iteration    70800/  500000 | consumed samples:      4531200 | elapsed time per iteration (ms): 620.6 | learning rate: 1.348917E-04 | global batch size:    64 | lm loss: 3.269546E+00 | loss scale: 2097152.0 | grad norm: 0.401 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 15:56:11] iteration    70900/  500000 | consumed samples:      4537600 | elapsed time per iteration (ms): 619.9 | learning rate: 1.348486E-04 | global batch size:    64 | lm loss: 3.294821E+00 | loss scale: 2097152.0 | grad norm: 0.392 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 15:57:13] iteration    71000/  500000 | consumed samples:      4544000 | elapsed time per iteration (ms): 619.4 | learning rate: 1.348055E-04 | global batch size:    64 | lm loss: 3.299672E+00 | loss scale: 2097152.0 | grad norm: 0.395 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2463.03, 2463.30)
-------------------------------------------------------------------------------------------------
 validation loss at iteration 71000 | lm loss value: 3.681366E+00 | lm loss PPL: 3.970058E+01 | 
-------------------------------------------------------------------------------------------------
 [2024-06-24 15:58:18] iteration    71100/  500000 | consumed samples:      4550400 | elapsed time per iteration (ms): 620.1 | learning rate: 1.347623E-04 | global batch size:    64 | lm loss: 3.272861E+00 | loss scale: 2097152.0 | grad norm: 0.392 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 15:59:19] iteration    71200/  500000 | consumed samples:      4556800 | elapsed time per iteration (ms): 618.1 | learning rate: 1.347190E-04 | global batch size:    64 | lm loss: 3.280106E+00 | loss scale: 2097152.0 | grad norm: 0.397 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 16:00:21] iteration    71300/  500000 | consumed samples:      4563200 | elapsed time per iteration (ms): 619.5 | learning rate: 1.346757E-04 | global batch size:    64 | lm loss: 3.285906E+00 | loss scale: 2097152.0 | grad norm: 0.402 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 16:01:23] iteration    71400/  500000 | consumed samples:      4569600 | elapsed time per iteration (ms): 618.7 | learning rate: 1.346323E-04 | global batch size:    64 | lm loss: 3.277545E+00 | loss scale: 2097152.0 | grad norm: 0.402 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 16:02:25] iteration    71500/  500000 | consumed samples:      4576000 | elapsed time per iteration (ms): 620.1 | learning rate: 1.345889E-04 | global batch size:    64 | lm loss: 3.274539E+00 | loss scale: 2097152.0 | grad norm: 0.397 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 16:03:27] iteration    71600/  500000 | consumed samples:      4582400 | elapsed time per iteration (ms): 619.2 | learning rate: 1.345454E-04 | global batch size:    64 | lm loss: 3.273195E+00 | loss scale: 2097152.0 | grad norm: 0.405 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 16:04:29] iteration    71700/  500000 | consumed samples:      4588800 | elapsed time per iteration (ms): 620.1 | learning rate: 1.345019E-04 | global batch size:    64 | lm loss: 3.277120E+00 | loss scale: 2097152.0 | grad norm: 0.409 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 16:05:31] iteration    71800/  500000 | consumed samples:      4595200 | elapsed time per iteration (ms): 619.3 | learning rate: 1.344583E-04 | global batch size:    64 | lm loss: 3.294331E+00 | loss scale: 4194304.0 | grad norm: 0.395 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 16:06:33] iteration    71900/  500000 | consumed samples:      4601600 | elapsed time per iteration (ms): 617.5 | learning rate: 1.344155E-04 | global batch size:    64 | lm loss: 3.279238E+00 | loss scale: 2097152.0 | grad norm: 0.396 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-24 16:07:35] iteration    72000/  500000 | consumed samples:      4608000 | elapsed time per iteration (ms): 619.0 | learning rate: 1.343722E-04 | global batch size:    64 | lm loss: 3.276841E+00 | loss scale: 1048576.0 | grad norm: 0.403 | number of skipped iterations:   1 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2462.15, 2462.24)
-------------------------------------------------------------------------------------------------
 validation loss at iteration 72000 | lm loss value: 3.667864E+00 | lm loss PPL: 3.916814E+01 | 
-------------------------------------------------------------------------------------------------
 [2024-06-24 16:08:39] iteration    72100/  500000 | consumed samples:      4614400 | elapsed time per iteration (ms): 619.4 | learning rate: 1.343285E-04 | global batch size:    64 | lm loss: 3.292520E+00 | loss scale: 1048576.0 | grad norm: 0.388 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 16:09:41] iteration    72200/  500000 | consumed samples:      4620800 | elapsed time per iteration (ms): 618.8 | learning rate: 1.342847E-04 | global batch size:    64 | lm loss: 3.277721E+00 | loss scale: 1048576.0 | grad norm: 0.394 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 16:10:43] iteration    72300/  500000 | consumed samples:      4627200 | elapsed time per iteration (ms): 619.5 | learning rate: 1.342408E-04 | global batch size:    64 | lm loss: 3.277158E+00 | loss scale: 1048576.0 | grad norm: 0.407 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 16:11:45] iteration    72400/  500000 | consumed samples:      4633600 | elapsed time per iteration (ms): 620.9 | learning rate: 1.341969E-04 | global batch size:    64 | lm loss: 3.284730E+00 | loss scale: 1048576.0 | grad norm: 0.399 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 16:12:47] iteration    72500/  500000 | consumed samples:      4640000 | elapsed time per iteration (ms): 620.8 | learning rate: 1.341530E-04 | global batch size:    64 | lm loss: 3.270176E+00 | loss scale: 1048576.0 | grad norm: 0.385 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 16:13:49] iteration    72600/  500000 | consumed samples:      4646400 | elapsed time per iteration (ms): 621.0 | learning rate: 1.341090E-04 | global batch size:    64 | lm loss: 3.280011E+00 | loss scale: 1048576.0 | grad norm: 0.410 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 16:14:51] iteration    72700/  500000 | consumed samples:      4652800 | elapsed time per iteration (ms): 619.1 | learning rate: 1.340649E-04 | global batch size:    64 | lm loss: 3.273576E+00 | loss scale: 1048576.0 | grad norm: 0.388 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 16:15:53] iteration    72800/  500000 | consumed samples:      4659200 | elapsed time per iteration (ms): 620.7 | learning rate: 1.340208E-04 | global batch size:    64 | lm loss: 3.265991E+00 | loss scale: 1048576.0 | grad norm: 0.397 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 16:16:55] iteration    72900/  500000 | consumed samples:      4665600 | elapsed time per iteration (ms): 618.9 | learning rate: 1.339766E-04 | global batch size:    64 | lm loss: 3.268119E+00 | loss scale: 1048576.0 | grad norm: 0.399 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 16:17:57] iteration    73000/  500000 | consumed samples:      4672000 | elapsed time per iteration (ms): 620.0 | learning rate: 1.339324E-04 | global batch size:    64 | lm loss: 3.257976E+00 | loss scale: 2097152.0 | grad norm: 0.391 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2462.95, 2462.98)
-------------------------------------------------------------------------------------------------
 validation loss at iteration 73000 | lm loss value: 3.677785E+00 | lm loss PPL: 3.955866E+01 | 
-------------------------------------------------------------------------------------------------
 [2024-06-24 16:19:02] iteration    73100/  500000 | consumed samples:      4678400 | elapsed time per iteration (ms): 618.9 | learning rate: 1.338881E-04 | global batch size:    64 | lm loss: 3.286082E+00 | loss scale: 2097152.0 | grad norm: 0.388 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 16:20:03] iteration    73200/  500000 | consumed samples:      4684800 | elapsed time per iteration (ms): 618.9 | learning rate: 1.338438E-04 | global batch size:    64 | lm loss: 3.261024E+00 | loss scale: 2097152.0 | grad norm: 0.404 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 16:21:06] iteration    73300/  500000 | consumed samples:      4691200 | elapsed time per iteration (ms): 621.1 | learning rate: 1.337994E-04 | global batch size:    64 | lm loss: 3.273228E+00 | loss scale: 2097152.0 | grad norm: 0.408 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 16:22:08] iteration    73400/  500000 | consumed samples:      4697600 | elapsed time per iteration (ms): 622.0 | learning rate: 1.337550E-04 | global batch size:    64 | lm loss: 3.275336E+00 | loss scale: 2097152.0 | grad norm: 0.395 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 16:23:10] iteration    73500/  500000 | consumed samples:      4704000 | elapsed time per iteration (ms): 620.4 | learning rate: 1.337105E-04 | global batch size:    64 | lm loss: 3.266225E+00 | loss scale: 2097152.0 | grad norm: 0.397 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 16:24:12] iteration    73600/  500000 | consumed samples:      4710400 | elapsed time per iteration (ms): 619.0 | learning rate: 1.336659E-04 | global batch size:    64 | lm loss: 3.273315E+00 | loss scale: 2097152.0 | grad norm: 0.399 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 16:25:14] iteration    73700/  500000 | consumed samples:      4716800 | elapsed time per iteration (ms): 621.7 | learning rate: 1.336213E-04 | global batch size:    64 | lm loss: 3.290608E+00 | loss scale: 2097152.0 | grad norm: 0.390 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 16:26:16] iteration    73800/  500000 | consumed samples:      4723200 | elapsed time per iteration (ms): 618.8 | learning rate: 1.335767E-04 | global batch size:    64 | lm loss: 3.274860E+00 | loss scale: 2097152.0 | grad norm: 0.431 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 16:27:18] iteration    73900/  500000 | consumed samples:      4729600 | elapsed time per iteration (ms): 618.6 | learning rate: 1.335320E-04 | global batch size:    64 | lm loss: 3.271231E+00 | loss scale: 2097152.0 | grad norm: 0.426 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 16:28:20] iteration    74000/  500000 | consumed samples:      4736000 | elapsed time per iteration (ms): 619.1 | learning rate: 1.334881E-04 | global batch size:    64 | lm loss: 3.279673E+00 | loss scale: 2097152.0 | grad norm: 0.389 | number of skipped iterations:   2 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2463.22, 2463.24)
-------------------------------------------------------------------------------------------------
 validation loss at iteration 74000 | lm loss value: 3.670895E+00 | lm loss PPL: 3.928706E+01 | 
-------------------------------------------------------------------------------------------------
 [2024-06-24 16:29:24] iteration    74100/  500000 | consumed samples:      4742400 | elapsed time per iteration (ms): 620.5 | learning rate: 1.334438E-04 | global batch size:    64 | lm loss: 3.264747E+00 | loss scale: 1048576.0 | grad norm: 0.410 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-24 16:30:26] iteration    74200/  500000 | consumed samples:      4748800 | elapsed time per iteration (ms): 621.6 | learning rate: 1.333989E-04 | global batch size:    64 | lm loss: 3.276552E+00 | loss scale: 1048576.0 | grad norm: 0.395 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 16:31:28] iteration    74300/  500000 | consumed samples:      4755200 | elapsed time per iteration (ms): 620.8 | learning rate: 1.333540E-04 | global batch size:    64 | lm loss: 3.259991E+00 | loss scale: 1048576.0 | grad norm: 0.404 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 16:32:30] iteration    74400/  500000 | consumed samples:      4761600 | elapsed time per iteration (ms): 619.6 | learning rate: 1.333090E-04 | global batch size:    64 | lm loss: 3.270432E+00 | loss scale: 1048576.0 | grad norm: 0.413 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 16:33:32] iteration    74500/  500000 | consumed samples:      4768000 | elapsed time per iteration (ms): 619.6 | learning rate: 1.332640E-04 | global batch size:    64 | lm loss: 3.263809E+00 | loss scale: 1048576.0 | grad norm: 0.530 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 16:34:34] iteration    74600/  500000 | consumed samples:      4774400 | elapsed time per iteration (ms): 619.3 | learning rate: 1.332189E-04 | global batch size:    64 | lm loss: 3.278836E+00 | loss scale: 1048576.0 | grad norm: 0.392 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 16:35:36] iteration    74700/  500000 | consumed samples:      4780800 | elapsed time per iteration (ms): 618.8 | learning rate: 1.331738E-04 | global batch size:    64 | lm loss: 3.266474E+00 | loss scale: 1048576.0 | grad norm: 0.390 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 16:36:38] iteration    74800/  500000 | consumed samples:      4787200 | elapsed time per iteration (ms): 620.3 | learning rate: 1.331287E-04 | global batch size:    64 | lm loss: 3.266430E+00 | loss scale: 1048576.0 | grad norm: 0.399 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 16:37:40] iteration    74900/  500000 | consumed samples:      4793600 | elapsed time per iteration (ms): 620.0 | learning rate: 1.330834E-04 | global batch size:    64 | lm loss: 3.264105E+00 | loss scale: 1048576.0 | grad norm: 0.394 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 16:38:42] iteration    75000/  500000 | consumed samples:      4800000 | elapsed time per iteration (ms): 619.0 | learning rate: 1.330382E-04 | global batch size:    64 | lm loss: 3.263055E+00 | loss scale: 1048576.0 | grad norm: 0.395 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2462.22, 2462.31)
-------------------------------------------------------------------------------------------------
 validation loss at iteration 75000 | lm loss value: 3.707846E+00 | lm loss PPL: 4.076589E+01 | 
-------------------------------------------------------------------------------------------------
 [2024-06-24 16:39:47] iteration    75100/  500000 | consumed samples:      4806400 | elapsed time per iteration (ms): 620.8 | learning rate: 1.329928E-04 | global batch size:    64 | lm loss: 3.272538E+00 | loss scale: 2097152.0 | grad norm: 0.401 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 16:40:48] iteration    75200/  500000 | consumed samples:      4812800 | elapsed time per iteration (ms): 618.6 | learning rate: 1.329474E-04 | global batch size:    64 | lm loss: 3.258210E+00 | loss scale: 2097152.0 | grad norm: 0.412 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 16:41:50] iteration    75300/  500000 | consumed samples:      4819200 | elapsed time per iteration (ms): 618.0 | learning rate: 1.329020E-04 | global batch size:    64 | lm loss: 3.282374E+00 | loss scale: 2097152.0 | grad norm: 0.413 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 16:42:52] iteration    75400/  500000 | consumed samples:      4825600 | elapsed time per iteration (ms): 619.4 | learning rate: 1.328565E-04 | global batch size:    64 | lm loss: 3.264708E+00 | loss scale: 2097152.0 | grad norm: 0.393 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 16:43:54] iteration    75500/  500000 | consumed samples:      4832000 | elapsed time per iteration (ms): 619.9 | learning rate: 1.328110E-04 | global batch size:    64 | lm loss: 3.255387E+00 | loss scale: 2097152.0 | grad norm: 0.398 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 16:44:56] iteration    75600/  500000 | consumed samples:      4838400 | elapsed time per iteration (ms): 620.2 | learning rate: 1.327654E-04 | global batch size:    64 | lm loss: 3.276185E+00 | loss scale: 2097152.0 | grad norm: 0.403 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 16:45:58] iteration    75700/  500000 | consumed samples:      4844800 | elapsed time per iteration (ms): 619.0 | learning rate: 1.327198E-04 | global batch size:    64 | lm loss: 3.259453E+00 | loss scale: 2097152.0 | grad norm: 0.404 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 16:47:00] iteration    75800/  500000 | consumed samples:      4851200 | elapsed time per iteration (ms): 620.1 | learning rate: 1.326741E-04 | global batch size:    64 | lm loss: 3.252704E+00 | loss scale: 2097152.0 | grad norm: 0.410 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 16:48:02] iteration    75900/  500000 | consumed samples:      4857600 | elapsed time per iteration (ms): 618.7 | learning rate: 1.326283E-04 | global batch size:    64 | lm loss: 3.262466E+00 | loss scale: 2097152.0 | grad norm: 0.413 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 16:49:04] iteration    76000/  500000 | consumed samples:      4864000 | elapsed time per iteration (ms): 619.4 | learning rate: 1.325830E-04 | global batch size:    64 | lm loss: 3.258790E+00 | loss scale: 2097152.0 | grad norm: 0.410 | number of skipped iterations:   1 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2461.70, 2461.71)
-------------------------------------------------------------------------------------------------
 validation loss at iteration 76000 | lm loss value: 3.706330E+00 | lm loss PPL: 4.070415E+01 | 
-------------------------------------------------------------------------------------------------
 [2024-06-24 16:50:08] iteration    76100/  500000 | consumed samples:      4870400 | elapsed time per iteration (ms): 620.0 | learning rate: 1.325371E-04 | global batch size:    64 | lm loss: 3.257799E+00 | loss scale: 2097152.0 | grad norm: 0.404 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 16:51:10] iteration    76200/  500000 | consumed samples:      4876800 | elapsed time per iteration (ms): 618.3 | learning rate: 1.324912E-04 | global batch size:    64 | lm loss: 3.263919E+00 | loss scale: 2097152.0 | grad norm: 0.406 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 16:52:12] iteration    76300/  500000 | consumed samples:      4883200 | elapsed time per iteration (ms): 617.7 | learning rate: 1.324453E-04 | global batch size:    64 | lm loss: 3.258008E+00 | loss scale: 2097152.0 | grad norm: 0.390 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 16:53:14] iteration    76400/  500000 | consumed samples:      4889600 | elapsed time per iteration (ms): 622.2 | learning rate: 1.323993E-04 | global batch size:    64 | lm loss: 3.257698E+00 | loss scale: 2097152.0 | grad norm: 0.392 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 16:54:16] iteration    76500/  500000 | consumed samples:      4896000 | elapsed time per iteration (ms): 618.1 | learning rate: 1.323537E-04 | global batch size:    64 | lm loss: 3.275079E+00 | loss scale: 1048576.0 | grad norm: 0.420 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-24 16:55:18] iteration    76600/  500000 | consumed samples:      4902400 | elapsed time per iteration (ms): 618.9 | learning rate: 1.323076E-04 | global batch size:    64 | lm loss: 3.269552E+00 | loss scale: 1048576.0 | grad norm: 0.401 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 16:56:20] iteration    76700/  500000 | consumed samples:      4908800 | elapsed time per iteration (ms): 620.1 | learning rate: 1.322614E-04 | global batch size:    64 | lm loss: 3.271690E+00 | loss scale: 1048576.0 | grad norm: 0.392 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 16:57:22] iteration    76800/  500000 | consumed samples:      4915200 | elapsed time per iteration (ms): 619.7 | learning rate: 1.322152E-04 | global batch size:    64 | lm loss: 3.265786E+00 | loss scale: 1048576.0 | grad norm: 0.398 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 16:58:24] iteration    76900/  500000 | consumed samples:      4921600 | elapsed time per iteration (ms): 621.9 | learning rate: 1.321690E-04 | global batch size:    64 | lm loss: 3.268767E+00 | loss scale: 1048576.0 | grad norm: 0.400 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 16:59:26] iteration    77000/  500000 | consumed samples:      4928000 | elapsed time per iteration (ms): 621.4 | learning rate: 1.321227E-04 | global batch size:    64 | lm loss: 3.256941E+00 | loss scale: 1048576.0 | grad norm: 0.400 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2462.58, 2462.77)
-------------------------------------------------------------------------------------------------
 validation loss at iteration 77000 | lm loss value: 3.652617E+00 | lm loss PPL: 3.857549E+01 | 
-------------------------------------------------------------------------------------------------
 [2024-06-24 17:00:30] iteration    77100/  500000 | consumed samples:      4934400 | elapsed time per iteration (ms): 618.4 | learning rate: 1.320763E-04 | global batch size:    64 | lm loss: 3.249570E+00 | loss scale: 1048576.0 | grad norm: 0.398 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 17:01:32] iteration    77200/  500000 | consumed samples:      4940800 | elapsed time per iteration (ms): 616.7 | learning rate: 1.320299E-04 | global batch size:    64 | lm loss: 3.240677E+00 | loss scale: 1048576.0 | grad norm: 0.414 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 17:02:34] iteration    77300/  500000 | consumed samples:      4947200 | elapsed time per iteration (ms): 617.4 | learning rate: 1.319834E-04 | global batch size:    64 | lm loss: 3.261367E+00 | loss scale: 1048576.0 | grad norm: 0.392 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 17:03:36] iteration    77400/  500000 | consumed samples:      4953600 | elapsed time per iteration (ms): 617.4 | learning rate: 1.319369E-04 | global batch size:    64 | lm loss: 3.254701E+00 | loss scale: 1048576.0 | grad norm: 0.404 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 17:04:37] iteration    77500/  500000 | consumed samples:      4960000 | elapsed time per iteration (ms): 618.8 | learning rate: 1.318903E-04 | global batch size:    64 | lm loss: 3.273664E+00 | loss scale: 2097152.0 | grad norm: 0.398 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 17:05:39] iteration    77600/  500000 | consumed samples:      4966400 | elapsed time per iteration (ms): 619.1 | learning rate: 1.318437E-04 | global batch size:    64 | lm loss: 3.259585E+00 | loss scale: 2097152.0 | grad norm: 0.401 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 17:06:41] iteration    77700/  500000 | consumed samples:      4972800 | elapsed time per iteration (ms): 619.2 | learning rate: 1.317971E-04 | global batch size:    64 | lm loss: 3.266732E+00 | loss scale: 2097152.0 | grad norm: 0.393 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 17:07:43] iteration    77800/  500000 | consumed samples:      4979200 | elapsed time per iteration (ms): 619.8 | learning rate: 1.317503E-04 | global batch size:    64 | lm loss: 3.262895E+00 | loss scale: 2097152.0 | grad norm: 0.415 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 17:08:45] iteration    77900/  500000 | consumed samples:      4985600 | elapsed time per iteration (ms): 619.8 | learning rate: 1.317036E-04 | global batch size:    64 | lm loss: 3.265692E+00 | loss scale: 2097152.0 | grad norm: 0.408 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 17:09:47] iteration    78000/  500000 | consumed samples:      4992000 | elapsed time per iteration (ms): 618.8 | learning rate: 1.316568E-04 | global batch size:    64 | lm loss: 3.248091E+00 | loss scale: 2097152.0 | grad norm: 0.414 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2461.83, 2461.99)
-------------------------------------------------------------------------------------------------
 validation loss at iteration 78000 | lm loss value: 3.717108E+00 | lm loss PPL: 4.114525E+01 | 
-------------------------------------------------------------------------------------------------
 [2024-06-24 17:10:52] iteration    78100/  500000 | consumed samples:      4998400 | elapsed time per iteration (ms): 619.9 | learning rate: 1.316099E-04 | global batch size:    64 | lm loss: 3.255605E+00 | loss scale: 2097152.0 | grad norm: 0.396 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 17:11:54] iteration    78200/  500000 | consumed samples:      5004800 | elapsed time per iteration (ms): 620.0 | learning rate: 1.315630E-04 | global batch size:    64 | lm loss: 3.273043E+00 | loss scale: 2097152.0 | grad norm: 0.410 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 17:12:55] iteration    78300/  500000 | consumed samples:      5011200 | elapsed time per iteration (ms): 617.3 | learning rate: 1.315160E-04 | global batch size:    64 | lm loss: 3.250895E+00 | loss scale: 2097152.0 | grad norm: 0.402 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 17:13:57] iteration    78400/  500000 | consumed samples:      5017600 | elapsed time per iteration (ms): 618.3 | learning rate: 1.314690E-04 | global batch size:    64 | lm loss: 3.261017E+00 | loss scale: 2097152.0 | grad norm: 0.400 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 17:14:59] iteration    78500/  500000 | consumed samples:      5024000 | elapsed time per iteration (ms): 619.9 | learning rate: 1.314219E-04 | global batch size:    64 | lm loss: 3.243875E+00 | loss scale: 4194304.0 | grad norm: 0.411 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 17:16:01] iteration    78600/  500000 | consumed samples:      5030400 | elapsed time per iteration (ms): 617.7 | learning rate: 1.313757E-04 | global batch size:    64 | lm loss: 3.262077E+00 | loss scale: 2097152.0 | grad norm: 0.396 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-24 17:17:03] iteration    78700/  500000 | consumed samples:      5036800 | elapsed time per iteration (ms): 619.9 | learning rate: 1.313285E-04 | global batch size:    64 | lm loss: 3.262352E+00 | loss scale: 2097152.0 | grad norm: 0.403 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 17:18:05] iteration    78800/  500000 | consumed samples:      5043200 | elapsed time per iteration (ms): 620.5 | learning rate: 1.312813E-04 | global batch size:    64 | lm loss: 3.261565E+00 | loss scale: 2097152.0 | grad norm: 0.388 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 17:19:07] iteration    78900/  500000 | consumed samples:      5049600 | elapsed time per iteration (ms): 616.5 | learning rate: 1.312340E-04 | global batch size:    64 | lm loss: 3.247090E+00 | loss scale: 2097152.0 | grad norm: 0.404 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 17:20:09] iteration    79000/  500000 | consumed samples:      5056000 | elapsed time per iteration (ms): 620.9 | learning rate: 1.311867E-04 | global batch size:    64 | lm loss: 3.242112E+00 | loss scale: 2097152.0 | grad norm: 0.410 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2462.45, 2462.76)
-------------------------------------------------------------------------------------------------
 validation loss at iteration 79000 | lm loss value: 3.698675E+00 | lm loss PPL: 4.039375E+01 | 
-------------------------------------------------------------------------------------------------
 [2024-06-24 17:21:13] iteration    79100/  500000 | consumed samples:      5062400 | elapsed time per iteration (ms): 620.0 | learning rate: 1.311393E-04 | global batch size:    64 | lm loss: 3.256071E+00 | loss scale: 2097152.0 | grad norm: 0.422 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 17:22:15] iteration    79200/  500000 | consumed samples:      5068800 | elapsed time per iteration (ms): 617.0 | learning rate: 1.310919E-04 | global batch size:    64 | lm loss: 3.243204E+00 | loss scale: 2097152.0 | grad norm: 0.402 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 17:23:17] iteration    79300/  500000 | consumed samples:      5075200 | elapsed time per iteration (ms): 620.4 | learning rate: 1.310444E-04 | global batch size:    64 | lm loss: 3.253840E+00 | loss scale: 2097152.0 | grad norm: 0.397 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 17:24:19] iteration    79400/  500000 | consumed samples:      5081600 | elapsed time per iteration (ms): 621.3 | learning rate: 1.309969E-04 | global batch size:    64 | lm loss: 3.250060E+00 | loss scale: 2097152.0 | grad norm: 0.395 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 17:25:21] iteration    79500/  500000 | consumed samples:      5088000 | elapsed time per iteration (ms): 620.3 | learning rate: 1.309493E-04 | global batch size:    64 | lm loss: 3.251822E+00 | loss scale: 2097152.0 | grad norm: 0.394 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 17:26:23] iteration    79600/  500000 | consumed samples:      5094400 | elapsed time per iteration (ms): 621.5 | learning rate: 1.309022E-04 | global batch size:    64 | lm loss: 3.255178E+00 | loss scale: 1048576.0 | grad norm: 0.413 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-24 17:27:25] iteration    79700/  500000 | consumed samples:      5100800 | elapsed time per iteration (ms): 619.7 | learning rate: 1.308545E-04 | global batch size:    64 | lm loss: 3.262865E+00 | loss scale: 1048576.0 | grad norm: 0.399 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 17:28:27] iteration    79800/  500000 | consumed samples:      5107200 | elapsed time per iteration (ms): 618.7 | learning rate: 1.308068E-04 | global batch size:    64 | lm loss: 3.243044E+00 | loss scale: 1048576.0 | grad norm: 0.400 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 17:29:29] iteration    79900/  500000 | consumed samples:      5113600 | elapsed time per iteration (ms): 616.5 | learning rate: 1.307590E-04 | global batch size:    64 | lm loss: 3.244048E+00 | loss scale: 1048576.0 | grad norm: 0.403 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 17:30:31] iteration    80000/  500000 | consumed samples:      5120000 | elapsed time per iteration (ms): 619.8 | learning rate: 1.307112E-04 | global batch size:    64 | lm loss: 3.260071E+00 | loss scale: 1048576.0 | grad norm: 0.400 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2463.03, 2463.05)
-------------------------------------------------------------------------------------------------
 validation loss at iteration 80000 | lm loss value: 3.645400E+00 | lm loss PPL: 3.829807E+01 | 
-------------------------------------------------------------------------------------------------
saving checkpoint at iteration   80000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-distribution in torch format
  successfully saved checkpoint at iteration   80000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-distribution
(min, max) time across ranks (ms):
    save-checkpoint ................................: (2281.72, 2281.73)
 [2024-06-24 17:31:37] iteration    80100/  500000 | consumed samples:      5126400 | elapsed time per iteration (ms): 619.5 | learning rate: 1.306633E-04 | global batch size:    64 | lm loss: 3.242293E+00 | loss scale: 1048576.0 | grad norm: 0.396 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 17:32:39] iteration    80200/  500000 | consumed samples:      5132800 | elapsed time per iteration (ms): 619.6 | learning rate: 1.306154E-04 | global batch size:    64 | lm loss: 3.256168E+00 | loss scale: 1048576.0 | grad norm: 0.398 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 17:33:41] iteration    80300/  500000 | consumed samples:      5139200 | elapsed time per iteration (ms): 620.3 | learning rate: 1.305674E-04 | global batch size:    64 | lm loss: 3.257411E+00 | loss scale: 1048576.0 | grad norm: 0.392 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 17:34:43] iteration    80400/  500000 | consumed samples:      5145600 | elapsed time per iteration (ms): 619.8 | learning rate: 1.305194E-04 | global batch size:    64 | lm loss: 3.258709E+00 | loss scale: 1048576.0 | grad norm: 0.400 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 17:35:45] iteration    80500/  500000 | consumed samples:      5152000 | elapsed time per iteration (ms): 619.9 | learning rate: 1.304713E-04 | global batch size:    64 | lm loss: 3.261545E+00 | loss scale: 1048576.0 | grad norm: 0.410 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 17:36:47] iteration    80600/  500000 | consumed samples:      5158400 | elapsed time per iteration (ms): 620.6 | learning rate: 1.304237E-04 | global batch size:    64 | lm loss: 3.254632E+00 | loss scale: 2097152.0 | grad norm: 0.404 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-24 17:37:49] iteration    80700/  500000 | consumed samples:      5164800 | elapsed time per iteration (ms): 620.1 | learning rate: 1.303755E-04 | global batch size:    64 | lm loss: 3.262051E+00 | loss scale: 2097152.0 | grad norm: 0.418 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 17:38:51] iteration    80800/  500000 | consumed samples:      5171200 | elapsed time per iteration (ms): 619.0 | learning rate: 1.303277E-04 | global batch size:    64 | lm loss: 3.257165E+00 | loss scale: 1048576.0 | grad norm: 0.407 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-24 17:39:53] iteration    80900/  500000 | consumed samples:      5177600 | elapsed time per iteration (ms): 618.9 | learning rate: 1.302795E-04 | global batch size:    64 | lm loss: 3.249493E+00 | loss scale: 1048576.0 | grad norm: 0.390 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 17:40:55] iteration    81000/  500000 | consumed samples:      5184000 | elapsed time per iteration (ms): 619.7 | learning rate: 1.302311E-04 | global batch size:    64 | lm loss: 3.243403E+00 | loss scale: 1048576.0 | grad norm: 0.404 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2462.48, 2462.67)
-------------------------------------------------------------------------------------------------
 validation loss at iteration 81000 | lm loss value: 3.660313E+00 | lm loss PPL: 3.887352E+01 | 
-------------------------------------------------------------------------------------------------
 [2024-06-24 17:42:00] iteration    81100/  500000 | consumed samples:      5190400 | elapsed time per iteration (ms): 621.5 | learning rate: 1.301828E-04 | global batch size:    64 | lm loss: 3.240984E+00 | loss scale: 1048576.0 | grad norm: 0.411 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 17:43:02] iteration    81200/  500000 | consumed samples:      5196800 | elapsed time per iteration (ms): 618.5 | learning rate: 1.301344E-04 | global batch size:    64 | lm loss: 3.253567E+00 | loss scale: 1048576.0 | grad norm: 0.416 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 17:44:04] iteration    81300/  500000 | consumed samples:      5203200 | elapsed time per iteration (ms): 619.6 | learning rate: 1.300859E-04 | global batch size:    64 | lm loss: 3.238329E+00 | loss scale: 1048576.0 | grad norm: 0.396 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 17:45:06] iteration    81400/  500000 | consumed samples:      5209600 | elapsed time per iteration (ms): 619.9 | learning rate: 1.300374E-04 | global batch size:    64 | lm loss: 3.233397E+00 | loss scale: 1048576.0 | grad norm: 0.397 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 17:46:07] iteration    81500/  500000 | consumed samples:      5216000 | elapsed time per iteration (ms): 618.7 | learning rate: 1.299888E-04 | global batch size:    64 | lm loss: 3.252669E+00 | loss scale: 1048576.0 | grad norm: 0.403 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 17:47:10] iteration    81600/  500000 | consumed samples:      5222400 | elapsed time per iteration (ms): 620.6 | learning rate: 1.299402E-04 | global batch size:    64 | lm loss: 3.242277E+00 | loss scale: 1048576.0 | grad norm: 0.401 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 17:48:12] iteration    81700/  500000 | consumed samples:      5228800 | elapsed time per iteration (ms): 620.6 | learning rate: 1.298915E-04 | global batch size:    64 | lm loss: 3.250643E+00 | loss scale: 1048576.0 | grad norm: 0.399 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 17:49:13] iteration    81800/  500000 | consumed samples:      5235200 | elapsed time per iteration (ms): 618.3 | learning rate: 1.298433E-04 | global batch size:    64 | lm loss: 3.261753E+00 | loss scale: 2097152.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-24 17:50:15] iteration    81900/  500000 | consumed samples:      5241600 | elapsed time per iteration (ms): 618.8 | learning rate: 1.297945E-04 | global batch size:    64 | lm loss: 3.240592E+00 | loss scale: 2097152.0 | grad norm: 0.390 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 17:51:17] iteration    82000/  500000 | consumed samples:      5248000 | elapsed time per iteration (ms): 620.3 | learning rate: 1.297457E-04 | global batch size:    64 | lm loss: 3.245779E+00 | loss scale: 2097152.0 | grad norm: 0.407 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2464.15, 2464.18)
-------------------------------------------------------------------------------------------------
 validation loss at iteration 82000 | lm loss value: 3.647387E+00 | lm loss PPL: 3.837426E+01 | 
-------------------------------------------------------------------------------------------------
 [2024-06-24 17:52:22] iteration    82100/  500000 | consumed samples:      5254400 | elapsed time per iteration (ms): 620.2 | learning rate: 1.296968E-04 | global batch size:    64 | lm loss: 3.263490E+00 | loss scale: 2097152.0 | grad norm: 0.402 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 17:53:24] iteration    82200/  500000 | consumed samples:      5260800 | elapsed time per iteration (ms): 617.7 | learning rate: 1.296479E-04 | global batch size:    64 | lm loss: 3.257845E+00 | loss scale: 2097152.0 | grad norm: 0.411 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 17:54:26] iteration    82300/  500000 | consumed samples:      5267200 | elapsed time per iteration (ms): 619.4 | learning rate: 1.295990E-04 | global batch size:    64 | lm loss: 3.248164E+00 | loss scale: 2097152.0 | grad norm: 0.396 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 17:55:27] iteration    82400/  500000 | consumed samples:      5273600 | elapsed time per iteration (ms): 618.9 | learning rate: 1.295500E-04 | global batch size:    64 | lm loss: 3.225889E+00 | loss scale: 2097152.0 | grad norm: 0.395 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 17:56:29] iteration    82500/  500000 | consumed samples:      5280000 | elapsed time per iteration (ms): 618.8 | learning rate: 1.295009E-04 | global batch size:    64 | lm loss: 3.226685E+00 | loss scale: 2097152.0 | grad norm: 0.390 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 17:57:31] iteration    82600/  500000 | consumed samples:      5286400 | elapsed time per iteration (ms): 619.2 | learning rate: 1.294518E-04 | global batch size:    64 | lm loss: 3.254760E+00 | loss scale: 2097152.0 | grad norm: 0.400 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 17:58:33] iteration    82700/  500000 | consumed samples:      5292800 | elapsed time per iteration (ms): 618.5 | learning rate: 1.294031E-04 | global batch size:    64 | lm loss: 3.243819E+00 | loss scale: 1048576.0 | grad norm: 0.404 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-24 17:59:35] iteration    82800/  500000 | consumed samples:      5299200 | elapsed time per iteration (ms): 619.4 | learning rate: 1.293539E-04 | global batch size:    64 | lm loss: 3.236080E+00 | loss scale: 1048576.0 | grad norm: 0.410 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 18:00:37] iteration    82900/  500000 | consumed samples:      5305600 | elapsed time per iteration (ms): 617.9 | learning rate: 1.293047E-04 | global batch size:    64 | lm loss: 3.245888E+00 | loss scale: 1048576.0 | grad norm: 0.408 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 18:01:39] iteration    83000/  500000 | consumed samples:      5312000 | elapsed time per iteration (ms): 621.0 | learning rate: 1.292554E-04 | global batch size:    64 | lm loss: 3.241475E+00 | loss scale: 1048576.0 | grad norm: 0.420 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2466.29, 2466.48)
-------------------------------------------------------------------------------------------------
 validation loss at iteration 83000 | lm loss value: 3.654994E+00 | lm loss PPL: 3.866730E+01 | 
-------------------------------------------------------------------------------------------------
 [2024-06-24 18:02:43] iteration    83100/  500000 | consumed samples:      5318400 | elapsed time per iteration (ms): 619.4 | learning rate: 1.292060E-04 | global batch size:    64 | lm loss: 3.229451E+00 | loss scale: 1048576.0 | grad norm: 0.420 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 18:03:45] iteration    83200/  500000 | consumed samples:      5324800 | elapsed time per iteration (ms): 617.8 | learning rate: 1.291566E-04 | global batch size:    64 | lm loss: 3.239736E+00 | loss scale: 1048576.0 | grad norm: 0.394 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 18:04:47] iteration    83300/  500000 | consumed samples:      5331200 | elapsed time per iteration (ms): 617.9 | learning rate: 1.291072E-04 | global batch size:    64 | lm loss: 3.235096E+00 | loss scale: 1048576.0 | grad norm: 0.412 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 18:05:49] iteration    83400/  500000 | consumed samples:      5337600 | elapsed time per iteration (ms): 618.3 | learning rate: 1.290577E-04 | global batch size:    64 | lm loss: 3.246569E+00 | loss scale: 1048576.0 | grad norm: 0.415 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 18:06:51] iteration    83500/  500000 | consumed samples:      5344000 | elapsed time per iteration (ms): 618.7 | learning rate: 1.290082E-04 | global batch size:    64 | lm loss: 3.245815E+00 | loss scale: 1048576.0 | grad norm: 0.393 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 18:07:52] iteration    83600/  500000 | consumed samples:      5350400 | elapsed time per iteration (ms): 619.1 | learning rate: 1.289586E-04 | global batch size:    64 | lm loss: 3.253907E+00 | loss scale: 1048576.0 | grad norm: 0.415 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 18:08:55] iteration    83700/  500000 | consumed samples:      5356800 | elapsed time per iteration (ms): 620.6 | learning rate: 1.289089E-04 | global batch size:    64 | lm loss: 3.247036E+00 | loss scale: 2097152.0 | grad norm: 0.407 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 18:09:57] iteration    83800/  500000 | consumed samples:      5363200 | elapsed time per iteration (ms): 621.2 | learning rate: 1.288593E-04 | global batch size:    64 | lm loss: 3.242630E+00 | loss scale: 2097152.0 | grad norm: 0.417 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 18:10:59] iteration    83900/  500000 | consumed samples:      5369600 | elapsed time per iteration (ms): 619.4 | learning rate: 1.288095E-04 | global batch size:    64 | lm loss: 3.238657E+00 | loss scale: 2097152.0 | grad norm: 0.406 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 18:12:01] iteration    84000/  500000 | consumed samples:      5376000 | elapsed time per iteration (ms): 621.0 | learning rate: 1.287597E-04 | global batch size:    64 | lm loss: 3.252508E+00 | loss scale: 2097152.0 | grad norm: 0.407 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2463.81, 2463.93)
-------------------------------------------------------------------------------------------------
 validation loss at iteration 84000 | lm loss value: 3.733123E+00 | lm loss PPL: 4.180948E+01 | 
-------------------------------------------------------------------------------------------------
 [2024-06-24 18:13:05] iteration    84100/  500000 | consumed samples:      5382400 | elapsed time per iteration (ms): 618.4 | learning rate: 1.287104E-04 | global batch size:    64 | lm loss: 3.236505E+00 | loss scale: 2097152.0 | grad norm: 0.399 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-24 18:14:07] iteration    84200/  500000 | consumed samples:      5388800 | elapsed time per iteration (ms): 619.0 | learning rate: 1.286610E-04 | global batch size:    64 | lm loss: 3.239850E+00 | loss scale: 1048576.0 | grad norm: 0.399 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-24 18:15:09] iteration    84300/  500000 | consumed samples:      5395200 | elapsed time per iteration (ms): 618.1 | learning rate: 1.286111E-04 | global batch size:    64 | lm loss: 3.251907E+00 | loss scale: 1048576.0 | grad norm: 0.403 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 18:16:11] iteration    84400/  500000 | consumed samples:      5401600 | elapsed time per iteration (ms): 619.0 | learning rate: 1.285611E-04 | global batch size:    64 | lm loss: 3.255613E+00 | loss scale: 1048576.0 | grad norm: 0.404 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 18:17:12] iteration    84500/  500000 | consumed samples:      5408000 | elapsed time per iteration (ms): 618.6 | learning rate: 1.285111E-04 | global batch size:    64 | lm loss: 3.235876E+00 | loss scale: 1048576.0 | grad norm: 0.394 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 18:18:14] iteration    84600/  500000 | consumed samples:      5414400 | elapsed time per iteration (ms): 620.1 | learning rate: 1.284610E-04 | global batch size:    64 | lm loss: 3.233722E+00 | loss scale: 1048576.0 | grad norm: 0.398 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 18:19:16] iteration    84700/  500000 | consumed samples:      5420800 | elapsed time per iteration (ms): 618.0 | learning rate: 1.284109E-04 | global batch size:    64 | lm loss: 3.239358E+00 | loss scale: 1048576.0 | grad norm: 0.399 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 18:20:18] iteration    84800/  500000 | consumed samples:      5427200 | elapsed time per iteration (ms): 618.1 | learning rate: 1.283608E-04 | global batch size:    64 | lm loss: 3.242586E+00 | loss scale: 1048576.0 | grad norm: 0.403 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 18:21:20] iteration    84900/  500000 | consumed samples:      5433600 | elapsed time per iteration (ms): 619.0 | learning rate: 1.283106E-04 | global batch size:    64 | lm loss: 3.238730E+00 | loss scale: 1048576.0 | grad norm: 0.399 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 18:22:22] iteration    85000/  500000 | consumed samples:      5440000 | elapsed time per iteration (ms): 620.0 | learning rate: 1.282603E-04 | global batch size:    64 | lm loss: 3.241905E+00 | loss scale: 1048576.0 | grad norm: 0.398 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2463.74, 2463.88)
-------------------------------------------------------------------------------------------------
 validation loss at iteration 85000 | lm loss value: 3.700010E+00 | lm loss PPL: 4.044769E+01 | 
-------------------------------------------------------------------------------------------------
 [2024-06-24 18:23:26] iteration    85100/  500000 | consumed samples:      5446400 | elapsed time per iteration (ms): 620.0 | learning rate: 1.282100E-04 | global batch size:    64 | lm loss: 3.229981E+00 | loss scale: 1048576.0 | grad norm: 0.395 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 18:24:28] iteration    85200/  500000 | consumed samples:      5452800 | elapsed time per iteration (ms): 620.2 | learning rate: 1.281596E-04 | global batch size:    64 | lm loss: 3.239346E+00 | loss scale: 2097152.0 | grad norm: 0.396 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 18:25:30] iteration    85300/  500000 | consumed samples:      5459200 | elapsed time per iteration (ms): 619.9 | learning rate: 1.281092E-04 | global batch size:    64 | lm loss: 3.244599E+00 | loss scale: 2097152.0 | grad norm: 0.395 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 18:26:32] iteration    85400/  500000 | consumed samples:      5465600 | elapsed time per iteration (ms): 620.4 | learning rate: 1.280588E-04 | global batch size:    64 | lm loss: 3.224377E+00 | loss scale: 2097152.0 | grad norm: 0.401 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 18:27:34] iteration    85500/  500000 | consumed samples:      5472000 | elapsed time per iteration (ms): 618.2 | learning rate: 1.280083E-04 | global batch size:    64 | lm loss: 3.227363E+00 | loss scale: 2097152.0 | grad norm: 0.411 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 18:28:36] iteration    85600/  500000 | consumed samples:      5478400 | elapsed time per iteration (ms): 619.5 | learning rate: 1.279578E-04 | global batch size:    64 | lm loss: 3.235669E+00 | loss scale: 2097152.0 | grad norm: 0.397 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 18:29:38] iteration    85700/  500000 | consumed samples:      5484800 | elapsed time per iteration (ms): 618.9 | learning rate: 1.279072E-04 | global batch size:    64 | lm loss: 3.242342E+00 | loss scale: 2097152.0 | grad norm: 0.408 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 18:30:40] iteration    85800/  500000 | consumed samples:      5491200 | elapsed time per iteration (ms): 619.6 | learning rate: 1.278565E-04 | global batch size:    64 | lm loss: 3.231679E+00 | loss scale: 2097152.0 | grad norm: 0.398 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 18:31:42] iteration    85900/  500000 | consumed samples:      5497600 | elapsed time per iteration (ms): 618.2 | learning rate: 1.278058E-04 | global batch size:    64 | lm loss: 3.250251E+00 | loss scale: 2097152.0 | grad norm: 0.408 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 18:32:44] iteration    86000/  500000 | consumed samples:      5504000 | elapsed time per iteration (ms): 620.1 | learning rate: 1.277551E-04 | global batch size:    64 | lm loss: 3.229256E+00 | loss scale: 2097152.0 | grad norm: 0.397 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2463.53, 2463.61)
-------------------------------------------------------------------------------------------------
 validation loss at iteration 86000 | lm loss value: 3.681183E+00 | lm loss PPL: 3.969331E+01 | 
-------------------------------------------------------------------------------------------------
 [2024-06-24 18:33:48] iteration    86100/  500000 | consumed samples:      5510400 | elapsed time per iteration (ms): 620.3 | learning rate: 1.277043E-04 | global batch size:    64 | lm loss: 3.237221E+00 | loss scale: 2097152.0 | grad norm: 0.415 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 18:34:50] iteration    86200/  500000 | consumed samples:      5516800 | elapsed time per iteration (ms): 618.4 | learning rate: 1.276545E-04 | global batch size:    64 | lm loss: 3.231123E+00 | loss scale: 2097152.0 | grad norm: 0.401 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-24 18:35:52] iteration    86300/  500000 | consumed samples:      5523200 | elapsed time per iteration (ms): 618.9 | learning rate: 1.276037E-04 | global batch size:    64 | lm loss: 3.227148E+00 | loss scale: 2097152.0 | grad norm: 0.402 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 18:36:54] iteration    86400/  500000 | consumed samples:      5529600 | elapsed time per iteration (ms): 616.4 | learning rate: 1.275527E-04 | global batch size:    64 | lm loss: 3.238579E+00 | loss scale: 2097152.0 | grad norm: 0.398 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 18:37:56] iteration    86500/  500000 | consumed samples:      5536000 | elapsed time per iteration (ms): 617.8 | learning rate: 1.275018E-04 | global batch size:    64 | lm loss: 3.233689E+00 | loss scale: 2097152.0 | grad norm: 0.390 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 18:38:58] iteration    86600/  500000 | consumed samples:      5542400 | elapsed time per iteration (ms): 620.1 | learning rate: 1.274508E-04 | global batch size:    64 | lm loss: 3.220316E+00 | loss scale: 2097152.0 | grad norm: 0.413 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 18:40:00] iteration    86700/  500000 | consumed samples:      5548800 | elapsed time per iteration (ms): 621.0 | learning rate: 1.273997E-04 | global batch size:    64 | lm loss: 3.222036E+00 | loss scale: 2097152.0 | grad norm: 0.411 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 18:41:01] iteration    86800/  500000 | consumed samples:      5555200 | elapsed time per iteration (ms): 617.4 | learning rate: 1.273486E-04 | global batch size:    64 | lm loss: 3.233318E+00 | loss scale: 2097152.0 | grad norm: 0.404 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 18:42:03] iteration    86900/  500000 | consumed samples:      5561600 | elapsed time per iteration (ms): 617.8 | learning rate: 1.272975E-04 | global batch size:    64 | lm loss: 3.223987E+00 | loss scale: 2097152.0 | grad norm: 0.401 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 18:43:05] iteration    87000/  500000 | consumed samples:      5568000 | elapsed time per iteration (ms): 621.0 | learning rate: 1.272463E-04 | global batch size:    64 | lm loss: 3.222693E+00 | loss scale: 2097152.0 | grad norm: 0.409 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2463.66, 2463.67)
-------------------------------------------------------------------------------------------------
 validation loss at iteration 87000 | lm loss value: 3.679503E+00 | lm loss PPL: 3.962669E+01 | 
-------------------------------------------------------------------------------------------------
 [2024-06-24 18:44:10] iteration    87100/  500000 | consumed samples:      5574400 | elapsed time per iteration (ms): 619.4 | learning rate: 1.271950E-04 | global batch size:    64 | lm loss: 3.246863E+00 | loss scale: 2097152.0 | grad norm: 0.406 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 18:45:12] iteration    87200/  500000 | consumed samples:      5580800 | elapsed time per iteration (ms): 618.7 | learning rate: 1.271448E-04 | global batch size:    64 | lm loss: 3.236380E+00 | loss scale: 2097152.0 | grad norm: 0.400 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-24 18:46:14] iteration    87300/  500000 | consumed samples:      5587200 | elapsed time per iteration (ms): 621.4 | learning rate: 1.270934E-04 | global batch size:    64 | lm loss: 3.215896E+00 | loss scale: 2097152.0 | grad norm: 0.399 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 18:47:16] iteration    87400/  500000 | consumed samples:      5593600 | elapsed time per iteration (ms): 618.7 | learning rate: 1.270420E-04 | global batch size:    64 | lm loss: 3.240837E+00 | loss scale: 2097152.0 | grad norm: 0.412 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 18:48:17] iteration    87500/  500000 | consumed samples:      5600000 | elapsed time per iteration (ms): 618.2 | learning rate: 1.269906E-04 | global batch size:    64 | lm loss: 3.226482E+00 | loss scale: 2097152.0 | grad norm: 0.401 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 18:49:19] iteration    87600/  500000 | consumed samples:      5606400 | elapsed time per iteration (ms): 618.8 | learning rate: 1.269391E-04 | global batch size:    64 | lm loss: 3.212127E+00 | loss scale: 2097152.0 | grad norm: 0.391 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 18:50:21] iteration    87700/  500000 | consumed samples:      5612800 | elapsed time per iteration (ms): 619.5 | learning rate: 1.268876E-04 | global batch size:    64 | lm loss: 3.222580E+00 | loss scale: 2097152.0 | grad norm: 0.408 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 18:51:23] iteration    87800/  500000 | consumed samples:      5619200 | elapsed time per iteration (ms): 619.4 | learning rate: 1.268360E-04 | global batch size:    64 | lm loss: 3.223234E+00 | loss scale: 2097152.0 | grad norm: 0.408 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 18:52:25] iteration    87900/  500000 | consumed samples:      5625600 | elapsed time per iteration (ms): 620.4 | learning rate: 1.267844E-04 | global batch size:    64 | lm loss: 3.231722E+00 | loss scale: 2097152.0 | grad norm: 0.406 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 18:53:27] iteration    88000/  500000 | consumed samples:      5632000 | elapsed time per iteration (ms): 622.2 | learning rate: 1.267328E-04 | global batch size:    64 | lm loss: 3.222796E+00 | loss scale: 2097152.0 | grad norm: 0.411 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2463.72, 2463.82)
-------------------------------------------------------------------------------------------------
 validation loss at iteration 88000 | lm loss value: 3.665958E+00 | lm loss PPL: 3.909358E+01 | 
-------------------------------------------------------------------------------------------------
 [2024-06-24 18:54:32] iteration    88100/  500000 | consumed samples:      5638400 | elapsed time per iteration (ms): 619.2 | learning rate: 1.266816E-04 | global batch size:    64 | lm loss: 3.233165E+00 | loss scale: 1048576.0 | grad norm: 0.391 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-24 18:55:34] iteration    88200/  500000 | consumed samples:      5644800 | elapsed time per iteration (ms): 618.4 | learning rate: 1.266298E-04 | global batch size:    64 | lm loss: 3.218791E+00 | loss scale: 1048576.0 | grad norm: 0.396 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 18:56:36] iteration    88300/  500000 | consumed samples:      5651200 | elapsed time per iteration (ms): 620.5 | learning rate: 1.265780E-04 | global batch size:    64 | lm loss: 3.236738E+00 | loss scale: 1048576.0 | grad norm: 0.395 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 18:57:38] iteration    88400/  500000 | consumed samples:      5657600 | elapsed time per iteration (ms): 620.3 | learning rate: 1.265262E-04 | global batch size:    64 | lm loss: 3.230318E+00 | loss scale: 1048576.0 | grad norm: 0.410 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 18:58:40] iteration    88500/  500000 | consumed samples:      5664000 | elapsed time per iteration (ms): 618.4 | learning rate: 1.264743E-04 | global batch size:    64 | lm loss: 3.221428E+00 | loss scale: 1048576.0 | grad norm: 0.400 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 18:59:42] iteration    88600/  500000 | consumed samples:      5670400 | elapsed time per iteration (ms): 619.5 | learning rate: 1.264224E-04 | global batch size:    64 | lm loss: 3.228629E+00 | loss scale: 1048576.0 | grad norm: 0.388 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 19:00:44] iteration    88700/  500000 | consumed samples:      5676800 | elapsed time per iteration (ms): 619.9 | learning rate: 1.263704E-04 | global batch size:    64 | lm loss: 3.234012E+00 | loss scale: 1048576.0 | grad norm: 0.399 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 19:01:45] iteration    88800/  500000 | consumed samples:      5683200 | elapsed time per iteration (ms): 619.4 | learning rate: 1.263184E-04 | global batch size:    64 | lm loss: 3.215071E+00 | loss scale: 1048576.0 | grad norm: 0.412 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 19:02:47] iteration    88900/  500000 | consumed samples:      5689600 | elapsed time per iteration (ms): 618.9 | learning rate: 1.262663E-04 | global batch size:    64 | lm loss: 3.245205E+00 | loss scale: 1048576.0 | grad norm: 0.398 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 19:03:49] iteration    89000/  500000 | consumed samples:      5696000 | elapsed time per iteration (ms): 619.0 | learning rate: 1.262142E-04 | global batch size:    64 | lm loss: 3.225952E+00 | loss scale: 1048576.0 | grad norm: 0.407 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2465.37, 2465.41)
-------------------------------------------------------------------------------------------------
 validation loss at iteration 89000 | lm loss value: 3.646750E+00 | lm loss PPL: 3.834983E+01 | 
-------------------------------------------------------------------------------------------------
 [2024-06-24 19:04:54] iteration    89100/  500000 | consumed samples:      5702400 | elapsed time per iteration (ms): 619.1 | learning rate: 1.261620E-04 | global batch size:    64 | lm loss: 3.229957E+00 | loss scale: 2097152.0 | grad norm: 0.419 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 19:05:56] iteration    89200/  500000 | consumed samples:      5708800 | elapsed time per iteration (ms): 619.0 | learning rate: 1.261098E-04 | global batch size:    64 | lm loss: 3.228363E+00 | loss scale: 2097152.0 | grad norm: 0.401 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 19:06:58] iteration    89300/  500000 | consumed samples:      5715200 | elapsed time per iteration (ms): 620.5 | learning rate: 1.260576E-04 | global batch size:    64 | lm loss: 3.229441E+00 | loss scale: 2097152.0 | grad norm: 0.408 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 19:07:59] iteration    89400/  500000 | consumed samples:      5721600 | elapsed time per iteration (ms): 618.9 | learning rate: 1.260053E-04 | global batch size:    64 | lm loss: 3.206326E+00 | loss scale: 2097152.0 | grad norm: 0.402 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 19:09:01] iteration    89500/  500000 | consumed samples:      5728000 | elapsed time per iteration (ms): 619.6 | learning rate: 1.259529E-04 | global batch size:    64 | lm loss: 3.244409E+00 | loss scale: 2097152.0 | grad norm: 0.425 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 19:10:03] iteration    89600/  500000 | consumed samples:      5734400 | elapsed time per iteration (ms): 619.7 | learning rate: 1.259006E-04 | global batch size:    64 | lm loss: 3.223632E+00 | loss scale: 2097152.0 | grad norm: 0.391 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 19:11:05] iteration    89700/  500000 | consumed samples:      5740800 | elapsed time per iteration (ms): 619.3 | learning rate: 1.258481E-04 | global batch size:    64 | lm loss: 3.216970E+00 | loss scale: 2097152.0 | grad norm: 0.409 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 19:12:07] iteration    89800/  500000 | consumed samples:      5747200 | elapsed time per iteration (ms): 618.9 | learning rate: 1.257956E-04 | global batch size:    64 | lm loss: 3.228181E+00 | loss scale: 2097152.0 | grad norm: 0.398 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 19:13:09] iteration    89900/  500000 | consumed samples:      5753600 | elapsed time per iteration (ms): 620.0 | learning rate: 1.257431E-04 | global batch size:    64 | lm loss: 3.224721E+00 | loss scale: 2097152.0 | grad norm: 0.410 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 19:14:11] iteration    90000/  500000 | consumed samples:      5760000 | elapsed time per iteration (ms): 619.2 | learning rate: 1.256906E-04 | global batch size:    64 | lm loss: 3.215214E+00 | loss scale: 2097152.0 | grad norm: 0.391 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2462.52, 2462.65)
-------------------------------------------------------------------------------------------------
 validation loss at iteration 90000 | lm loss value: 3.654821E+00 | lm loss PPL: 3.866061E+01 | 
-------------------------------------------------------------------------------------------------
saving checkpoint at iteration   90000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-distribution in torch format
  successfully saved checkpoint at iteration   90000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-distribution
(min, max) time across ranks (ms):
    save-checkpoint ................................: (2283.50, 2283.52)
 [2024-06-24 19:15:18] iteration    90100/  500000 | consumed samples:      5766400 | elapsed time per iteration (ms): 616.7 | learning rate: 1.256390E-04 | global batch size:    64 | lm loss: 3.215137E+00 | loss scale: 2097152.0 | grad norm: 0.406 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-24 19:16:19] iteration    90200/  500000 | consumed samples:      5772800 | elapsed time per iteration (ms): 618.3 | learning rate: 1.255863E-04 | global batch size:    64 | lm loss: 3.228018E+00 | loss scale: 2097152.0 | grad norm: 0.396 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 19:17:21] iteration    90300/  500000 | consumed samples:      5779200 | elapsed time per iteration (ms): 618.6 | learning rate: 1.255336E-04 | global batch size:    64 | lm loss: 3.231791E+00 | loss scale: 2097152.0 | grad norm: 0.390 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 19:18:23] iteration    90400/  500000 | consumed samples:      5785600 | elapsed time per iteration (ms): 620.8 | learning rate: 1.254809E-04 | global batch size:    64 | lm loss: 3.215836E+00 | loss scale: 2097152.0 | grad norm: 0.397 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 19:19:25] iteration    90500/  500000 | consumed samples:      5792000 | elapsed time per iteration (ms): 619.1 | learning rate: 1.254286E-04 | global batch size:    64 | lm loss: 3.223000E+00 | loss scale: 1048576.0 | grad norm: 0.468 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-24 19:20:27] iteration    90600/  500000 | consumed samples:      5798400 | elapsed time per iteration (ms): 621.9 | learning rate: 1.253758E-04 | global batch size:    64 | lm loss: 3.221347E+00 | loss scale: 1048576.0 | grad norm: 0.403 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 19:21:30] iteration    90700/  500000 | consumed samples:      5804800 | elapsed time per iteration (ms): 621.5 | learning rate: 1.253229E-04 | global batch size:    64 | lm loss: 3.220134E+00 | loss scale: 1048576.0 | grad norm: 0.399 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 19:22:32] iteration    90800/  500000 | consumed samples:      5811200 | elapsed time per iteration (ms): 621.3 | learning rate: 1.252700E-04 | global batch size:    64 | lm loss: 3.197520E+00 | loss scale: 1048576.0 | grad norm: 0.396 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 19:23:34] iteration    90900/  500000 | consumed samples:      5817600 | elapsed time per iteration (ms): 620.4 | learning rate: 1.252170E-04 | global batch size:    64 | lm loss: 3.229530E+00 | loss scale: 1048576.0 | grad norm: 0.411 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 19:24:36] iteration    91000/  500000 | consumed samples:      5824000 | elapsed time per iteration (ms): 620.2 | learning rate: 1.251640E-04 | global batch size:    64 | lm loss: 3.220386E+00 | loss scale: 1048576.0 | grad norm: 0.407 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2462.19, 2462.22)
-------------------------------------------------------------------------------------------------
 validation loss at iteration 91000 | lm loss value: 3.680191E+00 | lm loss PPL: 3.965396E+01 | 
-------------------------------------------------------------------------------------------------
 [2024-06-24 19:25:40] iteration    91100/  500000 | consumed samples:      5830400 | elapsed time per iteration (ms): 619.8 | learning rate: 1.251110E-04 | global batch size:    64 | lm loss: 3.214264E+00 | loss scale: 1048576.0 | grad norm: 0.402 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 19:26:42] iteration    91200/  500000 | consumed samples:      5836800 | elapsed time per iteration (ms): 621.5 | learning rate: 1.250578E-04 | global batch size:    64 | lm loss: 3.232117E+00 | loss scale: 1048576.0 | grad norm: 0.405 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 19:27:44] iteration    91300/  500000 | consumed samples:      5843200 | elapsed time per iteration (ms): 620.6 | learning rate: 1.250047E-04 | global batch size:    64 | lm loss: 3.222646E+00 | loss scale: 1048576.0 | grad norm: 0.388 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 19:28:46] iteration    91400/  500000 | consumed samples:      5849600 | elapsed time per iteration (ms): 619.4 | learning rate: 1.249515E-04 | global batch size:    64 | lm loss: 3.214746E+00 | loss scale: 1048576.0 | grad norm: 0.400 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 19:29:48] iteration    91500/  500000 | consumed samples:      5856000 | elapsed time per iteration (ms): 621.5 | learning rate: 1.248983E-04 | global batch size:    64 | lm loss: 3.208272E+00 | loss scale: 2097152.0 | grad norm: 0.415 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 19:30:50] iteration    91600/  500000 | consumed samples:      5862400 | elapsed time per iteration (ms): 618.8 | learning rate: 1.248450E-04 | global batch size:    64 | lm loss: 3.220862E+00 | loss scale: 2097152.0 | grad norm: 0.404 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 19:31:52] iteration    91700/  500000 | consumed samples:      5868800 | elapsed time per iteration (ms): 619.3 | learning rate: 1.247917E-04 | global batch size:    64 | lm loss: 3.219732E+00 | loss scale: 2097152.0 | grad norm: 0.404 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 19:32:54] iteration    91800/  500000 | consumed samples:      5875200 | elapsed time per iteration (ms): 617.5 | learning rate: 1.247383E-04 | global batch size:    64 | lm loss: 3.213427E+00 | loss scale: 2097152.0 | grad norm: 0.395 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 19:33:56] iteration    91900/  500000 | consumed samples:      5881600 | elapsed time per iteration (ms): 618.4 | learning rate: 1.246849E-04 | global batch size:    64 | lm loss: 3.222973E+00 | loss scale: 2097152.0 | grad norm: 0.400 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 19:34:58] iteration    92000/  500000 | consumed samples:      5888000 | elapsed time per iteration (ms): 618.1 | learning rate: 1.246314E-04 | global batch size:    64 | lm loss: 3.224411E+00 | loss scale: 2097152.0 | grad norm: 0.404 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2465.35, 2465.42)
-------------------------------------------------------------------------------------------------
 validation loss at iteration 92000 | lm loss value: 3.689435E+00 | lm loss PPL: 4.002222E+01 | 
-------------------------------------------------------------------------------------------------
 [2024-06-24 19:36:02] iteration    92100/  500000 | consumed samples:      5894400 | elapsed time per iteration (ms): 618.8 | learning rate: 1.245779E-04 | global batch size:    64 | lm loss: 3.217965E+00 | loss scale: 2097152.0 | grad norm: 0.412 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 19:37:04] iteration    92200/  500000 | consumed samples:      5900800 | elapsed time per iteration (ms): 617.8 | learning rate: 1.245244E-04 | global batch size:    64 | lm loss: 3.214783E+00 | loss scale: 2097152.0 | grad norm: 0.392 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 19:38:06] iteration    92300/  500000 | consumed samples:      5907200 | elapsed time per iteration (ms): 618.8 | learning rate: 1.244708E-04 | global batch size:    64 | lm loss: 3.212493E+00 | loss scale: 2097152.0 | grad norm: 0.394 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 19:39:08] iteration    92400/  500000 | consumed samples:      5913600 | elapsed time per iteration (ms): 619.0 | learning rate: 1.244172E-04 | global batch size:    64 | lm loss: 3.221776E+00 | loss scale: 2097152.0 | grad norm: 0.412 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 19:40:10] iteration    92500/  500000 | consumed samples:      5920000 | elapsed time per iteration (ms): 621.0 | learning rate: 1.243646E-04 | global batch size:    64 | lm loss: 3.209289E+00 | loss scale: 2097152.0 | grad norm: 0.399 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-24 19:41:12] iteration    92600/  500000 | consumed samples:      5926400 | elapsed time per iteration (ms): 619.7 | learning rate: 1.243109E-04 | global batch size:    64 | lm loss: 3.218542E+00 | loss scale: 2097152.0 | grad norm: 0.426 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 19:42:14] iteration    92700/  500000 | consumed samples:      5932800 | elapsed time per iteration (ms): 620.1 | learning rate: 1.242571E-04 | global batch size:    64 | lm loss: 3.206217E+00 | loss scale: 2097152.0 | grad norm: 0.411 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 19:43:15] iteration    92800/  500000 | consumed samples:      5939200 | elapsed time per iteration (ms): 617.8 | learning rate: 1.242033E-04 | global batch size:    64 | lm loss: 3.198698E+00 | loss scale: 2097152.0 | grad norm: 0.396 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 19:44:17] iteration    92900/  500000 | consumed samples:      5945600 | elapsed time per iteration (ms): 618.8 | learning rate: 1.241495E-04 | global batch size:    64 | lm loss: 3.202524E+00 | loss scale: 2097152.0 | grad norm: 0.408 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 19:45:19] iteration    93000/  500000 | consumed samples:      5952000 | elapsed time per iteration (ms): 620.1 | learning rate: 1.240956E-04 | global batch size:    64 | lm loss: 3.215089E+00 | loss scale: 2097152.0 | grad norm: 0.401 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2463.78, 2463.78)
-------------------------------------------------------------------------------------------------
 validation loss at iteration 93000 | lm loss value: 3.696772E+00 | lm loss PPL: 4.031696E+01 | 
-------------------------------------------------------------------------------------------------
 [2024-06-24 19:46:24] iteration    93100/  500000 | consumed samples:      5958400 | elapsed time per iteration (ms): 620.1 | learning rate: 1.240416E-04 | global batch size:    64 | lm loss: 3.211839E+00 | loss scale: 2097152.0 | grad norm: 0.403 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 19:47:26] iteration    93200/  500000 | consumed samples:      5964800 | elapsed time per iteration (ms): 623.6 | learning rate: 1.239877E-04 | global batch size:    64 | lm loss: 3.225432E+00 | loss scale: 2097152.0 | grad norm: 0.408 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 19:48:28] iteration    93300/  500000 | consumed samples:      5971200 | elapsed time per iteration (ms): 620.4 | learning rate: 1.239336E-04 | global batch size:    64 | lm loss: 3.209875E+00 | loss scale: 2097152.0 | grad norm: 0.419 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 19:49:30] iteration    93400/  500000 | consumed samples:      5977600 | elapsed time per iteration (ms): 622.0 | learning rate: 1.238796E-04 | global batch size:    64 | lm loss: 3.223344E+00 | loss scale: 2097152.0 | grad norm: 0.404 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 19:50:32] iteration    93500/  500000 | consumed samples:      5984000 | elapsed time per iteration (ms): 617.7 | learning rate: 1.238266E-04 | global batch size:    64 | lm loss: 3.203880E+00 | loss scale: 2097152.0 | grad norm: 0.416 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-24 19:51:34] iteration    93600/  500000 | consumed samples:      5990400 | elapsed time per iteration (ms): 619.1 | learning rate: 1.237724E-04 | global batch size:    64 | lm loss: 3.216213E+00 | loss scale: 2097152.0 | grad norm: 0.391 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 19:52:36] iteration    93700/  500000 | consumed samples:      5996800 | elapsed time per iteration (ms): 619.9 | learning rate: 1.237188E-04 | global batch size:    64 | lm loss: 3.216313E+00 | loss scale: 1048576.0 | grad norm: 0.403 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-24 19:53:38] iteration    93800/  500000 | consumed samples:      6003200 | elapsed time per iteration (ms): 619.8 | learning rate: 1.236645E-04 | global batch size:    64 | lm loss: 3.222491E+00 | loss scale: 1048576.0 | grad norm: 0.396 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 19:54:40] iteration    93900/  500000 | consumed samples:      6009600 | elapsed time per iteration (ms): 620.6 | learning rate: 1.236102E-04 | global batch size:    64 | lm loss: 3.216784E+00 | loss scale: 1048576.0 | grad norm: 0.410 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 19:55:42] iteration    94000/  500000 | consumed samples:      6016000 | elapsed time per iteration (ms): 617.3 | learning rate: 1.235559E-04 | global batch size:    64 | lm loss: 3.202764E+00 | loss scale: 1048576.0 | grad norm: 0.421 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2463.23, 2463.30)
-------------------------------------------------------------------------------------------------
 validation loss at iteration 94000 | lm loss value: 3.664144E+00 | lm loss PPL: 3.902271E+01 | 
-------------------------------------------------------------------------------------------------
 [2024-06-24 19:56:46] iteration    94100/  500000 | consumed samples:      6022400 | elapsed time per iteration (ms): 618.8 | learning rate: 1.235016E-04 | global batch size:    64 | lm loss: 3.216251E+00 | loss scale: 1048576.0 | grad norm: 0.418 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 19:57:48] iteration    94200/  500000 | consumed samples:      6028800 | elapsed time per iteration (ms): 618.6 | learning rate: 1.234472E-04 | global batch size:    64 | lm loss: 3.213348E+00 | loss scale: 1048576.0 | grad norm: 0.393 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 19:58:50] iteration    94300/  500000 | consumed samples:      6035200 | elapsed time per iteration (ms): 619.2 | learning rate: 1.233927E-04 | global batch size:    64 | lm loss: 3.206382E+00 | loss scale: 1048576.0 | grad norm: 0.400 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 19:59:52] iteration    94400/  500000 | consumed samples:      6041600 | elapsed time per iteration (ms): 619.4 | learning rate: 1.233382E-04 | global batch size:    64 | lm loss: 3.200555E+00 | loss scale: 1048576.0 | grad norm: 0.429 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 20:00:54] iteration    94500/  500000 | consumed samples:      6048000 | elapsed time per iteration (ms): 618.2 | learning rate: 1.232837E-04 | global batch size:    64 | lm loss: 3.212949E+00 | loss scale: 1048576.0 | grad norm: 0.393 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 20:01:55] iteration    94600/  500000 | consumed samples:      6054400 | elapsed time per iteration (ms): 616.0 | learning rate: 1.232291E-04 | global batch size:    64 | lm loss: 3.226166E+00 | loss scale: 1048576.0 | grad norm: 0.399 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 20:02:57] iteration    94700/  500000 | consumed samples:      6060800 | elapsed time per iteration (ms): 618.9 | learning rate: 1.231745E-04 | global batch size:    64 | lm loss: 3.217477E+00 | loss scale: 2097152.0 | grad norm: 0.398 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 20:03:59] iteration    94800/  500000 | consumed samples:      6067200 | elapsed time per iteration (ms): 620.2 | learning rate: 1.231204E-04 | global batch size:    64 | lm loss: 3.205582E+00 | loss scale: 2097152.0 | grad norm: 0.401 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-24 20:05:01] iteration    94900/  500000 | consumed samples:      6073600 | elapsed time per iteration (ms): 619.1 | learning rate: 1.230657E-04 | global batch size:    64 | lm loss: 3.213032E+00 | loss scale: 2097152.0 | grad norm: 0.405 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 20:06:03] iteration    95000/  500000 | consumed samples:      6080000 | elapsed time per iteration (ms): 620.1 | learning rate: 1.230109E-04 | global batch size:    64 | lm loss: 3.203408E+00 | loss scale: 2097152.0 | grad norm: 0.396 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2464.03, 2464.16)
-------------------------------------------------------------------------------------------------
 validation loss at iteration 95000 | lm loss value: 3.599257E+00 | lm loss PPL: 3.657103E+01 | 
-------------------------------------------------------------------------------------------------
 [2024-06-24 20:07:08] iteration    95100/  500000 | consumed samples:      6086400 | elapsed time per iteration (ms): 618.6 | learning rate: 1.229561E-04 | global batch size:    64 | lm loss: 3.214799E+00 | loss scale: 2097152.0 | grad norm: 0.409 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 20:08:10] iteration    95200/  500000 | consumed samples:      6092800 | elapsed time per iteration (ms): 620.2 | learning rate: 1.229013E-04 | global batch size:    64 | lm loss: 3.215201E+00 | loss scale: 2097152.0 | grad norm: 0.425 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 20:09:11] iteration    95300/  500000 | consumed samples:      6099200 | elapsed time per iteration (ms): 618.8 | learning rate: 1.228470E-04 | global batch size:    64 | lm loss: 3.214456E+00 | loss scale: 1048576.0 | grad norm: 0.412 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-24 20:10:13] iteration    95400/  500000 | consumed samples:      6105600 | elapsed time per iteration (ms): 619.9 | learning rate: 1.227921E-04 | global batch size:    64 | lm loss: 3.214392E+00 | loss scale: 1048576.0 | grad norm: 0.411 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 20:11:15] iteration    95500/  500000 | consumed samples:      6112000 | elapsed time per iteration (ms): 620.4 | learning rate: 1.227371E-04 | global batch size:    64 | lm loss: 3.193687E+00 | loss scale: 1048576.0 | grad norm: 0.396 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 20:12:18] iteration    95600/  500000 | consumed samples:      6118400 | elapsed time per iteration (ms): 620.5 | learning rate: 1.226821E-04 | global batch size:    64 | lm loss: 3.189778E+00 | loss scale: 1048576.0 | grad norm: 0.415 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 20:13:20] iteration    95700/  500000 | consumed samples:      6124800 | elapsed time per iteration (ms): 620.3 | learning rate: 1.226271E-04 | global batch size:    64 | lm loss: 3.205813E+00 | loss scale: 1048576.0 | grad norm: 0.408 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 20:14:22] iteration    95800/  500000 | consumed samples:      6131200 | elapsed time per iteration (ms): 620.8 | learning rate: 1.225720E-04 | global batch size:    64 | lm loss: 3.229734E+00 | loss scale: 1048576.0 | grad norm: 0.386 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 20:15:24] iteration    95900/  500000 | consumed samples:      6137600 | elapsed time per iteration (ms): 620.7 | learning rate: 1.225169E-04 | global batch size:    64 | lm loss: 3.207360E+00 | loss scale: 1048576.0 | grad norm: 0.400 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 20:16:26] iteration    96000/  500000 | consumed samples:      6144000 | elapsed time per iteration (ms): 619.6 | learning rate: 1.224617E-04 | global batch size:    64 | lm loss: 3.210683E+00 | loss scale: 1048576.0 | grad norm: 0.409 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2463.57, 2463.71)
-------------------------------------------------------------------------------------------------
 validation loss at iteration 96000 | lm loss value: 3.665398E+00 | lm loss PPL: 3.907170E+01 | 
-------------------------------------------------------------------------------------------------
 [2024-06-24 20:17:30] iteration    96100/  500000 | consumed samples:      6150400 | elapsed time per iteration (ms): 618.6 | learning rate: 1.224065E-04 | global batch size:    64 | lm loss: 3.214225E+00 | loss scale: 1048576.0 | grad norm: 0.415 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 20:18:32] iteration    96200/  500000 | consumed samples:      6156800 | elapsed time per iteration (ms): 619.0 | learning rate: 1.223512E-04 | global batch size:    64 | lm loss: 3.210893E+00 | loss scale: 1048576.0 | grad norm: 0.396 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 20:19:34] iteration    96300/  500000 | consumed samples:      6163200 | elapsed time per iteration (ms): 619.8 | learning rate: 1.222959E-04 | global batch size:    64 | lm loss: 3.199464E+00 | loss scale: 2097152.0 | grad norm: 0.397 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 20:20:36] iteration    96400/  500000 | consumed samples:      6169600 | elapsed time per iteration (ms): 616.6 | learning rate: 1.222406E-04 | global batch size:    64 | lm loss: 3.219074E+00 | loss scale: 2097152.0 | grad norm: 0.402 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 20:21:37] iteration    96500/  500000 | consumed samples:      6176000 | elapsed time per iteration (ms): 618.4 | learning rate: 1.221852E-04 | global batch size:    64 | lm loss: 3.205387E+00 | loss scale: 2097152.0 | grad norm: 0.413 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 20:22:39] iteration    96600/  500000 | consumed samples:      6182400 | elapsed time per iteration (ms): 620.0 | learning rate: 1.221298E-04 | global batch size:    64 | lm loss: 3.200884E+00 | loss scale: 2097152.0 | grad norm: 0.390 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 20:23:41] iteration    96700/  500000 | consumed samples:      6188800 | elapsed time per iteration (ms): 621.3 | learning rate: 1.220744E-04 | global batch size:    64 | lm loss: 3.197928E+00 | loss scale: 2097152.0 | grad norm: 0.406 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 20:24:43] iteration    96800/  500000 | consumed samples:      6195200 | elapsed time per iteration (ms): 617.7 | learning rate: 1.220189E-04 | global batch size:    64 | lm loss: 3.201093E+00 | loss scale: 2097152.0 | grad norm: 0.398 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 20:25:45] iteration    96900/  500000 | consumed samples:      6201600 | elapsed time per iteration (ms): 618.7 | learning rate: 1.219633E-04 | global batch size:    64 | lm loss: 3.206046E+00 | loss scale: 2097152.0 | grad norm: 0.417 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 20:26:47] iteration    97000/  500000 | consumed samples:      6208000 | elapsed time per iteration (ms): 619.7 | learning rate: 1.219077E-04 | global batch size:    64 | lm loss: 3.189611E+00 | loss scale: 2097152.0 | grad norm: 0.406 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2464.80, 2464.88)
-------------------------------------------------------------------------------------------------
 validation loss at iteration 97000 | lm loss value: 3.726639E+00 | lm loss PPL: 4.153927E+01 | 
-------------------------------------------------------------------------------------------------
 [2024-06-24 20:27:52] iteration    97100/  500000 | consumed samples:      6214400 | elapsed time per iteration (ms): 619.8 | learning rate: 1.218521E-04 | global batch size:    64 | lm loss: 3.209723E+00 | loss scale: 2097152.0 | grad norm: 0.400 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 20:28:53] iteration    97200/  500000 | consumed samples:      6220800 | elapsed time per iteration (ms): 618.3 | learning rate: 1.217965E-04 | global batch size:    64 | lm loss: 3.189363E+00 | loss scale: 2097152.0 | grad norm: 0.407 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 20:29:55] iteration    97300/  500000 | consumed samples:      6227200 | elapsed time per iteration (ms): 619.8 | learning rate: 1.217419E-04 | global batch size:    64 | lm loss: 3.199248E+00 | loss scale: 2097152.0 | grad norm: 0.402 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-24 20:30:57] iteration    97400/  500000 | consumed samples:      6233600 | elapsed time per iteration (ms): 618.9 | learning rate: 1.216861E-04 | global batch size:    64 | lm loss: 3.207573E+00 | loss scale: 2097152.0 | grad norm: 0.405 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 20:31:59] iteration    97500/  500000 | consumed samples:      6240000 | elapsed time per iteration (ms): 618.9 | learning rate: 1.216303E-04 | global batch size:    64 | lm loss: 3.190157E+00 | loss scale: 2097152.0 | grad norm: 0.401 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 20:33:01] iteration    97600/  500000 | consumed samples:      6246400 | elapsed time per iteration (ms): 618.6 | learning rate: 1.215745E-04 | global batch size:    64 | lm loss: 3.193409E+00 | loss scale: 2097152.0 | grad norm: 0.414 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 20:34:03] iteration    97700/  500000 | consumed samples:      6252800 | elapsed time per iteration (ms): 619.7 | learning rate: 1.215186E-04 | global batch size:    64 | lm loss: 3.197706E+00 | loss scale: 2097152.0 | grad norm: 0.428 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 20:35:05] iteration    97800/  500000 | consumed samples:      6259200 | elapsed time per iteration (ms): 619.9 | learning rate: 1.214627E-04 | global batch size:    64 | lm loss: 3.197539E+00 | loss scale: 2097152.0 | grad norm: 0.425 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 20:36:07] iteration    97900/  500000 | consumed samples:      6265600 | elapsed time per iteration (ms): 619.0 | learning rate: 1.214068E-04 | global batch size:    64 | lm loss: 3.198000E+00 | loss scale: 2097152.0 | grad norm: 0.407 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 20:37:09] iteration    98000/  500000 | consumed samples:      6272000 | elapsed time per iteration (ms): 620.5 | learning rate: 1.213508E-04 | global batch size:    64 | lm loss: 3.191977E+00 | loss scale: 2097152.0 | grad norm: 0.407 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2463.34, 2463.34)
-------------------------------------------------------------------------------------------------
 validation loss at iteration 98000 | lm loss value: 3.669986E+00 | lm loss PPL: 3.925136E+01 | 
-------------------------------------------------------------------------------------------------
 [2024-06-24 20:38:13] iteration    98100/  500000 | consumed samples:      6278400 | elapsed time per iteration (ms): 619.3 | learning rate: 1.212948E-04 | global batch size:    64 | lm loss: 3.206656E+00 | loss scale: 2097152.0 | grad norm: 0.396 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 20:39:15] iteration    98200/  500000 | consumed samples:      6284800 | elapsed time per iteration (ms): 617.8 | learning rate: 1.212387E-04 | global batch size:    64 | lm loss: 3.202380E+00 | loss scale: 2097152.0 | grad norm: 0.401 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 20:40:17] iteration    98300/  500000 | consumed samples:      6291200 | elapsed time per iteration (ms): 622.6 | learning rate: 1.211837E-04 | global batch size:    64 | lm loss: 3.208309E+00 | loss scale: 2097152.0 | grad norm: 0.404 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-24 20:41:19] iteration    98400/  500000 | consumed samples:      6297600 | elapsed time per iteration (ms): 620.6 | learning rate: 1.211276E-04 | global batch size:    64 | lm loss: 3.201021E+00 | loss scale: 2097152.0 | grad norm: 0.391 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 20:42:21] iteration    98500/  500000 | consumed samples:      6304000 | elapsed time per iteration (ms): 620.4 | learning rate: 1.210714E-04 | global batch size:    64 | lm loss: 3.204544E+00 | loss scale: 2097152.0 | grad norm: 0.406 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 20:43:23] iteration    98600/  500000 | consumed samples:      6310400 | elapsed time per iteration (ms): 619.3 | learning rate: 1.210151E-04 | global batch size:    64 | lm loss: 3.202021E+00 | loss scale: 2097152.0 | grad norm: 0.403 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 20:44:25] iteration    98700/  500000 | consumed samples:      6316800 | elapsed time per iteration (ms): 618.5 | learning rate: 1.209589E-04 | global batch size:    64 | lm loss: 3.191588E+00 | loss scale: 2097152.0 | grad norm: 0.404 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 20:45:27] iteration    98800/  500000 | consumed samples:      6323200 | elapsed time per iteration (ms): 620.2 | learning rate: 1.209025E-04 | global batch size:    64 | lm loss: 3.196969E+00 | loss scale: 2097152.0 | grad norm: 0.424 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 20:46:29] iteration    98900/  500000 | consumed samples:      6329600 | elapsed time per iteration (ms): 618.0 | learning rate: 1.208462E-04 | global batch size:    64 | lm loss: 3.200082E+00 | loss scale: 2097152.0 | grad norm: 0.410 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 20:47:31] iteration    99000/  500000 | consumed samples:      6336000 | elapsed time per iteration (ms): 619.1 | learning rate: 1.207898E-04 | global batch size:    64 | lm loss: 3.206370E+00 | loss scale: 2097152.0 | grad norm: 0.414 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2463.16, 2463.27)
-------------------------------------------------------------------------------------------------
 validation loss at iteration 99000 | lm loss value: 3.664911E+00 | lm loss PPL: 3.905266E+01 | 
-------------------------------------------------------------------------------------------------
 [2024-06-24 20:48:35] iteration    99100/  500000 | consumed samples:      6342400 | elapsed time per iteration (ms): 618.0 | learning rate: 1.207334E-04 | global batch size:    64 | lm loss: 3.209237E+00 | loss scale: 2097152.0 | grad norm: 0.421 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 20:49:37] iteration    99200/  500000 | consumed samples:      6348800 | elapsed time per iteration (ms): 618.6 | learning rate: 1.206769E-04 | global batch size:    64 | lm loss: 3.197951E+00 | loss scale: 2097152.0 | grad norm: 0.395 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 20:50:39] iteration    99300/  500000 | consumed samples:      6355200 | elapsed time per iteration (ms): 618.9 | learning rate: 1.206204E-04 | global batch size:    64 | lm loss: 3.199955E+00 | loss scale: 4194304.0 | grad norm: 0.402 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 20:51:41] iteration    99400/  500000 | consumed samples:      6361600 | elapsed time per iteration (ms): 617.9 | learning rate: 1.205650E-04 | global batch size:    64 | lm loss: 3.197808E+00 | loss scale: 2097152.0 | grad norm: 0.395 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-24 20:52:43] iteration    99500/  500000 | consumed samples:      6368000 | elapsed time per iteration (ms): 618.9 | learning rate: 1.205089E-04 | global batch size:    64 | lm loss: 3.220943E+00 | loss scale: 1048576.0 | grad norm: 0.401 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-24 20:53:45] iteration    99600/  500000 | consumed samples:      6374400 | elapsed time per iteration (ms): 619.0 | learning rate: 1.204523E-04 | global batch size:    64 | lm loss: 3.202935E+00 | loss scale: 1048576.0 | grad norm: 0.418 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 20:54:46] iteration    99700/  500000 | consumed samples:      6380800 | elapsed time per iteration (ms): 618.9 | learning rate: 1.203956E-04 | global batch size:    64 | lm loss: 3.208161E+00 | loss scale: 1048576.0 | grad norm: 0.415 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 20:55:49] iteration    99800/  500000 | consumed samples:      6387200 | elapsed time per iteration (ms): 621.0 | learning rate: 1.203389E-04 | global batch size:    64 | lm loss: 3.204137E+00 | loss scale: 1048576.0 | grad norm: 0.411 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 20:56:50] iteration    99900/  500000 | consumed samples:      6393600 | elapsed time per iteration (ms): 618.8 | learning rate: 1.202822E-04 | global batch size:    64 | lm loss: 3.204699E+00 | loss scale: 1048576.0 | grad norm: 0.401 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 20:57:52] iteration   100000/  500000 | consumed samples:      6400000 | elapsed time per iteration (ms): 620.6 | learning rate: 1.202254E-04 | global batch size:    64 | lm loss: 3.207716E+00 | loss scale: 1048576.0 | grad norm: 0.412 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2462.71, 2462.71)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 100000 | lm loss value: 3.660428E+00 | lm loss PPL: 3.887799E+01 | 
--------------------------------------------------------------------------------------------------
saving checkpoint at iteration  100000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-distribution in torch format
  successfully saved checkpoint at iteration  100000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-distribution
(min, max) time across ranks (ms):
    save-checkpoint ................................: (2285.55, 2285.56)
 [2024-06-24 20:58:59] iteration   100100/  500000 | consumed samples:      6406400 | elapsed time per iteration (ms): 620.6 | learning rate: 1.201685E-04 | global batch size:    64 | lm loss: 3.212093E+00 | loss scale: 1048576.0 | grad norm: 0.393 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 21:00:01] iteration   100200/  500000 | consumed samples:      6412800 | elapsed time per iteration (ms): 620.4 | learning rate: 1.201117E-04 | global batch size:    64 | lm loss: 3.193288E+00 | loss scale: 1048576.0 | grad norm: 0.400 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 21:01:03] iteration   100300/  500000 | consumed samples:      6419200 | elapsed time per iteration (ms): 620.1 | learning rate: 1.200548E-04 | global batch size:    64 | lm loss: 3.190605E+00 | loss scale: 1048576.0 | grad norm: 0.404 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 21:02:05] iteration   100400/  500000 | consumed samples:      6425600 | elapsed time per iteration (ms): 620.8 | learning rate: 1.199978E-04 | global batch size:    64 | lm loss: 3.191194E+00 | loss scale: 1048576.0 | grad norm: 0.420 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 21:03:07] iteration   100500/  500000 | consumed samples:      6432000 | elapsed time per iteration (ms): 619.6 | learning rate: 1.199408E-04 | global batch size:    64 | lm loss: 3.212857E+00 | loss scale: 2097152.0 | grad norm: 0.396 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 21:04:09] iteration   100600/  500000 | consumed samples:      6438400 | elapsed time per iteration (ms): 618.2 | learning rate: 1.198838E-04 | global batch size:    64 | lm loss: 3.201117E+00 | loss scale: 2097152.0 | grad norm: 0.403 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 21:05:11] iteration   100700/  500000 | consumed samples:      6444800 | elapsed time per iteration (ms): 620.1 | learning rate: 1.198273E-04 | global batch size:    64 | lm loss: 3.200600E+00 | loss scale: 2097152.0 | grad norm: 0.395 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-24 21:06:13] iteration   100800/  500000 | consumed samples:      6451200 | elapsed time per iteration (ms): 618.2 | learning rate: 1.197708E-04 | global batch size:    64 | lm loss: 3.201923E+00 | loss scale: 1048576.0 | grad norm: 0.409 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-24 21:07:15] iteration   100900/  500000 | consumed samples:      6457600 | elapsed time per iteration (ms): 618.2 | learning rate: 1.197136E-04 | global batch size:    64 | lm loss: 3.197273E+00 | loss scale: 1048576.0 | grad norm: 0.408 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 21:08:17] iteration   101000/  500000 | consumed samples:      6464000 | elapsed time per iteration (ms): 619.1 | learning rate: 1.196564E-04 | global batch size:    64 | lm loss: 3.199459E+00 | loss scale: 1048576.0 | grad norm: 0.413 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2463.98, 2463.98)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 101000 | lm loss value: 3.655135E+00 | lm loss PPL: 3.867274E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-24 21:09:21] iteration   101100/  500000 | consumed samples:      6470400 | elapsed time per iteration (ms): 618.7 | learning rate: 1.195992E-04 | global batch size:    64 | lm loss: 3.187845E+00 | loss scale: 1048576.0 | grad norm: 0.398 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 21:10:23] iteration   101200/  500000 | consumed samples:      6476800 | elapsed time per iteration (ms): 619.7 | learning rate: 1.195420E-04 | global batch size:    64 | lm loss: 3.178308E+00 | loss scale: 1048576.0 | grad norm: 0.406 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 21:11:25] iteration   101300/  500000 | consumed samples:      6483200 | elapsed time per iteration (ms): 619.8 | learning rate: 1.194847E-04 | global batch size:    64 | lm loss: 3.178948E+00 | loss scale: 1048576.0 | grad norm: 0.419 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 21:12:27] iteration   101400/  500000 | consumed samples:      6489600 | elapsed time per iteration (ms): 619.1 | learning rate: 1.194273E-04 | global batch size:    64 | lm loss: 3.205228E+00 | loss scale: 1048576.0 | grad norm: 0.406 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 21:13:29] iteration   101500/  500000 | consumed samples:      6496000 | elapsed time per iteration (ms): 618.7 | learning rate: 1.193699E-04 | global batch size:    64 | lm loss: 3.188426E+00 | loss scale: 1048576.0 | grad norm: 0.409 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 21:14:31] iteration   101600/  500000 | consumed samples:      6502400 | elapsed time per iteration (ms): 619.5 | learning rate: 1.193125E-04 | global batch size:    64 | lm loss: 3.205039E+00 | loss scale: 1048576.0 | grad norm: 0.409 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 21:15:33] iteration   101700/  500000 | consumed samples:      6508800 | elapsed time per iteration (ms): 618.4 | learning rate: 1.192551E-04 | global batch size:    64 | lm loss: 3.197729E+00 | loss scale: 1048576.0 | grad norm: 0.411 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 21:16:35] iteration   101800/  500000 | consumed samples:      6515200 | elapsed time per iteration (ms): 619.8 | learning rate: 1.191976E-04 | global batch size:    64 | lm loss: 3.194236E+00 | loss scale: 2097152.0 | grad norm: 0.407 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 21:17:37] iteration   101900/  500000 | consumed samples:      6521600 | elapsed time per iteration (ms): 619.6 | learning rate: 1.191401E-04 | global batch size:    64 | lm loss: 3.204006E+00 | loss scale: 2097152.0 | grad norm: 0.414 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 21:18:39] iteration   102000/  500000 | consumed samples:      6528000 | elapsed time per iteration (ms): 620.3 | learning rate: 1.190825E-04 | global batch size:    64 | lm loss: 3.202759E+00 | loss scale: 2097152.0 | grad norm: 0.399 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2465.77, 2465.79)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 102000 | lm loss value: 3.708029E+00 | lm loss PPL: 4.077335E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-24 21:19:43] iteration   102100/  500000 | consumed samples:      6534400 | elapsed time per iteration (ms): 619.2 | learning rate: 1.190249E-04 | global batch size:    64 | lm loss: 3.206797E+00 | loss scale: 2097152.0 | grad norm: 0.412 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 21:20:45] iteration   102200/  500000 | consumed samples:      6540800 | elapsed time per iteration (ms): 617.9 | learning rate: 1.189672E-04 | global batch size:    64 | lm loss: 3.197671E+00 | loss scale: 2097152.0 | grad norm: 0.418 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 21:21:47] iteration   102300/  500000 | consumed samples:      6547200 | elapsed time per iteration (ms): 622.1 | learning rate: 1.189095E-04 | global batch size:    64 | lm loss: 3.174169E+00 | loss scale: 2097152.0 | grad norm: 0.409 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 21:22:49] iteration   102400/  500000 | consumed samples:      6553600 | elapsed time per iteration (ms): 619.5 | learning rate: 1.188524E-04 | global batch size:    64 | lm loss: 3.191151E+00 | loss scale: 2097152.0 | grad norm: 0.403 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-24 21:23:51] iteration   102500/  500000 | consumed samples:      6560000 | elapsed time per iteration (ms): 619.1 | learning rate: 1.187946E-04 | global batch size:    64 | lm loss: 3.182581E+00 | loss scale: 2097152.0 | grad norm: 0.417 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 21:24:53] iteration   102600/  500000 | consumed samples:      6566400 | elapsed time per iteration (ms): 620.0 | learning rate: 1.187368E-04 | global batch size:    64 | lm loss: 3.202800E+00 | loss scale: 2097152.0 | grad norm: 0.407 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 21:25:55] iteration   102700/  500000 | consumed samples:      6572800 | elapsed time per iteration (ms): 618.1 | learning rate: 1.186790E-04 | global batch size:    64 | lm loss: 3.200928E+00 | loss scale: 2097152.0 | grad norm: 0.415 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 21:26:57] iteration   102800/  500000 | consumed samples:      6579200 | elapsed time per iteration (ms): 621.4 | learning rate: 1.186211E-04 | global batch size:    64 | lm loss: 3.179310E+00 | loss scale: 2097152.0 | grad norm: 0.402 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 21:27:59] iteration   102900/  500000 | consumed samples:      6585600 | elapsed time per iteration (ms): 620.5 | learning rate: 1.185632E-04 | global batch size:    64 | lm loss: 3.185599E+00 | loss scale: 2097152.0 | grad norm: 0.404 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 21:29:01] iteration   103000/  500000 | consumed samples:      6592000 | elapsed time per iteration (ms): 620.7 | learning rate: 1.185053E-04 | global batch size:    64 | lm loss: 3.190770E+00 | loss scale: 2097152.0 | grad norm: 0.419 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2464.25, 2464.42)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 103000 | lm loss value: 3.688396E+00 | lm loss PPL: 3.998068E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-24 21:30:05] iteration   103100/  500000 | consumed samples:      6598400 | elapsed time per iteration (ms): 619.1 | learning rate: 1.184473E-04 | global batch size:    64 | lm loss: 3.191554E+00 | loss scale: 2097152.0 | grad norm: 0.416 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 21:31:07] iteration   103200/  500000 | consumed samples:      6604800 | elapsed time per iteration (ms): 619.5 | learning rate: 1.183892E-04 | global batch size:    64 | lm loss: 3.190482E+00 | loss scale: 2097152.0 | grad norm: 0.412 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 21:32:09] iteration   103300/  500000 | consumed samples:      6611200 | elapsed time per iteration (ms): 619.5 | learning rate: 1.183312E-04 | global batch size:    64 | lm loss: 3.202373E+00 | loss scale: 2097152.0 | grad norm: 0.412 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 21:33:11] iteration   103400/  500000 | consumed samples:      6617600 | elapsed time per iteration (ms): 620.9 | learning rate: 1.182742E-04 | global batch size:    64 | lm loss: 3.193766E+00 | loss scale: 2097152.0 | grad norm: 0.431 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-24 21:34:13] iteration   103500/  500000 | consumed samples:      6624000 | elapsed time per iteration (ms): 620.5 | learning rate: 1.182161E-04 | global batch size:    64 | lm loss: 3.183032E+00 | loss scale: 2097152.0 | grad norm: 0.410 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 21:35:15] iteration   103600/  500000 | consumed samples:      6630400 | elapsed time per iteration (ms): 617.6 | learning rate: 1.181579E-04 | global batch size:    64 | lm loss: 3.195345E+00 | loss scale: 2097152.0 | grad norm: 0.403 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 21:36:17] iteration   103700/  500000 | consumed samples:      6636800 | elapsed time per iteration (ms): 620.0 | learning rate: 1.180997E-04 | global batch size:    64 | lm loss: 3.194372E+00 | loss scale: 2097152.0 | grad norm: 0.394 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 21:37:19] iteration   103800/  500000 | consumed samples:      6643200 | elapsed time per iteration (ms): 618.9 | learning rate: 1.180414E-04 | global batch size:    64 | lm loss: 3.196406E+00 | loss scale: 2097152.0 | grad norm: 0.383 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 21:38:21] iteration   103900/  500000 | consumed samples:      6649600 | elapsed time per iteration (ms): 620.3 | learning rate: 1.179832E-04 | global batch size:    64 | lm loss: 3.195356E+00 | loss scale: 2097152.0 | grad norm: 0.407 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 21:39:23] iteration   104000/  500000 | consumed samples:      6656000 | elapsed time per iteration (ms): 620.1 | learning rate: 1.179254E-04 | global batch size:    64 | lm loss: 3.183838E+00 | loss scale: 1048576.0 | grad norm: 0.411 | number of skipped iterations:   1 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2463.17, 2463.18)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 104000 | lm loss value: 3.708359E+00 | lm loss PPL: 4.078684E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-24 21:40:27] iteration   104100/  500000 | consumed samples:      6662400 | elapsed time per iteration (ms): 619.7 | learning rate: 1.178670E-04 | global batch size:    64 | lm loss: 3.192239E+00 | loss scale: 1048576.0 | grad norm: 0.404 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 21:41:29] iteration   104200/  500000 | consumed samples:      6668800 | elapsed time per iteration (ms): 619.3 | learning rate: 1.178086E-04 | global batch size:    64 | lm loss: 3.201792E+00 | loss scale: 1048576.0 | grad norm: 0.409 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 21:42:31] iteration   104300/  500000 | consumed samples:      6675200 | elapsed time per iteration (ms): 620.1 | learning rate: 1.177502E-04 | global batch size:    64 | lm loss: 3.205608E+00 | loss scale: 1048576.0 | grad norm: 0.390 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 21:43:33] iteration   104400/  500000 | consumed samples:      6681600 | elapsed time per iteration (ms): 619.2 | learning rate: 1.176917E-04 | global batch size:    64 | lm loss: 3.193866E+00 | loss scale: 1048576.0 | grad norm: 0.405 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 21:44:35] iteration   104500/  500000 | consumed samples:      6688000 | elapsed time per iteration (ms): 619.7 | learning rate: 1.176332E-04 | global batch size:    64 | lm loss: 3.195963E+00 | loss scale: 1048576.0 | grad norm: 0.404 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 21:45:37] iteration   104600/  500000 | consumed samples:      6694400 | elapsed time per iteration (ms): 619.0 | learning rate: 1.175747E-04 | global batch size:    64 | lm loss: 3.190598E+00 | loss scale: 1048576.0 | grad norm: 0.404 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 21:46:39] iteration   104700/  500000 | consumed samples:      6700800 | elapsed time per iteration (ms): 620.4 | learning rate: 1.175161E-04 | global batch size:    64 | lm loss: 3.176912E+00 | loss scale: 1048576.0 | grad norm: 0.402 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 21:47:41] iteration   104800/  500000 | consumed samples:      6707200 | elapsed time per iteration (ms): 618.8 | learning rate: 1.174575E-04 | global batch size:    64 | lm loss: 3.188936E+00 | loss scale: 1048576.0 | grad norm: 0.405 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 21:48:43] iteration   104900/  500000 | consumed samples:      6713600 | elapsed time per iteration (ms): 620.9 | learning rate: 1.173988E-04 | global batch size:    64 | lm loss: 3.190159E+00 | loss scale: 1048576.0 | grad norm: 0.398 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 21:49:45] iteration   105000/  500000 | consumed samples:      6720000 | elapsed time per iteration (ms): 619.9 | learning rate: 1.173401E-04 | global batch size:    64 | lm loss: 3.177399E+00 | loss scale: 2097152.0 | grad norm: 0.413 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2464.82, 2464.88)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 105000 | lm loss value: 3.674162E+00 | lm loss PPL: 3.941561E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-24 21:50:50] iteration   105100/  500000 | consumed samples:      6726400 | elapsed time per iteration (ms): 618.6 | learning rate: 1.172814E-04 | global batch size:    64 | lm loss: 3.182119E+00 | loss scale: 2097152.0 | grad norm: 0.389 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 21:51:51] iteration   105200/  500000 | consumed samples:      6732800 | elapsed time per iteration (ms): 618.1 | learning rate: 1.172226E-04 | global batch size:    64 | lm loss: 3.179075E+00 | loss scale: 2097152.0 | grad norm: 0.416 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 21:52:53] iteration   105300/  500000 | consumed samples:      6739200 | elapsed time per iteration (ms): 621.4 | learning rate: 1.171638E-04 | global batch size:    64 | lm loss: 3.191698E+00 | loss scale: 2097152.0 | grad norm: 0.413 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 21:53:55] iteration   105400/  500000 | consumed samples:      6745600 | elapsed time per iteration (ms): 619.1 | learning rate: 1.171049E-04 | global batch size:    64 | lm loss: 3.175832E+00 | loss scale: 2097152.0 | grad norm: 0.407 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 21:54:57] iteration   105500/  500000 | consumed samples:      6752000 | elapsed time per iteration (ms): 618.5 | learning rate: 1.170467E-04 | global batch size:    64 | lm loss: 3.187111E+00 | loss scale: 2097152.0 | grad norm: 0.402 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-24 21:55:59] iteration   105600/  500000 | consumed samples:      6758400 | elapsed time per iteration (ms): 621.1 | learning rate: 1.169877E-04 | global batch size:    64 | lm loss: 3.189612E+00 | loss scale: 2097152.0 | grad norm: 0.401 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 21:57:01] iteration   105700/  500000 | consumed samples:      6764800 | elapsed time per iteration (ms): 618.2 | learning rate: 1.169288E-04 | global batch size:    64 | lm loss: 3.191133E+00 | loss scale: 2097152.0 | grad norm: 0.417 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 21:58:03] iteration   105800/  500000 | consumed samples:      6771200 | elapsed time per iteration (ms): 618.1 | learning rate: 1.168698E-04 | global batch size:    64 | lm loss: 3.193697E+00 | loss scale: 2097152.0 | grad norm: 0.410 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 21:59:05] iteration   105900/  500000 | consumed samples:      6777600 | elapsed time per iteration (ms): 620.9 | learning rate: 1.168114E-04 | global batch size:    64 | lm loss: 3.177120E+00 | loss scale: 1048576.0 | grad norm: 0.414 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-24 22:00:07] iteration   106000/  500000 | consumed samples:      6784000 | elapsed time per iteration (ms): 619.9 | learning rate: 1.167523E-04 | global batch size:    64 | lm loss: 3.198755E+00 | loss scale: 1048576.0 | grad norm: 0.412 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2464.60, 2464.79)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 106000 | lm loss value: 3.661594E+00 | lm loss PPL: 3.892332E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-24 22:01:11] iteration   106100/  500000 | consumed samples:      6790400 | elapsed time per iteration (ms): 619.4 | learning rate: 1.166932E-04 | global batch size:    64 | lm loss: 3.187244E+00 | loss scale: 1048576.0 | grad norm: 0.407 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 22:02:13] iteration   106200/  500000 | consumed samples:      6796800 | elapsed time per iteration (ms): 620.4 | learning rate: 1.166341E-04 | global batch size:    64 | lm loss: 3.175558E+00 | loss scale: 1048576.0 | grad norm: 0.413 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 22:03:15] iteration   106300/  500000 | consumed samples:      6803200 | elapsed time per iteration (ms): 619.1 | learning rate: 1.165749E-04 | global batch size:    64 | lm loss: 3.202083E+00 | loss scale: 1048576.0 | grad norm: 0.399 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 22:04:17] iteration   106400/  500000 | consumed samples:      6809600 | elapsed time per iteration (ms): 619.7 | learning rate: 1.165157E-04 | global batch size:    64 | lm loss: 3.188253E+00 | loss scale: 1048576.0 | grad norm: 0.397 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 22:05:19] iteration   106500/  500000 | consumed samples:      6816000 | elapsed time per iteration (ms): 620.4 | learning rate: 1.164565E-04 | global batch size:    64 | lm loss: 3.178020E+00 | loss scale: 1048576.0 | grad norm: 0.398 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 22:06:21] iteration   106600/  500000 | consumed samples:      6822400 | elapsed time per iteration (ms): 619.3 | learning rate: 1.163972E-04 | global batch size:    64 | lm loss: 3.196860E+00 | loss scale: 1048576.0 | grad norm: 0.389 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 22:07:23] iteration   106700/  500000 | consumed samples:      6828800 | elapsed time per iteration (ms): 618.6 | learning rate: 1.163379E-04 | global batch size:    64 | lm loss: 3.191214E+00 | loss scale: 1048576.0 | grad norm: 0.397 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 22:08:25] iteration   106800/  500000 | consumed samples:      6835200 | elapsed time per iteration (ms): 620.8 | learning rate: 1.162785E-04 | global batch size:    64 | lm loss: 3.184649E+00 | loss scale: 1048576.0 | grad norm: 0.414 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 22:09:27] iteration   106900/  500000 | consumed samples:      6841600 | elapsed time per iteration (ms): 621.6 | learning rate: 1.162191E-04 | global batch size:    64 | lm loss: 3.182229E+00 | loss scale: 2097152.0 | grad norm: 0.403 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 22:10:30] iteration   107000/  500000 | consumed samples:      6848000 | elapsed time per iteration (ms): 620.7 | learning rate: 1.161597E-04 | global batch size:    64 | lm loss: 3.184634E+00 | loss scale: 2097152.0 | grad norm: 0.413 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2463.40, 2463.44)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 107000 | lm loss value: 3.678709E+00 | lm loss PPL: 3.959524E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-24 22:11:34] iteration   107100/  500000 | consumed samples:      6854400 | elapsed time per iteration (ms): 618.0 | learning rate: 1.161003E-04 | global batch size:    64 | lm loss: 3.175163E+00 | loss scale: 2097152.0 | grad norm: 0.407 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 22:12:36] iteration   107200/  500000 | consumed samples:      6860800 | elapsed time per iteration (ms): 620.3 | learning rate: 1.160408E-04 | global batch size:    64 | lm loss: 3.169905E+00 | loss scale: 2097152.0 | grad norm: 0.422 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 22:13:38] iteration   107300/  500000 | consumed samples:      6867200 | elapsed time per iteration (ms): 620.6 | learning rate: 1.159818E-04 | global batch size:    64 | lm loss: 3.195749E+00 | loss scale: 2097152.0 | grad norm: 0.392 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-24 22:14:40] iteration   107400/  500000 | consumed samples:      6873600 | elapsed time per iteration (ms): 618.3 | learning rate: 1.159223E-04 | global batch size:    64 | lm loss: 3.184755E+00 | loss scale: 2097152.0 | grad norm: 0.413 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 22:15:42] iteration   107500/  500000 | consumed samples:      6880000 | elapsed time per iteration (ms): 619.3 | learning rate: 1.158627E-04 | global batch size:    64 | lm loss: 3.197415E+00 | loss scale: 2097152.0 | grad norm: 0.404 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 22:16:44] iteration   107600/  500000 | consumed samples:      6886400 | elapsed time per iteration (ms): 620.2 | learning rate: 1.158030E-04 | global batch size:    64 | lm loss: 3.180188E+00 | loss scale: 2097152.0 | grad norm: 0.401 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 22:17:46] iteration   107700/  500000 | consumed samples:      6892800 | elapsed time per iteration (ms): 619.6 | learning rate: 1.157434E-04 | global batch size:    64 | lm loss: 3.178458E+00 | loss scale: 2097152.0 | grad norm: 0.406 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 22:18:48] iteration   107800/  500000 | consumed samples:      6899200 | elapsed time per iteration (ms): 620.2 | learning rate: 1.156837E-04 | global batch size:    64 | lm loss: 3.187093E+00 | loss scale: 2097152.0 | grad norm: 0.411 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 22:19:50] iteration   107900/  500000 | consumed samples:      6905600 | elapsed time per iteration (ms): 619.2 | learning rate: 1.156239E-04 | global batch size:    64 | lm loss: 3.173294E+00 | loss scale: 2097152.0 | grad norm: 0.408 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 22:20:51] iteration   108000/  500000 | consumed samples:      6912000 | elapsed time per iteration (ms): 617.7 | learning rate: 1.155642E-04 | global batch size:    64 | lm loss: 3.189952E+00 | loss scale: 2097152.0 | grad norm: 0.405 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2463.86, 2463.97)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 108000 | lm loss value: 3.628699E+00 | lm loss PPL: 3.766378E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-24 22:21:56] iteration   108100/  500000 | consumed samples:      6918400 | elapsed time per iteration (ms): 617.7 | learning rate: 1.155044E-04 | global batch size:    64 | lm loss: 3.183612E+00 | loss scale: 2097152.0 | grad norm: 0.414 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 22:22:58] iteration   108200/  500000 | consumed samples:      6924800 | elapsed time per iteration (ms): 621.2 | learning rate: 1.154445E-04 | global batch size:    64 | lm loss: 3.189601E+00 | loss scale: 2097152.0 | grad norm: 0.398 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 22:23:59] iteration   108300/  500000 | consumed samples:      6931200 | elapsed time per iteration (ms): 617.8 | learning rate: 1.153864E-04 | global batch size:    64 | lm loss: 3.185150E+00 | loss scale: 1048576.0 | grad norm: 0.416 | number of skipped iterations:   3 | number of nan iterations:   0 |
 [2024-06-24 22:25:01] iteration   108400/  500000 | consumed samples:      6937600 | elapsed time per iteration (ms): 618.6 | learning rate: 1.153265E-04 | global batch size:    64 | lm loss: 3.187758E+00 | loss scale: 1048576.0 | grad norm: 0.411 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 22:26:03] iteration   108500/  500000 | consumed samples:      6944000 | elapsed time per iteration (ms): 618.7 | learning rate: 1.152666E-04 | global batch size:    64 | lm loss: 3.187383E+00 | loss scale: 1048576.0 | grad norm: 0.422 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 22:27:05] iteration   108600/  500000 | consumed samples:      6950400 | elapsed time per iteration (ms): 618.7 | learning rate: 1.152066E-04 | global batch size:    64 | lm loss: 3.177959E+00 | loss scale: 1048576.0 | grad norm: 0.407 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 22:28:07] iteration   108700/  500000 | consumed samples:      6956800 | elapsed time per iteration (ms): 616.5 | learning rate: 1.151466E-04 | global batch size:    64 | lm loss: 3.167935E+00 | loss scale: 1048576.0 | grad norm: 0.410 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 22:29:09] iteration   108800/  500000 | consumed samples:      6963200 | elapsed time per iteration (ms): 618.7 | learning rate: 1.150865E-04 | global batch size:    64 | lm loss: 3.197399E+00 | loss scale: 1048576.0 | grad norm: 0.412 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 22:30:10] iteration   108900/  500000 | consumed samples:      6969600 | elapsed time per iteration (ms): 618.2 | learning rate: 1.150264E-04 | global batch size:    64 | lm loss: 3.189989E+00 | loss scale: 1048576.0 | grad norm: 0.412 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 22:31:12] iteration   109000/  500000 | consumed samples:      6976000 | elapsed time per iteration (ms): 619.5 | learning rate: 1.149663E-04 | global batch size:    64 | lm loss: 3.182608E+00 | loss scale: 1048576.0 | grad norm: 0.409 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2464.68, 2464.82)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 109000 | lm loss value: 3.675106E+00 | lm loss PPL: 3.945283E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-24 22:32:17] iteration   109100/  500000 | consumed samples:      6982400 | elapsed time per iteration (ms): 619.2 | learning rate: 1.149062E-04 | global batch size:    64 | lm loss: 3.171454E+00 | loss scale: 1048576.0 | grad norm: 0.409 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 22:33:19] iteration   109200/  500000 | consumed samples:      6988800 | elapsed time per iteration (ms): 620.6 | learning rate: 1.148460E-04 | global batch size:    64 | lm loss: 3.179456E+00 | loss scale: 1048576.0 | grad norm: 0.406 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 22:34:21] iteration   109300/  500000 | consumed samples:      6995200 | elapsed time per iteration (ms): 617.7 | learning rate: 1.147858E-04 | global batch size:    64 | lm loss: 3.175786E+00 | loss scale: 2097152.0 | grad norm: 0.419 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 22:35:23] iteration   109400/  500000 | consumed samples:      7001600 | elapsed time per iteration (ms): 619.5 | learning rate: 1.147255E-04 | global batch size:    64 | lm loss: 3.181467E+00 | loss scale: 2097152.0 | grad norm: 0.396 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 22:36:24] iteration   109500/  500000 | consumed samples:      7008000 | elapsed time per iteration (ms): 619.0 | learning rate: 1.146652E-04 | global batch size:    64 | lm loss: 3.166520E+00 | loss scale: 2097152.0 | grad norm: 0.407 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 22:37:26] iteration   109600/  500000 | consumed samples:      7014400 | elapsed time per iteration (ms): 619.8 | learning rate: 1.146049E-04 | global batch size:    64 | lm loss: 3.195359E+00 | loss scale: 2097152.0 | grad norm: 0.411 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 22:38:28] iteration   109700/  500000 | consumed samples:      7020800 | elapsed time per iteration (ms): 619.6 | learning rate: 1.145445E-04 | global batch size:    64 | lm loss: 3.181846E+00 | loss scale: 2097152.0 | grad norm: 0.409 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 22:39:30] iteration   109800/  500000 | consumed samples:      7027200 | elapsed time per iteration (ms): 620.5 | learning rate: 1.144841E-04 | global batch size:    64 | lm loss: 3.175562E+00 | loss scale: 2097152.0 | grad norm: 0.405 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 22:40:32] iteration   109900/  500000 | consumed samples:      7033600 | elapsed time per iteration (ms): 617.9 | learning rate: 1.144237E-04 | global batch size:    64 | lm loss: 3.184542E+00 | loss scale: 2097152.0 | grad norm: 0.415 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 22:41:34] iteration   110000/  500000 | consumed samples:      7040000 | elapsed time per iteration (ms): 617.9 | learning rate: 1.143633E-04 | global batch size:    64 | lm loss: 3.160439E+00 | loss scale: 2097152.0 | grad norm: 0.409 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2463.09, 2463.19)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 110000 | lm loss value: 3.666441E+00 | lm loss PPL: 3.911246E+01 | 
--------------------------------------------------------------------------------------------------
saving checkpoint at iteration  110000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-distribution in torch format
  successfully saved checkpoint at iteration  110000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-distribution
(min, max) time across ranks (ms):
    save-checkpoint ................................: (2410.76, 2410.76)
 [2024-06-24 22:42:41] iteration   110100/  500000 | consumed samples:      7046400 | elapsed time per iteration (ms): 619.3 | learning rate: 1.143028E-04 | global batch size:    64 | lm loss: 3.171322E+00 | loss scale: 2097152.0 | grad norm: 0.402 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 22:43:43] iteration   110200/  500000 | consumed samples:      7052800 | elapsed time per iteration (ms): 617.5 | learning rate: 1.142422E-04 | global batch size:    64 | lm loss: 3.172997E+00 | loss scale: 2097152.0 | grad norm: 0.410 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 22:44:44] iteration   110300/  500000 | consumed samples:      7059200 | elapsed time per iteration (ms): 619.1 | learning rate: 1.141829E-04 | global batch size:    64 | lm loss: 3.191097E+00 | loss scale: 2097152.0 | grad norm: 0.402 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-24 22:45:46] iteration   110400/  500000 | consumed samples:      7065600 | elapsed time per iteration (ms): 619.9 | learning rate: 1.141223E-04 | global batch size:    64 | lm loss: 3.181687E+00 | loss scale: 2097152.0 | grad norm: 0.398 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 22:46:48] iteration   110500/  500000 | consumed samples:      7072000 | elapsed time per iteration (ms): 619.6 | learning rate: 1.140623E-04 | global batch size:    64 | lm loss: 3.173535E+00 | loss scale: 1048576.0 | grad norm: 0.406 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-24 22:47:50] iteration   110600/  500000 | consumed samples:      7078400 | elapsed time per iteration (ms): 618.7 | learning rate: 1.140016E-04 | global batch size:    64 | lm loss: 3.187860E+00 | loss scale: 1048576.0 | grad norm: 0.412 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 22:48:52] iteration   110700/  500000 | consumed samples:      7084800 | elapsed time per iteration (ms): 622.1 | learning rate: 1.139409E-04 | global batch size:    64 | lm loss: 3.190675E+00 | loss scale: 1048576.0 | grad norm: 0.429 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 22:49:54] iteration   110800/  500000 | consumed samples:      7091200 | elapsed time per iteration (ms): 618.5 | learning rate: 1.138802E-04 | global batch size:    64 | lm loss: 3.171113E+00 | loss scale: 1048576.0 | grad norm: 0.400 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 22:50:56] iteration   110900/  500000 | consumed samples:      7097600 | elapsed time per iteration (ms): 617.3 | learning rate: 1.138194E-04 | global batch size:    64 | lm loss: 3.171783E+00 | loss scale: 1048576.0 | grad norm: 0.412 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 22:51:58] iteration   111000/  500000 | consumed samples:      7104000 | elapsed time per iteration (ms): 618.6 | learning rate: 1.137586E-04 | global batch size:    64 | lm loss: 3.168100E+00 | loss scale: 1048576.0 | grad norm: 0.407 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2464.71, 2464.88)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 111000 | lm loss value: 3.676287E+00 | lm loss PPL: 3.949945E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-24 22:53:02] iteration   111100/  500000 | consumed samples:      7110400 | elapsed time per iteration (ms): 620.9 | learning rate: 1.136978E-04 | global batch size:    64 | lm loss: 3.164304E+00 | loss scale: 1048576.0 | grad norm: 0.405 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 22:54:04] iteration   111200/  500000 | consumed samples:      7116800 | elapsed time per iteration (ms): 619.6 | learning rate: 1.136370E-04 | global batch size:    64 | lm loss: 3.176594E+00 | loss scale: 1048576.0 | grad norm: 0.414 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 22:55:06] iteration   111300/  500000 | consumed samples:      7123200 | elapsed time per iteration (ms): 619.7 | learning rate: 1.135761E-04 | global batch size:    64 | lm loss: 3.169753E+00 | loss scale: 1048576.0 | grad norm: 0.398 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 22:56:08] iteration   111400/  500000 | consumed samples:      7129600 | elapsed time per iteration (ms): 618.3 | learning rate: 1.135151E-04 | global batch size:    64 | lm loss: 3.172852E+00 | loss scale: 1048576.0 | grad norm: 0.388 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 22:57:10] iteration   111500/  500000 | consumed samples:      7136000 | elapsed time per iteration (ms): 619.7 | learning rate: 1.134542E-04 | global batch size:    64 | lm loss: 3.165686E+00 | loss scale: 2097152.0 | grad norm: 0.411 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 22:58:12] iteration   111600/  500000 | consumed samples:      7142400 | elapsed time per iteration (ms): 619.4 | learning rate: 1.133932E-04 | global batch size:    64 | lm loss: 3.172864E+00 | loss scale: 2097152.0 | grad norm: 0.413 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 22:59:14] iteration   111700/  500000 | consumed samples:      7148800 | elapsed time per iteration (ms): 620.9 | learning rate: 1.133328E-04 | global batch size:    64 | lm loss: 3.164304E+00 | loss scale: 2097152.0 | grad norm: 0.400 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-24 23:00:16] iteration   111800/  500000 | consumed samples:      7155200 | elapsed time per iteration (ms): 619.9 | learning rate: 1.132717E-04 | global batch size:    64 | lm loss: 3.184023E+00 | loss scale: 2097152.0 | grad norm: 0.412 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 23:01:18] iteration   111900/  500000 | consumed samples:      7161600 | elapsed time per iteration (ms): 619.8 | learning rate: 1.132106E-04 | global batch size:    64 | lm loss: 3.169133E+00 | loss scale: 2097152.0 | grad norm: 0.422 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 23:02:20] iteration   112000/  500000 | consumed samples:      7168000 | elapsed time per iteration (ms): 618.4 | learning rate: 1.131495E-04 | global batch size:    64 | lm loss: 3.174166E+00 | loss scale: 2097152.0 | grad norm: 0.408 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2462.40, 2462.86)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 112000 | lm loss value: 3.676436E+00 | lm loss PPL: 3.950534E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-24 23:03:24] iteration   112100/  500000 | consumed samples:      7174400 | elapsed time per iteration (ms): 619.1 | learning rate: 1.130883E-04 | global batch size:    64 | lm loss: 3.169958E+00 | loss scale: 2097152.0 | grad norm: 0.401 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 23:04:26] iteration   112200/  500000 | consumed samples:      7180800 | elapsed time per iteration (ms): 619.3 | learning rate: 1.130272E-04 | global batch size:    64 | lm loss: 3.177145E+00 | loss scale: 2097152.0 | grad norm: 0.406 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 23:05:28] iteration   112300/  500000 | consumed samples:      7187200 | elapsed time per iteration (ms): 618.4 | learning rate: 1.129659E-04 | global batch size:    64 | lm loss: 3.176613E+00 | loss scale: 2097152.0 | grad norm: 0.418 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 23:06:30] iteration   112400/  500000 | consumed samples:      7193600 | elapsed time per iteration (ms): 618.5 | learning rate: 1.129047E-04 | global batch size:    64 | lm loss: 3.173777E+00 | loss scale: 2097152.0 | grad norm: 0.420 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 23:07:32] iteration   112500/  500000 | consumed samples:      7200000 | elapsed time per iteration (ms): 620.8 | learning rate: 1.128434E-04 | global batch size:    64 | lm loss: 3.164975E+00 | loss scale: 2097152.0 | grad norm: 0.413 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 23:08:34] iteration   112600/  500000 | consumed samples:      7206400 | elapsed time per iteration (ms): 620.6 | learning rate: 1.127821E-04 | global batch size:    64 | lm loss: 3.182948E+00 | loss scale: 2097152.0 | grad norm: 0.397 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 23:09:36] iteration   112700/  500000 | consumed samples:      7212800 | elapsed time per iteration (ms): 619.0 | learning rate: 1.127220E-04 | global batch size:    64 | lm loss: 3.161181E+00 | loss scale: 2097152.0 | grad norm: 0.416 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-24 23:10:38] iteration   112800/  500000 | consumed samples:      7219200 | elapsed time per iteration (ms): 620.1 | learning rate: 1.126606E-04 | global batch size:    64 | lm loss: 3.188220E+00 | loss scale: 2097152.0 | grad norm: 0.407 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 23:11:40] iteration   112900/  500000 | consumed samples:      7225600 | elapsed time per iteration (ms): 618.6 | learning rate: 1.125992E-04 | global batch size:    64 | lm loss: 3.173116E+00 | loss scale: 2097152.0 | grad norm: 0.407 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 23:12:42] iteration   113000/  500000 | consumed samples:      7232000 | elapsed time per iteration (ms): 619.5 | learning rate: 1.125377E-04 | global batch size:    64 | lm loss: 3.172725E+00 | loss scale: 2097152.0 | grad norm: 0.410 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2461.64, 2461.72)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 113000 | lm loss value: 3.708871E+00 | lm loss PPL: 4.080769E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-24 23:13:46] iteration   113100/  500000 | consumed samples:      7238400 | elapsed time per iteration (ms): 618.7 | learning rate: 1.124762E-04 | global batch size:    64 | lm loss: 3.166553E+00 | loss scale: 2097152.0 | grad norm: 0.401 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 23:14:48] iteration   113200/  500000 | consumed samples:      7244800 | elapsed time per iteration (ms): 618.3 | learning rate: 1.124147E-04 | global batch size:    64 | lm loss: 3.172924E+00 | loss scale: 2097152.0 | grad norm: 0.408 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 23:15:50] iteration   113300/  500000 | consumed samples:      7251200 | elapsed time per iteration (ms): 619.9 | learning rate: 1.123538E-04 | global batch size:    64 | lm loss: 3.168789E+00 | loss scale: 1048576.0 | grad norm: 0.417 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-24 23:16:52] iteration   113400/  500000 | consumed samples:      7257600 | elapsed time per iteration (ms): 620.1 | learning rate: 1.122922E-04 | global batch size:    64 | lm loss: 3.168121E+00 | loss scale: 1048576.0 | grad norm: 0.403 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 23:17:54] iteration   113500/  500000 | consumed samples:      7264000 | elapsed time per iteration (ms): 618.9 | learning rate: 1.122306E-04 | global batch size:    64 | lm loss: 3.176747E+00 | loss scale: 1048576.0 | grad norm: 0.407 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 23:18:56] iteration   113600/  500000 | consumed samples:      7270400 | elapsed time per iteration (ms): 619.3 | learning rate: 1.121690E-04 | global batch size:    64 | lm loss: 3.178619E+00 | loss scale: 1048576.0 | grad norm: 0.409 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 23:19:58] iteration   113700/  500000 | consumed samples:      7276800 | elapsed time per iteration (ms): 618.2 | learning rate: 1.121073E-04 | global batch size:    64 | lm loss: 3.148972E+00 | loss scale: 1048576.0 | grad norm: 0.395 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 23:21:00] iteration   113800/  500000 | consumed samples:      7283200 | elapsed time per iteration (ms): 619.6 | learning rate: 1.120456E-04 | global batch size:    64 | lm loss: 3.168251E+00 | loss scale: 1048576.0 | grad norm: 0.408 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 23:22:01] iteration   113900/  500000 | consumed samples:      7289600 | elapsed time per iteration (ms): 618.6 | learning rate: 1.119839E-04 | global batch size:    64 | lm loss: 3.167285E+00 | loss scale: 1048576.0 | grad norm: 0.404 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 23:23:03] iteration   114000/  500000 | consumed samples:      7296000 | elapsed time per iteration (ms): 617.2 | learning rate: 1.119221E-04 | global batch size:    64 | lm loss: 3.171580E+00 | loss scale: 1048576.0 | grad norm: 0.401 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2463.72, 2463.86)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 114000 | lm loss value: 3.673674E+00 | lm loss PPL: 3.939640E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-24 23:24:08] iteration   114100/  500000 | consumed samples:      7302400 | elapsed time per iteration (ms): 619.2 | learning rate: 1.118603E-04 | global batch size:    64 | lm loss: 3.163137E+00 | loss scale: 1048576.0 | grad norm: 0.404 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 23:25:09] iteration   114200/  500000 | consumed samples:      7308800 | elapsed time per iteration (ms): 618.0 | learning rate: 1.117985E-04 | global batch size:    64 | lm loss: 3.156556E+00 | loss scale: 1048576.0 | grad norm: 0.414 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 23:26:11] iteration   114300/  500000 | consumed samples:      7315200 | elapsed time per iteration (ms): 619.8 | learning rate: 1.117373E-04 | global batch size:    64 | lm loss: 3.165963E+00 | loss scale: 2097152.0 | grad norm: 0.420 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-24 23:27:13] iteration   114400/  500000 | consumed samples:      7321600 | elapsed time per iteration (ms): 617.7 | learning rate: 1.116754E-04 | global batch size:    64 | lm loss: 3.180400E+00 | loss scale: 2097152.0 | grad norm: 0.414 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 23:28:15] iteration   114500/  500000 | consumed samples:      7328000 | elapsed time per iteration (ms): 620.6 | learning rate: 1.116135E-04 | global batch size:    64 | lm loss: 3.157820E+00 | loss scale: 2097152.0 | grad norm: 0.397 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 23:29:17] iteration   114600/  500000 | consumed samples:      7334400 | elapsed time per iteration (ms): 619.2 | learning rate: 1.115515E-04 | global batch size:    64 | lm loss: 3.160138E+00 | loss scale: 2097152.0 | grad norm: 0.409 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 23:30:19] iteration   114700/  500000 | consumed samples:      7340800 | elapsed time per iteration (ms): 620.3 | learning rate: 1.114895E-04 | global batch size:    64 | lm loss: 3.179999E+00 | loss scale: 2097152.0 | grad norm: 0.402 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 23:31:21] iteration   114800/  500000 | consumed samples:      7347200 | elapsed time per iteration (ms): 618.7 | learning rate: 1.114275E-04 | global batch size:    64 | lm loss: 3.159318E+00 | loss scale: 2097152.0 | grad norm: 0.414 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 23:32:23] iteration   114900/  500000 | consumed samples:      7353600 | elapsed time per iteration (ms): 618.2 | learning rate: 1.113655E-04 | global batch size:    64 | lm loss: 3.157161E+00 | loss scale: 2097152.0 | grad norm: 0.402 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 23:33:25] iteration   115000/  500000 | consumed samples:      7360000 | elapsed time per iteration (ms): 619.3 | learning rate: 1.113034E-04 | global batch size:    64 | lm loss: 3.158026E+00 | loss scale: 2097152.0 | grad norm: 0.404 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2463.59, 2465.10)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 115000 | lm loss value: 3.660333E+00 | lm loss PPL: 3.887430E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-24 23:34:29] iteration   115100/  500000 | consumed samples:      7366400 | elapsed time per iteration (ms): 617.8 | learning rate: 1.112413E-04 | global batch size:    64 | lm loss: 3.168302E+00 | loss scale: 2097152.0 | grad norm: 0.409 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 23:35:31] iteration   115200/  500000 | consumed samples:      7372800 | elapsed time per iteration (ms): 619.8 | learning rate: 1.111792E-04 | global batch size:    64 | lm loss: 3.169174E+00 | loss scale: 2097152.0 | grad norm: 0.402 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 23:36:33] iteration   115300/  500000 | consumed samples:      7379200 | elapsed time per iteration (ms): 618.8 | learning rate: 1.111170E-04 | global batch size:    64 | lm loss: 3.173369E+00 | loss scale: 4194304.0 | grad norm: 0.405 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 23:37:35] iteration   115400/  500000 | consumed samples:      7385600 | elapsed time per iteration (ms): 618.1 | learning rate: 1.110560E-04 | global batch size:    64 | lm loss: 3.174512E+00 | loss scale: 2097152.0 | grad norm: 0.422 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-24 23:38:37] iteration   115500/  500000 | consumed samples:      7392000 | elapsed time per iteration (ms): 619.8 | learning rate: 1.109938E-04 | global batch size:    64 | lm loss: 3.166936E+00 | loss scale: 2097152.0 | grad norm: 0.426 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 23:39:38] iteration   115600/  500000 | consumed samples:      7398400 | elapsed time per iteration (ms): 618.4 | learning rate: 1.109322E-04 | global batch size:    64 | lm loss: 3.162907E+00 | loss scale: 1048576.0 | grad norm: 0.413 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-24 23:40:40] iteration   115700/  500000 | consumed samples:      7404800 | elapsed time per iteration (ms): 618.9 | learning rate: 1.108699E-04 | global batch size:    64 | lm loss: 3.167708E+00 | loss scale: 1048576.0 | grad norm: 0.435 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 23:41:42] iteration   115800/  500000 | consumed samples:      7411200 | elapsed time per iteration (ms): 619.5 | learning rate: 1.108076E-04 | global batch size:    64 | lm loss: 3.175047E+00 | loss scale: 1048576.0 | grad norm: 0.400 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 23:42:44] iteration   115900/  500000 | consumed samples:      7417600 | elapsed time per iteration (ms): 619.5 | learning rate: 1.107459E-04 | global batch size:    64 | lm loss: 3.150519E+00 | loss scale: 524288.0 | grad norm: 0.412 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-24 23:43:46] iteration   116000/  500000 | consumed samples:      7424000 | elapsed time per iteration (ms): 618.0 | learning rate: 1.106835E-04 | global batch size:    64 | lm loss: 3.157348E+00 | loss scale: 524288.0 | grad norm: 0.396 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2461.06, 2461.28)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 116000 | lm loss value: 3.682116E+00 | lm loss PPL: 3.973039E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-24 23:44:50] iteration   116100/  500000 | consumed samples:      7430400 | elapsed time per iteration (ms): 618.3 | learning rate: 1.106211E-04 | global batch size:    64 | lm loss: 3.160911E+00 | loss scale: 524288.0 | grad norm: 0.414 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 23:45:52] iteration   116200/  500000 | consumed samples:      7436800 | elapsed time per iteration (ms): 619.7 | learning rate: 1.105586E-04 | global batch size:    64 | lm loss: 3.171545E+00 | loss scale: 524288.0 | grad norm: 0.407 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 23:46:54] iteration   116300/  500000 | consumed samples:      7443200 | elapsed time per iteration (ms): 617.6 | learning rate: 1.104962E-04 | global batch size:    64 | lm loss: 3.178543E+00 | loss scale: 524288.0 | grad norm: 0.392 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 23:47:56] iteration   116400/  500000 | consumed samples:      7449600 | elapsed time per iteration (ms): 618.3 | learning rate: 1.104337E-04 | global batch size:    64 | lm loss: 3.163351E+00 | loss scale: 524288.0 | grad norm: 0.403 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 23:48:58] iteration   116500/  500000 | consumed samples:      7456000 | elapsed time per iteration (ms): 617.8 | learning rate: 1.103711E-04 | global batch size:    64 | lm loss: 3.181021E+00 | loss scale: 524288.0 | grad norm: 0.410 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 23:50:00] iteration   116600/  500000 | consumed samples:      7462400 | elapsed time per iteration (ms): 619.7 | learning rate: 1.103086E-04 | global batch size:    64 | lm loss: 3.175376E+00 | loss scale: 524288.0 | grad norm: 0.405 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 23:51:02] iteration   116700/  500000 | consumed samples:      7468800 | elapsed time per iteration (ms): 618.8 | learning rate: 1.102460E-04 | global batch size:    64 | lm loss: 3.147939E+00 | loss scale: 524288.0 | grad norm: 0.421 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 23:52:03] iteration   116800/  500000 | consumed samples:      7475200 | elapsed time per iteration (ms): 619.1 | learning rate: 1.101834E-04 | global batch size:    64 | lm loss: 3.140826E+00 | loss scale: 524288.0 | grad norm: 0.401 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 23:53:05] iteration   116900/  500000 | consumed samples:      7481600 | elapsed time per iteration (ms): 619.6 | learning rate: 1.101207E-04 | global batch size:    64 | lm loss: 3.169405E+00 | loss scale: 1048576.0 | grad norm: 0.409 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 23:54:07] iteration   117000/  500000 | consumed samples:      7488000 | elapsed time per iteration (ms): 619.0 | learning rate: 1.100581E-04 | global batch size:    64 | lm loss: 3.159384E+00 | loss scale: 1048576.0 | grad norm: 0.411 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2462.23, 2462.31)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 117000 | lm loss value: 3.685981E+00 | lm loss PPL: 3.988423E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-24 23:55:12] iteration   117100/  500000 | consumed samples:      7494400 | elapsed time per iteration (ms): 619.8 | learning rate: 1.099954E-04 | global batch size:    64 | lm loss: 3.161884E+00 | loss scale: 1048576.0 | grad norm: 0.400 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 23:56:14] iteration   117200/  500000 | consumed samples:      7500800 | elapsed time per iteration (ms): 619.1 | learning rate: 1.099326E-04 | global batch size:    64 | lm loss: 3.153145E+00 | loss scale: 1048576.0 | grad norm: 0.409 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 23:57:15] iteration   117300/  500000 | consumed samples:      7507200 | elapsed time per iteration (ms): 618.1 | learning rate: 1.098699E-04 | global batch size:    64 | lm loss: 3.159454E+00 | loss scale: 1048576.0 | grad norm: 0.410 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 23:58:17] iteration   117400/  500000 | consumed samples:      7513600 | elapsed time per iteration (ms): 619.2 | learning rate: 1.098071E-04 | global batch size:    64 | lm loss: 3.160115E+00 | loss scale: 1048576.0 | grad norm: 0.402 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-24 23:59:19] iteration   117500/  500000 | consumed samples:      7520000 | elapsed time per iteration (ms): 618.4 | learning rate: 1.097442E-04 | global batch size:    64 | lm loss: 3.159727E+00 | loss scale: 1048576.0 | grad norm: 0.413 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 00:00:21] iteration   117600/  500000 | consumed samples:      7526400 | elapsed time per iteration (ms): 619.8 | learning rate: 1.096814E-04 | global batch size:    64 | lm loss: 3.150981E+00 | loss scale: 1048576.0 | grad norm: 0.417 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 00:01:23] iteration   117700/  500000 | consumed samples:      7532800 | elapsed time per iteration (ms): 618.7 | learning rate: 1.096185E-04 | global batch size:    64 | lm loss: 3.149835E+00 | loss scale: 1048576.0 | grad norm: 0.426 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 00:02:25] iteration   117800/  500000 | consumed samples:      7539200 | elapsed time per iteration (ms): 617.1 | learning rate: 1.095556E-04 | global batch size:    64 | lm loss: 3.169623E+00 | loss scale: 1048576.0 | grad norm: 0.414 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 00:03:27] iteration   117900/  500000 | consumed samples:      7545600 | elapsed time per iteration (ms): 619.9 | learning rate: 1.094939E-04 | global batch size:    64 | lm loss: 3.166218E+00 | loss scale: 1048576.0 | grad norm: 0.416 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-25 00:04:29] iteration   118000/  500000 | consumed samples:      7552000 | elapsed time per iteration (ms): 621.4 | learning rate: 1.094309E-04 | global batch size:    64 | lm loss: 3.174125E+00 | loss scale: 1048576.0 | grad norm: 0.406 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2462.62, 2462.64)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 118000 | lm loss value: 3.662538E+00 | lm loss PPL: 3.896011E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-25 00:05:33] iteration   118100/  500000 | consumed samples:      7558400 | elapsed time per iteration (ms): 619.2 | learning rate: 1.093679E-04 | global batch size:    64 | lm loss: 3.151418E+00 | loss scale: 1048576.0 | grad norm: 0.419 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 00:06:35] iteration   118200/  500000 | consumed samples:      7564800 | elapsed time per iteration (ms): 619.5 | learning rate: 1.093049E-04 | global batch size:    64 | lm loss: 3.164133E+00 | loss scale: 1048576.0 | grad norm: 0.400 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 00:07:37] iteration   118300/  500000 | consumed samples:      7571200 | elapsed time per iteration (ms): 617.7 | learning rate: 1.092419E-04 | global batch size:    64 | lm loss: 3.155849E+00 | loss scale: 1048576.0 | grad norm: 0.392 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 00:08:39] iteration   118400/  500000 | consumed samples:      7577600 | elapsed time per iteration (ms): 620.6 | learning rate: 1.091788E-04 | global batch size:    64 | lm loss: 3.167105E+00 | loss scale: 1048576.0 | grad norm: 0.404 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 00:09:41] iteration   118500/  500000 | consumed samples:      7584000 | elapsed time per iteration (ms): 618.3 | learning rate: 1.091157E-04 | global batch size:    64 | lm loss: 3.164278E+00 | loss scale: 1048576.0 | grad norm: 0.426 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 00:10:43] iteration   118600/  500000 | consumed samples:      7590400 | elapsed time per iteration (ms): 618.6 | learning rate: 1.090525E-04 | global batch size:    64 | lm loss: 3.165851E+00 | loss scale: 1048576.0 | grad norm: 0.432 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 00:11:45] iteration   118700/  500000 | consumed samples:      7596800 | elapsed time per iteration (ms): 618.2 | learning rate: 1.089894E-04 | global batch size:    64 | lm loss: 3.165137E+00 | loss scale: 1048576.0 | grad norm: 0.419 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 00:12:47] iteration   118800/  500000 | consumed samples:      7603200 | elapsed time per iteration (ms): 621.0 | learning rate: 1.089262E-04 | global batch size:    64 | lm loss: 3.161702E+00 | loss scale: 1048576.0 | grad norm: 0.408 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 00:13:49] iteration   118900/  500000 | consumed samples:      7609600 | elapsed time per iteration (ms): 618.4 | learning rate: 1.088629E-04 | global batch size:    64 | lm loss: 3.167294E+00 | loss scale: 2097152.0 | grad norm: 0.413 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 00:14:51] iteration   119000/  500000 | consumed samples:      7616000 | elapsed time per iteration (ms): 619.7 | learning rate: 1.087997E-04 | global batch size:    64 | lm loss: 3.154474E+00 | loss scale: 2097152.0 | grad norm: 0.417 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2462.76, 2462.80)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 119000 | lm loss value: 3.683686E+00 | lm loss PPL: 3.979282E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-25 00:15:55] iteration   119100/  500000 | consumed samples:      7622400 | elapsed time per iteration (ms): 621.0 | learning rate: 1.087364E-04 | global batch size:    64 | lm loss: 3.177390E+00 | loss scale: 2097152.0 | grad norm: 0.388 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 00:16:57] iteration   119200/  500000 | consumed samples:      7628800 | elapsed time per iteration (ms): 619.4 | learning rate: 1.086731E-04 | global batch size:    64 | lm loss: 3.164314E+00 | loss scale: 2097152.0 | grad norm: 0.405 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 00:17:59] iteration   119300/  500000 | consumed samples:      7635200 | elapsed time per iteration (ms): 618.3 | learning rate: 1.086097E-04 | global batch size:    64 | lm loss: 3.150680E+00 | loss scale: 2097152.0 | grad norm: 0.413 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 00:19:01] iteration   119400/  500000 | consumed samples:      7641600 | elapsed time per iteration (ms): 620.9 | learning rate: 1.085464E-04 | global batch size:    64 | lm loss: 3.167694E+00 | loss scale: 2097152.0 | grad norm: 0.405 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 00:20:03] iteration   119500/  500000 | consumed samples:      7648000 | elapsed time per iteration (ms): 620.1 | learning rate: 1.084830E-04 | global batch size:    64 | lm loss: 3.168001E+00 | loss scale: 2097152.0 | grad norm: 0.400 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 00:21:05] iteration   119600/  500000 | consumed samples:      7654400 | elapsed time per iteration (ms): 619.4 | learning rate: 1.084196E-04 | global batch size:    64 | lm loss: 3.157730E+00 | loss scale: 2097152.0 | grad norm: 0.414 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 00:22:07] iteration   119700/  500000 | consumed samples:      7660800 | elapsed time per iteration (ms): 618.3 | learning rate: 1.083567E-04 | global batch size:    64 | lm loss: 3.166494E+00 | loss scale: 2097152.0 | grad norm: 0.410 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-25 00:23:09] iteration   119800/  500000 | consumed samples:      7667200 | elapsed time per iteration (ms): 620.6 | learning rate: 1.082933E-04 | global batch size:    64 | lm loss: 3.155090E+00 | loss scale: 2097152.0 | grad norm: 0.413 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 00:24:11] iteration   119900/  500000 | consumed samples:      7673600 | elapsed time per iteration (ms): 618.4 | learning rate: 1.082298E-04 | global batch size:    64 | lm loss: 3.142758E+00 | loss scale: 2097152.0 | grad norm: 0.426 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 00:25:13] iteration   120000/  500000 | consumed samples:      7680000 | elapsed time per iteration (ms): 620.1 | learning rate: 1.081662E-04 | global batch size:    64 | lm loss: 3.170155E+00 | loss scale: 2097152.0 | grad norm: 0.409 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2464.02, 2464.09)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 120000 | lm loss value: 3.664224E+00 | lm loss PPL: 3.902586E+01 | 
--------------------------------------------------------------------------------------------------
saving checkpoint at iteration  120000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-distribution in torch format
  successfully saved checkpoint at iteration  120000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-distribution
(min, max) time across ranks (ms):
    save-checkpoint ................................: (2418.39, 2418.40)
 [2024-06-25 00:26:19] iteration   120100/  500000 | consumed samples:      7686400 | elapsed time per iteration (ms): 618.3 | learning rate: 1.081027E-04 | global batch size:    64 | lm loss: 3.167471E+00 | loss scale: 2097152.0 | grad norm: 0.413 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 00:27:21] iteration   120200/  500000 | consumed samples:      7692800 | elapsed time per iteration (ms): 621.3 | learning rate: 1.080391E-04 | global batch size:    64 | lm loss: 3.152206E+00 | loss scale: 2097152.0 | grad norm: 0.402 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 00:28:24] iteration   120300/  500000 | consumed samples:      7699200 | elapsed time per iteration (ms): 620.3 | learning rate: 1.079754E-04 | global batch size:    64 | lm loss: 3.146463E+00 | loss scale: 2097152.0 | grad norm: 0.424 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 00:29:25] iteration   120400/  500000 | consumed samples:      7705600 | elapsed time per iteration (ms): 619.2 | learning rate: 1.079124E-04 | global batch size:    64 | lm loss: 3.157522E+00 | loss scale: 1048576.0 | grad norm: 0.397 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-25 00:30:27] iteration   120500/  500000 | consumed samples:      7712000 | elapsed time per iteration (ms): 619.0 | learning rate: 1.078488E-04 | global batch size:    64 | lm loss: 3.142201E+00 | loss scale: 1048576.0 | grad norm: 0.417 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 00:31:29] iteration   120600/  500000 | consumed samples:      7718400 | elapsed time per iteration (ms): 621.2 | learning rate: 1.077851E-04 | global batch size:    64 | lm loss: 3.159283E+00 | loss scale: 1048576.0 | grad norm: 0.409 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 00:32:32] iteration   120700/  500000 | consumed samples:      7724800 | elapsed time per iteration (ms): 620.7 | learning rate: 1.077213E-04 | global batch size:    64 | lm loss: 3.161125E+00 | loss scale: 1048576.0 | grad norm: 0.399 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 00:33:34] iteration   120800/  500000 | consumed samples:      7731200 | elapsed time per iteration (ms): 621.4 | learning rate: 1.076576E-04 | global batch size:    64 | lm loss: 3.157483E+00 | loss scale: 1048576.0 | grad norm: 0.414 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 00:34:36] iteration   120900/  500000 | consumed samples:      7737600 | elapsed time per iteration (ms): 619.3 | learning rate: 1.075938E-04 | global batch size:    64 | lm loss: 3.165938E+00 | loss scale: 1048576.0 | grad norm: 0.411 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 00:35:37] iteration   121000/  500000 | consumed samples:      7744000 | elapsed time per iteration (ms): 617.6 | learning rate: 1.075300E-04 | global batch size:    64 | lm loss: 3.151827E+00 | loss scale: 1048576.0 | grad norm: 0.403 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2463.02, 2463.13)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 121000 | lm loss value: 3.722404E+00 | lm loss PPL: 4.136372E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-25 00:36:42] iteration   121100/  500000 | consumed samples:      7750400 | elapsed time per iteration (ms): 622.4 | learning rate: 1.074662E-04 | global batch size:    64 | lm loss: 3.151524E+00 | loss scale: 1048576.0 | grad norm: 0.391 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 00:37:44] iteration   121200/  500000 | consumed samples:      7756800 | elapsed time per iteration (ms): 618.7 | learning rate: 1.074023E-04 | global batch size:    64 | lm loss: 3.157634E+00 | loss scale: 1048576.0 | grad norm: 0.418 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 00:38:46] iteration   121300/  500000 | consumed samples:      7763200 | elapsed time per iteration (ms): 620.7 | learning rate: 1.073384E-04 | global batch size:    64 | lm loss: 3.157715E+00 | loss scale: 1048576.0 | grad norm: 0.419 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 00:39:48] iteration   121400/  500000 | consumed samples:      7769600 | elapsed time per iteration (ms): 617.7 | learning rate: 1.072745E-04 | global batch size:    64 | lm loss: 3.158715E+00 | loss scale: 2097152.0 | grad norm: 0.409 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 00:40:50] iteration   121500/  500000 | consumed samples:      7776000 | elapsed time per iteration (ms): 619.0 | learning rate: 1.072105E-04 | global batch size:    64 | lm loss: 3.152705E+00 | loss scale: 2097152.0 | grad norm: 0.412 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 00:41:52] iteration   121600/  500000 | consumed samples:      7782400 | elapsed time per iteration (ms): 619.9 | learning rate: 1.071466E-04 | global batch size:    64 | lm loss: 3.170099E+00 | loss scale: 2097152.0 | grad norm: 0.409 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 00:42:54] iteration   121700/  500000 | consumed samples:      7788800 | elapsed time per iteration (ms): 622.6 | learning rate: 1.070826E-04 | global batch size:    64 | lm loss: 3.141399E+00 | loss scale: 2097152.0 | grad norm: 0.406 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 00:43:56] iteration   121800/  500000 | consumed samples:      7795200 | elapsed time per iteration (ms): 618.6 | learning rate: 1.070185E-04 | global batch size:    64 | lm loss: 3.158140E+00 | loss scale: 2097152.0 | grad norm: 0.401 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 00:44:58] iteration   121900/  500000 | consumed samples:      7801600 | elapsed time per iteration (ms): 617.4 | learning rate: 1.069545E-04 | global batch size:    64 | lm loss: 3.160146E+00 | loss scale: 2097152.0 | grad norm: 0.408 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 00:45:59] iteration   122000/  500000 | consumed samples:      7808000 | elapsed time per iteration (ms): 619.0 | learning rate: 1.068904E-04 | global batch size:    64 | lm loss: 3.160566E+00 | loss scale: 2097152.0 | grad norm: 0.397 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2462.23, 2462.24)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 122000 | lm loss value: 3.688981E+00 | lm loss PPL: 4.000405E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-25 00:47:04] iteration   122100/  500000 | consumed samples:      7814400 | elapsed time per iteration (ms): 619.8 | learning rate: 1.068263E-04 | global batch size:    64 | lm loss: 3.161321E+00 | loss scale: 2097152.0 | grad norm: 0.402 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 00:48:06] iteration   122200/  500000 | consumed samples:      7820800 | elapsed time per iteration (ms): 619.7 | learning rate: 1.067622E-04 | global batch size:    64 | lm loss: 3.154519E+00 | loss scale: 2097152.0 | grad norm: 0.397 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 00:49:07] iteration   122300/  500000 | consumed samples:      7827200 | elapsed time per iteration (ms): 616.4 | learning rate: 1.066987E-04 | global batch size:    64 | lm loss: 3.161622E+00 | loss scale: 2097152.0 | grad norm: 0.422 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-25 00:50:09] iteration   122400/  500000 | consumed samples:      7833600 | elapsed time per iteration (ms): 618.5 | learning rate: 1.066351E-04 | global batch size:    64 | lm loss: 3.149491E+00 | loss scale: 1048576.0 | grad norm: 0.407 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-25 00:51:11] iteration   122500/  500000 | consumed samples:      7840000 | elapsed time per iteration (ms): 619.9 | learning rate: 1.065709E-04 | global batch size:    64 | lm loss: 3.155293E+00 | loss scale: 1048576.0 | grad norm: 0.413 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 00:52:13] iteration   122600/  500000 | consumed samples:      7846400 | elapsed time per iteration (ms): 617.8 | learning rate: 1.065067E-04 | global batch size:    64 | lm loss: 3.158386E+00 | loss scale: 1048576.0 | grad norm: 0.424 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 00:53:15] iteration   122700/  500000 | consumed samples:      7852800 | elapsed time per iteration (ms): 618.5 | learning rate: 1.064424E-04 | global batch size:    64 | lm loss: 3.156227E+00 | loss scale: 1048576.0 | grad norm: 0.419 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 00:54:17] iteration   122800/  500000 | consumed samples:      7859200 | elapsed time per iteration (ms): 617.9 | learning rate: 1.063781E-04 | global batch size:    64 | lm loss: 3.144718E+00 | loss scale: 1048576.0 | grad norm: 0.413 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 00:55:19] iteration   122900/  500000 | consumed samples:      7865600 | elapsed time per iteration (ms): 621.0 | learning rate: 1.063138E-04 | global batch size:    64 | lm loss: 3.147832E+00 | loss scale: 1048576.0 | grad norm: 0.416 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 00:56:21] iteration   123000/  500000 | consumed samples:      7872000 | elapsed time per iteration (ms): 619.1 | learning rate: 1.062495E-04 | global batch size:    64 | lm loss: 3.157255E+00 | loss scale: 1048576.0 | grad norm: 0.407 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2462.92, 2462.97)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 123000 | lm loss value: 3.691126E+00 | lm loss PPL: 4.008998E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-25 00:57:25] iteration   123100/  500000 | consumed samples:      7878400 | elapsed time per iteration (ms): 619.4 | learning rate: 1.061851E-04 | global batch size:    64 | lm loss: 3.161964E+00 | loss scale: 1048576.0 | grad norm: 0.415 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 00:58:27] iteration   123200/  500000 | consumed samples:      7884800 | elapsed time per iteration (ms): 619.1 | learning rate: 1.061207E-04 | global batch size:    64 | lm loss: 3.161355E+00 | loss scale: 1048576.0 | grad norm: 0.411 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 00:59:29] iteration   123300/  500000 | consumed samples:      7891200 | elapsed time per iteration (ms): 621.8 | learning rate: 1.060563E-04 | global batch size:    64 | lm loss: 3.143480E+00 | loss scale: 1048576.0 | grad norm: 0.399 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 01:00:31] iteration   123400/  500000 | consumed samples:      7897600 | elapsed time per iteration (ms): 618.6 | learning rate: 1.059919E-04 | global batch size:    64 | lm loss: 3.144914E+00 | loss scale: 2097152.0 | grad norm: 0.412 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 01:01:33] iteration   123500/  500000 | consumed samples:      7904000 | elapsed time per iteration (ms): 621.4 | learning rate: 1.059274E-04 | global batch size:    64 | lm loss: 3.126620E+00 | loss scale: 2097152.0 | grad norm: 0.416 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 01:02:35] iteration   123600/  500000 | consumed samples:      7910400 | elapsed time per iteration (ms): 620.1 | learning rate: 1.058629E-04 | global batch size:    64 | lm loss: 3.152713E+00 | loss scale: 2097152.0 | grad norm: 0.435 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 01:03:37] iteration   123700/  500000 | consumed samples:      7916800 | elapsed time per iteration (ms): 617.6 | learning rate: 1.057984E-04 | global batch size:    64 | lm loss: 3.133875E+00 | loss scale: 2097152.0 | grad norm: 0.418 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 01:04:39] iteration   123800/  500000 | consumed samples:      7923200 | elapsed time per iteration (ms): 620.0 | learning rate: 1.057339E-04 | global batch size:    64 | lm loss: 3.142962E+00 | loss scale: 2097152.0 | grad norm: 0.424 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 01:05:41] iteration   123900/  500000 | consumed samples:      7929600 | elapsed time per iteration (ms): 619.4 | learning rate: 1.056693E-04 | global batch size:    64 | lm loss: 3.162631E+00 | loss scale: 2097152.0 | grad norm: 0.413 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 01:06:43] iteration   124000/  500000 | consumed samples:      7936000 | elapsed time per iteration (ms): 620.6 | learning rate: 1.056047E-04 | global batch size:    64 | lm loss: 3.147257E+00 | loss scale: 2097152.0 | grad norm: 0.405 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2464.23, 2464.27)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 124000 | lm loss value: 3.692405E+00 | lm loss PPL: 4.014129E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-25 01:07:47] iteration   124100/  500000 | consumed samples:      7942400 | elapsed time per iteration (ms): 618.7 | learning rate: 1.055401E-04 | global batch size:    64 | lm loss: 3.142525E+00 | loss scale: 2097152.0 | grad norm: 0.422 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 01:08:49] iteration   124200/  500000 | consumed samples:      7948800 | elapsed time per iteration (ms): 618.0 | learning rate: 1.054761E-04 | global batch size:    64 | lm loss: 3.139248E+00 | loss scale: 2097152.0 | grad norm: 0.415 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-25 01:09:51] iteration   124300/  500000 | consumed samples:      7955200 | elapsed time per iteration (ms): 619.1 | learning rate: 1.054121E-04 | global batch size:    64 | lm loss: 3.149656E+00 | loss scale: 1048576.0 | grad norm: 0.405 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-25 01:10:53] iteration   124400/  500000 | consumed samples:      7961600 | elapsed time per iteration (ms): 619.8 | learning rate: 1.053474E-04 | global batch size:    64 | lm loss: 3.155722E+00 | loss scale: 1048576.0 | grad norm: 0.411 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 01:11:55] iteration   124500/  500000 | consumed samples:      7968000 | elapsed time per iteration (ms): 619.0 | learning rate: 1.052827E-04 | global batch size:    64 | lm loss: 3.139171E+00 | loss scale: 1048576.0 | grad norm: 0.414 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 01:12:57] iteration   124600/  500000 | consumed samples:      7974400 | elapsed time per iteration (ms): 622.6 | learning rate: 1.052179E-04 | global batch size:    64 | lm loss: 3.168840E+00 | loss scale: 1048576.0 | grad norm: 0.415 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 01:13:59] iteration   124700/  500000 | consumed samples:      7980800 | elapsed time per iteration (ms): 618.9 | learning rate: 1.051531E-04 | global batch size:    64 | lm loss: 3.146989E+00 | loss scale: 1048576.0 | grad norm: 0.411 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 01:15:01] iteration   124800/  500000 | consumed samples:      7987200 | elapsed time per iteration (ms): 620.5 | learning rate: 1.050883E-04 | global batch size:    64 | lm loss: 3.143174E+00 | loss scale: 1048576.0 | grad norm: 0.403 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 01:16:03] iteration   124900/  500000 | consumed samples:      7993600 | elapsed time per iteration (ms): 618.0 | learning rate: 1.050235E-04 | global batch size:    64 | lm loss: 3.140276E+00 | loss scale: 1048576.0 | grad norm: 0.410 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 01:17:05] iteration   125000/  500000 | consumed samples:      8000000 | elapsed time per iteration (ms): 619.7 | learning rate: 1.049587E-04 | global batch size:    64 | lm loss: 3.151455E+00 | loss scale: 1048576.0 | grad norm: 0.410 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2462.70, 2462.81)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 125000 | lm loss value: 3.683532E+00 | lm loss PPL: 3.978667E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-25 01:18:09] iteration   125100/  500000 | consumed samples:      8006400 | elapsed time per iteration (ms): 620.4 | learning rate: 1.048938E-04 | global batch size:    64 | lm loss: 3.153431E+00 | loss scale: 1048576.0 | grad norm: 0.429 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 01:19:11] iteration   125200/  500000 | consumed samples:      8012800 | elapsed time per iteration (ms): 620.1 | learning rate: 1.048289E-04 | global batch size:    64 | lm loss: 3.168638E+00 | loss scale: 1048576.0 | grad norm: 0.424 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 01:20:13] iteration   125300/  500000 | consumed samples:      8019200 | elapsed time per iteration (ms): 619.0 | learning rate: 1.047640E-04 | global batch size:    64 | lm loss: 3.136802E+00 | loss scale: 2097152.0 | grad norm: 0.410 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 01:21:15] iteration   125400/  500000 | consumed samples:      8025600 | elapsed time per iteration (ms): 619.4 | learning rate: 1.046991E-04 | global batch size:    64 | lm loss: 3.134067E+00 | loss scale: 2097152.0 | grad norm: 0.414 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 01:22:17] iteration   125500/  500000 | consumed samples:      8032000 | elapsed time per iteration (ms): 618.5 | learning rate: 1.046348E-04 | global batch size:    64 | lm loss: 3.153293E+00 | loss scale: 2097152.0 | grad norm: 0.434 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-25 01:23:19] iteration   125600/  500000 | consumed samples:      8038400 | elapsed time per iteration (ms): 619.2 | learning rate: 1.045698E-04 | global batch size:    64 | lm loss: 3.154948E+00 | loss scale: 2097152.0 | grad norm: 0.412 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 01:24:21] iteration   125700/  500000 | consumed samples:      8044800 | elapsed time per iteration (ms): 619.9 | learning rate: 1.045048E-04 | global batch size:    64 | lm loss: 3.159485E+00 | loss scale: 2097152.0 | grad norm: 0.404 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 01:25:23] iteration   125800/  500000 | consumed samples:      8051200 | elapsed time per iteration (ms): 622.2 | learning rate: 1.044397E-04 | global batch size:    64 | lm loss: 3.151750E+00 | loss scale: 2097152.0 | grad norm: 0.399 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 01:26:25] iteration   125900/  500000 | consumed samples:      8057600 | elapsed time per iteration (ms): 620.7 | learning rate: 1.043747E-04 | global batch size:    64 | lm loss: 3.143898E+00 | loss scale: 2097152.0 | grad norm: 0.411 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 01:27:27] iteration   126000/  500000 | consumed samples:      8064000 | elapsed time per iteration (ms): 619.0 | learning rate: 1.043102E-04 | global batch size:    64 | lm loss: 3.150933E+00 | loss scale: 1048576.0 | grad norm: 0.406 | number of skipped iterations:   1 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2464.02, 2464.07)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 126000 | lm loss value: 3.694149E+00 | lm loss PPL: 4.021133E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-25 01:28:32] iteration   126100/  500000 | consumed samples:      8070400 | elapsed time per iteration (ms): 620.0 | learning rate: 1.042451E-04 | global batch size:    64 | lm loss: 3.156693E+00 | loss scale: 1048576.0 | grad norm: 0.404 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 01:29:33] iteration   126200/  500000 | consumed samples:      8076800 | elapsed time per iteration (ms): 617.6 | learning rate: 1.041800E-04 | global batch size:    64 | lm loss: 3.146265E+00 | loss scale: 1048576.0 | grad norm: 0.415 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 01:30:35] iteration   126300/  500000 | consumed samples:      8083200 | elapsed time per iteration (ms): 617.3 | learning rate: 1.041148E-04 | global batch size:    64 | lm loss: 3.140331E+00 | loss scale: 1048576.0 | grad norm: 0.412 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 01:31:37] iteration   126400/  500000 | consumed samples:      8089600 | elapsed time per iteration (ms): 620.6 | learning rate: 1.040497E-04 | global batch size:    64 | lm loss: 3.152009E+00 | loss scale: 1048576.0 | grad norm: 0.415 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 01:32:39] iteration   126500/  500000 | consumed samples:      8096000 | elapsed time per iteration (ms): 618.6 | learning rate: 1.039845E-04 | global batch size:    64 | lm loss: 3.158072E+00 | loss scale: 1048576.0 | grad norm: 0.416 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 01:33:41] iteration   126600/  500000 | consumed samples:      8102400 | elapsed time per iteration (ms): 619.5 | learning rate: 1.039192E-04 | global batch size:    64 | lm loss: 3.149044E+00 | loss scale: 1048576.0 | grad norm: 0.418 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 01:34:43] iteration   126700/  500000 | consumed samples:      8108800 | elapsed time per iteration (ms): 620.1 | learning rate: 1.038540E-04 | global batch size:    64 | lm loss: 3.142751E+00 | loss scale: 1048576.0 | grad norm: 0.419 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 01:35:45] iteration   126800/  500000 | consumed samples:      8115200 | elapsed time per iteration (ms): 617.0 | learning rate: 1.037887E-04 | global batch size:    64 | lm loss: 3.132412E+00 | loss scale: 1048576.0 | grad norm: 0.440 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 01:36:47] iteration   126900/  500000 | consumed samples:      8121600 | elapsed time per iteration (ms): 618.0 | learning rate: 1.037241E-04 | global batch size:    64 | lm loss: 3.153406E+00 | loss scale: 524288.0 | grad norm: 0.415 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-25 01:37:49] iteration   127000/  500000 | consumed samples:      8128000 | elapsed time per iteration (ms): 620.8 | learning rate: 1.036587E-04 | global batch size:    64 | lm loss: 3.132586E+00 | loss scale: 524288.0 | grad norm: 0.411 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2463.11, 2463.14)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 127000 | lm loss value: 3.728364E+00 | lm loss PPL: 4.161099E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-25 01:38:53] iteration   127100/  500000 | consumed samples:      8134400 | elapsed time per iteration (ms): 619.0 | learning rate: 1.035934E-04 | global batch size:    64 | lm loss: 3.141526E+00 | loss scale: 524288.0 | grad norm: 0.423 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 01:39:55] iteration   127200/  500000 | consumed samples:      8140800 | elapsed time per iteration (ms): 619.4 | learning rate: 1.035280E-04 | global batch size:    64 | lm loss: 3.143826E+00 | loss scale: 524288.0 | grad norm: 0.418 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 01:40:57] iteration   127300/  500000 | consumed samples:      8147200 | elapsed time per iteration (ms): 616.9 | learning rate: 1.034626E-04 | global batch size:    64 | lm loss: 3.139504E+00 | loss scale: 524288.0 | grad norm: 0.408 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 01:41:58] iteration   127400/  500000 | consumed samples:      8153600 | elapsed time per iteration (ms): 617.4 | learning rate: 1.033972E-04 | global batch size:    64 | lm loss: 3.149686E+00 | loss scale: 524288.0 | grad norm: 0.404 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 01:43:00] iteration   127500/  500000 | consumed samples:      8160000 | elapsed time per iteration (ms): 619.4 | learning rate: 1.033318E-04 | global batch size:    64 | lm loss: 3.133636E+00 | loss scale: 524288.0 | grad norm: 0.402 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 01:44:02] iteration   127600/  500000 | consumed samples:      8166400 | elapsed time per iteration (ms): 618.9 | learning rate: 1.032663E-04 | global batch size:    64 | lm loss: 3.145610E+00 | loss scale: 524288.0 | grad norm: 0.408 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 01:45:04] iteration   127700/  500000 | consumed samples:      8172800 | elapsed time per iteration (ms): 618.9 | learning rate: 1.032009E-04 | global batch size:    64 | lm loss: 3.145954E+00 | loss scale: 524288.0 | grad norm: 0.425 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 01:46:06] iteration   127800/  500000 | consumed samples:      8179200 | elapsed time per iteration (ms): 619.6 | learning rate: 1.031354E-04 | global batch size:    64 | lm loss: 3.161461E+00 | loss scale: 524288.0 | grad norm: 0.408 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 01:47:08] iteration   127900/  500000 | consumed samples:      8185600 | elapsed time per iteration (ms): 619.8 | learning rate: 1.030698E-04 | global batch size:    64 | lm loss: 3.156471E+00 | loss scale: 1048576.0 | grad norm: 0.400 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 01:48:10] iteration   128000/  500000 | consumed samples:      8192000 | elapsed time per iteration (ms): 618.7 | learning rate: 1.030043E-04 | global batch size:    64 | lm loss: 3.135629E+00 | loss scale: 1048576.0 | grad norm: 0.421 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2461.27, 2461.34)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 128000 | lm loss value: 3.676530E+00 | lm loss PPL: 3.950906E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-25 01:49:15] iteration   128100/  500000 | consumed samples:      8198400 | elapsed time per iteration (ms): 621.6 | learning rate: 1.029387E-04 | global batch size:    64 | lm loss: 3.139984E+00 | loss scale: 1048576.0 | grad norm: 0.401 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 01:50:16] iteration   128200/  500000 | consumed samples:      8204800 | elapsed time per iteration (ms): 618.9 | learning rate: 1.028731E-04 | global batch size:    64 | lm loss: 3.150190E+00 | loss scale: 1048576.0 | grad norm: 0.408 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 01:51:18] iteration   128300/  500000 | consumed samples:      8211200 | elapsed time per iteration (ms): 617.8 | learning rate: 1.028075E-04 | global batch size:    64 | lm loss: 3.140483E+00 | loss scale: 1048576.0 | grad norm: 0.414 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 01:52:20] iteration   128400/  500000 | consumed samples:      8217600 | elapsed time per iteration (ms): 619.8 | learning rate: 1.027419E-04 | global batch size:    64 | lm loss: 3.142976E+00 | loss scale: 1048576.0 | grad norm: 0.427 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 01:53:22] iteration   128500/  500000 | consumed samples:      8224000 | elapsed time per iteration (ms): 618.4 | learning rate: 1.026762E-04 | global batch size:    64 | lm loss: 3.135220E+00 | loss scale: 1048576.0 | grad norm: 0.413 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 01:54:24] iteration   128600/  500000 | consumed samples:      8230400 | elapsed time per iteration (ms): 618.4 | learning rate: 1.026105E-04 | global batch size:    64 | lm loss: 3.141958E+00 | loss scale: 1048576.0 | grad norm: 0.405 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 01:55:26] iteration   128700/  500000 | consumed samples:      8236800 | elapsed time per iteration (ms): 618.4 | learning rate: 1.025448E-04 | global batch size:    64 | lm loss: 3.155189E+00 | loss scale: 1048576.0 | grad norm: 0.409 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 01:56:28] iteration   128800/  500000 | consumed samples:      8243200 | elapsed time per iteration (ms): 618.9 | learning rate: 1.024791E-04 | global batch size:    64 | lm loss: 3.149489E+00 | loss scale: 1048576.0 | grad norm: 0.406 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 01:57:30] iteration   128900/  500000 | consumed samples:      8249600 | elapsed time per iteration (ms): 621.1 | learning rate: 1.024140E-04 | global batch size:    64 | lm loss: 3.149766E+00 | loss scale: 2097152.0 | grad norm: 0.418 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-25 01:58:32] iteration   129000/  500000 | consumed samples:      8256000 | elapsed time per iteration (ms): 620.5 | learning rate: 1.023482E-04 | global batch size:    64 | lm loss: 3.156404E+00 | loss scale: 2097152.0 | grad norm: 0.411 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2462.68, 2462.87)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 129000 | lm loss value: 3.663184E+00 | lm loss PPL: 3.898529E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-25 01:59:36] iteration   129100/  500000 | consumed samples:      8262400 | elapsed time per iteration (ms): 621.1 | learning rate: 1.022824E-04 | global batch size:    64 | lm loss: 3.141032E+00 | loss scale: 2097152.0 | grad norm: 0.417 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 02:00:38] iteration   129200/  500000 | consumed samples:      8268800 | elapsed time per iteration (ms): 619.2 | learning rate: 1.022166E-04 | global batch size:    64 | lm loss: 3.142330E+00 | loss scale: 2097152.0 | grad norm: 0.413 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 02:01:40] iteration   129300/  500000 | consumed samples:      8275200 | elapsed time per iteration (ms): 618.7 | learning rate: 1.021508E-04 | global batch size:    64 | lm loss: 3.149127E+00 | loss scale: 2097152.0 | grad norm: 0.412 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 02:02:42] iteration   129400/  500000 | consumed samples:      8281600 | elapsed time per iteration (ms): 618.7 | learning rate: 1.020849E-04 | global batch size:    64 | lm loss: 3.139845E+00 | loss scale: 2097152.0 | grad norm: 0.414 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 02:03:44] iteration   129500/  500000 | consumed samples:      8288000 | elapsed time per iteration (ms): 616.9 | learning rate: 1.020190E-04 | global batch size:    64 | lm loss: 3.135441E+00 | loss scale: 2097152.0 | grad norm: 0.425 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 02:04:45] iteration   129600/  500000 | consumed samples:      8294400 | elapsed time per iteration (ms): 617.5 | learning rate: 1.019531E-04 | global batch size:    64 | lm loss: 3.149536E+00 | loss scale: 2097152.0 | grad norm: 0.410 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 02:05:47] iteration   129700/  500000 | consumed samples:      8300800 | elapsed time per iteration (ms): 617.3 | learning rate: 1.018872E-04 | global batch size:    64 | lm loss: 3.155440E+00 | loss scale: 2097152.0 | grad norm: 0.403 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 02:06:49] iteration   129800/  500000 | consumed samples:      8307200 | elapsed time per iteration (ms): 617.9 | learning rate: 1.018212E-04 | global batch size:    64 | lm loss: 3.141678E+00 | loss scale: 2097152.0 | grad norm: 0.411 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 02:07:51] iteration   129900/  500000 | consumed samples:      8313600 | elapsed time per iteration (ms): 619.2 | learning rate: 1.017566E-04 | global batch size:    64 | lm loss: 3.148438E+00 | loss scale: 2097152.0 | grad norm: 0.401 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-25 02:08:53] iteration   130000/  500000 | consumed samples:      8320000 | elapsed time per iteration (ms): 619.2 | learning rate: 1.016906E-04 | global batch size:    64 | lm loss: 3.139487E+00 | loss scale: 2097152.0 | grad norm: 0.417 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2468.40, 2468.42)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 130000 | lm loss value: 3.739693E+00 | lm loss PPL: 4.208509E+01 | 
--------------------------------------------------------------------------------------------------
saving checkpoint at iteration  130000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-distribution in torch format
  successfully saved checkpoint at iteration  130000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-distribution
(min, max) time across ranks (ms):
    save-checkpoint ................................: (2331.18, 2331.26)
 [2024-06-25 02:09:59] iteration   130100/  500000 | consumed samples:      8326400 | elapsed time per iteration (ms): 618.0 | learning rate: 1.016246E-04 | global batch size:    64 | lm loss: 3.138140E+00 | loss scale: 2097152.0 | grad norm: 0.422 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 02:11:01] iteration   130200/  500000 | consumed samples:      8332800 | elapsed time per iteration (ms): 617.3 | learning rate: 1.015586E-04 | global batch size:    64 | lm loss: 3.123448E+00 | loss scale: 2097152.0 | grad norm: 0.428 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 02:12:03] iteration   130300/  500000 | consumed samples:      8339200 | elapsed time per iteration (ms): 619.6 | learning rate: 1.014925E-04 | global batch size:    64 | lm loss: 3.136417E+00 | loss scale: 2097152.0 | grad norm: 0.427 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 02:13:05] iteration   130400/  500000 | consumed samples:      8345600 | elapsed time per iteration (ms): 618.4 | learning rate: 1.014264E-04 | global batch size:    64 | lm loss: 3.147965E+00 | loss scale: 2097152.0 | grad norm: 0.409 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 02:14:07] iteration   130500/  500000 | consumed samples:      8352000 | elapsed time per iteration (ms): 616.9 | learning rate: 1.013610E-04 | global batch size:    64 | lm loss: 3.150496E+00 | loss scale: 1048576.0 | grad norm: 0.409 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-25 02:15:08] iteration   130600/  500000 | consumed samples:      8358400 | elapsed time per iteration (ms): 619.0 | learning rate: 1.012949E-04 | global batch size:    64 | lm loss: 3.136161E+00 | loss scale: 1048576.0 | grad norm: 0.418 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 02:16:10] iteration   130700/  500000 | consumed samples:      8364800 | elapsed time per iteration (ms): 619.4 | learning rate: 1.012287E-04 | global batch size:    64 | lm loss: 3.147842E+00 | loss scale: 1048576.0 | grad norm: 0.417 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 02:17:12] iteration   130800/  500000 | consumed samples:      8371200 | elapsed time per iteration (ms): 618.4 | learning rate: 1.011626E-04 | global batch size:    64 | lm loss: 3.140472E+00 | loss scale: 1048576.0 | grad norm: 0.409 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 02:18:14] iteration   130900/  500000 | consumed samples:      8377600 | elapsed time per iteration (ms): 620.4 | learning rate: 1.010964E-04 | global batch size:    64 | lm loss: 3.135380E+00 | loss scale: 1048576.0 | grad norm: 0.411 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 02:19:16] iteration   131000/  500000 | consumed samples:      8384000 | elapsed time per iteration (ms): 618.0 | learning rate: 1.010302E-04 | global batch size:    64 | lm loss: 3.140546E+00 | loss scale: 1048576.0 | grad norm: 0.416 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2462.55, 2462.62)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 131000 | lm loss value: 3.678577E+00 | lm loss PPL: 3.959001E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-25 02:20:21] iteration   131100/  500000 | consumed samples:      8390400 | elapsed time per iteration (ms): 619.6 | learning rate: 1.009640E-04 | global batch size:    64 | lm loss: 3.133979E+00 | loss scale: 1048576.0 | grad norm: 0.419 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 02:21:22] iteration   131200/  500000 | consumed samples:      8396800 | elapsed time per iteration (ms): 616.9 | learning rate: 1.008977E-04 | global batch size:    64 | lm loss: 3.129322E+00 | loss scale: 1048576.0 | grad norm: 0.414 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 02:22:24] iteration   131300/  500000 | consumed samples:      8403200 | elapsed time per iteration (ms): 617.3 | learning rate: 1.008315E-04 | global batch size:    64 | lm loss: 3.128255E+00 | loss scale: 1048576.0 | grad norm: 0.422 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 02:23:26] iteration   131400/  500000 | consumed samples:      8409600 | elapsed time per iteration (ms): 617.7 | learning rate: 1.007652E-04 | global batch size:    64 | lm loss: 3.134430E+00 | loss scale: 1048576.0 | grad norm: 0.429 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 02:24:28] iteration   131500/  500000 | consumed samples:      8416000 | elapsed time per iteration (ms): 619.5 | learning rate: 1.006989E-04 | global batch size:    64 | lm loss: 3.138404E+00 | loss scale: 2097152.0 | grad norm: 0.406 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 02:25:30] iteration   131600/  500000 | consumed samples:      8422400 | elapsed time per iteration (ms): 622.0 | learning rate: 1.006326E-04 | global batch size:    64 | lm loss: 3.152361E+00 | loss scale: 2097152.0 | grad norm: 0.416 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 02:26:32] iteration   131700/  500000 | consumed samples:      8428800 | elapsed time per iteration (ms): 617.8 | learning rate: 1.005676E-04 | global batch size:    64 | lm loss: 3.138719E+00 | loss scale: 1048576.0 | grad norm: 0.437 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-25 02:27:34] iteration   131800/  500000 | consumed samples:      8435200 | elapsed time per iteration (ms): 618.6 | learning rate: 1.005012E-04 | global batch size:    64 | lm loss: 3.142449E+00 | loss scale: 1048576.0 | grad norm: 0.419 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 02:28:35] iteration   131900/  500000 | consumed samples:      8441600 | elapsed time per iteration (ms): 617.9 | learning rate: 1.004348E-04 | global batch size:    64 | lm loss: 3.145934E+00 | loss scale: 1048576.0 | grad norm: 0.403 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 02:29:37] iteration   132000/  500000 | consumed samples:      8448000 | elapsed time per iteration (ms): 617.5 | learning rate: 1.003684E-04 | global batch size:    64 | lm loss: 3.139702E+00 | loss scale: 1048576.0 | grad norm: 0.419 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2463.39, 2463.48)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 132000 | lm loss value: 3.634067E+00 | lm loss PPL: 3.786650E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-25 02:30:42] iteration   132100/  500000 | consumed samples:      8454400 | elapsed time per iteration (ms): 620.2 | learning rate: 1.003020E-04 | global batch size:    64 | lm loss: 3.146725E+00 | loss scale: 1048576.0 | grad norm: 0.418 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 02:31:43] iteration   132200/  500000 | consumed samples:      8460800 | elapsed time per iteration (ms): 619.1 | learning rate: 1.002355E-04 | global batch size:    64 | lm loss: 3.140246E+00 | loss scale: 1048576.0 | grad norm: 0.421 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 02:32:45] iteration   132300/  500000 | consumed samples:      8467200 | elapsed time per iteration (ms): 619.0 | learning rate: 1.001691E-04 | global batch size:    64 | lm loss: 3.148608E+00 | loss scale: 1048576.0 | grad norm: 0.407 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 02:33:48] iteration   132400/  500000 | consumed samples:      8473600 | elapsed time per iteration (ms): 621.6 | learning rate: 1.001026E-04 | global batch size:    64 | lm loss: 3.142128E+00 | loss scale: 1048576.0 | grad norm: 0.412 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 02:34:50] iteration   132500/  500000 | consumed samples:      8480000 | elapsed time per iteration (ms): 621.5 | learning rate: 1.000361E-04 | global batch size:    64 | lm loss: 3.149476E+00 | loss scale: 1048576.0 | grad norm: 0.411 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 02:35:52] iteration   132600/  500000 | consumed samples:      8486400 | elapsed time per iteration (ms): 618.7 | learning rate: 9.996958E-05 | global batch size:    64 | lm loss: 3.151407E+00 | loss scale: 1048576.0 | grad norm: 0.416 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 02:36:53] iteration   132700/  500000 | consumed samples:      8492800 | elapsed time per iteration (ms): 618.9 | learning rate: 9.990304E-05 | global batch size:    64 | lm loss: 3.127996E+00 | loss scale: 2097152.0 | grad norm: 0.416 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 02:37:55] iteration   132800/  500000 | consumed samples:      8499200 | elapsed time per iteration (ms): 618.3 | learning rate: 9.983648E-05 | global batch size:    64 | lm loss: 3.128246E+00 | loss scale: 2097152.0 | grad norm: 0.407 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 02:38:57] iteration   132900/  500000 | consumed samples:      8505600 | elapsed time per iteration (ms): 619.8 | learning rate: 9.976990E-05 | global batch size:    64 | lm loss: 3.134677E+00 | loss scale: 2097152.0 | grad norm: 0.419 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 02:39:59] iteration   133000/  500000 | consumed samples:      8512000 | elapsed time per iteration (ms): 620.2 | learning rate: 9.970330E-05 | global batch size:    64 | lm loss: 3.127371E+00 | loss scale: 2097152.0 | grad norm: 0.412 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2475.08, 2475.13)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 133000 | lm loss value: 3.637124E+00 | lm loss PPL: 3.798244E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-25 02:41:04] iteration   133100/  500000 | consumed samples:      8518400 | elapsed time per iteration (ms): 620.1 | learning rate: 9.963734E-05 | global batch size:    64 | lm loss: 3.130838E+00 | loss scale: 2097152.0 | grad norm: 0.403 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-25 02:42:06] iteration   133200/  500000 | consumed samples:      8524800 | elapsed time per iteration (ms): 620.4 | learning rate: 9.957070E-05 | global batch size:    64 | lm loss: 3.140746E+00 | loss scale: 2097152.0 | grad norm: 0.405 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 02:43:08] iteration   133300/  500000 | consumed samples:      8531200 | elapsed time per iteration (ms): 620.9 | learning rate: 9.950405E-05 | global batch size:    64 | lm loss: 3.150369E+00 | loss scale: 2097152.0 | grad norm: 0.406 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 02:44:10] iteration   133400/  500000 | consumed samples:      8537600 | elapsed time per iteration (ms): 621.2 | learning rate: 9.943803E-05 | global batch size:    64 | lm loss: 3.146245E+00 | loss scale: 1048576.0 | grad norm: 0.405 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-25 02:45:12] iteration   133500/  500000 | consumed samples:      8544000 | elapsed time per iteration (ms): 619.2 | learning rate: 9.937134E-05 | global batch size:    64 | lm loss: 3.130573E+00 | loss scale: 1048576.0 | grad norm: 0.409 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 02:46:14] iteration   133600/  500000 | consumed samples:      8550400 | elapsed time per iteration (ms): 620.0 | learning rate: 9.930462E-05 | global batch size:    64 | lm loss: 3.125833E+00 | loss scale: 1048576.0 | grad norm: 0.404 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 02:47:16] iteration   133700/  500000 | consumed samples:      8556800 | elapsed time per iteration (ms): 619.5 | learning rate: 9.923789E-05 | global batch size:    64 | lm loss: 3.136359E+00 | loss scale: 1048576.0 | grad norm: 0.426 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 02:48:18] iteration   133800/  500000 | consumed samples:      8563200 | elapsed time per iteration (ms): 619.9 | learning rate: 9.917114E-05 | global batch size:    64 | lm loss: 3.130069E+00 | loss scale: 1048576.0 | grad norm: 0.445 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 02:49:20] iteration   133900/  500000 | consumed samples:      8569600 | elapsed time per iteration (ms): 619.9 | learning rate: 9.910436E-05 | global batch size:    64 | lm loss: 3.119886E+00 | loss scale: 1048576.0 | grad norm: 0.402 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 02:50:22] iteration   134000/  500000 | consumed samples:      8576000 | elapsed time per iteration (ms): 617.3 | learning rate: 9.903757E-05 | global batch size:    64 | lm loss: 3.120246E+00 | loss scale: 1048576.0 | grad norm: 0.411 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2462.15, 2462.24)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 134000 | lm loss value: 3.625922E+00 | lm loss PPL: 3.755935E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-25 02:51:26] iteration   134100/  500000 | consumed samples:      8582400 | elapsed time per iteration (ms): 617.7 | learning rate: 9.897076E-05 | global batch size:    64 | lm loss: 3.141745E+00 | loss scale: 1048576.0 | grad norm: 0.425 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 02:52:28] iteration   134200/  500000 | consumed samples:      8588800 | elapsed time per iteration (ms): 619.6 | learning rate: 9.890394E-05 | global batch size:    64 | lm loss: 3.144930E+00 | loss scale: 1048576.0 | grad norm: 0.391 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 02:53:30] iteration   134300/  500000 | consumed samples:      8595200 | elapsed time per iteration (ms): 619.1 | learning rate: 9.883776E-05 | global batch size:    64 | lm loss: 3.134415E+00 | loss scale: 524288.0 | grad norm: 0.417 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-25 02:54:32] iteration   134400/  500000 | consumed samples:      8601600 | elapsed time per iteration (ms): 620.0 | learning rate: 9.877089E-05 | global batch size:    64 | lm loss: 3.132371E+00 | loss scale: 524288.0 | grad norm: 0.418 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 02:55:34] iteration   134500/  500000 | consumed samples:      8608000 | elapsed time per iteration (ms): 620.0 | learning rate: 9.870401E-05 | global batch size:    64 | lm loss: 3.128805E+00 | loss scale: 524288.0 | grad norm: 0.429 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 02:56:36] iteration   134600/  500000 | consumed samples:      8614400 | elapsed time per iteration (ms): 620.8 | learning rate: 9.863711E-05 | global batch size:    64 | lm loss: 3.129904E+00 | loss scale: 524288.0 | grad norm: 0.419 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 02:57:38] iteration   134700/  500000 | consumed samples:      8620800 | elapsed time per iteration (ms): 619.8 | learning rate: 9.857019E-05 | global batch size:    64 | lm loss: 3.130496E+00 | loss scale: 524288.0 | grad norm: 0.416 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 02:58:40] iteration   134800/  500000 | consumed samples:      8627200 | elapsed time per iteration (ms): 620.1 | learning rate: 9.850325E-05 | global batch size:    64 | lm loss: 3.133673E+00 | loss scale: 524288.0 | grad norm: 0.399 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 02:59:42] iteration   134900/  500000 | consumed samples:      8633600 | elapsed time per iteration (ms): 619.1 | learning rate: 9.843629E-05 | global batch size:    64 | lm loss: 3.128669E+00 | loss scale: 524288.0 | grad norm: 0.415 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 03:00:44] iteration   135000/  500000 | consumed samples:      8640000 | elapsed time per iteration (ms): 619.1 | learning rate: 9.836932E-05 | global batch size:    64 | lm loss: 3.135651E+00 | loss scale: 524288.0 | grad norm: 0.427 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2462.64, 2462.65)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 135000 | lm loss value: 3.654322E+00 | lm loss PPL: 3.864130E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-25 03:01:48] iteration   135100/  500000 | consumed samples:      8646400 | elapsed time per iteration (ms): 619.2 | learning rate: 9.830233E-05 | global batch size:    64 | lm loss: 3.130878E+00 | loss scale: 524288.0 | grad norm: 0.424 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 03:02:50] iteration   135200/  500000 | consumed samples:      8652800 | elapsed time per iteration (ms): 618.9 | learning rate: 9.823532E-05 | global batch size:    64 | lm loss: 3.137566E+00 | loss scale: 524288.0 | grad norm: 0.415 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 03:03:52] iteration   135300/  500000 | consumed samples:      8659200 | elapsed time per iteration (ms): 618.4 | learning rate: 9.816829E-05 | global batch size:    64 | lm loss: 3.142641E+00 | loss scale: 1048576.0 | grad norm: 0.399 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 03:04:54] iteration   135400/  500000 | consumed samples:      8665600 | elapsed time per iteration (ms): 621.1 | learning rate: 9.810124E-05 | global batch size:    64 | lm loss: 3.126526E+00 | loss scale: 1048576.0 | grad norm: 0.424 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 03:05:56] iteration   135500/  500000 | consumed samples:      8672000 | elapsed time per iteration (ms): 617.1 | learning rate: 9.803418E-05 | global batch size:    64 | lm loss: 3.134092E+00 | loss scale: 1048576.0 | grad norm: 0.421 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 03:06:57] iteration   135600/  500000 | consumed samples:      8678400 | elapsed time per iteration (ms): 619.3 | learning rate: 9.796709E-05 | global batch size:    64 | lm loss: 3.135014E+00 | loss scale: 1048576.0 | grad norm: 0.410 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 03:07:59] iteration   135700/  500000 | consumed samples:      8684800 | elapsed time per iteration (ms): 619.3 | learning rate: 9.789999E-05 | global batch size:    64 | lm loss: 3.126734E+00 | loss scale: 1048576.0 | grad norm: 0.418 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 03:09:01] iteration   135800/  500000 | consumed samples:      8691200 | elapsed time per iteration (ms): 619.8 | learning rate: 9.783288E-05 | global batch size:    64 | lm loss: 3.125773E+00 | loss scale: 1048576.0 | grad norm: 0.414 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 03:10:03] iteration   135900/  500000 | consumed samples:      8697600 | elapsed time per iteration (ms): 618.9 | learning rate: 9.776574E-05 | global batch size:    64 | lm loss: 3.131173E+00 | loss scale: 1048576.0 | grad norm: 0.411 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 03:11:05] iteration   136000/  500000 | consumed samples:      8704000 | elapsed time per iteration (ms): 618.9 | learning rate: 9.769859E-05 | global batch size:    64 | lm loss: 3.132513E+00 | loss scale: 1048576.0 | grad norm: 0.417 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2461.80, 2461.90)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 136000 | lm loss value: 3.701381E+00 | lm loss PPL: 4.050320E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-25 03:12:09] iteration   136100/  500000 | consumed samples:      8710400 | elapsed time per iteration (ms): 618.2 | learning rate: 9.763142E-05 | global batch size:    64 | lm loss: 3.134236E+00 | loss scale: 1048576.0 | grad norm: 0.416 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 03:13:11] iteration   136200/  500000 | consumed samples:      8716800 | elapsed time per iteration (ms): 618.4 | learning rate: 9.756423E-05 | global batch size:    64 | lm loss: 3.127909E+00 | loss scale: 1048576.0 | grad norm: 0.411 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 03:14:13] iteration   136300/  500000 | consumed samples:      8723200 | elapsed time per iteration (ms): 618.3 | learning rate: 9.749703E-05 | global batch size:    64 | lm loss: 3.147545E+00 | loss scale: 2097152.0 | grad norm: 0.408 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 03:15:15] iteration   136400/  500000 | consumed samples:      8729600 | elapsed time per iteration (ms): 619.7 | learning rate: 9.742981E-05 | global batch size:    64 | lm loss: 3.140724E+00 | loss scale: 2097152.0 | grad norm: 0.418 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 03:16:17] iteration   136500/  500000 | consumed samples:      8736000 | elapsed time per iteration (ms): 620.8 | learning rate: 9.736257E-05 | global batch size:    64 | lm loss: 3.126266E+00 | loss scale: 2097152.0 | grad norm: 0.407 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 03:17:19] iteration   136600/  500000 | consumed samples:      8742400 | elapsed time per iteration (ms): 618.8 | learning rate: 9.729531E-05 | global batch size:    64 | lm loss: 3.152407E+00 | loss scale: 2097152.0 | grad norm: 0.433 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 03:18:21] iteration   136700/  500000 | consumed samples:      8748800 | elapsed time per iteration (ms): 619.5 | learning rate: 9.722804E-05 | global batch size:    64 | lm loss: 3.131552E+00 | loss scale: 2097152.0 | grad norm: 0.411 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 03:19:23] iteration   136800/  500000 | consumed samples:      8755200 | elapsed time per iteration (ms): 618.1 | learning rate: 9.716075E-05 | global batch size:    64 | lm loss: 3.126630E+00 | loss scale: 2097152.0 | grad norm: 0.405 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 03:20:25] iteration   136900/  500000 | consumed samples:      8761600 | elapsed time per iteration (ms): 618.0 | learning rate: 9.709344E-05 | global batch size:    64 | lm loss: 3.142592E+00 | loss scale: 2097152.0 | grad norm: 0.413 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 03:21:27] iteration   137000/  500000 | consumed samples:      8768000 | elapsed time per iteration (ms): 619.2 | learning rate: 9.702612E-05 | global batch size:    64 | lm loss: 3.130155E+00 | loss scale: 2097152.0 | grad norm: 0.418 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2463.80, 2463.81)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 137000 | lm loss value: 3.732846E+00 | lm loss PPL: 4.179792E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-25 03:22:31] iteration   137100/  500000 | consumed samples:      8774400 | elapsed time per iteration (ms): 618.5 | learning rate: 9.695878E-05 | global batch size:    64 | lm loss: 3.123863E+00 | loss scale: 2097152.0 | grad norm: 0.408 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 03:23:33] iteration   137200/  500000 | consumed samples:      8780800 | elapsed time per iteration (ms): 620.6 | learning rate: 9.689142E-05 | global batch size:    64 | lm loss: 3.129950E+00 | loss scale: 2097152.0 | grad norm: 0.415 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 03:24:35] iteration   137300/  500000 | consumed samples:      8787200 | elapsed time per iteration (ms): 620.5 | learning rate: 9.682607E-05 | global batch size:    64 | lm loss: 3.131854E+00 | loss scale: 1048576.0 | grad norm: 0.405 | number of skipped iterations:   3 | number of nan iterations:   0 |
 [2024-06-25 03:25:37] iteration   137400/  500000 | consumed samples:      8793600 | elapsed time per iteration (ms): 618.5 | learning rate: 9.675868E-05 | global batch size:    64 | lm loss: 3.122838E+00 | loss scale: 1048576.0 | grad norm: 0.407 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 03:26:39] iteration   137500/  500000 | consumed samples:      8800000 | elapsed time per iteration (ms): 617.9 | learning rate: 9.669127E-05 | global batch size:    64 | lm loss: 3.137471E+00 | loss scale: 1048576.0 | grad norm: 0.423 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 03:27:40] iteration   137600/  500000 | consumed samples:      8806400 | elapsed time per iteration (ms): 618.8 | learning rate: 9.662385E-05 | global batch size:    64 | lm loss: 3.133239E+00 | loss scale: 1048576.0 | grad norm: 0.416 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 03:28:42] iteration   137700/  500000 | consumed samples:      8812800 | elapsed time per iteration (ms): 618.9 | learning rate: 9.655641E-05 | global batch size:    64 | lm loss: 3.114623E+00 | loss scale: 1048576.0 | grad norm: 0.404 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 03:29:44] iteration   137800/  500000 | consumed samples:      8819200 | elapsed time per iteration (ms): 620.7 | learning rate: 9.648896E-05 | global batch size:    64 | lm loss: 3.129199E+00 | loss scale: 1048576.0 | grad norm: 0.414 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 03:30:47] iteration   137900/  500000 | consumed samples:      8825600 | elapsed time per iteration (ms): 621.3 | learning rate: 9.642149E-05 | global batch size:    64 | lm loss: 3.121139E+00 | loss scale: 1048576.0 | grad norm: 0.420 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 03:31:48] iteration   138000/  500000 | consumed samples:      8832000 | elapsed time per iteration (ms): 617.7 | learning rate: 9.635400E-05 | global batch size:    64 | lm loss: 3.129140E+00 | loss scale: 1048576.0 | grad norm: 0.410 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2464.67, 2467.40)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 138000 | lm loss value: 3.640342E+00 | lm loss PPL: 3.810487E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-25 03:32:53] iteration   138100/  500000 | consumed samples:      8838400 | elapsed time per iteration (ms): 617.9 | learning rate: 9.628650E-05 | global batch size:    64 | lm loss: 3.134847E+00 | loss scale: 1048576.0 | grad norm: 0.415 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 03:33:54] iteration   138200/  500000 | consumed samples:      8844800 | elapsed time per iteration (ms): 618.9 | learning rate: 9.621898E-05 | global batch size:    64 | lm loss: 3.118431E+00 | loss scale: 1048576.0 | grad norm: 0.416 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 03:34:56] iteration   138300/  500000 | consumed samples:      8851200 | elapsed time per iteration (ms): 619.7 | learning rate: 9.615144E-05 | global batch size:    64 | lm loss: 3.116503E+00 | loss scale: 2097152.0 | grad norm: 0.425 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 03:35:58] iteration   138400/  500000 | consumed samples:      8857600 | elapsed time per iteration (ms): 619.6 | learning rate: 9.608389E-05 | global batch size:    64 | lm loss: 3.118020E+00 | loss scale: 2097152.0 | grad norm: 0.435 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 03:37:00] iteration   138500/  500000 | consumed samples:      8864000 | elapsed time per iteration (ms): 617.9 | learning rate: 9.601632E-05 | global batch size:    64 | lm loss: 3.127824E+00 | loss scale: 2097152.0 | grad norm: 0.415 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 03:38:02] iteration   138600/  500000 | consumed samples:      8870400 | elapsed time per iteration (ms): 619.0 | learning rate: 9.594874E-05 | global batch size:    64 | lm loss: 3.129119E+00 | loss scale: 2097152.0 | grad norm: 0.421 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 03:39:04] iteration   138700/  500000 | consumed samples:      8876800 | elapsed time per iteration (ms): 619.0 | learning rate: 9.588114E-05 | global batch size:    64 | lm loss: 3.132892E+00 | loss scale: 2097152.0 | grad norm: 0.423 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 03:40:06] iteration   138800/  500000 | consumed samples:      8883200 | elapsed time per iteration (ms): 616.5 | learning rate: 9.581488E-05 | global batch size:    64 | lm loss: 3.121820E+00 | loss scale: 1048576.0 | grad norm: 0.405 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-25 03:41:08] iteration   138900/  500000 | consumed samples:      8889600 | elapsed time per iteration (ms): 619.0 | learning rate: 9.574725E-05 | global batch size:    64 | lm loss: 3.128553E+00 | loss scale: 1048576.0 | grad norm: 0.417 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 03:42:10] iteration   139000/  500000 | consumed samples:      8896000 | elapsed time per iteration (ms): 619.8 | learning rate: 9.567961E-05 | global batch size:    64 | lm loss: 3.114640E+00 | loss scale: 1048576.0 | grad norm: 0.415 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2466.08, 2466.46)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 139000 | lm loss value: 3.698995E+00 | lm loss PPL: 4.040667E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-25 03:43:14] iteration   139100/  500000 | consumed samples:      8902400 | elapsed time per iteration (ms): 619.7 | learning rate: 9.561194E-05 | global batch size:    64 | lm loss: 3.116918E+00 | loss scale: 1048576.0 | grad norm: 0.423 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 03:44:16] iteration   139200/  500000 | consumed samples:      8908800 | elapsed time per iteration (ms): 619.3 | learning rate: 9.554427E-05 | global batch size:    64 | lm loss: 3.115297E+00 | loss scale: 1048576.0 | grad norm: 0.419 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 03:45:18] iteration   139300/  500000 | consumed samples:      8915200 | elapsed time per iteration (ms): 619.7 | learning rate: 9.547658E-05 | global batch size:    64 | lm loss: 3.122184E+00 | loss scale: 1048576.0 | grad norm: 0.413 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 03:46:20] iteration   139400/  500000 | consumed samples:      8921600 | elapsed time per iteration (ms): 619.6 | learning rate: 9.540887E-05 | global batch size:    64 | lm loss: 3.117211E+00 | loss scale: 1048576.0 | grad norm: 0.419 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 03:47:22] iteration   139500/  500000 | consumed samples:      8928000 | elapsed time per iteration (ms): 619.2 | learning rate: 9.534115E-05 | global batch size:    64 | lm loss: 3.121058E+00 | loss scale: 1048576.0 | grad norm: 0.430 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 03:48:24] iteration   139600/  500000 | consumed samples:      8934400 | elapsed time per iteration (ms): 619.2 | learning rate: 9.527341E-05 | global batch size:    64 | lm loss: 3.119467E+00 | loss scale: 1048576.0 | grad norm: 0.431 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 03:49:25] iteration   139700/  500000 | consumed samples:      8940800 | elapsed time per iteration (ms): 617.7 | learning rate: 9.520566E-05 | global batch size:    64 | lm loss: 3.131201E+00 | loss scale: 1048576.0 | grad norm: 0.408 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 03:50:27] iteration   139800/  500000 | consumed samples:      8947200 | elapsed time per iteration (ms): 619.2 | learning rate: 9.513790E-05 | global batch size:    64 | lm loss: 3.125096E+00 | loss scale: 2097152.0 | grad norm: 0.410 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 03:51:29] iteration   139900/  500000 | consumed samples:      8953600 | elapsed time per iteration (ms): 619.8 | learning rate: 9.507011E-05 | global batch size:    64 | lm loss: 3.122992E+00 | loss scale: 2097152.0 | grad norm: 0.414 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 03:52:31] iteration   140000/  500000 | consumed samples:      8960000 | elapsed time per iteration (ms): 618.1 | learning rate: 9.500232E-05 | global batch size:    64 | lm loss: 3.125208E+00 | loss scale: 2097152.0 | grad norm: 0.427 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2461.89, 2462.03)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 140000 | lm loss value: 3.716555E+00 | lm loss PPL: 4.112249E+01 | 
--------------------------------------------------------------------------------------------------
saving checkpoint at iteration  140000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-distribution in torch format
  successfully saved checkpoint at iteration  140000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-distribution
(min, max) time across ranks (ms):
    save-checkpoint ................................: (2260.54, 2260.54)
 [2024-06-25 03:53:38] iteration   140100/  500000 | consumed samples:      8966400 | elapsed time per iteration (ms): 617.1 | learning rate: 9.493451E-05 | global batch size:    64 | lm loss: 3.124343E+00 | loss scale: 2097152.0 | grad norm: 0.410 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 03:54:40] iteration   140200/  500000 | consumed samples:      8972800 | elapsed time per iteration (ms): 619.9 | learning rate: 9.486668E-05 | global batch size:    64 | lm loss: 3.102484E+00 | loss scale: 2097152.0 | grad norm: 0.401 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 03:55:42] iteration   140300/  500000 | consumed samples:      8979200 | elapsed time per iteration (ms): 619.9 | learning rate: 9.479884E-05 | global batch size:    64 | lm loss: 3.116300E+00 | loss scale: 2097152.0 | grad norm: 0.409 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 03:56:44] iteration   140400/  500000 | consumed samples:      8985600 | elapsed time per iteration (ms): 620.0 | learning rate: 9.473099E-05 | global batch size:    64 | lm loss: 3.125789E+00 | loss scale: 2097152.0 | grad norm: 0.420 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 03:57:45] iteration   140500/  500000 | consumed samples:      8992000 | elapsed time per iteration (ms): 617.7 | learning rate: 9.466312E-05 | global batch size:    64 | lm loss: 3.123138E+00 | loss scale: 2097152.0 | grad norm: 0.409 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 03:58:47] iteration   140600/  500000 | consumed samples:      8998400 | elapsed time per iteration (ms): 618.1 | learning rate: 9.459523E-05 | global batch size:    64 | lm loss: 3.129325E+00 | loss scale: 2097152.0 | grad norm: 0.424 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 03:59:49] iteration   140700/  500000 | consumed samples:      9004800 | elapsed time per iteration (ms): 619.1 | learning rate: 9.452734E-05 | global batch size:    64 | lm loss: 3.125814E+00 | loss scale: 2097152.0 | grad norm: 0.422 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 04:00:51] iteration   140800/  500000 | consumed samples:      9011200 | elapsed time per iteration (ms): 618.7 | learning rate: 9.446078E-05 | global batch size:    64 | lm loss: 3.116667E+00 | loss scale: 2097152.0 | grad norm: 0.420 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-25 04:01:53] iteration   140900/  500000 | consumed samples:      9017600 | elapsed time per iteration (ms): 618.8 | learning rate: 9.439286E-05 | global batch size:    64 | lm loss: 3.116427E+00 | loss scale: 2097152.0 | grad norm: 0.420 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 04:02:55] iteration   141000/  500000 | consumed samples:      9024000 | elapsed time per iteration (ms): 619.8 | learning rate: 9.432492E-05 | global batch size:    64 | lm loss: 3.123789E+00 | loss scale: 2097152.0 | grad norm: 0.434 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2467.56, 2467.66)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 141000 | lm loss value: 3.706802E+00 | lm loss PPL: 4.072338E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-25 04:03:59] iteration   141100/  500000 | consumed samples:      9030400 | elapsed time per iteration (ms): 617.3 | learning rate: 9.425696E-05 | global batch size:    64 | lm loss: 3.117865E+00 | loss scale: 2097152.0 | grad norm: 0.421 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 04:05:01] iteration   141200/  500000 | consumed samples:      9036800 | elapsed time per iteration (ms): 617.9 | learning rate: 9.418899E-05 | global batch size:    64 | lm loss: 3.119914E+00 | loss scale: 2097152.0 | grad norm: 0.407 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 04:06:03] iteration   141300/  500000 | consumed samples:      9043200 | elapsed time per iteration (ms): 621.2 | learning rate: 9.412169E-05 | global batch size:    64 | lm loss: 3.130706E+00 | loss scale: 1048576.0 | grad norm: 0.414 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-25 04:07:05] iteration   141400/  500000 | consumed samples:      9049600 | elapsed time per iteration (ms): 619.1 | learning rate: 9.405369E-05 | global batch size:    64 | lm loss: 3.123383E+00 | loss scale: 1048576.0 | grad norm: 0.412 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 04:08:07] iteration   141500/  500000 | consumed samples:      9056000 | elapsed time per iteration (ms): 620.3 | learning rate: 9.398568E-05 | global batch size:    64 | lm loss: 3.123539E+00 | loss scale: 1048576.0 | grad norm: 0.423 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 04:09:09] iteration   141600/  500000 | consumed samples:      9062400 | elapsed time per iteration (ms): 620.2 | learning rate: 9.391766E-05 | global batch size:    64 | lm loss: 3.122308E+00 | loss scale: 1048576.0 | grad norm: 0.422 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 04:10:11] iteration   141700/  500000 | consumed samples:      9068800 | elapsed time per iteration (ms): 619.0 | learning rate: 9.384962E-05 | global batch size:    64 | lm loss: 3.118498E+00 | loss scale: 1048576.0 | grad norm: 0.408 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 04:11:13] iteration   141800/  500000 | consumed samples:      9075200 | elapsed time per iteration (ms): 620.0 | learning rate: 9.378157E-05 | global batch size:    64 | lm loss: 3.114687E+00 | loss scale: 1048576.0 | grad norm: 0.418 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 04:12:15] iteration   141900/  500000 | consumed samples:      9081600 | elapsed time per iteration (ms): 619.9 | learning rate: 9.371351E-05 | global batch size:    64 | lm loss: 3.129451E+00 | loss scale: 1048576.0 | grad norm: 0.404 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 04:13:17] iteration   142000/  500000 | consumed samples:      9088000 | elapsed time per iteration (ms): 619.5 | learning rate: 9.364543E-05 | global batch size:    64 | lm loss: 3.112338E+00 | loss scale: 1048576.0 | grad norm: 0.410 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2461.95, 2462.11)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 142000 | lm loss value: 3.703707E+00 | lm loss PPL: 4.059750E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-25 04:14:21] iteration   142100/  500000 | consumed samples:      9094400 | elapsed time per iteration (ms): 618.4 | learning rate: 9.357734E-05 | global batch size:    64 | lm loss: 3.115026E+00 | loss scale: 1048576.0 | grad norm: 0.417 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 04:15:23] iteration   142200/  500000 | consumed samples:      9100800 | elapsed time per iteration (ms): 617.6 | learning rate: 9.350923E-05 | global batch size:    64 | lm loss: 3.104039E+00 | loss scale: 1048576.0 | grad norm: 0.416 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 04:16:25] iteration   142300/  500000 | consumed samples:      9107200 | elapsed time per iteration (ms): 619.6 | learning rate: 9.344180E-05 | global batch size:    64 | lm loss: 3.129370E+00 | loss scale: 2097152.0 | grad norm: 0.408 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-25 04:17:27] iteration   142400/  500000 | consumed samples:      9113600 | elapsed time per iteration (ms): 618.7 | learning rate: 9.337366E-05 | global batch size:    64 | lm loss: 3.116490E+00 | loss scale: 2097152.0 | grad norm: 0.415 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 04:18:29] iteration   142500/  500000 | consumed samples:      9120000 | elapsed time per iteration (ms): 619.6 | learning rate: 9.330552E-05 | global batch size:    64 | lm loss: 3.117574E+00 | loss scale: 2097152.0 | grad norm: 0.428 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 04:19:30] iteration   142600/  500000 | consumed samples:      9126400 | elapsed time per iteration (ms): 618.7 | learning rate: 9.323736E-05 | global batch size:    64 | lm loss: 3.123949E+00 | loss scale: 2097152.0 | grad norm: 0.403 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 04:20:32] iteration   142700/  500000 | consumed samples:      9132800 | elapsed time per iteration (ms): 619.9 | learning rate: 9.316919E-05 | global batch size:    64 | lm loss: 3.103176E+00 | loss scale: 2097152.0 | grad norm: 0.418 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 04:21:34] iteration   142800/  500000 | consumed samples:      9139200 | elapsed time per iteration (ms): 618.6 | learning rate: 9.310101E-05 | global batch size:    64 | lm loss: 3.140983E+00 | loss scale: 2097152.0 | grad norm: 0.415 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 04:22:36] iteration   142900/  500000 | consumed samples:      9145600 | elapsed time per iteration (ms): 620.4 | learning rate: 9.303281E-05 | global batch size:    64 | lm loss: 3.118051E+00 | loss scale: 2097152.0 | grad norm: 0.410 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 04:23:38] iteration   143000/  500000 | consumed samples:      9152000 | elapsed time per iteration (ms): 618.6 | learning rate: 9.296460E-05 | global batch size:    64 | lm loss: 3.122005E+00 | loss scale: 2097152.0 | grad norm: 0.403 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2464.17, 2464.25)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 143000 | lm loss value: 3.678172E+00 | lm loss PPL: 3.957397E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-25 04:24:42] iteration   143100/  500000 | consumed samples:      9158400 | elapsed time per iteration (ms): 618.1 | learning rate: 9.289706E-05 | global batch size:    64 | lm loss: 3.116829E+00 | loss scale: 1048576.0 | grad norm: 0.419 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-25 04:25:44] iteration   143200/  500000 | consumed samples:      9164800 | elapsed time per iteration (ms): 620.9 | learning rate: 9.282883E-05 | global batch size:    64 | lm loss: 3.110700E+00 | loss scale: 1048576.0 | grad norm: 0.427 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 04:26:46] iteration   143300/  500000 | consumed samples:      9171200 | elapsed time per iteration (ms): 619.5 | learning rate: 9.276058E-05 | global batch size:    64 | lm loss: 3.108357E+00 | loss scale: 1048576.0 | grad norm: 0.416 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 04:27:48] iteration   143400/  500000 | consumed samples:      9177600 | elapsed time per iteration (ms): 618.9 | learning rate: 9.269232E-05 | global batch size:    64 | lm loss: 3.118701E+00 | loss scale: 1048576.0 | grad norm: 0.420 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 04:28:50] iteration   143500/  500000 | consumed samples:      9184000 | elapsed time per iteration (ms): 617.2 | learning rate: 9.262405E-05 | global batch size:    64 | lm loss: 3.114087E+00 | loss scale: 1048576.0 | grad norm: 0.419 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 04:29:52] iteration   143600/  500000 | consumed samples:      9190400 | elapsed time per iteration (ms): 620.8 | learning rate: 9.255577E-05 | global batch size:    64 | lm loss: 3.133750E+00 | loss scale: 1048576.0 | grad norm: 0.424 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 04:30:54] iteration   143700/  500000 | consumed samples:      9196800 | elapsed time per iteration (ms): 619.0 | learning rate: 9.248747E-05 | global batch size:    64 | lm loss: 3.113536E+00 | loss scale: 1048576.0 | grad norm: 0.419 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 04:31:56] iteration   143800/  500000 | consumed samples:      9203200 | elapsed time per iteration (ms): 621.0 | learning rate: 9.241916E-05 | global batch size:    64 | lm loss: 3.105284E+00 | loss scale: 1048576.0 | grad norm: 0.398 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 04:32:58] iteration   143900/  500000 | consumed samples:      9209600 | elapsed time per iteration (ms): 619.5 | learning rate: 9.235084E-05 | global batch size:    64 | lm loss: 3.115865E+00 | loss scale: 1048576.0 | grad norm: 0.411 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 04:34:00] iteration   144000/  500000 | consumed samples:      9216000 | elapsed time per iteration (ms): 619.4 | learning rate: 9.228250E-05 | global batch size:    64 | lm loss: 3.116748E+00 | loss scale: 1048576.0 | grad norm: 0.416 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2464.22, 2464.38)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 144000 | lm loss value: 3.661011E+00 | lm loss PPL: 3.890063E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-25 04:35:04] iteration   144100/  500000 | consumed samples:      9222400 | elapsed time per iteration (ms): 620.0 | learning rate: 9.221416E-05 | global batch size:    64 | lm loss: 3.106973E+00 | loss scale: 2097152.0 | grad norm: 0.416 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 04:36:07] iteration   144200/  500000 | consumed samples:      9228800 | elapsed time per iteration (ms): 621.1 | learning rate: 9.214717E-05 | global batch size:    64 | lm loss: 3.109824E+00 | loss scale: 1048576.0 | grad norm: 0.408 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-25 04:37:08] iteration   144300/  500000 | consumed samples:      9235200 | elapsed time per iteration (ms): 618.8 | learning rate: 9.207880E-05 | global batch size:    64 | lm loss: 3.114146E+00 | loss scale: 1048576.0 | grad norm: 0.410 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 04:38:10] iteration   144400/  500000 | consumed samples:      9241600 | elapsed time per iteration (ms): 619.8 | learning rate: 9.201042E-05 | global batch size:    64 | lm loss: 3.103677E+00 | loss scale: 1048576.0 | grad norm: 0.422 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 04:39:12] iteration   144500/  500000 | consumed samples:      9248000 | elapsed time per iteration (ms): 619.2 | learning rate: 9.194203E-05 | global batch size:    64 | lm loss: 3.123326E+00 | loss scale: 1048576.0 | grad norm: 0.410 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 04:40:14] iteration   144600/  500000 | consumed samples:      9254400 | elapsed time per iteration (ms): 618.2 | learning rate: 9.187362E-05 | global batch size:    64 | lm loss: 3.101707E+00 | loss scale: 1048576.0 | grad norm: 0.418 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 04:41:16] iteration   144700/  500000 | consumed samples:      9260800 | elapsed time per iteration (ms): 618.5 | learning rate: 9.180520E-05 | global batch size:    64 | lm loss: 3.117901E+00 | loss scale: 1048576.0 | grad norm: 0.435 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 04:42:18] iteration   144800/  500000 | consumed samples:      9267200 | elapsed time per iteration (ms): 619.8 | learning rate: 9.173678E-05 | global batch size:    64 | lm loss: 3.115889E+00 | loss scale: 1048576.0 | grad norm: 0.429 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 04:43:20] iteration   144900/  500000 | consumed samples:      9273600 | elapsed time per iteration (ms): 619.0 | learning rate: 9.166834E-05 | global batch size:    64 | lm loss: 3.118516E+00 | loss scale: 1048576.0 | grad norm: 0.424 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 04:44:22] iteration   145000/  500000 | consumed samples:      9280000 | elapsed time per iteration (ms): 619.4 | learning rate: 9.159989E-05 | global batch size:    64 | lm loss: 3.110602E+00 | loss scale: 1048576.0 | grad norm: 0.411 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2462.26, 2462.30)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 145000 | lm loss value: 3.665709E+00 | lm loss PPL: 3.908382E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-25 04:45:26] iteration   145100/  500000 | consumed samples:      9286400 | elapsed time per iteration (ms): 618.6 | learning rate: 9.153142E-05 | global batch size:    64 | lm loss: 3.116317E+00 | loss scale: 1048576.0 | grad norm: 0.415 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 04:46:28] iteration   145200/  500000 | consumed samples:      9292800 | elapsed time per iteration (ms): 619.1 | learning rate: 9.146295E-05 | global batch size:    64 | lm loss: 3.104567E+00 | loss scale: 2097152.0 | grad norm: 0.422 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 04:47:30] iteration   145300/  500000 | consumed samples:      9299200 | elapsed time per iteration (ms): 618.8 | learning rate: 9.139446E-05 | global batch size:    64 | lm loss: 3.117126E+00 | loss scale: 2097152.0 | grad norm: 0.429 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 04:48:32] iteration   145400/  500000 | consumed samples:      9305600 | elapsed time per iteration (ms): 619.5 | learning rate: 9.132597E-05 | global batch size:    64 | lm loss: 3.127398E+00 | loss scale: 2097152.0 | grad norm: 0.421 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 04:49:34] iteration   145500/  500000 | consumed samples:      9312000 | elapsed time per iteration (ms): 619.3 | learning rate: 9.125746E-05 | global batch size:    64 | lm loss: 3.109875E+00 | loss scale: 2097152.0 | grad norm: 0.416 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 04:50:36] iteration   145600/  500000 | consumed samples:      9318400 | elapsed time per iteration (ms): 618.6 | learning rate: 9.118894E-05 | global batch size:    64 | lm loss: 3.119557E+00 | loss scale: 2097152.0 | grad norm: 0.418 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 04:51:38] iteration   145700/  500000 | consumed samples:      9324800 | elapsed time per iteration (ms): 619.2 | learning rate: 9.112041E-05 | global batch size:    64 | lm loss: 3.108429E+00 | loss scale: 2097152.0 | grad norm: 0.420 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 04:52:39] iteration   145800/  500000 | consumed samples:      9331200 | elapsed time per iteration (ms): 616.6 | learning rate: 9.105187E-05 | global batch size:    64 | lm loss: 3.105612E+00 | loss scale: 2097152.0 | grad norm: 0.422 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 04:53:41] iteration   145900/  500000 | consumed samples:      9337600 | elapsed time per iteration (ms): 617.7 | learning rate: 9.098332E-05 | global batch size:    64 | lm loss: 3.117452E+00 | loss scale: 2097152.0 | grad norm: 0.417 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 04:54:43] iteration   146000/  500000 | consumed samples:      9344000 | elapsed time per iteration (ms): 617.9 | learning rate: 9.091544E-05 | global batch size:    64 | lm loss: 3.116659E+00 | loss scale: 2097152.0 | grad norm: 0.426 | number of skipped iterations:   1 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2463.71, 2463.73)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 146000 | lm loss value: 3.693546E+00 | lm loss PPL: 4.018708E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-25 04:55:47] iteration   146100/  500000 | consumed samples:      9350400 | elapsed time per iteration (ms): 620.4 | learning rate: 9.084687E-05 | global batch size:    64 | lm loss: 3.114353E+00 | loss scale: 2097152.0 | grad norm: 0.414 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 04:56:49] iteration   146200/  500000 | consumed samples:      9356800 | elapsed time per iteration (ms): 619.8 | learning rate: 9.077829E-05 | global batch size:    64 | lm loss: 3.106324E+00 | loss scale: 2097152.0 | grad norm: 0.412 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 04:57:51] iteration   146300/  500000 | consumed samples:      9363200 | elapsed time per iteration (ms): 619.8 | learning rate: 9.070969E-05 | global batch size:    64 | lm loss: 3.116727E+00 | loss scale: 2097152.0 | grad norm: 0.417 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 04:58:53] iteration   146400/  500000 | consumed samples:      9369600 | elapsed time per iteration (ms): 619.3 | learning rate: 9.064109E-05 | global batch size:    64 | lm loss: 3.108584E+00 | loss scale: 2097152.0 | grad norm: 0.418 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 04:59:55] iteration   146500/  500000 | consumed samples:      9376000 | elapsed time per iteration (ms): 618.6 | learning rate: 9.057248E-05 | global batch size:    64 | lm loss: 3.112578E+00 | loss scale: 2097152.0 | grad norm: 0.436 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 05:00:57] iteration   146600/  500000 | consumed samples:      9382400 | elapsed time per iteration (ms): 618.2 | learning rate: 9.050385E-05 | global batch size:    64 | lm loss: 3.111754E+00 | loss scale: 2097152.0 | grad norm: 0.417 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 05:01:59] iteration   146700/  500000 | consumed samples:      9388800 | elapsed time per iteration (ms): 620.9 | learning rate: 9.043521E-05 | global batch size:    64 | lm loss: 3.121235E+00 | loss scale: 2097152.0 | grad norm: 0.430 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 05:03:01] iteration   146800/  500000 | consumed samples:      9395200 | elapsed time per iteration (ms): 618.7 | learning rate: 9.036657E-05 | global batch size:    64 | lm loss: 3.108586E+00 | loss scale: 2097152.0 | grad norm: 0.410 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 05:04:03] iteration   146900/  500000 | consumed samples:      9401600 | elapsed time per iteration (ms): 617.3 | learning rate: 9.029791E-05 | global batch size:    64 | lm loss: 3.114633E+00 | loss scale: 2097152.0 | grad norm: 0.425 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 05:05:05] iteration   147000/  500000 | consumed samples:      9408000 | elapsed time per iteration (ms): 619.4 | learning rate: 9.023062E-05 | global batch size:    64 | lm loss: 3.114350E+00 | loss scale: 2097152.0 | grad norm: 0.428 | number of skipped iterations:   2 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2462.66, 2462.77)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 147000 | lm loss value: 3.663052E+00 | lm loss PPL: 3.898013E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-25 05:06:09] iteration   147100/  500000 | consumed samples:      9414400 | elapsed time per iteration (ms): 618.9 | learning rate: 9.016194E-05 | global batch size:    64 | lm loss: 3.103592E+00 | loss scale: 2097152.0 | grad norm: 0.415 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 05:07:11] iteration   147200/  500000 | consumed samples:      9420800 | elapsed time per iteration (ms): 620.1 | learning rate: 9.009326E-05 | global batch size:    64 | lm loss: 3.114037E+00 | loss scale: 2097152.0 | grad norm: 0.416 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 05:08:13] iteration   147300/  500000 | consumed samples:      9427200 | elapsed time per iteration (ms): 619.6 | learning rate: 9.002456E-05 | global batch size:    64 | lm loss: 3.108555E+00 | loss scale: 2097152.0 | grad norm: 0.415 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 05:09:15] iteration   147400/  500000 | consumed samples:      9433600 | elapsed time per iteration (ms): 619.3 | learning rate: 8.995585E-05 | global batch size:    64 | lm loss: 3.114181E+00 | loss scale: 2097152.0 | grad norm: 0.444 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 05:10:17] iteration   147500/  500000 | consumed samples:      9440000 | elapsed time per iteration (ms): 618.7 | learning rate: 8.988714E-05 | global batch size:    64 | lm loss: 3.123580E+00 | loss scale: 2097152.0 | grad norm: 0.422 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 05:11:18] iteration   147600/  500000 | consumed samples:      9446400 | elapsed time per iteration (ms): 617.6 | learning rate: 8.981910E-05 | global batch size:    64 | lm loss: 3.115282E+00 | loss scale: 1048576.0 | grad norm: 0.415 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-25 05:12:20] iteration   147700/  500000 | consumed samples:      9452800 | elapsed time per iteration (ms): 618.5 | learning rate: 8.975037E-05 | global batch size:    64 | lm loss: 3.089532E+00 | loss scale: 1048576.0 | grad norm: 0.426 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 05:13:22] iteration   147800/  500000 | consumed samples:      9459200 | elapsed time per iteration (ms): 619.3 | learning rate: 8.968162E-05 | global batch size:    64 | lm loss: 3.100926E+00 | loss scale: 1048576.0 | grad norm: 0.413 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 05:14:24] iteration   147900/  500000 | consumed samples:      9465600 | elapsed time per iteration (ms): 619.7 | learning rate: 8.961287E-05 | global batch size:    64 | lm loss: 3.107018E+00 | loss scale: 1048576.0 | grad norm: 0.412 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 05:15:26] iteration   148000/  500000 | consumed samples:      9472000 | elapsed time per iteration (ms): 619.3 | learning rate: 8.954410E-05 | global batch size:    64 | lm loss: 3.118991E+00 | loss scale: 1048576.0 | grad norm: 0.416 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2464.42, 2464.59)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 148000 | lm loss value: 3.663728E+00 | lm loss PPL: 3.900647E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-25 05:16:31] iteration   148100/  500000 | consumed samples:      9478400 | elapsed time per iteration (ms): 619.5 | learning rate: 8.947533E-05 | global batch size:    64 | lm loss: 3.098643E+00 | loss scale: 1048576.0 | grad norm: 0.418 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 05:17:32] iteration   148200/  500000 | consumed samples:      9484800 | elapsed time per iteration (ms): 618.9 | learning rate: 8.940655E-05 | global batch size:    64 | lm loss: 3.112089E+00 | loss scale: 1048576.0 | grad norm: 0.409 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 05:18:34] iteration   148300/  500000 | consumed samples:      9491200 | elapsed time per iteration (ms): 617.7 | learning rate: 8.933776E-05 | global batch size:    64 | lm loss: 3.117656E+00 | loss scale: 1048576.0 | grad norm: 0.438 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 05:19:36] iteration   148400/  500000 | consumed samples:      9497600 | elapsed time per iteration (ms): 619.4 | learning rate: 8.926896E-05 | global batch size:    64 | lm loss: 3.118647E+00 | loss scale: 1048576.0 | grad norm: 0.420 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 05:20:38] iteration   148500/  500000 | consumed samples:      9504000 | elapsed time per iteration (ms): 620.3 | learning rate: 8.920015E-05 | global batch size:    64 | lm loss: 3.110964E+00 | loss scale: 1048576.0 | grad norm: 0.431 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 05:21:40] iteration   148600/  500000 | consumed samples:      9510400 | elapsed time per iteration (ms): 619.4 | learning rate: 8.913133E-05 | global batch size:    64 | lm loss: 3.114663E+00 | loss scale: 2097152.0 | grad norm: 0.409 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 05:22:42] iteration   148700/  500000 | consumed samples:      9516800 | elapsed time per iteration (ms): 619.2 | learning rate: 8.906319E-05 | global batch size:    64 | lm loss: 3.109897E+00 | loss scale: 2097152.0 | grad norm: 0.424 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-25 05:23:44] iteration   148800/  500000 | consumed samples:      9523200 | elapsed time per iteration (ms): 618.1 | learning rate: 8.899435E-05 | global batch size:    64 | lm loss: 3.110437E+00 | loss scale: 2097152.0 | grad norm: 0.418 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 05:24:46] iteration   148900/  500000 | consumed samples:      9529600 | elapsed time per iteration (ms): 618.4 | learning rate: 8.892551E-05 | global batch size:    64 | lm loss: 3.116915E+00 | loss scale: 2097152.0 | grad norm: 0.433 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 05:25:48] iteration   149000/  500000 | consumed samples:      9536000 | elapsed time per iteration (ms): 619.3 | learning rate: 8.885665E-05 | global batch size:    64 | lm loss: 3.118583E+00 | loss scale: 2097152.0 | grad norm: 0.412 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2463.01, 2463.14)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 149000 | lm loss value: 3.738072E+00 | lm loss PPL: 4.201691E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-25 05:26:52] iteration   149100/  500000 | consumed samples:      9542400 | elapsed time per iteration (ms): 620.3 | learning rate: 8.878779E-05 | global batch size:    64 | lm loss: 3.116307E+00 | loss scale: 2097152.0 | grad norm: 0.414 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 05:27:54] iteration   149200/  500000 | consumed samples:      9548800 | elapsed time per iteration (ms): 619.7 | learning rate: 8.871961E-05 | global batch size:    64 | lm loss: 3.112795E+00 | loss scale: 1048576.0 | grad norm: 0.428 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-25 05:28:56] iteration   149300/  500000 | consumed samples:      9555200 | elapsed time per iteration (ms): 621.0 | learning rate: 8.865073E-05 | global batch size:    64 | lm loss: 3.108053E+00 | loss scale: 1048576.0 | grad norm: 0.425 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 05:29:58] iteration   149400/  500000 | consumed samples:      9561600 | elapsed time per iteration (ms): 620.6 | learning rate: 8.858184E-05 | global batch size:    64 | lm loss: 3.104408E+00 | loss scale: 1048576.0 | grad norm: 0.414 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 05:31:00] iteration   149500/  500000 | consumed samples:      9568000 | elapsed time per iteration (ms): 619.6 | learning rate: 8.851294E-05 | global batch size:    64 | lm loss: 3.109619E+00 | loss scale: 1048576.0 | grad norm: 0.427 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 05:32:02] iteration   149600/  500000 | consumed samples:      9574400 | elapsed time per iteration (ms): 620.1 | learning rate: 8.844403E-05 | global batch size:    64 | lm loss: 3.097519E+00 | loss scale: 1048576.0 | grad norm: 0.415 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 05:33:04] iteration   149700/  500000 | consumed samples:      9580800 | elapsed time per iteration (ms): 619.6 | learning rate: 8.837512E-05 | global batch size:    64 | lm loss: 3.100816E+00 | loss scale: 1048576.0 | grad norm: 0.431 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 05:34:06] iteration   149800/  500000 | consumed samples:      9587200 | elapsed time per iteration (ms): 621.3 | learning rate: 8.830620E-05 | global batch size:    64 | lm loss: 3.106300E+00 | loss scale: 1048576.0 | grad norm: 0.398 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 05:35:08] iteration   149900/  500000 | consumed samples:      9593600 | elapsed time per iteration (ms): 618.8 | learning rate: 8.823727E-05 | global batch size:    64 | lm loss: 3.116586E+00 | loss scale: 1048576.0 | grad norm: 0.410 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 05:36:10] iteration   150000/  500000 | consumed samples:      9600000 | elapsed time per iteration (ms): 618.0 | learning rate: 8.816833E-05 | global batch size:    64 | lm loss: 3.110833E+00 | loss scale: 1048576.0 | grad norm: 0.415 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2462.74, 2462.86)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 150000 | lm loss value: 3.705197E+00 | lm loss PPL: 4.065805E+01 | 
--------------------------------------------------------------------------------------------------
saving checkpoint at iteration  150000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-distribution in torch format
  successfully saved checkpoint at iteration  150000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-distribution
(min, max) time across ranks (ms):
    save-checkpoint ................................: (2274.14, 2274.16)
 [2024-06-25 05:37:17] iteration   150100/  500000 | consumed samples:      9606400 | elapsed time per iteration (ms): 619.6 | learning rate: 8.809938E-05 | global batch size:    64 | lm loss: 3.111067E+00 | loss scale: 1048576.0 | grad norm: 0.408 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 05:38:18] iteration   150200/  500000 | consumed samples:      9612800 | elapsed time per iteration (ms): 617.7 | learning rate: 8.803043E-05 | global batch size:    64 | lm loss: 3.094182E+00 | loss scale: 2097152.0 | grad norm: 0.408 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 05:39:20] iteration   150300/  500000 | consumed samples:      9619200 | elapsed time per iteration (ms): 618.6 | learning rate: 8.796147E-05 | global batch size:    64 | lm loss: 3.115141E+00 | loss scale: 2097152.0 | grad norm: 0.422 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 05:40:22] iteration   150400/  500000 | consumed samples:      9625600 | elapsed time per iteration (ms): 618.8 | learning rate: 8.789250E-05 | global batch size:    64 | lm loss: 3.105577E+00 | loss scale: 2097152.0 | grad norm: 0.412 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 05:41:24] iteration   150500/  500000 | consumed samples:      9632000 | elapsed time per iteration (ms): 619.9 | learning rate: 8.782352E-05 | global batch size:    64 | lm loss: 3.110305E+00 | loss scale: 2097152.0 | grad norm: 0.431 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 05:42:26] iteration   150600/  500000 | consumed samples:      9638400 | elapsed time per iteration (ms): 617.7 | learning rate: 8.775453E-05 | global batch size:    64 | lm loss: 3.109839E+00 | loss scale: 2097152.0 | grad norm: 0.418 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 05:43:28] iteration   150700/  500000 | consumed samples:      9644800 | elapsed time per iteration (ms): 622.4 | learning rate: 8.768623E-05 | global batch size:    64 | lm loss: 3.098271E+00 | loss scale: 2097152.0 | grad norm: 0.409 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-25 05:44:30] iteration   150800/  500000 | consumed samples:      9651200 | elapsed time per iteration (ms): 620.9 | learning rate: 8.761723E-05 | global batch size:    64 | lm loss: 3.103501E+00 | loss scale: 2097152.0 | grad norm: 0.413 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 05:45:32] iteration   150900/  500000 | consumed samples:      9657600 | elapsed time per iteration (ms): 619.5 | learning rate: 8.754822E-05 | global batch size:    64 | lm loss: 3.099044E+00 | loss scale: 2097152.0 | grad norm: 0.409 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 05:46:34] iteration   151000/  500000 | consumed samples:      9664000 | elapsed time per iteration (ms): 619.7 | learning rate: 8.747990E-05 | global batch size:    64 | lm loss: 3.109382E+00 | loss scale: 1048576.0 | grad norm: 0.410 | number of skipped iterations:   1 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2464.62, 2464.70)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 151000 | lm loss value: 3.648238E+00 | lm loss PPL: 3.840693E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-25 05:47:39] iteration   151100/  500000 | consumed samples:      9670400 | elapsed time per iteration (ms): 620.0 | learning rate: 8.741088E-05 | global batch size:    64 | lm loss: 3.107896E+00 | loss scale: 1048576.0 | grad norm: 0.426 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 05:48:41] iteration   151200/  500000 | consumed samples:      9676800 | elapsed time per iteration (ms): 619.0 | learning rate: 8.734185E-05 | global batch size:    64 | lm loss: 3.093392E+00 | loss scale: 1048576.0 | grad norm: 0.428 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 05:49:43] iteration   151300/  500000 | consumed samples:      9683200 | elapsed time per iteration (ms): 620.3 | learning rate: 8.727281E-05 | global batch size:    64 | lm loss: 3.106718E+00 | loss scale: 1048576.0 | grad norm: 0.421 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 05:50:45] iteration   151400/  500000 | consumed samples:      9689600 | elapsed time per iteration (ms): 620.8 | learning rate: 8.720376E-05 | global batch size:    64 | lm loss: 3.109207E+00 | loss scale: 1048576.0 | grad norm: 0.438 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 05:51:47] iteration   151500/  500000 | consumed samples:      9696000 | elapsed time per iteration (ms): 619.8 | learning rate: 8.713471E-05 | global batch size:    64 | lm loss: 3.118546E+00 | loss scale: 1048576.0 | grad norm: 0.412 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 05:52:48] iteration   151600/  500000 | consumed samples:      9702400 | elapsed time per iteration (ms): 617.7 | learning rate: 8.706565E-05 | global batch size:    64 | lm loss: 3.115748E+00 | loss scale: 1048576.0 | grad norm: 0.429 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 05:53:50] iteration   151700/  500000 | consumed samples:      9708800 | elapsed time per iteration (ms): 617.7 | learning rate: 8.699659E-05 | global batch size:    64 | lm loss: 3.101310E+00 | loss scale: 1048576.0 | grad norm: 0.414 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 05:54:52] iteration   151800/  500000 | consumed samples:      9715200 | elapsed time per iteration (ms): 618.9 | learning rate: 8.692752E-05 | global batch size:    64 | lm loss: 3.090093E+00 | loss scale: 1048576.0 | grad norm: 0.424 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 05:55:54] iteration   151900/  500000 | consumed samples:      9721600 | elapsed time per iteration (ms): 619.1 | learning rate: 8.685844E-05 | global batch size:    64 | lm loss: 3.115107E+00 | loss scale: 1048576.0 | grad norm: 0.427 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 05:56:56] iteration   152000/  500000 | consumed samples:      9728000 | elapsed time per iteration (ms): 619.9 | learning rate: 8.679004E-05 | global batch size:    64 | lm loss: 3.108190E+00 | loss scale: 2097152.0 | grad norm: 0.425 | number of skipped iterations:   1 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2461.46, 2461.62)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 152000 | lm loss value: 3.763829E+00 | lm loss PPL: 4.311319E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-25 05:58:00] iteration   152100/  500000 | consumed samples:      9734400 | elapsed time per iteration (ms): 619.1 | learning rate: 8.672164E-05 | global batch size:    64 | lm loss: 3.111446E+00 | loss scale: 1048576.0 | grad norm: 0.417 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-25 05:59:02] iteration   152200/  500000 | consumed samples:      9740800 | elapsed time per iteration (ms): 619.1 | learning rate: 8.665254E-05 | global batch size:    64 | lm loss: 3.094054E+00 | loss scale: 1048576.0 | grad norm: 0.429 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 06:00:04] iteration   152300/  500000 | consumed samples:      9747200 | elapsed time per iteration (ms): 618.4 | learning rate: 8.658344E-05 | global batch size:    64 | lm loss: 3.117559E+00 | loss scale: 1048576.0 | grad norm: 0.416 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 06:01:06] iteration   152400/  500000 | consumed samples:      9753600 | elapsed time per iteration (ms): 619.2 | learning rate: 8.651432E-05 | global batch size:    64 | lm loss: 3.102095E+00 | loss scale: 1048576.0 | grad norm: 0.429 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 06:02:08] iteration   152500/  500000 | consumed samples:      9760000 | elapsed time per iteration (ms): 619.3 | learning rate: 8.644520E-05 | global batch size:    64 | lm loss: 3.104257E+00 | loss scale: 1048576.0 | grad norm: 0.415 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 06:03:10] iteration   152600/  500000 | consumed samples:      9766400 | elapsed time per iteration (ms): 619.3 | learning rate: 8.637608E-05 | global batch size:    64 | lm loss: 3.099580E+00 | loss scale: 1048576.0 | grad norm: 0.419 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 06:04:12] iteration   152700/  500000 | consumed samples:      9772800 | elapsed time per iteration (ms): 619.9 | learning rate: 8.630695E-05 | global batch size:    64 | lm loss: 3.093459E+00 | loss scale: 1048576.0 | grad norm: 0.417 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 06:05:14] iteration   152800/  500000 | consumed samples:      9779200 | elapsed time per iteration (ms): 618.9 | learning rate: 8.623781E-05 | global batch size:    64 | lm loss: 3.097084E+00 | loss scale: 1048576.0 | grad norm: 0.416 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 06:06:16] iteration   152900/  500000 | consumed samples:      9785600 | elapsed time per iteration (ms): 619.0 | learning rate: 8.616867E-05 | global batch size:    64 | lm loss: 3.086386E+00 | loss scale: 1048576.0 | grad norm: 0.429 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 06:07:18] iteration   153000/  500000 | consumed samples:      9792000 | elapsed time per iteration (ms): 618.3 | learning rate: 8.609952E-05 | global batch size:    64 | lm loss: 3.094972E+00 | loss scale: 1048576.0 | grad norm: 0.412 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2462.83, 2462.90)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 153000 | lm loss value: 3.701084E+00 | lm loss PPL: 4.049118E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-25 06:08:22] iteration   153100/  500000 | consumed samples:      9798400 | elapsed time per iteration (ms): 619.1 | learning rate: 8.603036E-05 | global batch size:    64 | lm loss: 3.089373E+00 | loss scale: 2097152.0 | grad norm: 0.426 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 06:09:24] iteration   153200/  500000 | consumed samples:      9804800 | elapsed time per iteration (ms): 621.5 | learning rate: 8.596120E-05 | global batch size:    64 | lm loss: 3.105814E+00 | loss scale: 2097152.0 | grad norm: 0.420 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 06:10:26] iteration   153300/  500000 | consumed samples:      9811200 | elapsed time per iteration (ms): 619.3 | learning rate: 8.589342E-05 | global batch size:    64 | lm loss: 3.113353E+00 | loss scale: 1048576.0 | grad norm: 0.427 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-25 06:11:28] iteration   153400/  500000 | consumed samples:      9817600 | elapsed time per iteration (ms): 620.0 | learning rate: 8.582425E-05 | global batch size:    64 | lm loss: 3.104279E+00 | loss scale: 1048576.0 | grad norm: 0.434 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 06:12:30] iteration   153500/  500000 | consumed samples:      9824000 | elapsed time per iteration (ms): 621.2 | learning rate: 8.575507E-05 | global batch size:    64 | lm loss: 3.099644E+00 | loss scale: 1048576.0 | grad norm: 0.405 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 06:13:32] iteration   153600/  500000 | consumed samples:      9830400 | elapsed time per iteration (ms): 618.8 | learning rate: 8.568588E-05 | global batch size:    64 | lm loss: 3.104088E+00 | loss scale: 1048576.0 | grad norm: 0.413 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 06:14:34] iteration   153700/  500000 | consumed samples:      9836800 | elapsed time per iteration (ms): 620.7 | learning rate: 8.561669E-05 | global batch size:    64 | lm loss: 3.112261E+00 | loss scale: 1048576.0 | grad norm: 0.414 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 06:15:36] iteration   153800/  500000 | consumed samples:      9843200 | elapsed time per iteration (ms): 618.8 | learning rate: 8.554750E-05 | global batch size:    64 | lm loss: 3.099213E+00 | loss scale: 1048576.0 | grad norm: 0.428 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 06:16:38] iteration   153900/  500000 | consumed samples:      9849600 | elapsed time per iteration (ms): 619.4 | learning rate: 8.547830E-05 | global batch size:    64 | lm loss: 3.098737E+00 | loss scale: 1048576.0 | grad norm: 0.403 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 06:17:40] iteration   154000/  500000 | consumed samples:      9856000 | elapsed time per iteration (ms): 618.4 | learning rate: 8.540909E-05 | global batch size:    64 | lm loss: 3.100598E+00 | loss scale: 1048576.0 | grad norm: 0.421 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2465.27, 2465.34)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 154000 | lm loss value: 3.664511E+00 | lm loss PPL: 3.903705E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-25 06:18:44] iteration   154100/  500000 | consumed samples:      9862400 | elapsed time per iteration (ms): 620.3 | learning rate: 8.533988E-05 | global batch size:    64 | lm loss: 3.094211E+00 | loss scale: 1048576.0 | grad norm: 0.425 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 06:19:46] iteration   154200/  500000 | consumed samples:      9868800 | elapsed time per iteration (ms): 618.4 | learning rate: 8.527066E-05 | global batch size:    64 | lm loss: 3.092725E+00 | loss scale: 1048576.0 | grad norm: 0.439 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 06:20:48] iteration   154300/  500000 | consumed samples:      9875200 | elapsed time per iteration (ms): 618.7 | learning rate: 8.520144E-05 | global batch size:    64 | lm loss: 3.103525E+00 | loss scale: 2097152.0 | grad norm: 0.423 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 06:21:50] iteration   154400/  500000 | consumed samples:      9881600 | elapsed time per iteration (ms): 620.9 | learning rate: 8.513221E-05 | global batch size:    64 | lm loss: 3.103792E+00 | loss scale: 2097152.0 | grad norm: 0.419 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 06:22:52] iteration   154500/  500000 | consumed samples:      9888000 | elapsed time per iteration (ms): 619.7 | learning rate: 8.506298E-05 | global batch size:    64 | lm loss: 3.102491E+00 | loss scale: 2097152.0 | grad norm: 0.419 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 06:23:54] iteration   154600/  500000 | consumed samples:      9894400 | elapsed time per iteration (ms): 620.0 | learning rate: 8.499444E-05 | global batch size:    64 | lm loss: 3.092324E+00 | loss scale: 2097152.0 | grad norm: 0.423 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-25 06:24:56] iteration   154700/  500000 | consumed samples:      9900800 | elapsed time per iteration (ms): 618.8 | learning rate: 8.492519E-05 | global batch size:    64 | lm loss: 3.106169E+00 | loss scale: 2097152.0 | grad norm: 0.417 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 06:25:58] iteration   154800/  500000 | consumed samples:      9907200 | elapsed time per iteration (ms): 619.4 | learning rate: 8.485595E-05 | global batch size:    64 | lm loss: 3.091552E+00 | loss scale: 2097152.0 | grad norm: 0.433 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 06:27:00] iteration   154900/  500000 | consumed samples:      9913600 | elapsed time per iteration (ms): 618.1 | learning rate: 8.478669E-05 | global batch size:    64 | lm loss: 3.103565E+00 | loss scale: 2097152.0 | grad norm: 0.443 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 06:28:01] iteration   155000/  500000 | consumed samples:      9920000 | elapsed time per iteration (ms): 617.1 | learning rate: 8.471744E-05 | global batch size:    64 | lm loss: 3.095242E+00 | loss scale: 2097152.0 | grad norm: 0.410 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2465.83, 2465.89)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 155000 | lm loss value: 3.679751E+00 | lm loss PPL: 3.963652E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-25 06:29:05] iteration   155100/  500000 | consumed samples:      9926400 | elapsed time per iteration (ms): 616.9 | learning rate: 8.464818E-05 | global batch size:    64 | lm loss: 3.105015E+00 | loss scale: 2097152.0 | grad norm: 0.412 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 06:30:07] iteration   155200/  500000 | consumed samples:      9932800 | elapsed time per iteration (ms): 619.6 | learning rate: 8.457960E-05 | global batch size:    64 | lm loss: 3.095165E+00 | loss scale: 1048576.0 | grad norm: 0.440 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-25 06:31:10] iteration   155300/  500000 | consumed samples:      9939200 | elapsed time per iteration (ms): 620.8 | learning rate: 8.451033E-05 | global batch size:    64 | lm loss: 3.103975E+00 | loss scale: 1048576.0 | grad norm: 0.438 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 06:32:11] iteration   155400/  500000 | consumed samples:      9945600 | elapsed time per iteration (ms): 619.7 | learning rate: 8.444106E-05 | global batch size:    64 | lm loss: 3.105108E+00 | loss scale: 1048576.0 | grad norm: 0.425 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 06:33:13] iteration   155500/  500000 | consumed samples:      9952000 | elapsed time per iteration (ms): 618.5 | learning rate: 8.437178E-05 | global batch size:    64 | lm loss: 3.099001E+00 | loss scale: 1048576.0 | grad norm: 0.427 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 06:34:15] iteration   155600/  500000 | consumed samples:      9958400 | elapsed time per iteration (ms): 617.5 | learning rate: 8.430250E-05 | global batch size:    64 | lm loss: 3.115629E+00 | loss scale: 1048576.0 | grad norm: 0.413 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 06:35:17] iteration   155700/  500000 | consumed samples:      9964800 | elapsed time per iteration (ms): 618.7 | learning rate: 8.423321E-05 | global batch size:    64 | lm loss: 3.110148E+00 | loss scale: 1048576.0 | grad norm: 0.418 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 06:36:19] iteration   155800/  500000 | consumed samples:      9971200 | elapsed time per iteration (ms): 618.8 | learning rate: 8.416392E-05 | global batch size:    64 | lm loss: 3.095843E+00 | loss scale: 1048576.0 | grad norm: 0.407 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 06:37:21] iteration   155900/  500000 | consumed samples:      9977600 | elapsed time per iteration (ms): 619.7 | learning rate: 8.409462E-05 | global batch size:    64 | lm loss: 3.104715E+00 | loss scale: 1048576.0 | grad norm: 0.414 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 06:38:23] iteration   156000/  500000 | consumed samples:      9984000 | elapsed time per iteration (ms): 619.8 | learning rate: 8.402532E-05 | global batch size:    64 | lm loss: 3.098188E+00 | loss scale: 1048576.0 | grad norm: 0.433 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2462.43, 2462.50)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 156000 | lm loss value: 3.687577E+00 | lm loss PPL: 3.994793E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-25 06:39:27] iteration   156100/  500000 | consumed samples:      9990400 | elapsed time per iteration (ms): 619.7 | learning rate: 8.395602E-05 | global batch size:    64 | lm loss: 3.112724E+00 | loss scale: 1048576.0 | grad norm: 0.415 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 06:40:29] iteration   156200/  500000 | consumed samples:      9996800 | elapsed time per iteration (ms): 618.4 | learning rate: 8.388671E-05 | global batch size:    64 | lm loss: 3.095382E+00 | loss scale: 2097152.0 | grad norm: 0.426 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 06:41:31] iteration   156300/  500000 | consumed samples:     10003200 | elapsed time per iteration (ms): 619.8 | learning rate: 8.381809E-05 | global batch size:    64 | lm loss: 3.107170E+00 | loss scale: 2097152.0 | grad norm: 0.435 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-25 06:42:33] iteration   156400/  500000 | consumed samples:     10009600 | elapsed time per iteration (ms): 619.7 | learning rate: 8.374947E-05 | global batch size:    64 | lm loss: 3.102039E+00 | loss scale: 1048576.0 | grad norm: 0.409 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-25 06:43:35] iteration   156500/  500000 | consumed samples:     10016000 | elapsed time per iteration (ms): 618.4 | learning rate: 8.368015E-05 | global batch size:    64 | lm loss: 3.091145E+00 | loss scale: 1048576.0 | grad norm: 0.423 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 06:44:37] iteration   156600/  500000 | consumed samples:     10022400 | elapsed time per iteration (ms): 619.3 | learning rate: 8.361083E-05 | global batch size:    64 | lm loss: 3.093410E+00 | loss scale: 1048576.0 | grad norm: 0.415 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 06:45:39] iteration   156700/  500000 | consumed samples:     10028800 | elapsed time per iteration (ms): 620.4 | learning rate: 8.354151E-05 | global batch size:    64 | lm loss: 3.111070E+00 | loss scale: 1048576.0 | grad norm: 0.425 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 06:46:41] iteration   156800/  500000 | consumed samples:     10035200 | elapsed time per iteration (ms): 621.5 | learning rate: 8.347218E-05 | global batch size:    64 | lm loss: 3.094212E+00 | loss scale: 1048576.0 | grad norm: 0.427 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 06:47:43] iteration   156900/  500000 | consumed samples:     10041600 | elapsed time per iteration (ms): 619.1 | learning rate: 8.340284E-05 | global batch size:    64 | lm loss: 3.082635E+00 | loss scale: 1048576.0 | grad norm: 0.424 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 06:48:45] iteration   157000/  500000 | consumed samples:     10048000 | elapsed time per iteration (ms): 618.4 | learning rate: 8.333351E-05 | global batch size:    64 | lm loss: 3.094488E+00 | loss scale: 1048576.0 | grad norm: 0.423 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2467.52, 2467.52)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 157000 | lm loss value: 3.693348E+00 | lm loss PPL: 4.017914E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-25 06:49:49] iteration   157100/  500000 | consumed samples:     10054400 | elapsed time per iteration (ms): 618.7 | learning rate: 8.326417E-05 | global batch size:    64 | lm loss: 3.089850E+00 | loss scale: 1048576.0 | grad norm: 0.438 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 06:50:51] iteration   157200/  500000 | consumed samples:     10060800 | elapsed time per iteration (ms): 619.1 | learning rate: 8.319483E-05 | global batch size:    64 | lm loss: 3.092198E+00 | loss scale: 1048576.0 | grad norm: 0.423 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 06:51:53] iteration   157300/  500000 | consumed samples:     10067200 | elapsed time per iteration (ms): 618.9 | learning rate: 8.312548E-05 | global batch size:    64 | lm loss: 3.101976E+00 | loss scale: 1048576.0 | grad norm: 0.424 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 06:52:55] iteration   157400/  500000 | consumed samples:     10073600 | elapsed time per iteration (ms): 620.1 | learning rate: 8.305613E-05 | global batch size:    64 | lm loss: 3.093153E+00 | loss scale: 2097152.0 | grad norm: 0.442 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 06:53:57] iteration   157500/  500000 | consumed samples:     10080000 | elapsed time per iteration (ms): 619.2 | learning rate: 8.298678E-05 | global batch size:    64 | lm loss: 3.090114E+00 | loss scale: 2097152.0 | grad norm: 0.424 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 06:54:59] iteration   157600/  500000 | consumed samples:     10086400 | elapsed time per iteration (ms): 618.0 | learning rate: 8.291742E-05 | global batch size:    64 | lm loss: 3.090772E+00 | loss scale: 2097152.0 | grad norm: 0.430 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 06:56:01] iteration   157700/  500000 | consumed samples:     10092800 | elapsed time per iteration (ms): 621.2 | learning rate: 8.284945E-05 | global batch size:    64 | lm loss: 3.101773E+00 | loss scale: 1048576.0 | grad norm: 0.434 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-25 06:57:03] iteration   157800/  500000 | consumed samples:     10099200 | elapsed time per iteration (ms): 618.5 | learning rate: 8.278009E-05 | global batch size:    64 | lm loss: 3.085638E+00 | loss scale: 1048576.0 | grad norm: 0.430 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 06:58:04] iteration   157900/  500000 | consumed samples:     10105600 | elapsed time per iteration (ms): 617.9 | learning rate: 8.271073E-05 | global batch size:    64 | lm loss: 3.093527E+00 | loss scale: 1048576.0 | grad norm: 0.420 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 06:59:07] iteration   158000/  500000 | consumed samples:     10112000 | elapsed time per iteration (ms): 621.9 | learning rate: 8.264136E-05 | global batch size:    64 | lm loss: 3.092430E+00 | loss scale: 1048576.0 | grad norm: 0.417 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2462.57, 2462.57)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 158000 | lm loss value: 3.698067E+00 | lm loss PPL: 4.036920E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-25 07:00:11] iteration   158100/  500000 | consumed samples:     10118400 | elapsed time per iteration (ms): 620.3 | learning rate: 8.257200E-05 | global batch size:    64 | lm loss: 3.091213E+00 | loss scale: 1048576.0 | grad norm: 0.426 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 07:01:13] iteration   158200/  500000 | consumed samples:     10124800 | elapsed time per iteration (ms): 619.0 | learning rate: 8.250263E-05 | global batch size:    64 | lm loss: 3.100069E+00 | loss scale: 1048576.0 | grad norm: 0.426 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 07:02:15] iteration   158300/  500000 | consumed samples:     10131200 | elapsed time per iteration (ms): 616.6 | learning rate: 8.243325E-05 | global batch size:    64 | lm loss: 3.078919E+00 | loss scale: 1048576.0 | grad norm: 0.419 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 07:03:17] iteration   158400/  500000 | consumed samples:     10137600 | elapsed time per iteration (ms): 620.3 | learning rate: 8.236388E-05 | global batch size:    64 | lm loss: 3.078332E+00 | loss scale: 1048576.0 | grad norm: 0.421 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 07:04:19] iteration   158500/  500000 | consumed samples:     10144000 | elapsed time per iteration (ms): 618.8 | learning rate: 8.229450E-05 | global batch size:    64 | lm loss: 3.085608E+00 | loss scale: 1048576.0 | grad norm: 0.428 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 07:05:20] iteration   158600/  500000 | consumed samples:     10150400 | elapsed time per iteration (ms): 619.3 | learning rate: 8.222512E-05 | global batch size:    64 | lm loss: 3.101245E+00 | loss scale: 1048576.0 | grad norm: 0.417 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 07:06:22] iteration   158700/  500000 | consumed samples:     10156800 | elapsed time per iteration (ms): 619.2 | learning rate: 8.215574E-05 | global batch size:    64 | lm loss: 3.093824E+00 | loss scale: 2097152.0 | grad norm: 0.420 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 07:07:24] iteration   158800/  500000 | consumed samples:     10163200 | elapsed time per iteration (ms): 618.8 | learning rate: 8.208635E-05 | global batch size:    64 | lm loss: 3.090904E+00 | loss scale: 2097152.0 | grad norm: 0.426 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 07:08:26] iteration   158900/  500000 | consumed samples:     10169600 | elapsed time per iteration (ms): 618.2 | learning rate: 8.201696E-05 | global batch size:    64 | lm loss: 3.100495E+00 | loss scale: 2097152.0 | grad norm: 0.421 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 07:09:28] iteration   159000/  500000 | consumed samples:     10176000 | elapsed time per iteration (ms): 619.9 | learning rate: 8.194758E-05 | global batch size:    64 | lm loss: 3.089550E+00 | loss scale: 2097152.0 | grad norm: 0.428 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2463.94, 2463.97)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 159000 | lm loss value: 3.740329E+00 | lm loss PPL: 4.211182E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-25 07:10:32] iteration   159100/  500000 | consumed samples:     10182400 | elapsed time per iteration (ms): 618.2 | learning rate: 8.187888E-05 | global batch size:    64 | lm loss: 3.090979E+00 | loss scale: 2097152.0 | grad norm: 0.411 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-25 07:11:34] iteration   159200/  500000 | consumed samples:     10188800 | elapsed time per iteration (ms): 618.6 | learning rate: 8.180949E-05 | global batch size:    64 | lm loss: 3.104481E+00 | loss scale: 2097152.0 | grad norm: 0.413 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 07:12:36] iteration   159300/  500000 | consumed samples:     10195200 | elapsed time per iteration (ms): 618.5 | learning rate: 8.174009E-05 | global batch size:    64 | lm loss: 3.098496E+00 | loss scale: 2097152.0 | grad norm: 0.426 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 07:13:38] iteration   159400/  500000 | consumed samples:     10201600 | elapsed time per iteration (ms): 620.0 | learning rate: 8.167070E-05 | global batch size:    64 | lm loss: 3.110715E+00 | loss scale: 2097152.0 | grad norm: 0.427 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 07:14:40] iteration   159500/  500000 | consumed samples:     10208000 | elapsed time per iteration (ms): 618.2 | learning rate: 8.160199E-05 | global batch size:    64 | lm loss: 3.096278E+00 | loss scale: 1048576.0 | grad norm: 0.422 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-25 07:15:42] iteration   159600/  500000 | consumed samples:     10214400 | elapsed time per iteration (ms): 619.0 | learning rate: 8.153259E-05 | global batch size:    64 | lm loss: 3.091900E+00 | loss scale: 1048576.0 | grad norm: 0.435 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 07:16:44] iteration   159700/  500000 | consumed samples:     10220800 | elapsed time per iteration (ms): 617.5 | learning rate: 8.146319E-05 | global batch size:    64 | lm loss: 3.103589E+00 | loss scale: 1048576.0 | grad norm: 0.427 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 07:17:45] iteration   159800/  500000 | consumed samples:     10227200 | elapsed time per iteration (ms): 619.1 | learning rate: 8.139379E-05 | global batch size:    64 | lm loss: 3.094917E+00 | loss scale: 1048576.0 | grad norm: 0.411 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 07:18:47] iteration   159900/  500000 | consumed samples:     10233600 | elapsed time per iteration (ms): 619.8 | learning rate: 8.132439E-05 | global batch size:    64 | lm loss: 3.088838E+00 | loss scale: 1048576.0 | grad norm: 0.431 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 07:19:49] iteration   160000/  500000 | consumed samples:     10240000 | elapsed time per iteration (ms): 619.7 | learning rate: 8.125498E-05 | global batch size:    64 | lm loss: 3.081672E+00 | loss scale: 1048576.0 | grad norm: 0.439 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2463.54, 2463.72)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 160000 | lm loss value: 3.693026E+00 | lm loss PPL: 4.016621E+01 | 
--------------------------------------------------------------------------------------------------
saving checkpoint at iteration  160000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-distribution in torch format
  successfully saved checkpoint at iteration  160000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-distribution
(min, max) time across ranks (ms):
    save-checkpoint ................................: (2318.87, 2318.89)
 [2024-06-25 07:20:56] iteration   160100/  500000 | consumed samples:     10246400 | elapsed time per iteration (ms): 618.0 | learning rate: 8.118558E-05 | global batch size:    64 | lm loss: 3.086740E+00 | loss scale: 1048576.0 | grad norm: 0.412 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 07:21:58] iteration   160200/  500000 | consumed samples:     10252800 | elapsed time per iteration (ms): 618.4 | learning rate: 8.111617E-05 | global batch size:    64 | lm loss: 3.089884E+00 | loss scale: 1048576.0 | grad norm: 0.430 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 07:23:00] iteration   160300/  500000 | consumed samples:     10259200 | elapsed time per iteration (ms): 618.8 | learning rate: 8.104676E-05 | global batch size:    64 | lm loss: 3.081614E+00 | loss scale: 1048576.0 | grad norm: 0.428 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 07:24:02] iteration   160400/  500000 | consumed samples:     10265600 | elapsed time per iteration (ms): 619.3 | learning rate: 8.097735E-05 | global batch size:    64 | lm loss: 3.082973E+00 | loss scale: 1048576.0 | grad norm: 0.421 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 07:25:03] iteration   160500/  500000 | consumed samples:     10272000 | elapsed time per iteration (ms): 618.5 | learning rate: 8.090864E-05 | global batch size:    64 | lm loss: 3.079957E+00 | loss scale: 2097152.0 | grad norm: 0.414 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-25 07:26:05] iteration   160600/  500000 | consumed samples:     10278400 | elapsed time per iteration (ms): 618.5 | learning rate: 8.083923E-05 | global batch size:    64 | lm loss: 3.084195E+00 | loss scale: 2097152.0 | grad norm: 0.424 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 07:27:07] iteration   160700/  500000 | consumed samples:     10284800 | elapsed time per iteration (ms): 619.6 | learning rate: 8.077051E-05 | global batch size:    64 | lm loss: 3.089243E+00 | loss scale: 1048576.0 | grad norm: 0.415 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-25 07:28:09] iteration   160800/  500000 | consumed samples:     10291200 | elapsed time per iteration (ms): 620.1 | learning rate: 8.070109E-05 | global batch size:    64 | lm loss: 3.079691E+00 | loss scale: 1048576.0 | grad norm: 0.426 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 07:29:11] iteration   160900/  500000 | consumed samples:     10297600 | elapsed time per iteration (ms): 618.7 | learning rate: 8.063168E-05 | global batch size:    64 | lm loss: 3.090453E+00 | loss scale: 1048576.0 | grad norm: 0.416 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 07:30:13] iteration   161000/  500000 | consumed samples:     10304000 | elapsed time per iteration (ms): 620.1 | learning rate: 8.056227E-05 | global batch size:    64 | lm loss: 3.087361E+00 | loss scale: 1048576.0 | grad norm: 0.424 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2464.81, 2464.94)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 161000 | lm loss value: 3.669337E+00 | lm loss PPL: 3.922589E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-25 07:31:18] iteration   161100/  500000 | consumed samples:     10310400 | elapsed time per iteration (ms): 620.5 | learning rate: 8.049285E-05 | global batch size:    64 | lm loss: 3.089889E+00 | loss scale: 1048576.0 | grad norm: 0.430 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 07:32:20] iteration   161200/  500000 | consumed samples:     10316800 | elapsed time per iteration (ms): 619.7 | learning rate: 8.042344E-05 | global batch size:    64 | lm loss: 3.088757E+00 | loss scale: 1048576.0 | grad norm: 0.417 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 07:33:22] iteration   161300/  500000 | consumed samples:     10323200 | elapsed time per iteration (ms): 621.0 | learning rate: 8.035402E-05 | global batch size:    64 | lm loss: 3.090798E+00 | loss scale: 1048576.0 | grad norm: 0.434 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 07:34:24] iteration   161400/  500000 | consumed samples:     10329600 | elapsed time per iteration (ms): 620.3 | learning rate: 8.028461E-05 | global batch size:    64 | lm loss: 3.080140E+00 | loss scale: 1048576.0 | grad norm: 0.424 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 07:35:26] iteration   161500/  500000 | consumed samples:     10336000 | elapsed time per iteration (ms): 620.1 | learning rate: 8.021519E-05 | global batch size:    64 | lm loss: 3.089810E+00 | loss scale: 1048576.0 | grad norm: 0.434 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 07:36:28] iteration   161600/  500000 | consumed samples:     10342400 | elapsed time per iteration (ms): 619.8 | learning rate: 8.014577E-05 | global batch size:    64 | lm loss: 3.096122E+00 | loss scale: 1048576.0 | grad norm: 0.434 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 07:37:30] iteration   161700/  500000 | consumed samples:     10348800 | elapsed time per iteration (ms): 618.7 | learning rate: 8.007636E-05 | global batch size:    64 | lm loss: 3.077789E+00 | loss scale: 2097152.0 | grad norm: 0.425 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 07:38:31] iteration   161800/  500000 | consumed samples:     10355200 | elapsed time per iteration (ms): 617.7 | learning rate: 8.000764E-05 | global batch size:    64 | lm loss: 3.087845E+00 | loss scale: 2097152.0 | grad norm: 0.443 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-25 07:39:33] iteration   161900/  500000 | consumed samples:     10361600 | elapsed time per iteration (ms): 619.7 | learning rate: 7.993891E-05 | global batch size:    64 | lm loss: 3.090098E+00 | loss scale: 1048576.0 | grad norm: 0.430 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-25 07:40:35] iteration   162000/  500000 | consumed samples:     10368000 | elapsed time per iteration (ms): 620.9 | learning rate: 7.986950E-05 | global batch size:    64 | lm loss: 3.081798E+00 | loss scale: 1048576.0 | grad norm: 0.427 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2463.43, 2463.48)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 162000 | lm loss value: 3.665036E+00 | lm loss PPL: 3.905756E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-25 07:41:40] iteration   162100/  500000 | consumed samples:     10374400 | elapsed time per iteration (ms): 621.4 | learning rate: 7.980008E-05 | global batch size:    64 | lm loss: 3.084533E+00 | loss scale: 1048576.0 | grad norm: 0.422 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 07:42:42] iteration   162200/  500000 | consumed samples:     10380800 | elapsed time per iteration (ms): 619.3 | learning rate: 7.973066E-05 | global batch size:    64 | lm loss: 3.085991E+00 | loss scale: 1048576.0 | grad norm: 0.427 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 07:43:44] iteration   162300/  500000 | consumed samples:     10387200 | elapsed time per iteration (ms): 620.2 | learning rate: 7.966125E-05 | global batch size:    64 | lm loss: 3.081994E+00 | loss scale: 1048576.0 | grad norm: 0.418 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 07:44:46] iteration   162400/  500000 | consumed samples:     10393600 | elapsed time per iteration (ms): 618.9 | learning rate: 7.959183E-05 | global batch size:    64 | lm loss: 3.092254E+00 | loss scale: 1048576.0 | grad norm: 0.421 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 07:45:48] iteration   162500/  500000 | consumed samples:     10400000 | elapsed time per iteration (ms): 620.2 | learning rate: 7.952242E-05 | global batch size:    64 | lm loss: 3.104305E+00 | loss scale: 1048576.0 | grad norm: 0.420 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 07:46:50] iteration   162600/  500000 | consumed samples:     10406400 | elapsed time per iteration (ms): 618.6 | learning rate: 7.945300E-05 | global batch size:    64 | lm loss: 3.100550E+00 | loss scale: 1048576.0 | grad norm: 0.417 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 07:47:52] iteration   162700/  500000 | consumed samples:     10412800 | elapsed time per iteration (ms): 619.2 | learning rate: 7.938359E-05 | global batch size:    64 | lm loss: 3.082548E+00 | loss scale: 1048576.0 | grad norm: 0.434 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 07:48:54] iteration   162800/  500000 | consumed samples:     10419200 | elapsed time per iteration (ms): 621.3 | learning rate: 7.931418E-05 | global batch size:    64 | lm loss: 3.071257E+00 | loss scale: 1048576.0 | grad norm: 0.432 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 07:49:56] iteration   162900/  500000 | consumed samples:     10425600 | elapsed time per iteration (ms): 619.4 | learning rate: 7.924476E-05 | global batch size:    64 | lm loss: 3.098710E+00 | loss scale: 2097152.0 | grad norm: 0.429 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 07:50:58] iteration   163000/  500000 | consumed samples:     10432000 | elapsed time per iteration (ms): 620.5 | learning rate: 7.917535E-05 | global batch size:    64 | lm loss: 3.085874E+00 | loss scale: 2097152.0 | grad norm: 0.425 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2466.89, 2466.90)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 163000 | lm loss value: 3.677557E+00 | lm loss PPL: 3.954966E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-25 07:52:02] iteration   163100/  500000 | consumed samples:     10438400 | elapsed time per iteration (ms): 620.1 | learning rate: 7.910594E-05 | global batch size:    64 | lm loss: 3.086844E+00 | loss scale: 2097152.0 | grad norm: 0.436 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 07:53:04] iteration   163200/  500000 | consumed samples:     10444800 | elapsed time per iteration (ms): 618.7 | learning rate: 7.903653E-05 | global batch size:    64 | lm loss: 3.090429E+00 | loss scale: 2097152.0 | grad norm: 0.423 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 07:54:06] iteration   163300/  500000 | consumed samples:     10451200 | elapsed time per iteration (ms): 619.1 | learning rate: 7.896712E-05 | global batch size:    64 | lm loss: 3.094776E+00 | loss scale: 2097152.0 | grad norm: 0.419 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 07:55:08] iteration   163400/  500000 | consumed samples:     10457600 | elapsed time per iteration (ms): 621.1 | learning rate: 7.889771E-05 | global batch size:    64 | lm loss: 3.077468E+00 | loss scale: 2097152.0 | grad norm: 0.435 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 07:56:10] iteration   163500/  500000 | consumed samples:     10464000 | elapsed time per iteration (ms): 620.1 | learning rate: 7.882900E-05 | global batch size:    64 | lm loss: 3.087701E+00 | loss scale: 2097152.0 | grad norm: 0.420 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-25 07:57:12] iteration   163600/  500000 | consumed samples:     10470400 | elapsed time per iteration (ms): 621.3 | learning rate: 7.875959E-05 | global batch size:    64 | lm loss: 3.095741E+00 | loss scale: 2097152.0 | grad norm: 0.431 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 07:58:14] iteration   163700/  500000 | consumed samples:     10476800 | elapsed time per iteration (ms): 621.2 | learning rate: 7.869019E-05 | global batch size:    64 | lm loss: 3.085239E+00 | loss scale: 2097152.0 | grad norm: 0.417 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 07:59:17] iteration   163800/  500000 | consumed samples:     10483200 | elapsed time per iteration (ms): 621.4 | learning rate: 7.862078E-05 | global batch size:    64 | lm loss: 3.092293E+00 | loss scale: 2097152.0 | grad norm: 0.427 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 08:00:18] iteration   163900/  500000 | consumed samples:     10489600 | elapsed time per iteration (ms): 618.8 | learning rate: 7.855138E-05 | global batch size:    64 | lm loss: 3.081468E+00 | loss scale: 2097152.0 | grad norm: 0.435 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 08:01:21] iteration   164000/  500000 | consumed samples:     10496000 | elapsed time per iteration (ms): 622.3 | learning rate: 7.848198E-05 | global batch size:    64 | lm loss: 3.097455E+00 | loss scale: 2097152.0 | grad norm: 0.441 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2461.08, 2461.08)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 164000 | lm loss value: 3.668654E+00 | lm loss PPL: 3.919912E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-25 08:02:25] iteration   164100/  500000 | consumed samples:     10502400 | elapsed time per iteration (ms): 620.7 | learning rate: 7.841258E-05 | global batch size:    64 | lm loss: 3.080541E+00 | loss scale: 2097152.0 | grad norm: 0.432 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 08:03:27] iteration   164200/  500000 | consumed samples:     10508800 | elapsed time per iteration (ms): 617.5 | learning rate: 7.834318E-05 | global batch size:    64 | lm loss: 3.082922E+00 | loss scale: 2097152.0 | grad norm: 0.427 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 08:04:29] iteration   164300/  500000 | consumed samples:     10515200 | elapsed time per iteration (ms): 620.0 | learning rate: 7.827448E-05 | global batch size:    64 | lm loss: 3.084308E+00 | loss scale: 1048576.0 | grad norm: 0.436 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-25 08:05:31] iteration   164400/  500000 | consumed samples:     10521600 | elapsed time per iteration (ms): 621.6 | learning rate: 7.820509E-05 | global batch size:    64 | lm loss: 3.086304E+00 | loss scale: 1048576.0 | grad norm: 0.425 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 08:06:33] iteration   164500/  500000 | consumed samples:     10528000 | elapsed time per iteration (ms): 620.4 | learning rate: 7.813569E-05 | global batch size:    64 | lm loss: 3.082929E+00 | loss scale: 1048576.0 | grad norm: 0.427 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 08:07:35] iteration   164600/  500000 | consumed samples:     10534400 | elapsed time per iteration (ms): 618.5 | learning rate: 7.806630E-05 | global batch size:    64 | lm loss: 3.091157E+00 | loss scale: 1048576.0 | grad norm: 0.432 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 08:08:37] iteration   164700/  500000 | consumed samples:     10540800 | elapsed time per iteration (ms): 619.5 | learning rate: 7.799691E-05 | global batch size:    64 | lm loss: 3.089627E+00 | loss scale: 1048576.0 | grad norm: 0.436 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 08:09:39] iteration   164800/  500000 | consumed samples:     10547200 | elapsed time per iteration (ms): 620.0 | learning rate: 7.792753E-05 | global batch size:    64 | lm loss: 3.093147E+00 | loss scale: 1048576.0 | grad norm: 0.417 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 08:10:41] iteration   164900/  500000 | consumed samples:     10553600 | elapsed time per iteration (ms): 619.6 | learning rate: 7.785814E-05 | global batch size:    64 | lm loss: 3.085675E+00 | loss scale: 1048576.0 | grad norm: 0.419 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 08:11:43] iteration   165000/  500000 | consumed samples:     10560000 | elapsed time per iteration (ms): 619.4 | learning rate: 7.778876E-05 | global batch size:    64 | lm loss: 3.079093E+00 | loss scale: 1048576.0 | grad norm: 0.420 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2462.82, 2462.94)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 165000 | lm loss value: 3.742854E+00 | lm loss PPL: 4.221829E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-25 08:12:47] iteration   165100/  500000 | consumed samples:     10566400 | elapsed time per iteration (ms): 620.0 | learning rate: 7.771938E-05 | global batch size:    64 | lm loss: 3.093141E+00 | loss scale: 1048576.0 | grad norm: 0.427 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 08:13:49] iteration   165200/  500000 | consumed samples:     10572800 | elapsed time per iteration (ms): 617.3 | learning rate: 7.765000E-05 | global batch size:    64 | lm loss: 3.068947E+00 | loss scale: 1048576.0 | grad norm: 0.434 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 08:14:51] iteration   165300/  500000 | consumed samples:     10579200 | elapsed time per iteration (ms): 620.2 | learning rate: 7.758062E-05 | global batch size:    64 | lm loss: 3.086099E+00 | loss scale: 2097152.0 | grad norm: 0.432 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 08:15:53] iteration   165400/  500000 | consumed samples:     10585600 | elapsed time per iteration (ms): 621.1 | learning rate: 7.751125E-05 | global batch size:    64 | lm loss: 3.087513E+00 | loss scale: 2097152.0 | grad norm: 0.420 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 08:16:55] iteration   165500/  500000 | consumed samples:     10592000 | elapsed time per iteration (ms): 619.4 | learning rate: 7.744188E-05 | global batch size:    64 | lm loss: 3.087059E+00 | loss scale: 2097152.0 | grad norm: 0.427 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 08:17:57] iteration   165600/  500000 | consumed samples:     10598400 | elapsed time per iteration (ms): 620.1 | learning rate: 7.737251E-05 | global batch size:    64 | lm loss: 3.084806E+00 | loss scale: 2097152.0 | grad norm: 0.428 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 08:18:59] iteration   165700/  500000 | consumed samples:     10604800 | elapsed time per iteration (ms): 620.3 | learning rate: 7.730384E-05 | global batch size:    64 | lm loss: 3.078817E+00 | loss scale: 2097152.0 | grad norm: 0.429 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-25 08:20:01] iteration   165800/  500000 | consumed samples:     10611200 | elapsed time per iteration (ms): 617.5 | learning rate: 7.723447E-05 | global batch size:    64 | lm loss: 3.080917E+00 | loss scale: 2097152.0 | grad norm: 0.435 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 08:21:03] iteration   165900/  500000 | consumed samples:     10617600 | elapsed time per iteration (ms): 617.6 | learning rate: 7.716580E-05 | global batch size:    64 | lm loss: 3.082035E+00 | loss scale: 1048576.0 | grad norm: 0.434 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-25 08:22:05] iteration   166000/  500000 | consumed samples:     10624000 | elapsed time per iteration (ms): 620.8 | learning rate: 7.709645E-05 | global batch size:    64 | lm loss: 3.090730E+00 | loss scale: 1048576.0 | grad norm: 0.429 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2464.48, 2464.49)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 166000 | lm loss value: 3.702753E+00 | lm loss PPL: 4.055880E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-25 08:23:09] iteration   166100/  500000 | consumed samples:     10630400 | elapsed time per iteration (ms): 620.2 | learning rate: 7.702709E-05 | global batch size:    64 | lm loss: 3.079275E+00 | loss scale: 1048576.0 | grad norm: 0.433 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 08:24:11] iteration   166200/  500000 | consumed samples:     10636800 | elapsed time per iteration (ms): 619.8 | learning rate: 7.695774E-05 | global batch size:    64 | lm loss: 3.085365E+00 | loss scale: 1048576.0 | grad norm: 0.419 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 08:25:13] iteration   166300/  500000 | consumed samples:     10643200 | elapsed time per iteration (ms): 621.0 | learning rate: 7.688839E-05 | global batch size:    64 | lm loss: 3.092711E+00 | loss scale: 1048576.0 | grad norm: 0.430 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 08:26:16] iteration   166400/  500000 | consumed samples:     10649600 | elapsed time per iteration (ms): 622.2 | learning rate: 7.681904E-05 | global batch size:    64 | lm loss: 3.093431E+00 | loss scale: 1048576.0 | grad norm: 0.430 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 08:27:18] iteration   166500/  500000 | consumed samples:     10656000 | elapsed time per iteration (ms): 620.8 | learning rate: 7.674970E-05 | global batch size:    64 | lm loss: 3.080051E+00 | loss scale: 1048576.0 | grad norm: 0.429 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 08:28:20] iteration   166600/  500000 | consumed samples:     10662400 | elapsed time per iteration (ms): 620.9 | learning rate: 7.668036E-05 | global batch size:    64 | lm loss: 3.073438E+00 | loss scale: 1048576.0 | grad norm: 0.425 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 08:29:22] iteration   166700/  500000 | consumed samples:     10668800 | elapsed time per iteration (ms): 620.6 | learning rate: 7.661102E-05 | global batch size:    64 | lm loss: 3.112726E+00 | loss scale: 1048576.0 | grad norm: 0.433 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 08:30:24] iteration   166800/  500000 | consumed samples:     10675200 | elapsed time per iteration (ms): 621.0 | learning rate: 7.654169E-05 | global batch size:    64 | lm loss: 3.091322E+00 | loss scale: 1048576.0 | grad norm: 0.431 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 08:31:26] iteration   166900/  500000 | consumed samples:     10681600 | elapsed time per iteration (ms): 617.7 | learning rate: 7.647236E-05 | global batch size:    64 | lm loss: 3.079416E+00 | loss scale: 2097152.0 | grad norm: 0.425 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 08:32:28] iteration   167000/  500000 | consumed samples:     10688000 | elapsed time per iteration (ms): 619.9 | learning rate: 7.640303E-05 | global batch size:    64 | lm loss: 3.066405E+00 | loss scale: 2097152.0 | grad norm: 0.445 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2465.90, 2465.92)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 167000 | lm loss value: 3.713183E+00 | lm loss PPL: 4.098405E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-25 08:33:32] iteration   167100/  500000 | consumed samples:     10694400 | elapsed time per iteration (ms): 621.2 | learning rate: 7.633510E-05 | global batch size:    64 | lm loss: 3.087079E+00 | loss scale: 1048576.0 | grad norm: 0.439 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-25 08:34:34] iteration   167200/  500000 | consumed samples:     10700800 | elapsed time per iteration (ms): 618.9 | learning rate: 7.626578E-05 | global batch size:    64 | lm loss: 3.086786E+00 | loss scale: 1048576.0 | grad norm: 0.441 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 08:35:36] iteration   167300/  500000 | consumed samples:     10707200 | elapsed time per iteration (ms): 618.4 | learning rate: 7.619646E-05 | global batch size:    64 | lm loss: 3.085477E+00 | loss scale: 1048576.0 | grad norm: 0.439 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 08:36:38] iteration   167400/  500000 | consumed samples:     10713600 | elapsed time per iteration (ms): 619.9 | learning rate: 7.612715E-05 | global batch size:    64 | lm loss: 3.087433E+00 | loss scale: 1048576.0 | grad norm: 0.436 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 08:37:40] iteration   167500/  500000 | consumed samples:     10720000 | elapsed time per iteration (ms): 620.0 | learning rate: 7.605784E-05 | global batch size:    64 | lm loss: 3.077448E+00 | loss scale: 1048576.0 | grad norm: 0.434 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 08:38:42] iteration   167600/  500000 | consumed samples:     10726400 | elapsed time per iteration (ms): 620.4 | learning rate: 7.598854E-05 | global batch size:    64 | lm loss: 3.085746E+00 | loss scale: 1048576.0 | grad norm: 0.419 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 08:39:44] iteration   167700/  500000 | consumed samples:     10732800 | elapsed time per iteration (ms): 618.2 | learning rate: 7.591924E-05 | global batch size:    64 | lm loss: 3.083257E+00 | loss scale: 1048576.0 | grad norm: 0.424 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 08:40:46] iteration   167800/  500000 | consumed samples:     10739200 | elapsed time per iteration (ms): 618.5 | learning rate: 7.584994E-05 | global batch size:    64 | lm loss: 3.091902E+00 | loss scale: 1048576.0 | grad norm: 0.427 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 08:41:48] iteration   167900/  500000 | consumed samples:     10745600 | elapsed time per iteration (ms): 618.4 | learning rate: 7.578065E-05 | global batch size:    64 | lm loss: 3.092184E+00 | loss scale: 1048576.0 | grad norm: 0.429 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 08:42:50] iteration   168000/  500000 | consumed samples:     10752000 | elapsed time per iteration (ms): 620.4 | learning rate: 7.571136E-05 | global batch size:    64 | lm loss: 3.090085E+00 | loss scale: 1048576.0 | grad norm: 0.442 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2464.11, 2464.21)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 168000 | lm loss value: 3.696601E+00 | lm loss PPL: 4.031006E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-25 08:43:54] iteration   168100/  500000 | consumed samples:     10758400 | elapsed time per iteration (ms): 620.8 | learning rate: 7.564208E-05 | global batch size:    64 | lm loss: 3.090006E+00 | loss scale: 2097152.0 | grad norm: 0.424 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 08:44:56] iteration   168200/  500000 | consumed samples:     10764800 | elapsed time per iteration (ms): 618.1 | learning rate: 7.557280E-05 | global batch size:    64 | lm loss: 3.084776E+00 | loss scale: 2097152.0 | grad norm: 0.416 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 08:45:58] iteration   168300/  500000 | consumed samples:     10771200 | elapsed time per iteration (ms): 620.8 | learning rate: 7.550352E-05 | global batch size:    64 | lm loss: 3.084576E+00 | loss scale: 2097152.0 | grad norm: 0.438 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 08:47:00] iteration   168400/  500000 | consumed samples:     10777600 | elapsed time per iteration (ms): 618.8 | learning rate: 7.543563E-05 | global batch size:    64 | lm loss: 3.089237E+00 | loss scale: 1048576.0 | grad norm: 0.426 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-25 08:48:02] iteration   168500/  500000 | consumed samples:     10784000 | elapsed time per iteration (ms): 619.8 | learning rate: 7.536637E-05 | global batch size:    64 | lm loss: 3.082820E+00 | loss scale: 1048576.0 | grad norm: 0.434 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 08:49:04] iteration   168600/  500000 | consumed samples:     10790400 | elapsed time per iteration (ms): 619.1 | learning rate: 7.529711E-05 | global batch size:    64 | lm loss: 3.076100E+00 | loss scale: 1048576.0 | grad norm: 0.439 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 08:50:06] iteration   168700/  500000 | consumed samples:     10796800 | elapsed time per iteration (ms): 621.7 | learning rate: 7.522785E-05 | global batch size:    64 | lm loss: 3.078832E+00 | loss scale: 1048576.0 | grad norm: 0.432 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 08:51:08] iteration   168800/  500000 | consumed samples:     10803200 | elapsed time per iteration (ms): 619.3 | learning rate: 7.515860E-05 | global batch size:    64 | lm loss: 3.079379E+00 | loss scale: 1048576.0 | grad norm: 0.453 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 08:52:10] iteration   168900/  500000 | consumed samples:     10809600 | elapsed time per iteration (ms): 619.9 | learning rate: 7.508935E-05 | global batch size:    64 | lm loss: 3.074883E+00 | loss scale: 1048576.0 | grad norm: 0.440 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 08:53:12] iteration   169000/  500000 | consumed samples:     10816000 | elapsed time per iteration (ms): 619.3 | learning rate: 7.502011E-05 | global batch size:    64 | lm loss: 3.064071E+00 | loss scale: 1048576.0 | grad norm: 0.428 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2462.51, 2462.58)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 169000 | lm loss value: 3.717351E+00 | lm loss PPL: 4.115522E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-25 08:54:16] iteration   169100/  500000 | consumed samples:     10822400 | elapsed time per iteration (ms): 619.9 | learning rate: 7.495087E-05 | global batch size:    64 | lm loss: 3.080075E+00 | loss scale: 1048576.0 | grad norm: 0.423 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 08:55:18] iteration   169200/  500000 | consumed samples:     10828800 | elapsed time per iteration (ms): 619.6 | learning rate: 7.488163E-05 | global batch size:    64 | lm loss: 3.074309E+00 | loss scale: 1048576.0 | grad norm: 0.440 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 08:56:20] iteration   169300/  500000 | consumed samples:     10835200 | elapsed time per iteration (ms): 617.8 | learning rate: 7.481241E-05 | global batch size:    64 | lm loss: 3.059843E+00 | loss scale: 1048576.0 | grad norm: 0.432 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 08:57:22] iteration   169400/  500000 | consumed samples:     10841600 | elapsed time per iteration (ms): 621.9 | learning rate: 7.474318E-05 | global batch size:    64 | lm loss: 3.082593E+00 | loss scale: 2097152.0 | grad norm: 0.429 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 08:58:24] iteration   169500/  500000 | consumed samples:     10848000 | elapsed time per iteration (ms): 619.1 | learning rate: 7.467466E-05 | global batch size:    64 | lm loss: 3.075787E+00 | loss scale: 2097152.0 | grad norm: 0.429 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-25 08:59:26] iteration   169600/  500000 | consumed samples:     10854400 | elapsed time per iteration (ms): 619.2 | learning rate: 7.460614E-05 | global batch size:    64 | lm loss: 3.070367E+00 | loss scale: 1048576.0 | grad norm: 0.433 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-25 09:00:28] iteration   169700/  500000 | consumed samples:     10860800 | elapsed time per iteration (ms): 619.2 | learning rate: 7.453693E-05 | global batch size:    64 | lm loss: 3.062665E+00 | loss scale: 1048576.0 | grad norm: 0.431 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 09:01:30] iteration   169800/  500000 | consumed samples:     10867200 | elapsed time per iteration (ms): 619.2 | learning rate: 7.446773E-05 | global batch size:    64 | lm loss: 3.069351E+00 | loss scale: 1048576.0 | grad norm: 0.414 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 09:02:32] iteration   169900/  500000 | consumed samples:     10873600 | elapsed time per iteration (ms): 617.1 | learning rate: 7.439853E-05 | global batch size:    64 | lm loss: 3.077045E+00 | loss scale: 1048576.0 | grad norm: 0.416 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 09:03:34] iteration   170000/  500000 | consumed samples:     10880000 | elapsed time per iteration (ms): 620.7 | learning rate: 7.432934E-05 | global batch size:    64 | lm loss: 3.079889E+00 | loss scale: 1048576.0 | grad norm: 0.423 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2463.12, 2463.18)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 170000 | lm loss value: 3.693234E+00 | lm loss PPL: 4.017457E+01 | 
--------------------------------------------------------------------------------------------------
saving checkpoint at iteration  170000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-distribution in torch format
  successfully saved checkpoint at iteration  170000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-distribution
(min, max) time across ranks (ms):
    save-checkpoint ................................: (2261.76, 2261.77)
 [2024-06-25 09:04:40] iteration   170100/  500000 | consumed samples:     10886400 | elapsed time per iteration (ms): 617.0 | learning rate: 7.426015E-05 | global batch size:    64 | lm loss: 3.077672E+00 | loss scale: 1048576.0 | grad norm: 0.427 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 09:05:42] iteration   170200/  500000 | consumed samples:     10892800 | elapsed time per iteration (ms): 619.1 | learning rate: 7.419097E-05 | global batch size:    64 | lm loss: 3.074193E+00 | loss scale: 1048576.0 | grad norm: 0.425 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 09:06:44] iteration   170300/  500000 | consumed samples:     10899200 | elapsed time per iteration (ms): 620.0 | learning rate: 7.412180E-05 | global batch size:    64 | lm loss: 3.081215E+00 | loss scale: 1048576.0 | grad norm: 0.436 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 09:07:46] iteration   170400/  500000 | consumed samples:     10905600 | elapsed time per iteration (ms): 620.9 | learning rate: 7.405263E-05 | global batch size:    64 | lm loss: 3.074925E+00 | loss scale: 1048576.0 | grad norm: 0.452 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 09:08:48] iteration   170500/  500000 | consumed samples:     10912000 | elapsed time per iteration (ms): 619.5 | learning rate: 7.398347E-05 | global batch size:    64 | lm loss: 3.087651E+00 | loss scale: 1048576.0 | grad norm: 0.432 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 09:09:50] iteration   170600/  500000 | consumed samples:     10918400 | elapsed time per iteration (ms): 618.8 | learning rate: 7.391431E-05 | global batch size:    64 | lm loss: 3.072174E+00 | loss scale: 2097152.0 | grad norm: 0.427 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 09:10:52] iteration   170700/  500000 | consumed samples:     10924800 | elapsed time per iteration (ms): 620.6 | learning rate: 7.384654E-05 | global batch size:    64 | lm loss: 3.074757E+00 | loss scale: 1048576.0 | grad norm: 0.433 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-25 09:11:54] iteration   170800/  500000 | consumed samples:     10931200 | elapsed time per iteration (ms): 622.3 | learning rate: 7.377740E-05 | global batch size:    64 | lm loss: 3.077878E+00 | loss scale: 1048576.0 | grad norm: 0.428 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 09:12:56] iteration   170900/  500000 | consumed samples:     10937600 | elapsed time per iteration (ms): 618.8 | learning rate: 7.370826E-05 | global batch size:    64 | lm loss: 3.083734E+00 | loss scale: 1048576.0 | grad norm: 0.440 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 09:13:58] iteration   171000/  500000 | consumed samples:     10944000 | elapsed time per iteration (ms): 621.8 | learning rate: 7.363913E-05 | global batch size:    64 | lm loss: 3.091378E+00 | loss scale: 1048576.0 | grad norm: 0.430 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2465.92, 2465.98)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 171000 | lm loss value: 3.685549E+00 | lm loss PPL: 3.986702E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-25 09:15:03] iteration   171100/  500000 | consumed samples:     10950400 | elapsed time per iteration (ms): 618.1 | learning rate: 7.357000E-05 | global batch size:    64 | lm loss: 3.070938E+00 | loss scale: 1048576.0 | grad norm: 0.436 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 09:16:05] iteration   171200/  500000 | consumed samples:     10956800 | elapsed time per iteration (ms): 621.6 | learning rate: 7.350088E-05 | global batch size:    64 | lm loss: 3.090258E+00 | loss scale: 1048576.0 | grad norm: 0.416 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 09:17:07] iteration   171300/  500000 | consumed samples:     10963200 | elapsed time per iteration (ms): 620.6 | learning rate: 7.343177E-05 | global batch size:    64 | lm loss: 3.077197E+00 | loss scale: 1048576.0 | grad norm: 0.423 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 09:18:09] iteration   171400/  500000 | consumed samples:     10969600 | elapsed time per iteration (ms): 619.9 | learning rate: 7.336266E-05 | global batch size:    64 | lm loss: 3.078121E+00 | loss scale: 1048576.0 | grad norm: 0.430 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 09:19:11] iteration   171500/  500000 | consumed samples:     10976000 | elapsed time per iteration (ms): 619.4 | learning rate: 7.329356E-05 | global batch size:    64 | lm loss: 3.085736E+00 | loss scale: 1048576.0 | grad norm: 0.429 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 09:20:13] iteration   171600/  500000 | consumed samples:     10982400 | elapsed time per iteration (ms): 618.6 | learning rate: 7.322447E-05 | global batch size:    64 | lm loss: 3.065070E+00 | loss scale: 1048576.0 | grad norm: 0.430 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 09:21:15] iteration   171700/  500000 | consumed samples:     10988800 | elapsed time per iteration (ms): 620.7 | learning rate: 7.315538E-05 | global batch size:    64 | lm loss: 3.071716E+00 | loss scale: 2097152.0 | grad norm: 0.431 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 09:22:17] iteration   171800/  500000 | consumed samples:     10995200 | elapsed time per iteration (ms): 620.3 | learning rate: 7.308699E-05 | global batch size:    64 | lm loss: 3.080675E+00 | loss scale: 2097152.0 | grad norm: 0.442 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-25 09:23:19] iteration   171900/  500000 | consumed samples:     11001600 | elapsed time per iteration (ms): 620.2 | learning rate: 7.301861E-05 | global batch size:    64 | lm loss: 3.076425E+00 | loss scale: 1048576.0 | grad norm: 0.441 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-25 09:24:21] iteration   172000/  500000 | consumed samples:     11008000 | elapsed time per iteration (ms): 621.6 | learning rate: 7.294954E-05 | global batch size:    64 | lm loss: 3.070170E+00 | loss scale: 1048576.0 | grad norm: 0.450 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2464.41, 2464.59)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 172000 | lm loss value: 3.722544E+00 | lm loss PPL: 4.136951E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-25 09:25:25] iteration   172100/  500000 | consumed samples:     11014400 | elapsed time per iteration (ms): 620.5 | learning rate: 7.288048E-05 | global batch size:    64 | lm loss: 3.081981E+00 | loss scale: 1048576.0 | grad norm: 0.434 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 09:26:27] iteration   172200/  500000 | consumed samples:     11020800 | elapsed time per iteration (ms): 620.5 | learning rate: 7.281143E-05 | global batch size:    64 | lm loss: 3.068524E+00 | loss scale: 1048576.0 | grad norm: 0.420 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 09:27:29] iteration   172300/  500000 | consumed samples:     11027200 | elapsed time per iteration (ms): 619.6 | learning rate: 7.274238E-05 | global batch size:    64 | lm loss: 3.077513E+00 | loss scale: 1048576.0 | grad norm: 0.421 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 09:28:31] iteration   172400/  500000 | consumed samples:     11033600 | elapsed time per iteration (ms): 619.1 | learning rate: 7.267334E-05 | global batch size:    64 | lm loss: 3.073657E+00 | loss scale: 1048576.0 | grad norm: 0.425 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 09:29:33] iteration   172500/  500000 | consumed samples:     11040000 | elapsed time per iteration (ms): 621.8 | learning rate: 7.260431E-05 | global batch size:    64 | lm loss: 3.080882E+00 | loss scale: 1048576.0 | grad norm: 0.439 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 09:30:35] iteration   172600/  500000 | consumed samples:     11046400 | elapsed time per iteration (ms): 618.7 | learning rate: 7.253529E-05 | global batch size:    64 | lm loss: 3.080210E+00 | loss scale: 1048576.0 | grad norm: 0.436 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 09:31:37] iteration   172700/  500000 | consumed samples:     11052800 | elapsed time per iteration (ms): 618.9 | learning rate: 7.246627E-05 | global batch size:    64 | lm loss: 3.076602E+00 | loss scale: 1048576.0 | grad norm: 0.429 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 09:32:39] iteration   172800/  500000 | consumed samples:     11059200 | elapsed time per iteration (ms): 620.1 | learning rate: 7.239726E-05 | global batch size:    64 | lm loss: 3.063391E+00 | loss scale: 1048576.0 | grad norm: 0.437 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 09:33:41] iteration   172900/  500000 | consumed samples:     11065600 | elapsed time per iteration (ms): 621.1 | learning rate: 7.232826E-05 | global batch size:    64 | lm loss: 3.060970E+00 | loss scale: 2097152.0 | grad norm: 0.418 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 09:34:43] iteration   173000/  500000 | consumed samples:     11072000 | elapsed time per iteration (ms): 620.3 | learning rate: 7.225926E-05 | global batch size:    64 | lm loss: 3.069016E+00 | loss scale: 2097152.0 | grad norm: 0.429 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2463.79, 2463.82)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 173000 | lm loss value: 3.696983E+00 | lm loss PPL: 4.032546E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-25 09:35:48] iteration   173100/  500000 | consumed samples:     11078400 | elapsed time per iteration (ms): 620.9 | learning rate: 7.219097E-05 | global batch size:    64 | lm loss: 3.063774E+00 | loss scale: 2097152.0 | grad norm: 0.419 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-25 09:36:50] iteration   173200/  500000 | consumed samples:     11084800 | elapsed time per iteration (ms): 619.6 | learning rate: 7.212199E-05 | global batch size:    64 | lm loss: 3.083448E+00 | loss scale: 2097152.0 | grad norm: 0.425 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 09:37:52] iteration   173300/  500000 | consumed samples:     11091200 | elapsed time per iteration (ms): 619.9 | learning rate: 7.205302E-05 | global batch size:    64 | lm loss: 3.073559E+00 | loss scale: 2097152.0 | grad norm: 0.438 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 09:38:54] iteration   173400/  500000 | consumed samples:     11097600 | elapsed time per iteration (ms): 619.7 | learning rate: 7.198405E-05 | global batch size:    64 | lm loss: 3.074756E+00 | loss scale: 2097152.0 | grad norm: 0.420 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 09:39:56] iteration   173500/  500000 | consumed samples:     11104000 | elapsed time per iteration (ms): 619.5 | learning rate: 7.191579E-05 | global batch size:    64 | lm loss: 3.064339E+00 | loss scale: 1048576.0 | grad norm: 0.418 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-25 09:40:58] iteration   173600/  500000 | consumed samples:     11110400 | elapsed time per iteration (ms): 618.3 | learning rate: 7.184684E-05 | global batch size:    64 | lm loss: 3.072191E+00 | loss scale: 1048576.0 | grad norm: 0.429 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 09:42:00] iteration   173700/  500000 | consumed samples:     11116800 | elapsed time per iteration (ms): 620.9 | learning rate: 7.177790E-05 | global batch size:    64 | lm loss: 3.061242E+00 | loss scale: 1048576.0 | grad norm: 0.429 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 09:43:02] iteration   173800/  500000 | consumed samples:     11123200 | elapsed time per iteration (ms): 618.2 | learning rate: 7.170897E-05 | global batch size:    64 | lm loss: 3.070556E+00 | loss scale: 1048576.0 | grad norm: 0.436 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 09:44:03] iteration   173900/  500000 | consumed samples:     11129600 | elapsed time per iteration (ms): 618.7 | learning rate: 7.164004E-05 | global batch size:    64 | lm loss: 3.054636E+00 | loss scale: 1048576.0 | grad norm: 0.424 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 09:45:06] iteration   174000/  500000 | consumed samples:     11136000 | elapsed time per iteration (ms): 621.5 | learning rate: 7.157113E-05 | global batch size:    64 | lm loss: 3.069716E+00 | loss scale: 1048576.0 | grad norm: 0.454 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2462.39, 2462.50)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 174000 | lm loss value: 3.704509E+00 | lm loss PPL: 4.063007E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-25 09:46:10] iteration   174100/  500000 | consumed samples:     11142400 | elapsed time per iteration (ms): 618.8 | learning rate: 7.150222E-05 | global batch size:    64 | lm loss: 3.082033E+00 | loss scale: 1048576.0 | grad norm: 0.434 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 09:47:12] iteration   174200/  500000 | consumed samples:     11148800 | elapsed time per iteration (ms): 619.7 | learning rate: 7.143332E-05 | global batch size:    64 | lm loss: 3.076446E+00 | loss scale: 1048576.0 | grad norm: 0.432 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 09:48:14] iteration   174300/  500000 | consumed samples:     11155200 | elapsed time per iteration (ms): 621.5 | learning rate: 7.136443E-05 | global batch size:    64 | lm loss: 3.075763E+00 | loss scale: 1048576.0 | grad norm: 0.428 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 09:49:16] iteration   174400/  500000 | consumed samples:     11161600 | elapsed time per iteration (ms): 620.8 | learning rate: 7.129555E-05 | global batch size:    64 | lm loss: 3.077309E+00 | loss scale: 1048576.0 | grad norm: 0.448 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 09:50:18] iteration   174500/  500000 | consumed samples:     11168000 | elapsed time per iteration (ms): 618.9 | learning rate: 7.122667E-05 | global batch size:    64 | lm loss: 3.076056E+00 | loss scale: 2097152.0 | grad norm: 0.431 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 09:51:20] iteration   174600/  500000 | consumed samples:     11174400 | elapsed time per iteration (ms): 619.9 | learning rate: 7.115850E-05 | global batch size:    64 | lm loss: 3.072310E+00 | loss scale: 2097152.0 | grad norm: 0.438 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-25 09:52:22] iteration   174700/  500000 | consumed samples:     11180800 | elapsed time per iteration (ms): 618.4 | learning rate: 7.108964E-05 | global batch size:    64 | lm loss: 3.068694E+00 | loss scale: 2097152.0 | grad norm: 0.429 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 09:53:24] iteration   174800/  500000 | consumed samples:     11187200 | elapsed time per iteration (ms): 618.8 | learning rate: 7.102079E-05 | global batch size:    64 | lm loss: 3.066210E+00 | loss scale: 2097152.0 | grad norm: 0.431 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 09:54:26] iteration   174900/  500000 | consumed samples:     11193600 | elapsed time per iteration (ms): 619.6 | learning rate: 7.095264E-05 | global batch size:    64 | lm loss: 3.090602E+00 | loss scale: 1048576.0 | grad norm: 0.426 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-25 09:55:28] iteration   175000/  500000 | consumed samples:     11200000 | elapsed time per iteration (ms): 619.9 | learning rate: 7.088381E-05 | global batch size:    64 | lm loss: 3.083556E+00 | loss scale: 1048576.0 | grad norm: 0.426 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2464.14, 2464.25)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 175000 | lm loss value: 3.674157E+00 | lm loss PPL: 3.941541E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-25 09:56:32] iteration   175100/  500000 | consumed samples:     11206400 | elapsed time per iteration (ms): 618.4 | learning rate: 7.081499E-05 | global batch size:    64 | lm loss: 3.077696E+00 | loss scale: 1048576.0 | grad norm: 0.429 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 09:57:34] iteration   175200/  500000 | consumed samples:     11212800 | elapsed time per iteration (ms): 620.2 | learning rate: 7.074618E-05 | global batch size:    64 | lm loss: 3.064837E+00 | loss scale: 1048576.0 | grad norm: 0.440 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 09:58:36] iteration   175300/  500000 | consumed samples:     11219200 | elapsed time per iteration (ms): 617.7 | learning rate: 7.067738E-05 | global batch size:    64 | lm loss: 3.063586E+00 | loss scale: 1048576.0 | grad norm: 0.471 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 09:59:38] iteration   175400/  500000 | consumed samples:     11225600 | elapsed time per iteration (ms): 619.4 | learning rate: 7.060858E-05 | global batch size:    64 | lm loss: 3.070477E+00 | loss scale: 1048576.0 | grad norm: 0.426 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 10:00:40] iteration   175500/  500000 | consumed samples:     11232000 | elapsed time per iteration (ms): 619.6 | learning rate: 7.053980E-05 | global batch size:    64 | lm loss: 3.071066E+00 | loss scale: 1048576.0 | grad norm: 0.422 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 10:01:42] iteration   175600/  500000 | consumed samples:     11238400 | elapsed time per iteration (ms): 620.4 | learning rate: 7.047103E-05 | global batch size:    64 | lm loss: 3.065410E+00 | loss scale: 1048576.0 | grad norm: 0.441 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 10:02:44] iteration   175700/  500000 | consumed samples:     11244800 | elapsed time per iteration (ms): 621.0 | learning rate: 7.040226E-05 | global batch size:    64 | lm loss: 3.076633E+00 | loss scale: 1048576.0 | grad norm: 0.432 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 10:03:46] iteration   175800/  500000 | consumed samples:     11251200 | elapsed time per iteration (ms): 619.4 | learning rate: 7.033350E-05 | global batch size:    64 | lm loss: 3.075576E+00 | loss scale: 1048576.0 | grad norm: 0.448 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 10:04:48] iteration   175900/  500000 | consumed samples:     11257600 | elapsed time per iteration (ms): 619.7 | learning rate: 7.026476E-05 | global batch size:    64 | lm loss: 3.093955E+00 | loss scale: 2097152.0 | grad norm: 0.427 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 10:05:50] iteration   176000/  500000 | consumed samples:     11264000 | elapsed time per iteration (ms): 619.9 | learning rate: 7.019671E-05 | global batch size:    64 | lm loss: 3.060926E+00 | loss scale: 2097152.0 | grad norm: 0.436 | number of skipped iterations:   1 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2463.75, 2464.15)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 176000 | lm loss value: 3.704777E+00 | lm loss PPL: 4.064097E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-25 10:06:54] iteration   176100/  500000 | consumed samples:     11270400 | elapsed time per iteration (ms): 617.9 | learning rate: 7.012867E-05 | global batch size:    64 | lm loss: 3.070092E+00 | loss scale: 1048576.0 | grad norm: 0.444 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-25 10:07:56] iteration   176200/  500000 | consumed samples:     11276800 | elapsed time per iteration (ms): 617.8 | learning rate: 7.005995E-05 | global batch size:    64 | lm loss: 3.078626E+00 | loss scale: 1048576.0 | grad norm: 0.434 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 10:08:58] iteration   176300/  500000 | consumed samples:     11283200 | elapsed time per iteration (ms): 619.4 | learning rate: 6.999124E-05 | global batch size:    64 | lm loss: 3.063240E+00 | loss scale: 1048576.0 | grad norm: 0.439 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 10:10:00] iteration   176400/  500000 | consumed samples:     11289600 | elapsed time per iteration (ms): 620.3 | learning rate: 6.992254E-05 | global batch size:    64 | lm loss: 3.074384E+00 | loss scale: 1048576.0 | grad norm: 0.420 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 10:11:02] iteration   176500/  500000 | consumed samples:     11296000 | elapsed time per iteration (ms): 619.2 | learning rate: 6.985385E-05 | global batch size:    64 | lm loss: 3.084031E+00 | loss scale: 1048576.0 | grad norm: 0.432 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 10:12:04] iteration   176600/  500000 | consumed samples:     11302400 | elapsed time per iteration (ms): 619.9 | learning rate: 6.978518E-05 | global batch size:    64 | lm loss: 3.066396E+00 | loss scale: 1048576.0 | grad norm: 0.445 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 10:13:06] iteration   176700/  500000 | consumed samples:     11308800 | elapsed time per iteration (ms): 620.5 | learning rate: 6.971651E-05 | global batch size:    64 | lm loss: 3.079018E+00 | loss scale: 1048576.0 | grad norm: 0.439 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 10:14:08] iteration   176800/  500000 | consumed samples:     11315200 | elapsed time per iteration (ms): 618.7 | learning rate: 6.964785E-05 | global batch size:    64 | lm loss: 3.071842E+00 | loss scale: 1048576.0 | grad norm: 0.425 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 10:15:10] iteration   176900/  500000 | consumed samples:     11321600 | elapsed time per iteration (ms): 621.8 | learning rate: 6.957920E-05 | global batch size:    64 | lm loss: 3.055825E+00 | loss scale: 1048576.0 | grad norm: 0.440 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 10:16:12] iteration   177000/  500000 | consumed samples:     11328000 | elapsed time per iteration (ms): 619.0 | learning rate: 6.951056E-05 | global batch size:    64 | lm loss: 3.062731E+00 | loss scale: 1048576.0 | grad norm: 0.425 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2463.04, 2463.19)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 177000 | lm loss value: 3.724748E+00 | lm loss PPL: 4.146078E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-25 10:17:16] iteration   177100/  500000 | consumed samples:     11334400 | elapsed time per iteration (ms): 618.1 | learning rate: 6.944194E-05 | global batch size:    64 | lm loss: 3.080410E+00 | loss scale: 2097152.0 | grad norm: 0.424 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 10:18:18] iteration   177200/  500000 | consumed samples:     11340800 | elapsed time per iteration (ms): 616.9 | learning rate: 6.937332E-05 | global batch size:    64 | lm loss: 3.067713E+00 | loss scale: 2097152.0 | grad norm: 0.433 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 10:19:19] iteration   177300/  500000 | consumed samples:     11347200 | elapsed time per iteration (ms): 617.9 | learning rate: 6.930471E-05 | global batch size:    64 | lm loss: 3.083259E+00 | loss scale: 2097152.0 | grad norm: 0.427 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 10:20:21] iteration   177400/  500000 | consumed samples:     11353600 | elapsed time per iteration (ms): 618.9 | learning rate: 6.923749E-05 | global batch size:    64 | lm loss: 3.046958E+00 | loss scale: 1048576.0 | grad norm: 0.441 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-25 10:21:23] iteration   177500/  500000 | consumed samples:     11360000 | elapsed time per iteration (ms): 618.6 | learning rate: 6.916890E-05 | global batch size:    64 | lm loss: 3.065193E+00 | loss scale: 1048576.0 | grad norm: 0.436 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 10:22:25] iteration   177600/  500000 | consumed samples:     11366400 | elapsed time per iteration (ms): 621.2 | learning rate: 6.910033E-05 | global batch size:    64 | lm loss: 3.078514E+00 | loss scale: 1048576.0 | grad norm: 0.431 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 10:23:27] iteration   177700/  500000 | consumed samples:     11372800 | elapsed time per iteration (ms): 620.5 | learning rate: 6.903176E-05 | global batch size:    64 | lm loss: 3.069400E+00 | loss scale: 1048576.0 | grad norm: 0.440 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 10:24:29] iteration   177800/  500000 | consumed samples:     11379200 | elapsed time per iteration (ms): 619.8 | learning rate: 6.896321E-05 | global batch size:    64 | lm loss: 3.070457E+00 | loss scale: 1048576.0 | grad norm: 0.437 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 10:25:31] iteration   177900/  500000 | consumed samples:     11385600 | elapsed time per iteration (ms): 619.2 | learning rate: 6.889467E-05 | global batch size:    64 | lm loss: 3.085912E+00 | loss scale: 1048576.0 | grad norm: 0.430 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 10:26:33] iteration   178000/  500000 | consumed samples:     11392000 | elapsed time per iteration (ms): 618.8 | learning rate: 6.882613E-05 | global batch size:    64 | lm loss: 3.083997E+00 | loss scale: 1048576.0 | grad norm: 0.433 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2464.50, 2464.50)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 178000 | lm loss value: 3.690625E+00 | lm loss PPL: 4.006987E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-25 10:27:37] iteration   178100/  500000 | consumed samples:     11398400 | elapsed time per iteration (ms): 619.3 | learning rate: 6.875761E-05 | global batch size:    64 | lm loss: 3.061175E+00 | loss scale: 1048576.0 | grad norm: 0.417 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 10:28:39] iteration   178200/  500000 | consumed samples:     11404800 | elapsed time per iteration (ms): 619.0 | learning rate: 6.868910E-05 | global batch size:    64 | lm loss: 3.070356E+00 | loss scale: 1048576.0 | grad norm: 0.441 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 10:29:41] iteration   178300/  500000 | consumed samples:     11411200 | elapsed time per iteration (ms): 621.0 | learning rate: 6.862060E-05 | global batch size:    64 | lm loss: 3.056069E+00 | loss scale: 1048576.0 | grad norm: 0.417 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 10:30:43] iteration   178400/  500000 | consumed samples:     11417600 | elapsed time per iteration (ms): 619.3 | learning rate: 6.855212E-05 | global batch size:    64 | lm loss: 3.058337E+00 | loss scale: 2097152.0 | grad norm: 0.441 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 10:31:45] iteration   178500/  500000 | consumed samples:     11424000 | elapsed time per iteration (ms): 619.0 | learning rate: 6.848432E-05 | global batch size:    64 | lm loss: 3.066824E+00 | loss scale: 2097152.0 | grad norm: 0.437 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-25 10:32:47] iteration   178600/  500000 | consumed samples:     11430400 | elapsed time per iteration (ms): 619.6 | learning rate: 6.841586E-05 | global batch size:    64 | lm loss: 3.055304E+00 | loss scale: 2097152.0 | grad norm: 0.424 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 10:33:49] iteration   178700/  500000 | consumed samples:     11436800 | elapsed time per iteration (ms): 619.4 | learning rate: 6.834741E-05 | global batch size:    64 | lm loss: 3.073216E+00 | loss scale: 2097152.0 | grad norm: 0.431 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 10:34:51] iteration   178800/  500000 | consumed samples:     11443200 | elapsed time per iteration (ms): 618.8 | learning rate: 6.827896E-05 | global batch size:    64 | lm loss: 3.059492E+00 | loss scale: 2097152.0 | grad norm: 0.429 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 10:35:53] iteration   178900/  500000 | consumed samples:     11449600 | elapsed time per iteration (ms): 620.4 | learning rate: 6.821122E-05 | global batch size:    64 | lm loss: 3.054357E+00 | loss scale: 1048576.0 | grad norm: 0.426 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-25 10:36:55] iteration   179000/  500000 | consumed samples:     11456000 | elapsed time per iteration (ms): 618.3 | learning rate: 6.814280E-05 | global batch size:    64 | lm loss: 3.081968E+00 | loss scale: 1048576.0 | grad norm: 0.437 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2461.67, 2461.78)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 179000 | lm loss value: 3.734547E+00 | lm loss PPL: 4.186906E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-25 10:37:59] iteration   179100/  500000 | consumed samples:     11462400 | elapsed time per iteration (ms): 619.7 | learning rate: 6.807439E-05 | global batch size:    64 | lm loss: 3.058797E+00 | loss scale: 1048576.0 | grad norm: 0.429 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 10:39:01] iteration   179200/  500000 | consumed samples:     11468800 | elapsed time per iteration (ms): 618.9 | learning rate: 6.800599E-05 | global batch size:    64 | lm loss: 3.063275E+00 | loss scale: 1048576.0 | grad norm: 0.437 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 10:40:03] iteration   179300/  500000 | consumed samples:     11475200 | elapsed time per iteration (ms): 621.4 | learning rate: 6.793761E-05 | global batch size:    64 | lm loss: 3.072075E+00 | loss scale: 1048576.0 | grad norm: 0.436 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 10:41:05] iteration   179400/  500000 | consumed samples:     11481600 | elapsed time per iteration (ms): 618.9 | learning rate: 6.786924E-05 | global batch size:    64 | lm loss: 3.071249E+00 | loss scale: 1048576.0 | grad norm: 0.441 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 10:42:07] iteration   179500/  500000 | consumed samples:     11488000 | elapsed time per iteration (ms): 618.1 | learning rate: 6.780088E-05 | global batch size:    64 | lm loss: 3.061426E+00 | loss scale: 1048576.0 | grad norm: 0.425 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 10:43:09] iteration   179600/  500000 | consumed samples:     11494400 | elapsed time per iteration (ms): 619.7 | learning rate: 6.773253E-05 | global batch size:    64 | lm loss: 3.050119E+00 | loss scale: 1048576.0 | grad norm: 0.442 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 10:44:11] iteration   179700/  500000 | consumed samples:     11500800 | elapsed time per iteration (ms): 618.8 | learning rate: 6.766419E-05 | global batch size:    64 | lm loss: 3.067491E+00 | loss scale: 1048576.0 | grad norm: 0.428 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 10:45:13] iteration   179800/  500000 | consumed samples:     11507200 | elapsed time per iteration (ms): 618.8 | learning rate: 6.759587E-05 | global batch size:    64 | lm loss: 3.047347E+00 | loss scale: 1048576.0 | grad norm: 0.438 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 10:46:15] iteration   179900/  500000 | consumed samples:     11513600 | elapsed time per iteration (ms): 619.5 | learning rate: 6.752756E-05 | global batch size:    64 | lm loss: 3.065588E+00 | loss scale: 2097152.0 | grad norm: 0.428 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 10:47:17] iteration   180000/  500000 | consumed samples:     11520000 | elapsed time per iteration (ms): 621.3 | learning rate: 6.745926E-05 | global batch size:    64 | lm loss: 3.060540E+00 | loss scale: 2097152.0 | grad norm: 0.435 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2461.62, 2461.73)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 180000 | lm loss value: 3.669487E+00 | lm loss PPL: 3.923177E+01 | 
--------------------------------------------------------------------------------------------------
saving checkpoint at iteration  180000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-distribution in torch format
  successfully saved checkpoint at iteration  180000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-distribution
(min, max) time across ranks (ms):
    save-checkpoint ................................: (2366.74, 2366.75)
 [2024-06-25 10:48:24] iteration   180100/  500000 | consumed samples:     11526400 | elapsed time per iteration (ms): 619.0 | learning rate: 6.739097E-05 | global batch size:    64 | lm loss: 3.069569E+00 | loss scale: 2097152.0 | grad norm: 0.440 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 10:49:25] iteration   180200/  500000 | consumed samples:     11532800 | elapsed time per iteration (ms): 618.8 | learning rate: 6.732270E-05 | global batch size:    64 | lm loss: 3.074437E+00 | loss scale: 2097152.0 | grad norm: 0.423 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 10:50:27] iteration   180300/  500000 | consumed samples:     11539200 | elapsed time per iteration (ms): 619.6 | learning rate: 6.725443E-05 | global batch size:    64 | lm loss: 3.080005E+00 | loss scale: 2097152.0 | grad norm: 0.438 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 10:51:29] iteration   180400/  500000 | consumed samples:     11545600 | elapsed time per iteration (ms): 618.6 | learning rate: 6.718618E-05 | global batch size:    64 | lm loss: 3.065438E+00 | loss scale: 2097152.0 | grad norm: 0.426 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 10:52:31] iteration   180500/  500000 | consumed samples:     11552000 | elapsed time per iteration (ms): 618.9 | learning rate: 6.711863E-05 | global batch size:    64 | lm loss: 3.072370E+00 | loss scale: 2097152.0 | grad norm: 0.451 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-25 10:53:33] iteration   180600/  500000 | consumed samples:     11558400 | elapsed time per iteration (ms): 619.4 | learning rate: 6.705109E-05 | global batch size:    64 | lm loss: 3.073996E+00 | loss scale: 1048576.0 | grad norm: 0.445 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-25 10:54:35] iteration   180700/  500000 | consumed samples:     11564800 | elapsed time per iteration (ms): 619.7 | learning rate: 6.698287E-05 | global batch size:    64 | lm loss: 3.074591E+00 | loss scale: 1048576.0 | grad norm: 0.437 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 10:55:37] iteration   180800/  500000 | consumed samples:     11571200 | elapsed time per iteration (ms): 617.6 | learning rate: 6.691468E-05 | global batch size:    64 | lm loss: 3.070007E+00 | loss scale: 1048576.0 | grad norm: 0.435 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 10:56:39] iteration   180900/  500000 | consumed samples:     11577600 | elapsed time per iteration (ms): 619.1 | learning rate: 6.684649E-05 | global batch size:    64 | lm loss: 3.058149E+00 | loss scale: 1048576.0 | grad norm: 0.440 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 10:57:41] iteration   181000/  500000 | consumed samples:     11584000 | elapsed time per iteration (ms): 618.2 | learning rate: 6.677832E-05 | global batch size:    64 | lm loss: 3.064643E+00 | loss scale: 1048576.0 | grad norm: 0.437 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2462.40, 2462.53)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 181000 | lm loss value: 3.732809E+00 | lm loss PPL: 4.179635E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-25 10:58:45] iteration   181100/  500000 | consumed samples:     11590400 | elapsed time per iteration (ms): 619.3 | learning rate: 6.671015E-05 | global batch size:    64 | lm loss: 3.054245E+00 | loss scale: 1048576.0 | grad norm: 0.429 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 10:59:47] iteration   181200/  500000 | consumed samples:     11596800 | elapsed time per iteration (ms): 619.5 | learning rate: 6.664201E-05 | global batch size:    64 | lm loss: 3.070070E+00 | loss scale: 1048576.0 | grad norm: 0.439 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 11:00:49] iteration   181300/  500000 | consumed samples:     11603200 | elapsed time per iteration (ms): 620.6 | learning rate: 6.657387E-05 | global batch size:    64 | lm loss: 3.073603E+00 | loss scale: 1048576.0 | grad norm: 0.438 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 11:01:51] iteration   181400/  500000 | consumed samples:     11609600 | elapsed time per iteration (ms): 618.1 | learning rate: 6.650575E-05 | global batch size:    64 | lm loss: 3.068845E+00 | loss scale: 1048576.0 | grad norm: 0.416 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 11:02:53] iteration   181500/  500000 | consumed samples:     11616000 | elapsed time per iteration (ms): 621.1 | learning rate: 6.643764E-05 | global batch size:    64 | lm loss: 3.062191E+00 | loss scale: 1048576.0 | grad norm: 0.432 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 11:03:55] iteration   181600/  500000 | consumed samples:     11622400 | elapsed time per iteration (ms): 618.2 | learning rate: 6.637023E-05 | global batch size:    64 | lm loss: 3.059882E+00 | loss scale: 2097152.0 | grad norm: 0.449 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-25 11:04:57] iteration   181700/  500000 | consumed samples:     11628800 | elapsed time per iteration (ms): 620.5 | learning rate: 6.630283E-05 | global batch size:    64 | lm loss: 3.065530E+00 | loss scale: 1048576.0 | grad norm: 0.427 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-25 11:05:59] iteration   181800/  500000 | consumed samples:     11635200 | elapsed time per iteration (ms): 619.5 | learning rate: 6.623476E-05 | global batch size:    64 | lm loss: 3.057894E+00 | loss scale: 1048576.0 | grad norm: 0.442 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 11:07:01] iteration   181900/  500000 | consumed samples:     11641600 | elapsed time per iteration (ms): 621.8 | learning rate: 6.616671E-05 | global batch size:    64 | lm loss: 3.065267E+00 | loss scale: 1048576.0 | grad norm: 0.447 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 11:08:03] iteration   182000/  500000 | consumed samples:     11648000 | elapsed time per iteration (ms): 617.7 | learning rate: 6.609867E-05 | global batch size:    64 | lm loss: 3.053712E+00 | loss scale: 1048576.0 | grad norm: 0.441 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2465.43, 2465.50)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 182000 | lm loss value: 3.712080E+00 | lm loss PPL: 4.093887E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-25 11:09:07] iteration   182100/  500000 | consumed samples:     11654400 | elapsed time per iteration (ms): 619.0 | learning rate: 6.603064E-05 | global batch size:    64 | lm loss: 3.049034E+00 | loss scale: 1048576.0 | grad norm: 0.440 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 11:10:09] iteration   182200/  500000 | consumed samples:     11660800 | elapsed time per iteration (ms): 617.4 | learning rate: 6.596263E-05 | global batch size:    64 | lm loss: 3.061006E+00 | loss scale: 1048576.0 | grad norm: 0.453 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 11:11:11] iteration   182300/  500000 | consumed samples:     11667200 | elapsed time per iteration (ms): 620.4 | learning rate: 6.589463E-05 | global batch size:    64 | lm loss: 3.063963E+00 | loss scale: 1048576.0 | grad norm: 0.440 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 11:12:13] iteration   182400/  500000 | consumed samples:     11673600 | elapsed time per iteration (ms): 620.1 | learning rate: 6.582664E-05 | global batch size:    64 | lm loss: 3.054279E+00 | loss scale: 1048576.0 | grad norm: 0.418 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 11:13:15] iteration   182500/  500000 | consumed samples:     11680000 | elapsed time per iteration (ms): 619.6 | learning rate: 6.575867E-05 | global batch size:    64 | lm loss: 3.060409E+00 | loss scale: 1048576.0 | grad norm: 0.436 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 11:14:17] iteration   182600/  500000 | consumed samples:     11686400 | elapsed time per iteration (ms): 619.3 | learning rate: 6.569071E-05 | global batch size:    64 | lm loss: 3.048438E+00 | loss scale: 1048576.0 | grad norm: 0.422 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 11:15:19] iteration   182700/  500000 | consumed samples:     11692800 | elapsed time per iteration (ms): 619.0 | learning rate: 6.562277E-05 | global batch size:    64 | lm loss: 3.049938E+00 | loss scale: 2097152.0 | grad norm: 0.445 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 11:16:21] iteration   182800/  500000 | consumed samples:     11699200 | elapsed time per iteration (ms): 619.9 | learning rate: 6.555484E-05 | global batch size:    64 | lm loss: 3.051224E+00 | loss scale: 2097152.0 | grad norm: 0.424 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 11:17:23] iteration   182900/  500000 | consumed samples:     11705600 | elapsed time per iteration (ms): 619.7 | learning rate: 6.548692E-05 | global batch size:    64 | lm loss: 3.058632E+00 | loss scale: 2097152.0 | grad norm: 0.422 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 11:18:24] iteration   183000/  500000 | consumed samples:     11712000 | elapsed time per iteration (ms): 618.6 | learning rate: 6.542038E-05 | global batch size:    64 | lm loss: 3.057098E+00 | loss scale: 1048576.0 | grad norm: 0.431 | number of skipped iterations:   2 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2463.29, 2463.34)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 183000 | lm loss value: 3.704232E+00 | lm loss PPL: 4.061883E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-25 11:19:29] iteration   183100/  500000 | consumed samples:     11718400 | elapsed time per iteration (ms): 621.3 | learning rate: 6.535249E-05 | global batch size:    64 | lm loss: 3.069806E+00 | loss scale: 1048576.0 | grad norm: 0.435 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 11:20:31] iteration   183200/  500000 | consumed samples:     11724800 | elapsed time per iteration (ms): 619.2 | learning rate: 6.528462E-05 | global batch size:    64 | lm loss: 3.077000E+00 | loss scale: 1048576.0 | grad norm: 0.443 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 11:21:33] iteration   183300/  500000 | consumed samples:     11731200 | elapsed time per iteration (ms): 620.0 | learning rate: 6.521676E-05 | global batch size:    64 | lm loss: 3.071725E+00 | loss scale: 1048576.0 | grad norm: 0.461 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 11:22:35] iteration   183400/  500000 | consumed samples:     11737600 | elapsed time per iteration (ms): 619.4 | learning rate: 6.514892E-05 | global batch size:    64 | lm loss: 3.060870E+00 | loss scale: 1048576.0 | grad norm: 0.435 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 11:23:37] iteration   183500/  500000 | consumed samples:     11744000 | elapsed time per iteration (ms): 617.2 | learning rate: 6.508109E-05 | global batch size:    64 | lm loss: 3.045751E+00 | loss scale: 1048576.0 | grad norm: 0.442 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 11:24:38] iteration   183600/  500000 | consumed samples:     11750400 | elapsed time per iteration (ms): 618.5 | learning rate: 6.501328E-05 | global batch size:    64 | lm loss: 3.052733E+00 | loss scale: 1048576.0 | grad norm: 0.418 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 11:25:40] iteration   183700/  500000 | consumed samples:     11756800 | elapsed time per iteration (ms): 617.9 | learning rate: 6.494548E-05 | global batch size:    64 | lm loss: 3.062468E+00 | loss scale: 1048576.0 | grad norm: 0.437 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 11:26:42] iteration   183800/  500000 | consumed samples:     11763200 | elapsed time per iteration (ms): 618.1 | learning rate: 6.487769E-05 | global batch size:    64 | lm loss: 3.064919E+00 | loss scale: 1048576.0 | grad norm: 0.448 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 11:27:44] iteration   183900/  500000 | consumed samples:     11769600 | elapsed time per iteration (ms): 620.3 | learning rate: 6.480992E-05 | global batch size:    64 | lm loss: 3.064569E+00 | loss scale: 1048576.0 | grad norm: 0.440 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 11:28:46] iteration   184000/  500000 | consumed samples:     11776000 | elapsed time per iteration (ms): 618.5 | learning rate: 6.474217E-05 | global batch size:    64 | lm loss: 3.062656E+00 | loss scale: 2097152.0 | grad norm: 0.426 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2463.02, 2463.05)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 184000 | lm loss value: 3.698283E+00 | lm loss PPL: 4.037790E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-25 11:29:50] iteration   184100/  500000 | consumed samples:     11782400 | elapsed time per iteration (ms): 619.1 | learning rate: 6.467510E-05 | global batch size:    64 | lm loss: 3.063299E+00 | loss scale: 2097152.0 | grad norm: 0.435 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-25 11:30:52] iteration   184200/  500000 | consumed samples:     11788800 | elapsed time per iteration (ms): 618.5 | learning rate: 6.460806E-05 | global batch size:    64 | lm loss: 3.053165E+00 | loss scale: 1048576.0 | grad norm: 0.436 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-25 11:31:54] iteration   184300/  500000 | consumed samples:     11795200 | elapsed time per iteration (ms): 618.3 | learning rate: 6.454035E-05 | global batch size:    64 | lm loss: 3.064641E+00 | loss scale: 1048576.0 | grad norm: 0.452 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 11:32:56] iteration   184400/  500000 | consumed samples:     11801600 | elapsed time per iteration (ms): 621.9 | learning rate: 6.447265E-05 | global batch size:    64 | lm loss: 3.050435E+00 | loss scale: 1048576.0 | grad norm: 0.418 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 11:33:58] iteration   184500/  500000 | consumed samples:     11808000 | elapsed time per iteration (ms): 618.8 | learning rate: 6.440497E-05 | global batch size:    64 | lm loss: 3.064832E+00 | loss scale: 1048576.0 | grad norm: 0.429 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 11:35:00] iteration   184600/  500000 | consumed samples:     11814400 | elapsed time per iteration (ms): 617.4 | learning rate: 6.433731E-05 | global batch size:    64 | lm loss: 3.050479E+00 | loss scale: 1048576.0 | grad norm: 0.448 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 11:36:02] iteration   184700/  500000 | consumed samples:     11820800 | elapsed time per iteration (ms): 618.3 | learning rate: 6.426966E-05 | global batch size:    64 | lm loss: 3.066390E+00 | loss scale: 1048576.0 | grad norm: 0.453 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 11:37:04] iteration   184800/  500000 | consumed samples:     11827200 | elapsed time per iteration (ms): 619.3 | learning rate: 6.420203E-05 | global batch size:    64 | lm loss: 3.054465E+00 | loss scale: 1048576.0 | grad norm: 0.443 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 11:38:05] iteration   184900/  500000 | consumed samples:     11833600 | elapsed time per iteration (ms): 618.2 | learning rate: 6.413441E-05 | global batch size:    64 | lm loss: 3.044790E+00 | loss scale: 1048576.0 | grad norm: 0.444 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 11:39:07] iteration   185000/  500000 | consumed samples:     11840000 | elapsed time per iteration (ms): 619.7 | learning rate: 6.406681E-05 | global batch size:    64 | lm loss: 3.047956E+00 | loss scale: 1048576.0 | grad norm: 0.447 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2462.36, 2462.36)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 185000 | lm loss value: 3.781829E+00 | lm loss PPL: 4.389624E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-25 11:40:12] iteration   185100/  500000 | consumed samples:     11846400 | elapsed time per iteration (ms): 619.2 | learning rate: 6.399922E-05 | global batch size:    64 | lm loss: 3.058138E+00 | loss scale: 1048576.0 | grad norm: 0.426 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 11:41:14] iteration   185200/  500000 | consumed samples:     11852800 | elapsed time per iteration (ms): 618.7 | learning rate: 6.393165E-05 | global batch size:    64 | lm loss: 3.067303E+00 | loss scale: 2097152.0 | grad norm: 0.431 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 11:42:15] iteration   185300/  500000 | consumed samples:     11859200 | elapsed time per iteration (ms): 618.1 | learning rate: 6.386409E-05 | global batch size:    64 | lm loss: 3.056828E+00 | loss scale: 2097152.0 | grad norm: 0.438 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 11:43:17] iteration   185400/  500000 | consumed samples:     11865600 | elapsed time per iteration (ms): 617.9 | learning rate: 6.379655E-05 | global batch size:    64 | lm loss: 3.071412E+00 | loss scale: 2097152.0 | grad norm: 0.441 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 11:44:19] iteration   185500/  500000 | consumed samples:     11872000 | elapsed time per iteration (ms): 620.0 | learning rate: 6.372971E-05 | global batch size:    64 | lm loss: 3.055700E+00 | loss scale: 2097152.0 | grad norm: 0.433 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-25 11:45:21] iteration   185600/  500000 | consumed samples:     11878400 | elapsed time per iteration (ms): 621.6 | learning rate: 6.366220E-05 | global batch size:    64 | lm loss: 3.063259E+00 | loss scale: 2097152.0 | grad norm: 0.430 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 11:46:23] iteration   185700/  500000 | consumed samples:     11884800 | elapsed time per iteration (ms): 619.6 | learning rate: 6.359471E-05 | global batch size:    64 | lm loss: 3.080915E+00 | loss scale: 2097152.0 | grad norm: 0.445 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 11:47:25] iteration   185800/  500000 | consumed samples:     11891200 | elapsed time per iteration (ms): 617.2 | learning rate: 6.352791E-05 | global batch size:    64 | lm loss: 3.042563E+00 | loss scale: 1048576.0 | grad norm: 0.436 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-25 11:48:27] iteration   185900/  500000 | consumed samples:     11897600 | elapsed time per iteration (ms): 617.4 | learning rate: 6.346045E-05 | global batch size:    64 | lm loss: 3.063169E+00 | loss scale: 1048576.0 | grad norm: 0.450 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 11:49:29] iteration   186000/  500000 | consumed samples:     11904000 | elapsed time per iteration (ms): 619.2 | learning rate: 6.339301E-05 | global batch size:    64 | lm loss: 3.053473E+00 | loss scale: 1048576.0 | grad norm: 0.433 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2464.57, 2464.70)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 186000 | lm loss value: 3.680897E+00 | lm loss PPL: 3.968195E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-25 11:50:33] iteration   186100/  500000 | consumed samples:     11910400 | elapsed time per iteration (ms): 618.4 | learning rate: 6.332558E-05 | global batch size:    64 | lm loss: 3.048428E+00 | loss scale: 1048576.0 | grad norm: 0.437 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 11:51:35] iteration   186200/  500000 | consumed samples:     11916800 | elapsed time per iteration (ms): 620.3 | learning rate: 6.325817E-05 | global batch size:    64 | lm loss: 3.046722E+00 | loss scale: 1048576.0 | grad norm: 0.436 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 11:52:37] iteration   186300/  500000 | consumed samples:     11923200 | elapsed time per iteration (ms): 621.0 | learning rate: 6.319078E-05 | global batch size:    64 | lm loss: 3.070302E+00 | loss scale: 1048576.0 | grad norm: 0.454 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 11:53:39] iteration   186400/  500000 | consumed samples:     11929600 | elapsed time per iteration (ms): 618.4 | learning rate: 6.312340E-05 | global batch size:    64 | lm loss: 3.050417E+00 | loss scale: 1048576.0 | grad norm: 0.425 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 11:54:41] iteration   186500/  500000 | consumed samples:     11936000 | elapsed time per iteration (ms): 618.0 | learning rate: 6.305604E-05 | global batch size:    64 | lm loss: 3.064994E+00 | loss scale: 1048576.0 | grad norm: 0.432 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 11:55:43] iteration   186600/  500000 | consumed samples:     11942400 | elapsed time per iteration (ms): 621.0 | learning rate: 6.298869E-05 | global batch size:    64 | lm loss: 3.058039E+00 | loss scale: 1048576.0 | grad norm: 0.440 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 11:56:45] iteration   186700/  500000 | consumed samples:     11948800 | elapsed time per iteration (ms): 619.6 | learning rate: 6.292137E-05 | global batch size:    64 | lm loss: 3.044973E+00 | loss scale: 1048576.0 | grad norm: 0.441 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 11:57:47] iteration   186800/  500000 | consumed samples:     11955200 | elapsed time per iteration (ms): 617.6 | learning rate: 6.285473E-05 | global batch size:    64 | lm loss: 3.046802E+00 | loss scale: 2097152.0 | grad norm: 0.440 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-25 11:58:49] iteration   186900/  500000 | consumed samples:     11961600 | elapsed time per iteration (ms): 620.5 | learning rate: 6.278811E-05 | global batch size:    64 | lm loss: 3.042055E+00 | loss scale: 1048576.0 | grad norm: 0.435 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-25 11:59:50] iteration   187000/  500000 | consumed samples:     11968000 | elapsed time per iteration (ms): 617.8 | learning rate: 6.272083E-05 | global batch size:    64 | lm loss: 3.065574E+00 | loss scale: 1048576.0 | grad norm: 0.434 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2464.44, 2464.48)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 187000 | lm loss value: 3.714119E+00 | lm loss PPL: 4.102245E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-25 12:00:55] iteration   187100/  500000 | consumed samples:     11974400 | elapsed time per iteration (ms): 619.2 | learning rate: 6.265424E-05 | global batch size:    64 | lm loss: 3.056298E+00 | loss scale: 524288.0 | grad norm: 0.444 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-25 12:01:57] iteration   187200/  500000 | consumed samples:     11980800 | elapsed time per iteration (ms): 617.4 | learning rate: 6.258700E-05 | global batch size:    64 | lm loss: 3.052542E+00 | loss scale: 524288.0 | grad norm: 0.438 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 12:02:59] iteration   187300/  500000 | consumed samples:     11987200 | elapsed time per iteration (ms): 619.9 | learning rate: 6.251978E-05 | global batch size:    64 | lm loss: 3.047536E+00 | loss scale: 524288.0 | grad norm: 0.434 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 12:04:00] iteration   187400/  500000 | consumed samples:     11993600 | elapsed time per iteration (ms): 618.4 | learning rate: 6.245257E-05 | global batch size:    64 | lm loss: 3.054868E+00 | loss scale: 524288.0 | grad norm: 0.438 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 12:05:02] iteration   187500/  500000 | consumed samples:     12000000 | elapsed time per iteration (ms): 620.0 | learning rate: 6.238538E-05 | global batch size:    64 | lm loss: 3.050941E+00 | loss scale: 524288.0 | grad norm: 0.457 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 12:06:04] iteration   187600/  500000 | consumed samples:     12006400 | elapsed time per iteration (ms): 619.2 | learning rate: 6.231820E-05 | global batch size:    64 | lm loss: 3.049052E+00 | loss scale: 524288.0 | grad norm: 0.422 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 12:07:06] iteration   187700/  500000 | consumed samples:     12012800 | elapsed time per iteration (ms): 618.4 | learning rate: 6.225104E-05 | global batch size:    64 | lm loss: 3.050516E+00 | loss scale: 524288.0 | grad norm: 0.434 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 12:08:08] iteration   187800/  500000 | consumed samples:     12019200 | elapsed time per iteration (ms): 617.6 | learning rate: 6.218391E-05 | global batch size:    64 | lm loss: 3.081259E+00 | loss scale: 524288.0 | grad norm: 0.428 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 12:09:10] iteration   187900/  500000 | consumed samples:     12025600 | elapsed time per iteration (ms): 619.2 | learning rate: 6.211678E-05 | global batch size:    64 | lm loss: 3.033499E+00 | loss scale: 524288.0 | grad norm: 0.439 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 12:10:12] iteration   188000/  500000 | consumed samples:     12032000 | elapsed time per iteration (ms): 621.5 | learning rate: 6.204968E-05 | global batch size:    64 | lm loss: 3.056094E+00 | loss scale: 524288.0 | grad norm: 0.438 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2467.93, 2467.97)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 188000 | lm loss value: 3.700671E+00 | lm loss PPL: 4.047447E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-25 12:11:17] iteration   188100/  500000 | consumed samples:     12038400 | elapsed time per iteration (ms): 621.9 | learning rate: 6.198259E-05 | global batch size:    64 | lm loss: 3.063411E+00 | loss scale: 1048576.0 | grad norm: 0.433 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 12:12:19] iteration   188200/  500000 | consumed samples:     12044800 | elapsed time per iteration (ms): 620.2 | learning rate: 6.191552E-05 | global batch size:    64 | lm loss: 3.049575E+00 | loss scale: 1048576.0 | grad norm: 0.447 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 12:13:21] iteration   188300/  500000 | consumed samples:     12051200 | elapsed time per iteration (ms): 620.3 | learning rate: 6.184847E-05 | global batch size:    64 | lm loss: 3.062791E+00 | loss scale: 1048576.0 | grad norm: 0.437 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 12:14:23] iteration   188400/  500000 | consumed samples:     12057600 | elapsed time per iteration (ms): 619.1 | learning rate: 6.178144E-05 | global batch size:    64 | lm loss: 3.058973E+00 | loss scale: 1048576.0 | grad norm: 0.441 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 12:15:25] iteration   188500/  500000 | consumed samples:     12064000 | elapsed time per iteration (ms): 619.3 | learning rate: 6.171442E-05 | global batch size:    64 | lm loss: 3.059766E+00 | loss scale: 1048576.0 | grad norm: 0.439 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 12:16:26] iteration   188600/  500000 | consumed samples:     12070400 | elapsed time per iteration (ms): 618.4 | learning rate: 6.164743E-05 | global batch size:    64 | lm loss: 3.055475E+00 | loss scale: 1048576.0 | grad norm: 0.436 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 12:17:28] iteration   188700/  500000 | consumed samples:     12076800 | elapsed time per iteration (ms): 616.3 | learning rate: 6.158045E-05 | global batch size:    64 | lm loss: 3.052521E+00 | loss scale: 1048576.0 | grad norm: 0.435 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 12:18:30] iteration   188800/  500000 | consumed samples:     12083200 | elapsed time per iteration (ms): 619.3 | learning rate: 6.151349E-05 | global batch size:    64 | lm loss: 3.050117E+00 | loss scale: 1048576.0 | grad norm: 0.451 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 12:19:32] iteration   188900/  500000 | consumed samples:     12089600 | elapsed time per iteration (ms): 619.0 | learning rate: 6.144654E-05 | global batch size:    64 | lm loss: 3.057864E+00 | loss scale: 1048576.0 | grad norm: 0.439 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 12:20:34] iteration   189000/  500000 | consumed samples:     12096000 | elapsed time per iteration (ms): 619.8 | learning rate: 6.137962E-05 | global batch size:    64 | lm loss: 3.054213E+00 | loss scale: 1048576.0 | grad norm: 0.447 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2462.50, 2462.68)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 189000 | lm loss value: 3.673182E+00 | lm loss PPL: 3.937700E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-25 12:21:38] iteration   189100/  500000 | consumed samples:     12102400 | elapsed time per iteration (ms): 619.8 | learning rate: 6.131271E-05 | global batch size:    64 | lm loss: 3.052084E+00 | loss scale: 2097152.0 | grad norm: 0.439 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 12:22:40] iteration   189200/  500000 | consumed samples:     12108800 | elapsed time per iteration (ms): 620.6 | learning rate: 6.124583E-05 | global batch size:    64 | lm loss: 3.066253E+00 | loss scale: 2097152.0 | grad norm: 0.444 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 12:23:42] iteration   189300/  500000 | consumed samples:     12115200 | elapsed time per iteration (ms): 617.5 | learning rate: 6.117962E-05 | global batch size:    64 | lm loss: 3.051002E+00 | loss scale: 2097152.0 | grad norm: 0.445 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-25 12:24:44] iteration   189400/  500000 | consumed samples:     12121600 | elapsed time per iteration (ms): 619.3 | learning rate: 6.111277E-05 | global batch size:    64 | lm loss: 3.060667E+00 | loss scale: 2097152.0 | grad norm: 0.456 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 12:25:46] iteration   189500/  500000 | consumed samples:     12128000 | elapsed time per iteration (ms): 619.5 | learning rate: 6.104661E-05 | global batch size:    64 | lm loss: 3.056262E+00 | loss scale: 1048576.0 | grad norm: 0.438 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-25 12:26:48] iteration   189600/  500000 | consumed samples:     12134400 | elapsed time per iteration (ms): 619.8 | learning rate: 6.097979E-05 | global batch size:    64 | lm loss: 3.055172E+00 | loss scale: 1048576.0 | grad norm: 0.436 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 12:27:50] iteration   189700/  500000 | consumed samples:     12140800 | elapsed time per iteration (ms): 619.4 | learning rate: 6.091300E-05 | global batch size:    64 | lm loss: 3.070764E+00 | loss scale: 1048576.0 | grad norm: 0.442 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 12:28:52] iteration   189800/  500000 | consumed samples:     12147200 | elapsed time per iteration (ms): 621.2 | learning rate: 6.084622E-05 | global batch size:    64 | lm loss: 3.055949E+00 | loss scale: 1048576.0 | grad norm: 0.432 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 12:29:54] iteration   189900/  500000 | consumed samples:     12153600 | elapsed time per iteration (ms): 620.9 | learning rate: 6.077946E-05 | global batch size:    64 | lm loss: 3.041603E+00 | loss scale: 1048576.0 | grad norm: 0.439 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 12:30:56] iteration   190000/  500000 | consumed samples:     12160000 | elapsed time per iteration (ms): 619.4 | learning rate: 6.071273E-05 | global batch size:    64 | lm loss: 3.050592E+00 | loss scale: 1048576.0 | grad norm: 0.436 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2464.13, 2464.16)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 190000 | lm loss value: 3.676602E+00 | lm loss PPL: 3.951191E+01 | 
--------------------------------------------------------------------------------------------------
saving checkpoint at iteration  190000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-distribution in torch format
  successfully saved checkpoint at iteration  190000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-distribution
(min, max) time across ranks (ms):
    save-checkpoint ................................: (2359.54, 2359.60)
 [2024-06-25 12:32:03] iteration   190100/  500000 | consumed samples:     12166400 | elapsed time per iteration (ms): 618.2 | learning rate: 6.064601E-05 | global batch size:    64 | lm loss: 3.056613E+00 | loss scale: 1048576.0 | grad norm: 0.443 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 12:33:05] iteration   190200/  500000 | consumed samples:     12172800 | elapsed time per iteration (ms): 618.7 | learning rate: 6.057930E-05 | global batch size:    64 | lm loss: 3.055454E+00 | loss scale: 1048576.0 | grad norm: 0.437 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 12:34:07] iteration   190300/  500000 | consumed samples:     12179200 | elapsed time per iteration (ms): 621.2 | learning rate: 6.051262E-05 | global batch size:    64 | lm loss: 3.060676E+00 | loss scale: 1048576.0 | grad norm: 0.451 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 12:35:09] iteration   190400/  500000 | consumed samples:     12185600 | elapsed time per iteration (ms): 619.4 | learning rate: 6.044596E-05 | global batch size:    64 | lm loss: 3.043680E+00 | loss scale: 1048576.0 | grad norm: 0.440 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 12:36:10] iteration   190500/  500000 | consumed samples:     12192000 | elapsed time per iteration (ms): 617.8 | learning rate: 6.037932E-05 | global batch size:    64 | lm loss: 3.044068E+00 | loss scale: 2097152.0 | grad norm: 0.443 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 12:37:12] iteration   190600/  500000 | consumed samples:     12198400 | elapsed time per iteration (ms): 620.0 | learning rate: 6.031269E-05 | global batch size:    64 | lm loss: 3.052388E+00 | loss scale: 2097152.0 | grad norm: 0.433 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 12:38:14] iteration   190700/  500000 | consumed samples:     12204800 | elapsed time per iteration (ms): 619.2 | learning rate: 6.024609E-05 | global batch size:    64 | lm loss: 3.055246E+00 | loss scale: 2097152.0 | grad norm: 0.430 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 12:39:16] iteration   190800/  500000 | consumed samples:     12211200 | elapsed time per iteration (ms): 617.9 | learning rate: 6.017950E-05 | global batch size:    64 | lm loss: 3.065589E+00 | loss scale: 2097152.0 | grad norm: 0.440 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 12:40:18] iteration   190900/  500000 | consumed samples:     12217600 | elapsed time per iteration (ms): 618.6 | learning rate: 6.011360E-05 | global batch size:    64 | lm loss: 3.046347E+00 | loss scale: 2097152.0 | grad norm: 0.438 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-25 12:41:20] iteration   191000/  500000 | consumed samples:     12224000 | elapsed time per iteration (ms): 619.5 | learning rate: 6.004705E-05 | global batch size:    64 | lm loss: 3.062323E+00 | loss scale: 2097152.0 | grad norm: 0.440 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2463.13, 2463.22)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 191000 | lm loss value: 3.696330E+00 | lm loss PPL: 4.029915E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-25 12:42:24] iteration   191100/  500000 | consumed samples:     12230400 | elapsed time per iteration (ms): 619.8 | learning rate: 5.998053E-05 | global batch size:    64 | lm loss: 3.047091E+00 | loss scale: 2097152.0 | grad norm: 0.434 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 12:43:26] iteration   191200/  500000 | consumed samples:     12236800 | elapsed time per iteration (ms): 620.1 | learning rate: 5.991402E-05 | global batch size:    64 | lm loss: 3.053852E+00 | loss scale: 2097152.0 | grad norm: 0.426 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 12:44:28] iteration   191300/  500000 | consumed samples:     12243200 | elapsed time per iteration (ms): 621.0 | learning rate: 5.984820E-05 | global batch size:    64 | lm loss: 3.049178E+00 | loss scale: 1048576.0 | grad norm: 0.443 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-25 12:45:30] iteration   191400/  500000 | consumed samples:     12249600 | elapsed time per iteration (ms): 619.4 | learning rate: 5.978173E-05 | global batch size:    64 | lm loss: 3.066753E+00 | loss scale: 1048576.0 | grad norm: 0.442 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 12:46:32] iteration   191500/  500000 | consumed samples:     12256000 | elapsed time per iteration (ms): 620.5 | learning rate: 5.971528E-05 | global batch size:    64 | lm loss: 3.040951E+00 | loss scale: 1048576.0 | grad norm: 0.442 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 12:47:34] iteration   191600/  500000 | consumed samples:     12262400 | elapsed time per iteration (ms): 618.3 | learning rate: 5.964885E-05 | global batch size:    64 | lm loss: 3.049875E+00 | loss scale: 1048576.0 | grad norm: 0.436 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 12:48:36] iteration   191700/  500000 | consumed samples:     12268800 | elapsed time per iteration (ms): 619.7 | learning rate: 5.958245E-05 | global batch size:    64 | lm loss: 3.044613E+00 | loss scale: 1048576.0 | grad norm: 0.433 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 12:49:38] iteration   191800/  500000 | consumed samples:     12275200 | elapsed time per iteration (ms): 619.0 | learning rate: 5.951606E-05 | global batch size:    64 | lm loss: 3.052641E+00 | loss scale: 1048576.0 | grad norm: 0.435 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 12:50:40] iteration   191900/  500000 | consumed samples:     12281600 | elapsed time per iteration (ms): 618.6 | learning rate: 5.944969E-05 | global batch size:    64 | lm loss: 3.055113E+00 | loss scale: 1048576.0 | grad norm: 0.448 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 12:51:42] iteration   192000/  500000 | consumed samples:     12288000 | elapsed time per iteration (ms): 618.7 | learning rate: 5.938334E-05 | global batch size:    64 | lm loss: 3.046205E+00 | loss scale: 1048576.0 | grad norm: 0.436 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2462.67, 2462.76)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 192000 | lm loss value: 3.755319E+00 | lm loss PPL: 4.274785E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-25 12:52:46] iteration   192100/  500000 | consumed samples:     12294400 | elapsed time per iteration (ms): 619.8 | learning rate: 5.931702E-05 | global batch size:    64 | lm loss: 3.058410E+00 | loss scale: 1048576.0 | grad norm: 0.440 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 12:53:48] iteration   192200/  500000 | consumed samples:     12300800 | elapsed time per iteration (ms): 619.8 | learning rate: 5.925071E-05 | global batch size:    64 | lm loss: 3.069142E+00 | loss scale: 1048576.0 | grad norm: 0.443 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 12:54:50] iteration   192300/  500000 | consumed samples:     12307200 | elapsed time per iteration (ms): 619.2 | learning rate: 5.918442E-05 | global batch size:    64 | lm loss: 3.058027E+00 | loss scale: 2097152.0 | grad norm: 0.437 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 12:55:52] iteration   192400/  500000 | consumed samples:     12313600 | elapsed time per iteration (ms): 619.5 | learning rate: 5.911882E-05 | global batch size:    64 | lm loss: 3.044946E+00 | loss scale: 2097152.0 | grad norm: 0.449 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-25 12:56:54] iteration   192500/  500000 | consumed samples:     12320000 | elapsed time per iteration (ms): 619.1 | learning rate: 5.905257E-05 | global batch size:    64 | lm loss: 3.058159E+00 | loss scale: 2097152.0 | grad norm: 0.446 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 12:57:56] iteration   192600/  500000 | consumed samples:     12326400 | elapsed time per iteration (ms): 621.5 | learning rate: 5.898635E-05 | global batch size:    64 | lm loss: 3.043876E+00 | loss scale: 2097152.0 | grad norm: 0.426 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 12:58:58] iteration   192700/  500000 | consumed samples:     12332800 | elapsed time per iteration (ms): 618.2 | learning rate: 5.892014E-05 | global batch size:    64 | lm loss: 3.036021E+00 | loss scale: 2097152.0 | grad norm: 0.437 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 13:00:00] iteration   192800/  500000 | consumed samples:     12339200 | elapsed time per iteration (ms): 620.6 | learning rate: 5.885462E-05 | global batch size:    64 | lm loss: 3.061373E+00 | loss scale: 1048576.0 | grad norm: 0.438 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-25 13:01:02] iteration   192900/  500000 | consumed samples:     12345600 | elapsed time per iteration (ms): 619.7 | learning rate: 5.878846E-05 | global batch size:    64 | lm loss: 3.061194E+00 | loss scale: 1048576.0 | grad norm: 0.438 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 13:02:04] iteration   193000/  500000 | consumed samples:     12352000 | elapsed time per iteration (ms): 620.6 | learning rate: 5.872231E-05 | global batch size:    64 | lm loss: 3.039165E+00 | loss scale: 1048576.0 | grad norm: 0.451 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2463.65, 2463.71)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 193000 | lm loss value: 3.684157E+00 | lm loss PPL: 3.981154E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-25 13:03:09] iteration   193100/  500000 | consumed samples:     12358400 | elapsed time per iteration (ms): 620.2 | learning rate: 5.865619E-05 | global batch size:    64 | lm loss: 3.050778E+00 | loss scale: 1048576.0 | grad norm: 0.449 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 13:04:10] iteration   193200/  500000 | consumed samples:     12364800 | elapsed time per iteration (ms): 617.3 | learning rate: 5.859009E-05 | global batch size:    64 | lm loss: 3.049014E+00 | loss scale: 1048576.0 | grad norm: 0.436 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 13:05:12] iteration   193300/  500000 | consumed samples:     12371200 | elapsed time per iteration (ms): 619.6 | learning rate: 5.852401E-05 | global batch size:    64 | lm loss: 3.056205E+00 | loss scale: 1048576.0 | grad norm: 0.450 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 13:06:14] iteration   193400/  500000 | consumed samples:     12377600 | elapsed time per iteration (ms): 617.1 | learning rate: 5.845796E-05 | global batch size:    64 | lm loss: 3.035239E+00 | loss scale: 1048576.0 | grad norm: 0.435 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 13:07:16] iteration   193500/  500000 | consumed samples:     12384000 | elapsed time per iteration (ms): 617.9 | learning rate: 5.839192E-05 | global batch size:    64 | lm loss: 3.041573E+00 | loss scale: 1048576.0 | grad norm: 0.444 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 13:08:18] iteration   193600/  500000 | consumed samples:     12390400 | elapsed time per iteration (ms): 619.2 | learning rate: 5.832590E-05 | global batch size:    64 | lm loss: 3.046573E+00 | loss scale: 1048576.0 | grad norm: 0.448 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 13:09:20] iteration   193700/  500000 | consumed samples:     12396800 | elapsed time per iteration (ms): 618.3 | learning rate: 5.825991E-05 | global batch size:    64 | lm loss: 3.035574E+00 | loss scale: 1048576.0 | grad norm: 0.443 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 13:10:21] iteration   193800/  500000 | consumed samples:     12403200 | elapsed time per iteration (ms): 618.9 | learning rate: 5.819393E-05 | global batch size:    64 | lm loss: 3.056244E+00 | loss scale: 2097152.0 | grad norm: 0.436 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 13:11:23] iteration   193900/  500000 | consumed samples:     12409600 | elapsed time per iteration (ms): 618.4 | learning rate: 5.812930E-05 | global batch size:    64 | lm loss: 3.039811E+00 | loss scale: 1048576.0 | grad norm: 0.444 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-25 13:12:25] iteration   194000/  500000 | consumed samples:     12416000 | elapsed time per iteration (ms): 620.0 | learning rate: 5.806337E-05 | global batch size:    64 | lm loss: 3.039054E+00 | loss scale: 1048576.0 | grad norm: 0.474 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2462.24, 2462.27)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 194000 | lm loss value: 3.627118E+00 | lm loss PPL: 3.760430E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-25 13:13:30] iteration   194100/  500000 | consumed samples:     12422400 | elapsed time per iteration (ms): 619.3 | learning rate: 5.799746E-05 | global batch size:    64 | lm loss: 3.040769E+00 | loss scale: 1048576.0 | grad norm: 0.464 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 13:14:32] iteration   194200/  500000 | consumed samples:     12428800 | elapsed time per iteration (ms): 619.2 | learning rate: 5.793157E-05 | global batch size:    64 | lm loss: 3.029640E+00 | loss scale: 1048576.0 | grad norm: 0.445 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 13:15:34] iteration   194300/  500000 | consumed samples:     12435200 | elapsed time per iteration (ms): 619.6 | learning rate: 5.786571E-05 | global batch size:    64 | lm loss: 3.049517E+00 | loss scale: 1048576.0 | grad norm: 0.429 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 13:16:36] iteration   194400/  500000 | consumed samples:     12441600 | elapsed time per iteration (ms): 621.7 | learning rate: 5.779987E-05 | global batch size:    64 | lm loss: 3.035780E+00 | loss scale: 1048576.0 | grad norm: 0.450 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 13:17:38] iteration   194500/  500000 | consumed samples:     12448000 | elapsed time per iteration (ms): 620.0 | learning rate: 5.773404E-05 | global batch size:    64 | lm loss: 3.041659E+00 | loss scale: 1048576.0 | grad norm: 0.452 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 13:18:40] iteration   194600/  500000 | consumed samples:     12454400 | elapsed time per iteration (ms): 619.8 | learning rate: 5.766824E-05 | global batch size:    64 | lm loss: 3.058175E+00 | loss scale: 1048576.0 | grad norm: 0.445 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 13:19:42] iteration   194700/  500000 | consumed samples:     12460800 | elapsed time per iteration (ms): 619.2 | learning rate: 5.760246E-05 | global batch size:    64 | lm loss: 3.049323E+00 | loss scale: 1048576.0 | grad norm: 0.434 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 13:20:43] iteration   194800/  500000 | consumed samples:     12467200 | elapsed time per iteration (ms): 618.3 | learning rate: 5.753671E-05 | global batch size:    64 | lm loss: 3.051104E+00 | loss scale: 1048576.0 | grad norm: 0.440 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 13:21:45] iteration   194900/  500000 | consumed samples:     12473600 | elapsed time per iteration (ms): 619.2 | learning rate: 5.747097E-05 | global batch size:    64 | lm loss: 3.043842E+00 | loss scale: 2097152.0 | grad norm: 0.442 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 13:22:47] iteration   195000/  500000 | consumed samples:     12480000 | elapsed time per iteration (ms): 619.8 | learning rate: 5.740526E-05 | global batch size:    64 | lm loss: 3.041961E+00 | loss scale: 2097152.0 | grad norm: 0.444 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2463.07, 2463.35)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 195000 | lm loss value: 3.676634E+00 | lm loss PPL: 3.951316E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-25 13:23:52] iteration   195100/  500000 | consumed samples:     12486400 | elapsed time per iteration (ms): 619.1 | learning rate: 5.734023E-05 | global batch size:    64 | lm loss: 3.044655E+00 | loss scale: 2097152.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-25 13:24:54] iteration   195200/  500000 | consumed samples:     12492800 | elapsed time per iteration (ms): 619.2 | learning rate: 5.727522E-05 | global batch size:    64 | lm loss: 3.028948E+00 | loss scale: 1048576.0 | grad norm: 0.434 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-25 13:25:56] iteration   195300/  500000 | consumed samples:     12499200 | elapsed time per iteration (ms): 620.7 | learning rate: 5.720957E-05 | global batch size:    64 | lm loss: 3.060041E+00 | loss scale: 1048576.0 | grad norm: 0.440 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 13:26:58] iteration   195400/  500000 | consumed samples:     12505600 | elapsed time per iteration (ms): 620.0 | learning rate: 5.714395E-05 | global batch size:    64 | lm loss: 3.049731E+00 | loss scale: 1048576.0 | grad norm: 0.449 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 13:28:00] iteration   195500/  500000 | consumed samples:     12512000 | elapsed time per iteration (ms): 619.3 | learning rate: 5.707835E-05 | global batch size:    64 | lm loss: 3.062298E+00 | loss scale: 1048576.0 | grad norm: 0.455 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 13:29:02] iteration   195600/  500000 | consumed samples:     12518400 | elapsed time per iteration (ms): 618.8 | learning rate: 5.701277E-05 | global batch size:    64 | lm loss: 3.050659E+00 | loss scale: 1048576.0 | grad norm: 0.431 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 13:30:03] iteration   195700/  500000 | consumed samples:     12524800 | elapsed time per iteration (ms): 619.2 | learning rate: 5.694722E-05 | global batch size:    64 | lm loss: 3.046789E+00 | loss scale: 1048576.0 | grad norm: 0.454 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 13:31:05] iteration   195800/  500000 | consumed samples:     12531200 | elapsed time per iteration (ms): 618.3 | learning rate: 5.688168E-05 | global batch size:    64 | lm loss: 3.050980E+00 | loss scale: 1048576.0 | grad norm: 0.447 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 13:32:07] iteration   195900/  500000 | consumed samples:     12537600 | elapsed time per iteration (ms): 617.4 | learning rate: 5.681617E-05 | global batch size:    64 | lm loss: 3.038060E+00 | loss scale: 1048576.0 | grad norm: 0.454 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 13:33:09] iteration   196000/  500000 | consumed samples:     12544000 | elapsed time per iteration (ms): 618.5 | learning rate: 5.675069E-05 | global batch size:    64 | lm loss: 3.054059E+00 | loss scale: 1048576.0 | grad norm: 0.445 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2462.70, 2462.77)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 196000 | lm loss value: 3.693012E+00 | lm loss PPL: 4.016564E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-25 13:34:13] iteration   196100/  500000 | consumed samples:     12550400 | elapsed time per iteration (ms): 619.8 | learning rate: 5.668522E-05 | global batch size:    64 | lm loss: 3.048454E+00 | loss scale: 1048576.0 | grad norm: 0.450 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 13:35:15] iteration   196200/  500000 | consumed samples:     12556800 | elapsed time per iteration (ms): 618.2 | learning rate: 5.661978E-05 | global batch size:    64 | lm loss: 3.039535E+00 | loss scale: 2097152.0 | grad norm: 0.437 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 13:36:17] iteration   196300/  500000 | consumed samples:     12563200 | elapsed time per iteration (ms): 619.0 | learning rate: 5.655567E-05 | global batch size:    64 | lm loss: 3.055688E+00 | loss scale: 1048576.0 | grad norm: 0.438 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-25 13:37:19] iteration   196400/  500000 | consumed samples:     12569600 | elapsed time per iteration (ms): 618.3 | learning rate: 5.649027E-05 | global batch size:    64 | lm loss: 3.044906E+00 | loss scale: 1048576.0 | grad norm: 0.438 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 13:38:21] iteration   196500/  500000 | consumed samples:     12576000 | elapsed time per iteration (ms): 621.3 | learning rate: 5.642490E-05 | global batch size:    64 | lm loss: 3.059102E+00 | loss scale: 1048576.0 | grad norm: 0.450 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 13:39:23] iteration   196600/  500000 | consumed samples:     12582400 | elapsed time per iteration (ms): 619.0 | learning rate: 5.635955E-05 | global batch size:    64 | lm loss: 3.045282E+00 | loss scale: 1048576.0 | grad norm: 0.452 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 13:40:25] iteration   196700/  500000 | consumed samples:     12588800 | elapsed time per iteration (ms): 619.6 | learning rate: 5.629422E-05 | global batch size:    64 | lm loss: 3.031032E+00 | loss scale: 1048576.0 | grad norm: 0.443 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 13:41:27] iteration   196800/  500000 | consumed samples:     12595200 | elapsed time per iteration (ms): 620.1 | learning rate: 5.622892E-05 | global batch size:    64 | lm loss: 3.038672E+00 | loss scale: 1048576.0 | grad norm: 0.436 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 13:42:29] iteration   196900/  500000 | consumed samples:     12601600 | elapsed time per iteration (ms): 619.3 | learning rate: 5.616364E-05 | global batch size:    64 | lm loss: 3.044094E+00 | loss scale: 1048576.0 | grad norm: 0.449 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 13:43:31] iteration   197000/  500000 | consumed samples:     12608000 | elapsed time per iteration (ms): 618.2 | learning rate: 5.609838E-05 | global batch size:    64 | lm loss: 3.035325E+00 | loss scale: 1048576.0 | grad norm: 0.445 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2461.61, 2461.73)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 197000 | lm loss value: 3.751411E+00 | lm loss PPL: 4.258111E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-25 13:44:35] iteration   197100/  500000 | consumed samples:     12614400 | elapsed time per iteration (ms): 618.6 | learning rate: 5.603315E-05 | global batch size:    64 | lm loss: 3.041296E+00 | loss scale: 1048576.0 | grad norm: 0.440 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 13:45:37] iteration   197200/  500000 | consumed samples:     12620800 | elapsed time per iteration (ms): 618.3 | learning rate: 5.596794E-05 | global batch size:    64 | lm loss: 3.047740E+00 | loss scale: 1048576.0 | grad norm: 0.433 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 13:46:39] iteration   197300/  500000 | consumed samples:     12627200 | elapsed time per iteration (ms): 617.5 | learning rate: 5.590276E-05 | global batch size:    64 | lm loss: 3.051431E+00 | loss scale: 2097152.0 | grad norm: 0.452 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 13:47:40] iteration   197400/  500000 | consumed samples:     12633600 | elapsed time per iteration (ms): 618.5 | learning rate: 5.583760E-05 | global batch size:    64 | lm loss: 3.026816E+00 | loss scale: 2097152.0 | grad norm: 0.453 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 13:48:42] iteration   197500/  500000 | consumed samples:     12640000 | elapsed time per iteration (ms): 619.8 | learning rate: 5.577376E-05 | global batch size:    64 | lm loss: 3.050067E+00 | loss scale: 1048576.0 | grad norm: 0.445 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-25 13:49:44] iteration   197600/  500000 | consumed samples:     12646400 | elapsed time per iteration (ms): 619.7 | learning rate: 5.570865E-05 | global batch size:    64 | lm loss: 3.047274E+00 | loss scale: 1048576.0 | grad norm: 0.453 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 13:50:46] iteration   197700/  500000 | consumed samples:     12652800 | elapsed time per iteration (ms): 620.4 | learning rate: 5.564355E-05 | global batch size:    64 | lm loss: 3.057802E+00 | loss scale: 1048576.0 | grad norm: 0.445 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 13:51:49] iteration   197800/  500000 | consumed samples:     12659200 | elapsed time per iteration (ms): 622.1 | learning rate: 5.557849E-05 | global batch size:    64 | lm loss: 3.039043E+00 | loss scale: 1048576.0 | grad norm: 0.447 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 13:52:51] iteration   197900/  500000 | consumed samples:     12665600 | elapsed time per iteration (ms): 619.1 | learning rate: 5.551344E-05 | global batch size:    64 | lm loss: 3.052461E+00 | loss scale: 1048576.0 | grad norm: 0.434 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 13:53:52] iteration   198000/  500000 | consumed samples:     12672000 | elapsed time per iteration (ms): 618.9 | learning rate: 5.544843E-05 | global batch size:    64 | lm loss: 3.048310E+00 | loss scale: 1048576.0 | grad norm: 0.434 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2463.59, 2463.76)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 198000 | lm loss value: 3.711749E+00 | lm loss PPL: 4.092531E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-25 13:54:57] iteration   198100/  500000 | consumed samples:     12678400 | elapsed time per iteration (ms): 617.2 | learning rate: 5.538343E-05 | global batch size:    64 | lm loss: 3.044716E+00 | loss scale: 1048576.0 | grad norm: 0.440 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 13:55:59] iteration   198200/  500000 | consumed samples:     12684800 | elapsed time per iteration (ms): 619.5 | learning rate: 5.531846E-05 | global batch size:    64 | lm loss: 3.053007E+00 | loss scale: 1048576.0 | grad norm: 0.443 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 13:57:00] iteration   198300/  500000 | consumed samples:     12691200 | elapsed time per iteration (ms): 618.2 | learning rate: 5.525351E-05 | global batch size:    64 | lm loss: 3.049880E+00 | loss scale: 1048576.0 | grad norm: 0.449 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 13:58:02] iteration   198400/  500000 | consumed samples:     12697600 | elapsed time per iteration (ms): 619.9 | learning rate: 5.518859E-05 | global batch size:    64 | lm loss: 3.055675E+00 | loss scale: 1048576.0 | grad norm: 0.459 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 13:59:04] iteration   198500/  500000 | consumed samples:     12704000 | elapsed time per iteration (ms): 618.4 | learning rate: 5.512369E-05 | global batch size:    64 | lm loss: 3.019622E+00 | loss scale: 2097152.0 | grad norm: 0.444 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 14:00:06] iteration   198600/  500000 | consumed samples:     12710400 | elapsed time per iteration (ms): 616.5 | learning rate: 5.506012E-05 | global batch size:    64 | lm loss: 3.040298E+00 | loss scale: 1048576.0 | grad norm: 0.442 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-25 14:01:08] iteration   198700/  500000 | consumed samples:     12716800 | elapsed time per iteration (ms): 619.2 | learning rate: 5.499527E-05 | global batch size:    64 | lm loss: 3.047223E+00 | loss scale: 1048576.0 | grad norm: 0.438 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 14:02:10] iteration   198800/  500000 | consumed samples:     12723200 | elapsed time per iteration (ms): 618.0 | learning rate: 5.493045E-05 | global batch size:    64 | lm loss: 3.035107E+00 | loss scale: 1048576.0 | grad norm: 0.429 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 14:03:11] iteration   198900/  500000 | consumed samples:     12729600 | elapsed time per iteration (ms): 618.5 | learning rate: 5.486565E-05 | global batch size:    64 | lm loss: 3.040901E+00 | loss scale: 1048576.0 | grad norm: 0.439 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 14:04:13] iteration   199000/  500000 | consumed samples:     12736000 | elapsed time per iteration (ms): 618.2 | learning rate: 5.480087E-05 | global batch size:    64 | lm loss: 3.049656E+00 | loss scale: 1048576.0 | grad norm: 0.454 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2464.13, 2464.16)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 199000 | lm loss value: 3.709686E+00 | lm loss PPL: 4.084096E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-25 14:05:18] iteration   199100/  500000 | consumed samples:     12742400 | elapsed time per iteration (ms): 618.9 | learning rate: 5.473612E-05 | global batch size:    64 | lm loss: 3.034130E+00 | loss scale: 1048576.0 | grad norm: 0.442 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 14:06:19] iteration   199200/  500000 | consumed samples:     12748800 | elapsed time per iteration (ms): 617.7 | learning rate: 5.467140E-05 | global batch size:    64 | lm loss: 3.041642E+00 | loss scale: 1048576.0 | grad norm: 0.447 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 14:07:21] iteration   199300/  500000 | consumed samples:     12755200 | elapsed time per iteration (ms): 619.9 | learning rate: 5.460669E-05 | global batch size:    64 | lm loss: 3.049987E+00 | loss scale: 1048576.0 | grad norm: 0.457 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 14:08:23] iteration   199400/  500000 | consumed samples:     12761600 | elapsed time per iteration (ms): 617.6 | learning rate: 5.454202E-05 | global batch size:    64 | lm loss: 3.040531E+00 | loss scale: 1048576.0 | grad norm: 0.441 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 14:09:25] iteration   199500/  500000 | consumed samples:     12768000 | elapsed time per iteration (ms): 620.5 | learning rate: 5.447737E-05 | global batch size:    64 | lm loss: 3.039885E+00 | loss scale: 1048576.0 | grad norm: 0.446 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 14:10:27] iteration   199600/  500000 | consumed samples:     12774400 | elapsed time per iteration (ms): 619.2 | learning rate: 5.441274E-05 | global batch size:    64 | lm loss: 3.031341E+00 | loss scale: 2097152.0 | grad norm: 0.452 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 14:11:29] iteration   199700/  500000 | consumed samples:     12780800 | elapsed time per iteration (ms): 618.0 | learning rate: 5.434944E-05 | global batch size:    64 | lm loss: 3.049118E+00 | loss scale: 1048576.0 | grad norm: 0.445 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-25 14:12:31] iteration   199800/  500000 | consumed samples:     12787200 | elapsed time per iteration (ms): 622.5 | learning rate: 5.428486E-05 | global batch size:    64 | lm loss: 3.040171E+00 | loss scale: 1048576.0 | grad norm: 0.434 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 14:13:33] iteration   199900/  500000 | consumed samples:     12793600 | elapsed time per iteration (ms): 619.4 | learning rate: 5.422031E-05 | global batch size:    64 | lm loss: 3.062877E+00 | loss scale: 1048576.0 | grad norm: 0.458 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 14:14:35] iteration   200000/  500000 | consumed samples:     12800000 | elapsed time per iteration (ms): 618.9 | learning rate: 5.415578E-05 | global batch size:    64 | lm loss: 3.021543E+00 | loss scale: 1048576.0 | grad norm: 0.439 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2464.54, 2464.56)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 200000 | lm loss value: 3.674868E+00 | lm loss PPL: 3.944345E+01 | 
--------------------------------------------------------------------------------------------------
saving checkpoint at iteration  200000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-distribution in torch format
  successfully saved checkpoint at iteration  200000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-distribution
(min, max) time across ranks (ms):
    save-checkpoint ................................: (2291.27, 2291.34)
 [2024-06-25 14:15:42] iteration   200100/  500000 | consumed samples:     12806400 | elapsed time per iteration (ms): 619.9 | learning rate: 5.409129E-05 | global batch size:    64 | lm loss: 3.038099E+00 | loss scale: 1048576.0 | grad norm: 0.432 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 14:16:44] iteration   200200/  500000 | consumed samples:     12812800 | elapsed time per iteration (ms): 618.7 | learning rate: 5.402681E-05 | global batch size:    64 | lm loss: 3.043141E+00 | loss scale: 1048576.0 | grad norm: 0.435 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 14:17:45] iteration   200300/  500000 | consumed samples:     12819200 | elapsed time per iteration (ms): 618.5 | learning rate: 5.396236E-05 | global batch size:    64 | lm loss: 3.046072E+00 | loss scale: 1048576.0 | grad norm: 0.447 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 14:18:47] iteration   200400/  500000 | consumed samples:     12825600 | elapsed time per iteration (ms): 619.6 | learning rate: 5.389794E-05 | global batch size:    64 | lm loss: 3.050384E+00 | loss scale: 1048576.0 | grad norm: 0.450 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 14:19:49] iteration   200500/  500000 | consumed samples:     12832000 | elapsed time per iteration (ms): 617.8 | learning rate: 5.383354E-05 | global batch size:    64 | lm loss: 3.051866E+00 | loss scale: 1048576.0 | grad norm: 0.438 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 14:20:51] iteration   200600/  500000 | consumed samples:     12838400 | elapsed time per iteration (ms): 618.4 | learning rate: 5.376917E-05 | global batch size:    64 | lm loss: 3.026139E+00 | loss scale: 1048576.0 | grad norm: 0.434 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 14:21:53] iteration   200700/  500000 | consumed samples:     12844800 | elapsed time per iteration (ms): 617.7 | learning rate: 5.370483E-05 | global batch size:    64 | lm loss: 3.035804E+00 | loss scale: 2097152.0 | grad norm: 0.451 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 14:22:55] iteration   200800/  500000 | consumed samples:     12851200 | elapsed time per iteration (ms): 617.4 | learning rate: 5.364051E-05 | global batch size:    64 | lm loss: 3.042788E+00 | loss scale: 2097152.0 | grad norm: 0.439 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 14:23:56] iteration   200900/  500000 | consumed samples:     12857600 | elapsed time per iteration (ms): 617.9 | learning rate: 5.357621E-05 | global batch size:    64 | lm loss: 3.040857E+00 | loss scale: 2097152.0 | grad norm: 0.433 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 14:24:58] iteration   201000/  500000 | consumed samples:     12864000 | elapsed time per iteration (ms): 617.9 | learning rate: 5.351194E-05 | global batch size:    64 | lm loss: 3.034680E+00 | loss scale: 2097152.0 | grad norm: 0.441 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2464.10, 2464.38)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 201000 | lm loss value: 3.739161E+00 | lm loss PPL: 4.206267E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-25 14:26:02] iteration   201100/  500000 | consumed samples:     12870400 | elapsed time per iteration (ms): 619.3 | learning rate: 5.344899E-05 | global batch size:    64 | lm loss: 3.041489E+00 | loss scale: 1048576.0 | grad norm: 0.453 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-25 14:27:04] iteration   201200/  500000 | consumed samples:     12876800 | elapsed time per iteration (ms): 620.1 | learning rate: 5.338477E-05 | global batch size:    64 | lm loss: 3.051578E+00 | loss scale: 1048576.0 | grad norm: 0.437 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 14:28:06] iteration   201300/  500000 | consumed samples:     12883200 | elapsed time per iteration (ms): 618.1 | learning rate: 5.332058E-05 | global batch size:    64 | lm loss: 3.034872E+00 | loss scale: 1048576.0 | grad norm: 0.443 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 14:29:08] iteration   201400/  500000 | consumed samples:     12889600 | elapsed time per iteration (ms): 619.3 | learning rate: 5.325642E-05 | global batch size:    64 | lm loss: 3.055923E+00 | loss scale: 1048576.0 | grad norm: 0.447 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 14:30:10] iteration   201500/  500000 | consumed samples:     12896000 | elapsed time per iteration (ms): 618.9 | learning rate: 5.319228E-05 | global batch size:    64 | lm loss: 3.034320E+00 | loss scale: 1048576.0 | grad norm: 0.444 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 14:31:12] iteration   201600/  500000 | consumed samples:     12902400 | elapsed time per iteration (ms): 617.6 | learning rate: 5.312817E-05 | global batch size:    64 | lm loss: 3.043553E+00 | loss scale: 1048576.0 | grad norm: 0.442 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 14:32:14] iteration   201700/  500000 | consumed samples:     12908800 | elapsed time per iteration (ms): 620.1 | learning rate: 5.306408E-05 | global batch size:    64 | lm loss: 3.044871E+00 | loss scale: 1048576.0 | grad norm: 0.463 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 14:33:16] iteration   201800/  500000 | consumed samples:     12915200 | elapsed time per iteration (ms): 618.7 | learning rate: 5.300003E-05 | global batch size:    64 | lm loss: 3.028485E+00 | loss scale: 1048576.0 | grad norm: 0.438 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 14:34:18] iteration   201900/  500000 | consumed samples:     12921600 | elapsed time per iteration (ms): 617.9 | learning rate: 5.293599E-05 | global batch size:    64 | lm loss: 3.044763E+00 | loss scale: 1048576.0 | grad norm: 0.457 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 14:35:19] iteration   202000/  500000 | consumed samples:     12928000 | elapsed time per iteration (ms): 618.8 | learning rate: 5.287199E-05 | global batch size:    64 | lm loss: 3.029766E+00 | loss scale: 1048576.0 | grad norm: 0.446 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2464.87, 2464.95)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 202000 | lm loss value: 3.682762E+00 | lm loss PPL: 3.975605E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-25 14:36:24] iteration   202100/  500000 | consumed samples:     12934400 | elapsed time per iteration (ms): 618.7 | learning rate: 5.280801E-05 | global batch size:    64 | lm loss: 3.027683E+00 | loss scale: 2097152.0 | grad norm: 0.435 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 14:37:26] iteration   202200/  500000 | consumed samples:     12940800 | elapsed time per iteration (ms): 617.9 | learning rate: 5.274470E-05 | global batch size:    64 | lm loss: 3.035154E+00 | loss scale: 2097152.0 | grad norm: 0.449 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-25 14:38:28] iteration   202300/  500000 | consumed samples:     12947200 | elapsed time per iteration (ms): 619.9 | learning rate: 5.268141E-05 | global batch size:    64 | lm loss: 3.032790E+00 | loss scale: 1048576.0 | grad norm: 0.438 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-25 14:39:30] iteration   202400/  500000 | consumed samples:     12953600 | elapsed time per iteration (ms): 620.2 | learning rate: 5.261751E-05 | global batch size:    64 | lm loss: 3.028675E+00 | loss scale: 1048576.0 | grad norm: 0.482 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 14:40:32] iteration   202500/  500000 | consumed samples:     12960000 | elapsed time per iteration (ms): 621.6 | learning rate: 5.255364E-05 | global batch size:    64 | lm loss: 3.035523E+00 | loss scale: 1048576.0 | grad norm: 0.447 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 14:41:34] iteration   202600/  500000 | consumed samples:     12966400 | elapsed time per iteration (ms): 620.6 | learning rate: 5.248980E-05 | global batch size:    64 | lm loss: 3.050596E+00 | loss scale: 1048576.0 | grad norm: 0.447 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 14:42:36] iteration   202700/  500000 | consumed samples:     12972800 | elapsed time per iteration (ms): 619.3 | learning rate: 5.242598E-05 | global batch size:    64 | lm loss: 3.040083E+00 | loss scale: 1048576.0 | grad norm: 0.437 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 14:43:38] iteration   202800/  500000 | consumed samples:     12979200 | elapsed time per iteration (ms): 620.7 | learning rate: 5.236219E-05 | global batch size:    64 | lm loss: 3.038748E+00 | loss scale: 1048576.0 | grad norm: 0.452 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 14:44:40] iteration   202900/  500000 | consumed samples:     12985600 | elapsed time per iteration (ms): 619.7 | learning rate: 5.229843E-05 | global batch size:    64 | lm loss: 3.037359E+00 | loss scale: 1048576.0 | grad norm: 0.449 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 14:45:42] iteration   203000/  500000 | consumed samples:     12992000 | elapsed time per iteration (ms): 622.1 | learning rate: 5.223469E-05 | global batch size:    64 | lm loss: 3.024563E+00 | loss scale: 1048576.0 | grad norm: 0.455 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2461.65, 2461.78)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 203000 | lm loss value: 3.701468E+00 | lm loss PPL: 4.050673E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-25 14:46:46] iteration   203100/  500000 | consumed samples:     12998400 | elapsed time per iteration (ms): 618.2 | learning rate: 5.217098E-05 | global batch size:    64 | lm loss: 3.038136E+00 | loss scale: 1048576.0 | grad norm: 0.444 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 14:47:48] iteration   203200/  500000 | consumed samples:     13004800 | elapsed time per iteration (ms): 618.7 | learning rate: 5.210730E-05 | global batch size:    64 | lm loss: 3.029582E+00 | loss scale: 1048576.0 | grad norm: 0.451 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 14:48:50] iteration   203300/  500000 | consumed samples:     13011200 | elapsed time per iteration (ms): 617.6 | learning rate: 5.204428E-05 | global batch size:    64 | lm loss: 3.043317E+00 | loss scale: 2097152.0 | grad norm: 0.447 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-25 14:49:52] iteration   203400/  500000 | consumed samples:     13017600 | elapsed time per iteration (ms): 617.5 | learning rate: 5.198129E-05 | global batch size:    64 | lm loss: 3.038151E+00 | loss scale: 1048576.0 | grad norm: 0.437 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-25 14:50:54] iteration   203500/  500000 | consumed samples:     13024000 | elapsed time per iteration (ms): 619.5 | learning rate: 5.191769E-05 | global batch size:    64 | lm loss: 3.021572E+00 | loss scale: 1048576.0 | grad norm: 0.449 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 14:51:55] iteration   203600/  500000 | consumed samples:     13030400 | elapsed time per iteration (ms): 617.6 | learning rate: 5.185412E-05 | global batch size:    64 | lm loss: 3.042035E+00 | loss scale: 1048576.0 | grad norm: 0.434 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 14:52:57] iteration   203700/  500000 | consumed samples:     13036800 | elapsed time per iteration (ms): 617.2 | learning rate: 5.179058E-05 | global batch size:    64 | lm loss: 3.041285E+00 | loss scale: 1048576.0 | grad norm: 0.447 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 14:53:59] iteration   203800/  500000 | consumed samples:     13043200 | elapsed time per iteration (ms): 619.3 | learning rate: 5.172706E-05 | global batch size:    64 | lm loss: 3.022360E+00 | loss scale: 1048576.0 | grad norm: 0.448 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 14:55:01] iteration   203900/  500000 | consumed samples:     13049600 | elapsed time per iteration (ms): 620.1 | learning rate: 5.166357E-05 | global batch size:    64 | lm loss: 3.025502E+00 | loss scale: 1048576.0 | grad norm: 0.455 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 14:56:03] iteration   204000/  500000 | consumed samples:     13056000 | elapsed time per iteration (ms): 619.1 | learning rate: 5.160011E-05 | global batch size:    64 | lm loss: 3.036627E+00 | loss scale: 1048576.0 | grad norm: 0.466 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2466.11, 2466.49)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 204000 | lm loss value: 3.704016E+00 | lm loss PPL: 4.061006E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-25 14:57:07] iteration   204100/  500000 | consumed samples:     13062400 | elapsed time per iteration (ms): 619.1 | learning rate: 5.153668E-05 | global batch size:    64 | lm loss: 3.027305E+00 | loss scale: 1048576.0 | grad norm: 0.449 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 14:58:09] iteration   204200/  500000 | consumed samples:     13068800 | elapsed time per iteration (ms): 618.6 | learning rate: 5.147327E-05 | global batch size:    64 | lm loss: 3.034724E+00 | loss scale: 1048576.0 | grad norm: 0.431 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 14:59:11] iteration   204300/  500000 | consumed samples:     13075200 | elapsed time per iteration (ms): 619.9 | learning rate: 5.140990E-05 | global batch size:    64 | lm loss: 3.039576E+00 | loss scale: 1048576.0 | grad norm: 0.441 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 15:00:13] iteration   204400/  500000 | consumed samples:     13081600 | elapsed time per iteration (ms): 618.8 | learning rate: 5.134655E-05 | global batch size:    64 | lm loss: 3.034968E+00 | loss scale: 2097152.0 | grad norm: 0.444 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 15:01:15] iteration   204500/  500000 | consumed samples:     13088000 | elapsed time per iteration (ms): 619.5 | learning rate: 5.128449E-05 | global batch size:    64 | lm loss: 3.047301E+00 | loss scale: 1048576.0 | grad norm: 0.436 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-25 15:02:17] iteration   204600/  500000 | consumed samples:     13094400 | elapsed time per iteration (ms): 621.0 | learning rate: 5.122120E-05 | global batch size:    64 | lm loss: 3.042401E+00 | loss scale: 1048576.0 | grad norm: 0.440 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 15:03:19] iteration   204700/  500000 | consumed samples:     13100800 | elapsed time per iteration (ms): 621.2 | learning rate: 5.115794E-05 | global batch size:    64 | lm loss: 3.038673E+00 | loss scale: 1048576.0 | grad norm: 0.453 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 15:04:21] iteration   204800/  500000 | consumed samples:     13107200 | elapsed time per iteration (ms): 618.2 | learning rate: 5.109470E-05 | global batch size:    64 | lm loss: 3.045696E+00 | loss scale: 1048576.0 | grad norm: 0.465 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 15:05:23] iteration   204900/  500000 | consumed samples:     13113600 | elapsed time per iteration (ms): 620.8 | learning rate: 5.103149E-05 | global batch size:    64 | lm loss: 3.026236E+00 | loss scale: 1048576.0 | grad norm: 0.450 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 15:06:25] iteration   205000/  500000 | consumed samples:     13120000 | elapsed time per iteration (ms): 618.7 | learning rate: 5.096831E-05 | global batch size:    64 | lm loss: 3.026638E+00 | loss scale: 1048576.0 | grad norm: 0.452 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2461.83, 2462.10)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 205000 | lm loss value: 3.701344E+00 | lm loss PPL: 4.050170E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-25 15:07:29] iteration   205100/  500000 | consumed samples:     13126400 | elapsed time per iteration (ms): 619.4 | learning rate: 5.090516E-05 | global batch size:    64 | lm loss: 3.032669E+00 | loss scale: 1048576.0 | grad norm: 0.452 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 15:08:31] iteration   205200/  500000 | consumed samples:     13132800 | elapsed time per iteration (ms): 619.2 | learning rate: 5.084204E-05 | global batch size:    64 | lm loss: 3.034220E+00 | loss scale: 1048576.0 | grad norm: 0.438 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 15:09:33] iteration   205300/  500000 | consumed samples:     13139200 | elapsed time per iteration (ms): 620.2 | learning rate: 5.077895E-05 | global batch size:    64 | lm loss: 3.021438E+00 | loss scale: 1048576.0 | grad norm: 0.451 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 15:10:35] iteration   205400/  500000 | consumed samples:     13145600 | elapsed time per iteration (ms): 617.7 | learning rate: 5.071588E-05 | global batch size:    64 | lm loss: 3.050712E+00 | loss scale: 1048576.0 | grad norm: 0.439 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 15:11:37] iteration   205500/  500000 | consumed samples:     13152000 | elapsed time per iteration (ms): 620.5 | learning rate: 5.065285E-05 | global batch size:    64 | lm loss: 3.042501E+00 | loss scale: 2097152.0 | grad norm: 0.452 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 15:12:39] iteration   205600/  500000 | consumed samples:     13158400 | elapsed time per iteration (ms): 620.0 | learning rate: 5.059047E-05 | global batch size:    64 | lm loss: 3.038197E+00 | loss scale: 2097152.0 | grad norm: 0.447 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-25 15:13:41] iteration   205700/  500000 | consumed samples:     13164800 | elapsed time per iteration (ms): 618.4 | learning rate: 5.052812E-05 | global batch size:    64 | lm loss: 3.018283E+00 | loss scale: 1048576.0 | grad norm: 0.458 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-25 15:14:43] iteration   205800/  500000 | consumed samples:     13171200 | elapsed time per iteration (ms): 619.6 | learning rate: 5.046517E-05 | global batch size:    64 | lm loss: 3.024030E+00 | loss scale: 1048576.0 | grad norm: 0.452 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 15:15:45] iteration   205900/  500000 | consumed samples:     13177600 | elapsed time per iteration (ms): 619.0 | learning rate: 5.040225E-05 | global batch size:    64 | lm loss: 3.045833E+00 | loss scale: 1048576.0 | grad norm: 0.432 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 15:16:47] iteration   206000/  500000 | consumed samples:     13184000 | elapsed time per iteration (ms): 618.3 | learning rate: 5.033936E-05 | global batch size:    64 | lm loss: 3.037814E+00 | loss scale: 1048576.0 | grad norm: 0.450 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2463.83, 2463.92)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 206000 | lm loss value: 3.713032E+00 | lm loss PPL: 4.097787E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-25 15:17:51] iteration   206100/  500000 | consumed samples:     13190400 | elapsed time per iteration (ms): 619.1 | learning rate: 5.027650E-05 | global batch size:    64 | lm loss: 3.022884E+00 | loss scale: 1048576.0 | grad norm: 0.439 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 15:18:53] iteration   206200/  500000 | consumed samples:     13196800 | elapsed time per iteration (ms): 621.7 | learning rate: 5.021367E-05 | global batch size:    64 | lm loss: 3.022469E+00 | loss scale: 1048576.0 | grad norm: 0.456 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 15:19:55] iteration   206300/  500000 | consumed samples:     13203200 | elapsed time per iteration (ms): 617.6 | learning rate: 5.015086E-05 | global batch size:    64 | lm loss: 3.044264E+00 | loss scale: 1048576.0 | grad norm: 0.438 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 15:20:57] iteration   206400/  500000 | consumed samples:     13209600 | elapsed time per iteration (ms): 619.2 | learning rate: 5.008809E-05 | global batch size:    64 | lm loss: 3.033387E+00 | loss scale: 1048576.0 | grad norm: 0.449 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 15:21:59] iteration   206500/  500000 | consumed samples:     13216000 | elapsed time per iteration (ms): 617.8 | learning rate: 5.002534E-05 | global batch size:    64 | lm loss: 3.020708E+00 | loss scale: 1048576.0 | grad norm: 0.437 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 15:23:00] iteration   206600/  500000 | consumed samples:     13222400 | elapsed time per iteration (ms): 617.9 | learning rate: 4.996263E-05 | global batch size:    64 | lm loss: 3.035426E+00 | loss scale: 1048576.0 | grad norm: 0.441 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 15:24:02] iteration   206700/  500000 | consumed samples:     13228800 | elapsed time per iteration (ms): 618.5 | learning rate: 4.989994E-05 | global batch size:    64 | lm loss: 3.035892E+00 | loss scale: 2097152.0 | grad norm: 0.446 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 15:25:04] iteration   206800/  500000 | consumed samples:     13235200 | elapsed time per iteration (ms): 617.6 | learning rate: 4.983728E-05 | global batch size:    64 | lm loss: 3.016961E+00 | loss scale: 2097152.0 | grad norm: 0.447 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 15:26:06] iteration   206900/  500000 | consumed samples:     13241600 | elapsed time per iteration (ms): 619.6 | learning rate: 4.977591E-05 | global batch size:    64 | lm loss: 3.031943E+00 | loss scale: 1048576.0 | grad norm: 0.454 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-25 15:27:08] iteration   207000/  500000 | consumed samples:     13248000 | elapsed time per iteration (ms): 619.9 | learning rate: 4.971331E-05 | global batch size:    64 | lm loss: 3.039521E+00 | loss scale: 1048576.0 | grad norm: 0.453 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2462.43, 2462.45)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 207000 | lm loss value: 3.702883E+00 | lm loss PPL: 4.056409E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-25 15:28:13] iteration   207100/  500000 | consumed samples:     13254400 | elapsed time per iteration (ms): 620.5 | learning rate: 4.965074E-05 | global batch size:    64 | lm loss: 3.035618E+00 | loss scale: 1048576.0 | grad norm: 0.450 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 15:29:14] iteration   207200/  500000 | consumed samples:     13260800 | elapsed time per iteration (ms): 617.5 | learning rate: 4.958821E-05 | global batch size:    64 | lm loss: 3.031255E+00 | loss scale: 1048576.0 | grad norm: 0.447 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 15:30:16] iteration   207300/  500000 | consumed samples:     13267200 | elapsed time per iteration (ms): 618.6 | learning rate: 4.952570E-05 | global batch size:    64 | lm loss: 3.037263E+00 | loss scale: 1048576.0 | grad norm: 0.439 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 15:31:18] iteration   207400/  500000 | consumed samples:     13273600 | elapsed time per iteration (ms): 618.3 | learning rate: 4.946322E-05 | global batch size:    64 | lm loss: 3.016574E+00 | loss scale: 1048576.0 | grad norm: 0.451 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 15:32:20] iteration   207500/  500000 | consumed samples:     13280000 | elapsed time per iteration (ms): 618.1 | learning rate: 4.940077E-05 | global batch size:    64 | lm loss: 3.050928E+00 | loss scale: 1048576.0 | grad norm: 0.446 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 15:33:22] iteration   207600/  500000 | consumed samples:     13286400 | elapsed time per iteration (ms): 618.2 | learning rate: 4.933835E-05 | global batch size:    64 | lm loss: 3.033589E+00 | loss scale: 1048576.0 | grad norm: 0.454 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 15:34:23] iteration   207700/  500000 | consumed samples:     13292800 | elapsed time per iteration (ms): 618.7 | learning rate: 4.927597E-05 | global batch size:    64 | lm loss: 3.029993E+00 | loss scale: 1048576.0 | grad norm: 0.452 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 15:35:25] iteration   207800/  500000 | consumed samples:     13299200 | elapsed time per iteration (ms): 617.6 | learning rate: 4.921361E-05 | global batch size:    64 | lm loss: 3.050199E+00 | loss scale: 1048576.0 | grad norm: 0.453 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 15:36:27] iteration   207900/  500000 | consumed samples:     13305600 | elapsed time per iteration (ms): 618.9 | learning rate: 4.915190E-05 | global batch size:    64 | lm loss: 3.050068E+00 | loss scale: 2097152.0 | grad norm: 0.456 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-25 15:37:29] iteration   208000/  500000 | consumed samples:     13312000 | elapsed time per iteration (ms): 619.6 | learning rate: 4.909023E-05 | global batch size:    64 | lm loss: 3.017227E+00 | loss scale: 1048576.0 | grad norm: 0.449 | number of skipped iterations:   1 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2463.96, 2463.98)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 208000 | lm loss value: 3.661607E+00 | lm loss PPL: 3.892383E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-25 15:38:33] iteration   208100/  500000 | consumed samples:     13318400 | elapsed time per iteration (ms): 618.3 | learning rate: 4.902796E-05 | global batch size:    64 | lm loss: 3.030112E+00 | loss scale: 1048576.0 | grad norm: 0.455 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 15:39:35] iteration   208200/  500000 | consumed samples:     13324800 | elapsed time per iteration (ms): 617.5 | learning rate: 4.896573E-05 | global batch size:    64 | lm loss: 3.022134E+00 | loss scale: 1048576.0 | grad norm: 0.438 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 15:40:37] iteration   208300/  500000 | consumed samples:     13331200 | elapsed time per iteration (ms): 618.8 | learning rate: 4.890352E-05 | global batch size:    64 | lm loss: 3.031671E+00 | loss scale: 1048576.0 | grad norm: 0.447 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 15:41:39] iteration   208400/  500000 | consumed samples:     13337600 | elapsed time per iteration (ms): 620.7 | learning rate: 4.884134E-05 | global batch size:    64 | lm loss: 3.029412E+00 | loss scale: 1048576.0 | grad norm: 0.454 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 15:42:41] iteration   208500/  500000 | consumed samples:     13344000 | elapsed time per iteration (ms): 618.6 | learning rate: 4.877920E-05 | global batch size:    64 | lm loss: 3.024485E+00 | loss scale: 1048576.0 | grad norm: 0.452 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 15:43:43] iteration   208600/  500000 | consumed samples:     13350400 | elapsed time per iteration (ms): 618.7 | learning rate: 4.871709E-05 | global batch size:    64 | lm loss: 3.035349E+00 | loss scale: 1048576.0 | grad norm: 0.452 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 15:44:45] iteration   208700/  500000 | consumed samples:     13356800 | elapsed time per iteration (ms): 617.3 | learning rate: 4.865500E-05 | global batch size:    64 | lm loss: 3.025697E+00 | loss scale: 1048576.0 | grad norm: 0.463 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 15:45:46] iteration   208800/  500000 | consumed samples:     13363200 | elapsed time per iteration (ms): 616.5 | learning rate: 4.859295E-05 | global batch size:    64 | lm loss: 3.038658E+00 | loss scale: 1048576.0 | grad norm: 0.452 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 15:46:48] iteration   208900/  500000 | consumed samples:     13369600 | elapsed time per iteration (ms): 618.9 | learning rate: 4.853093E-05 | global batch size:    64 | lm loss: 3.037938E+00 | loss scale: 1048576.0 | grad norm: 0.464 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 15:47:50] iteration   209000/  500000 | consumed samples:     13376000 | elapsed time per iteration (ms): 621.2 | learning rate: 4.846956E-05 | global batch size:    64 | lm loss: 3.028644E+00 | loss scale: 2097152.0 | grad norm: 0.438 | number of skipped iterations:   1 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2463.62, 2463.65)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 209000 | lm loss value: 3.690082E+00 | lm loss PPL: 4.004814E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-25 15:48:55] iteration   209100/  500000 | consumed samples:     13382400 | elapsed time per iteration (ms): 620.2 | learning rate: 4.840760E-05 | global batch size:    64 | lm loss: 3.026304E+00 | loss scale: 2097152.0 | grad norm: 0.434 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 15:49:57] iteration   209200/  500000 | consumed samples:     13388800 | elapsed time per iteration (ms): 619.1 | learning rate: 4.834629E-05 | global batch size:    64 | lm loss: 3.038768E+00 | loss scale: 1048576.0 | grad norm: 0.449 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-25 15:50:59] iteration   209300/  500000 | consumed samples:     13395200 | elapsed time per iteration (ms): 619.2 | learning rate: 4.828439E-05 | global batch size:    64 | lm loss: 3.028774E+00 | loss scale: 1048576.0 | grad norm: 0.459 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 15:52:00] iteration   209400/  500000 | consumed samples:     13401600 | elapsed time per iteration (ms): 617.2 | learning rate: 4.822252E-05 | global batch size:    64 | lm loss: 3.033233E+00 | loss scale: 1048576.0 | grad norm: 0.461 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 15:53:02] iteration   209500/  500000 | consumed samples:     13408000 | elapsed time per iteration (ms): 619.2 | learning rate: 4.816068E-05 | global batch size:    64 | lm loss: 3.033332E+00 | loss scale: 1048576.0 | grad norm: 0.467 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 15:54:04] iteration   209600/  500000 | consumed samples:     13414400 | elapsed time per iteration (ms): 619.7 | learning rate: 4.809888E-05 | global batch size:    64 | lm loss: 3.031949E+00 | loss scale: 1048576.0 | grad norm: 0.446 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 15:55:06] iteration   209700/  500000 | consumed samples:     13420800 | elapsed time per iteration (ms): 619.4 | learning rate: 4.803711E-05 | global batch size:    64 | lm loss: 3.019927E+00 | loss scale: 1048576.0 | grad norm: 0.459 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 15:56:08] iteration   209800/  500000 | consumed samples:     13427200 | elapsed time per iteration (ms): 618.8 | learning rate: 4.797537E-05 | global batch size:    64 | lm loss: 3.034862E+00 | loss scale: 1048576.0 | grad norm: 0.454 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 15:57:10] iteration   209900/  500000 | consumed samples:     13433600 | elapsed time per iteration (ms): 619.3 | learning rate: 4.791365E-05 | global batch size:    64 | lm loss: 3.023538E+00 | loss scale: 1048576.0 | grad norm: 0.451 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 15:58:12] iteration   210000/  500000 | consumed samples:     13440000 | elapsed time per iteration (ms): 618.4 | learning rate: 4.785198E-05 | global batch size:    64 | lm loss: 3.037646E+00 | loss scale: 1048576.0 | grad norm: 0.444 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2461.69, 2461.78)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 210000 | lm loss value: 3.721240E+00 | lm loss PPL: 4.131558E+01 | 
--------------------------------------------------------------------------------------------------
saving checkpoint at iteration  210000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-distribution in torch format
  successfully saved checkpoint at iteration  210000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-distribution
(min, max) time across ranks (ms):
    save-checkpoint ................................: (2286.45, 2286.46)
 [2024-06-25 15:59:18] iteration   210100/  500000 | consumed samples:     13446400 | elapsed time per iteration (ms): 617.7 | learning rate: 4.779033E-05 | global batch size:    64 | lm loss: 3.031282E+00 | loss scale: 1048576.0 | grad norm: 0.450 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 16:00:20] iteration   210200/  500000 | consumed samples:     13452800 | elapsed time per iteration (ms): 618.1 | learning rate: 4.772871E-05 | global batch size:    64 | lm loss: 3.016942E+00 | loss scale: 2097152.0 | grad norm: 0.445 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 16:01:22] iteration   210300/  500000 | consumed samples:     13459200 | elapsed time per iteration (ms): 619.7 | learning rate: 4.766836E-05 | global batch size:    64 | lm loss: 3.034243E+00 | loss scale: 1048576.0 | grad norm: 0.453 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-25 16:02:24] iteration   210400/  500000 | consumed samples:     13465600 | elapsed time per iteration (ms): 617.8 | learning rate: 4.760681E-05 | global batch size:    64 | lm loss: 3.030632E+00 | loss scale: 1048576.0 | grad norm: 0.451 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 16:03:26] iteration   210500/  500000 | consumed samples:     13472000 | elapsed time per iteration (ms): 619.0 | learning rate: 4.754529E-05 | global batch size:    64 | lm loss: 3.033693E+00 | loss scale: 1048576.0 | grad norm: 0.429 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 16:04:28] iteration   210600/  500000 | consumed samples:     13478400 | elapsed time per iteration (ms): 620.0 | learning rate: 4.748380E-05 | global batch size:    64 | lm loss: 3.021233E+00 | loss scale: 1048576.0 | grad norm: 0.447 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 16:05:29] iteration   210700/  500000 | consumed samples:     13484800 | elapsed time per iteration (ms): 618.1 | learning rate: 4.742234E-05 | global batch size:    64 | lm loss: 3.032939E+00 | loss scale: 1048576.0 | grad norm: 0.443 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 16:06:31] iteration   210800/  500000 | consumed samples:     13491200 | elapsed time per iteration (ms): 618.5 | learning rate: 4.736092E-05 | global batch size:    64 | lm loss: 3.025695E+00 | loss scale: 1048576.0 | grad norm: 0.449 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 16:07:33] iteration   210900/  500000 | consumed samples:     13497600 | elapsed time per iteration (ms): 620.0 | learning rate: 4.729953E-05 | global batch size:    64 | lm loss: 3.015286E+00 | loss scale: 1048576.0 | grad norm: 0.457 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 16:08:35] iteration   211000/  500000 | consumed samples:     13504000 | elapsed time per iteration (ms): 619.6 | learning rate: 4.723816E-05 | global batch size:    64 | lm loss: 3.006778E+00 | loss scale: 1048576.0 | grad norm: 0.455 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2462.09, 2462.18)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 211000 | lm loss value: 3.769350E+00 | lm loss PPL: 4.335188E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-25 16:09:40] iteration   211100/  500000 | consumed samples:     13510400 | elapsed time per iteration (ms): 618.2 | learning rate: 4.717684E-05 | global batch size:    64 | lm loss: 3.028174E+00 | loss scale: 1048576.0 | grad norm: 0.441 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 16:10:42] iteration   211200/  500000 | consumed samples:     13516800 | elapsed time per iteration (ms): 619.4 | learning rate: 4.711554E-05 | global batch size:    64 | lm loss: 3.041130E+00 | loss scale: 1048576.0 | grad norm: 0.443 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 16:11:43] iteration   211300/  500000 | consumed samples:     13523200 | elapsed time per iteration (ms): 619.3 | learning rate: 4.705428E-05 | global batch size:    64 | lm loss: 3.030301E+00 | loss scale: 2097152.0 | grad norm: 0.452 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 16:12:45] iteration   211400/  500000 | consumed samples:     13529600 | elapsed time per iteration (ms): 619.3 | learning rate: 4.699305E-05 | global batch size:    64 | lm loss: 3.016952E+00 | loss scale: 2097152.0 | grad norm: 0.470 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 16:13:47] iteration   211500/  500000 | consumed samples:     13536000 | elapsed time per iteration (ms): 619.1 | learning rate: 4.693246E-05 | global batch size:    64 | lm loss: 3.040898E+00 | loss scale: 2097152.0 | grad norm: 0.461 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-25 16:14:49] iteration   211600/  500000 | consumed samples:     13542400 | elapsed time per iteration (ms): 619.3 | learning rate: 4.687129E-05 | global batch size:    64 | lm loss: 3.039071E+00 | loss scale: 2097152.0 | grad norm: 0.440 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 16:15:51] iteration   211700/  500000 | consumed samples:     13548800 | elapsed time per iteration (ms): 617.0 | learning rate: 4.681077E-05 | global batch size:    64 | lm loss: 3.045272E+00 | loss scale: 1048576.0 | grad norm: 0.454 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-25 16:16:53] iteration   211800/  500000 | consumed samples:     13555200 | elapsed time per iteration (ms): 619.3 | learning rate: 4.674967E-05 | global batch size:    64 | lm loss: 3.011120E+00 | loss scale: 1048576.0 | grad norm: 0.445 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 16:17:55] iteration   211900/  500000 | consumed samples:     13561600 | elapsed time per iteration (ms): 618.7 | learning rate: 4.668860E-05 | global batch size:    64 | lm loss: 3.045677E+00 | loss scale: 1048576.0 | grad norm: 0.440 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 16:18:57] iteration   212000/  500000 | consumed samples:     13568000 | elapsed time per iteration (ms): 619.5 | learning rate: 4.662756E-05 | global batch size:    64 | lm loss: 3.026630E+00 | loss scale: 1048576.0 | grad norm: 0.456 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2463.08, 2463.10)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 212000 | lm loss value: 3.689348E+00 | lm loss PPL: 4.001876E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-25 16:20:01] iteration   212100/  500000 | consumed samples:     13574400 | elapsed time per iteration (ms): 618.3 | learning rate: 4.656656E-05 | global batch size:    64 | lm loss: 3.033658E+00 | loss scale: 1048576.0 | grad norm: 0.448 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 16:21:03] iteration   212200/  500000 | consumed samples:     13580800 | elapsed time per iteration (ms): 622.9 | learning rate: 4.650559E-05 | global batch size:    64 | lm loss: 3.037158E+00 | loss scale: 1048576.0 | grad norm: 0.473 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 16:22:05] iteration   212300/  500000 | consumed samples:     13587200 | elapsed time per iteration (ms): 619.4 | learning rate: 4.644465E-05 | global batch size:    64 | lm loss: 3.026419E+00 | loss scale: 1048576.0 | grad norm: 0.448 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 16:23:07] iteration   212400/  500000 | consumed samples:     13593600 | elapsed time per iteration (ms): 621.0 | learning rate: 4.638375E-05 | global batch size:    64 | lm loss: 3.028225E+00 | loss scale: 1048576.0 | grad norm: 0.449 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 16:24:09] iteration   212500/  500000 | consumed samples:     13600000 | elapsed time per iteration (ms): 619.3 | learning rate: 4.632287E-05 | global batch size:    64 | lm loss: 3.015680E+00 | loss scale: 1048576.0 | grad norm: 0.451 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 16:25:11] iteration   212600/  500000 | consumed samples:     13606400 | elapsed time per iteration (ms): 618.8 | learning rate: 4.626204E-05 | global batch size:    64 | lm loss: 3.033705E+00 | loss scale: 1048576.0 | grad norm: 0.452 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 16:26:13] iteration   212700/  500000 | consumed samples:     13612800 | elapsed time per iteration (ms): 620.6 | learning rate: 4.620123E-05 | global batch size:    64 | lm loss: 3.014463E+00 | loss scale: 2097152.0 | grad norm: 0.446 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 16:27:15] iteration   212800/  500000 | consumed samples:     13619200 | elapsed time per iteration (ms): 618.5 | learning rate: 4.614167E-05 | global batch size:    64 | lm loss: 3.022325E+00 | loss scale: 1048576.0 | grad norm: 0.451 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-25 16:28:17] iteration   212900/  500000 | consumed samples:     13625600 | elapsed time per iteration (ms): 617.7 | learning rate: 4.608093E-05 | global batch size:    64 | lm loss: 3.021005E+00 | loss scale: 1048576.0 | grad norm: 0.442 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 16:29:19] iteration   213000/  500000 | consumed samples:     13632000 | elapsed time per iteration (ms): 617.2 | learning rate: 4.602023E-05 | global batch size:    64 | lm loss: 3.021939E+00 | loss scale: 1048576.0 | grad norm: 0.465 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2463.49, 2463.53)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 213000 | lm loss value: 3.758986E+00 | lm loss PPL: 4.290490E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-25 16:30:23] iteration   213100/  500000 | consumed samples:     13638400 | elapsed time per iteration (ms): 618.2 | learning rate: 4.595956E-05 | global batch size:    64 | lm loss: 3.032249E+00 | loss scale: 1048576.0 | grad norm: 0.458 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 16:31:25] iteration   213200/  500000 | consumed samples:     13644800 | elapsed time per iteration (ms): 619.7 | learning rate: 4.589892E-05 | global batch size:    64 | lm loss: 3.016166E+00 | loss scale: 1048576.0 | grad norm: 0.459 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 16:32:27] iteration   213300/  500000 | consumed samples:     13651200 | elapsed time per iteration (ms): 619.5 | learning rate: 4.583831E-05 | global batch size:    64 | lm loss: 3.033958E+00 | loss scale: 1048576.0 | grad norm: 0.447 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 16:33:29] iteration   213400/  500000 | consumed samples:     13657600 | elapsed time per iteration (ms): 619.0 | learning rate: 4.577774E-05 | global batch size:    64 | lm loss: 3.031193E+00 | loss scale: 1048576.0 | grad norm: 0.438 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 16:34:31] iteration   213500/  500000 | consumed samples:     13664000 | elapsed time per iteration (ms): 619.2 | learning rate: 4.571720E-05 | global batch size:    64 | lm loss: 3.009487E+00 | loss scale: 1048576.0 | grad norm: 0.445 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 16:35:32] iteration   213600/  500000 | consumed samples:     13670400 | elapsed time per iteration (ms): 617.8 | learning rate: 4.565730E-05 | global batch size:    64 | lm loss: 3.025109E+00 | loss scale: 524288.0 | grad norm: 0.457 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-25 16:36:34] iteration   213700/  500000 | consumed samples:     13676800 | elapsed time per iteration (ms): 617.6 | learning rate: 4.559683E-05 | global batch size:    64 | lm loss: 3.009107E+00 | loss scale: 524288.0 | grad norm: 0.454 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 16:37:36] iteration   213800/  500000 | consumed samples:     13683200 | elapsed time per iteration (ms): 616.8 | learning rate: 4.553639E-05 | global batch size:    64 | lm loss: 3.023345E+00 | loss scale: 524288.0 | grad norm: 0.439 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 16:38:38] iteration   213900/  500000 | consumed samples:     13689600 | elapsed time per iteration (ms): 622.1 | learning rate: 4.547599E-05 | global batch size:    64 | lm loss: 3.034989E+00 | loss scale: 524288.0 | grad norm: 0.457 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 16:39:40] iteration   214000/  500000 | consumed samples:     13696000 | elapsed time per iteration (ms): 619.7 | learning rate: 4.541562E-05 | global batch size:    64 | lm loss: 3.038075E+00 | loss scale: 524288.0 | grad norm: 0.438 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2463.23, 2463.28)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 214000 | lm loss value: 3.704811E+00 | lm loss PPL: 4.064237E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-25 16:40:44] iteration   214100/  500000 | consumed samples:     13702400 | elapsed time per iteration (ms): 619.2 | learning rate: 4.535528E-05 | global batch size:    64 | lm loss: 3.037568E+00 | loss scale: 524288.0 | grad norm: 0.434 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 16:41:46] iteration   214200/  500000 | consumed samples:     13708800 | elapsed time per iteration (ms): 618.7 | learning rate: 4.529498E-05 | global batch size:    64 | lm loss: 3.044006E+00 | loss scale: 524288.0 | grad norm: 0.436 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 16:42:48] iteration   214300/  500000 | consumed samples:     13715200 | elapsed time per iteration (ms): 620.0 | learning rate: 4.523472E-05 | global batch size:    64 | lm loss: 3.027102E+00 | loss scale: 524288.0 | grad norm: 0.449 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 16:43:50] iteration   214400/  500000 | consumed samples:     13721600 | elapsed time per iteration (ms): 618.3 | learning rate: 4.517448E-05 | global batch size:    64 | lm loss: 3.029897E+00 | loss scale: 524288.0 | grad norm: 0.456 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 16:44:52] iteration   214500/  500000 | consumed samples:     13728000 | elapsed time per iteration (ms): 619.8 | learning rate: 4.511428E-05 | global batch size:    64 | lm loss: 3.017168E+00 | loss scale: 524288.0 | grad norm: 0.461 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 16:45:54] iteration   214600/  500000 | consumed samples:     13734400 | elapsed time per iteration (ms): 622.6 | learning rate: 4.505412E-05 | global batch size:    64 | lm loss: 3.024203E+00 | loss scale: 1048576.0 | grad norm: 0.478 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 16:46:56] iteration   214700/  500000 | consumed samples:     13740800 | elapsed time per iteration (ms): 620.5 | learning rate: 4.499399E-05 | global batch size:    64 | lm loss: 3.023742E+00 | loss scale: 1048576.0 | grad norm: 0.435 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 16:47:58] iteration   214800/  500000 | consumed samples:     13747200 | elapsed time per iteration (ms): 619.7 | learning rate: 4.493389E-05 | global batch size:    64 | lm loss: 3.013299E+00 | loss scale: 1048576.0 | grad norm: 0.453 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 16:49:00] iteration   214900/  500000 | consumed samples:     13753600 | elapsed time per iteration (ms): 620.0 | learning rate: 4.487383E-05 | global batch size:    64 | lm loss: 3.039115E+00 | loss scale: 1048576.0 | grad norm: 0.455 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 16:50:02] iteration   215000/  500000 | consumed samples:     13760000 | elapsed time per iteration (ms): 619.8 | learning rate: 4.481380E-05 | global batch size:    64 | lm loss: 3.019906E+00 | loss scale: 1048576.0 | grad norm: 0.450 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2467.54, 2467.66)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 215000 | lm loss value: 3.747285E+00 | lm loss PPL: 4.240580E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-25 16:51:07] iteration   215100/  500000 | consumed samples:     13766400 | elapsed time per iteration (ms): 620.2 | learning rate: 4.475381E-05 | global batch size:    64 | lm loss: 3.040140E+00 | loss scale: 1048576.0 | grad norm: 0.460 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 16:52:09] iteration   215200/  500000 | consumed samples:     13772800 | elapsed time per iteration (ms): 618.8 | learning rate: 4.469385E-05 | global batch size:    64 | lm loss: 3.029836E+00 | loss scale: 1048576.0 | grad norm: 0.445 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 16:53:11] iteration   215300/  500000 | consumed samples:     13779200 | elapsed time per iteration (ms): 619.4 | learning rate: 4.463393E-05 | global batch size:    64 | lm loss: 3.028339E+00 | loss scale: 1048576.0 | grad norm: 0.454 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 16:54:12] iteration   215400/  500000 | consumed samples:     13785600 | elapsed time per iteration (ms): 619.1 | learning rate: 4.457404E-05 | global batch size:    64 | lm loss: 3.028281E+00 | loss scale: 1048576.0 | grad norm: 0.447 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 16:55:14] iteration   215500/  500000 | consumed samples:     13792000 | elapsed time per iteration (ms): 619.9 | learning rate: 4.451419E-05 | global batch size:    64 | lm loss: 3.030551E+00 | loss scale: 1048576.0 | grad norm: 0.448 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 16:56:16] iteration   215600/  500000 | consumed samples:     13798400 | elapsed time per iteration (ms): 617.6 | learning rate: 4.445497E-05 | global batch size:    64 | lm loss: 3.042084E+00 | loss scale: 2097152.0 | grad norm: 0.454 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-25 16:57:18] iteration   215700/  500000 | consumed samples:     13804800 | elapsed time per iteration (ms): 618.1 | learning rate: 4.439578E-05 | global batch size:    64 | lm loss: 3.017100E+00 | loss scale: 1048576.0 | grad norm: 0.465 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-25 16:58:20] iteration   215800/  500000 | consumed samples:     13811200 | elapsed time per iteration (ms): 619.0 | learning rate: 4.433604E-05 | global batch size:    64 | lm loss: 3.029917E+00 | loss scale: 1048576.0 | grad norm: 0.437 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 16:59:22] iteration   215900/  500000 | consumed samples:     13817600 | elapsed time per iteration (ms): 618.9 | learning rate: 4.427632E-05 | global batch size:    64 | lm loss: 3.039371E+00 | loss scale: 1048576.0 | grad norm: 0.454 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 17:00:24] iteration   216000/  500000 | consumed samples:     13824000 | elapsed time per iteration (ms): 620.4 | learning rate: 4.421664E-05 | global batch size:    64 | lm loss: 3.025227E+00 | loss scale: 1048576.0 | grad norm: 0.443 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2463.97, 2464.01)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 216000 | lm loss value: 3.664305E+00 | lm loss PPL: 3.902899E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-25 17:01:28] iteration   216100/  500000 | consumed samples:     13830400 | elapsed time per iteration (ms): 617.3 | learning rate: 4.415700E-05 | global batch size:    64 | lm loss: 3.017756E+00 | loss scale: 1048576.0 | grad norm: 0.448 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 17:02:30] iteration   216200/  500000 | consumed samples:     13836800 | elapsed time per iteration (ms): 618.3 | learning rate: 4.409739E-05 | global batch size:    64 | lm loss: 3.027263E+00 | loss scale: 1048576.0 | grad norm: 0.443 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 17:03:32] iteration   216300/  500000 | consumed samples:     13843200 | elapsed time per iteration (ms): 618.7 | learning rate: 4.403782E-05 | global batch size:    64 | lm loss: 3.018017E+00 | loss scale: 1048576.0 | grad norm: 0.458 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 17:04:34] iteration   216400/  500000 | consumed samples:     13849600 | elapsed time per iteration (ms): 618.7 | learning rate: 4.397828E-05 | global batch size:    64 | lm loss: 3.012036E+00 | loss scale: 1048576.0 | grad norm: 0.459 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 17:05:35] iteration   216500/  500000 | consumed samples:     13856000 | elapsed time per iteration (ms): 618.5 | learning rate: 4.391878E-05 | global batch size:    64 | lm loss: 3.019668E+00 | loss scale: 1048576.0 | grad norm: 0.452 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 17:06:37] iteration   216600/  500000 | consumed samples:     13862400 | elapsed time per iteration (ms): 617.9 | learning rate: 4.385931E-05 | global batch size:    64 | lm loss: 3.020756E+00 | loss scale: 1048576.0 | grad norm: 0.453 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 17:07:39] iteration   216700/  500000 | consumed samples:     13868800 | elapsed time per iteration (ms): 619.0 | learning rate: 4.379988E-05 | global batch size:    64 | lm loss: 3.034400E+00 | loss scale: 2097152.0 | grad norm: 0.456 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 17:08:41] iteration   216800/  500000 | consumed samples:     13875200 | elapsed time per iteration (ms): 617.5 | learning rate: 4.374048E-05 | global batch size:    64 | lm loss: 3.044007E+00 | loss scale: 2097152.0 | grad norm: 0.445 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 17:09:43] iteration   216900/  500000 | consumed samples:     13881600 | elapsed time per iteration (ms): 618.8 | learning rate: 4.368112E-05 | global batch size:    64 | lm loss: 3.022656E+00 | loss scale: 2097152.0 | grad norm: 0.443 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 17:10:45] iteration   217000/  500000 | consumed samples:     13888000 | elapsed time per iteration (ms): 621.4 | learning rate: 4.362239E-05 | global batch size:    64 | lm loss: 3.022531E+00 | loss scale: 2097152.0 | grad norm: 0.456 | number of skipped iterations:   1 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2462.21, 2462.23)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 217000 | lm loss value: 3.683931E+00 | lm loss PPL: 3.980256E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-25 17:11:49] iteration   217100/  500000 | consumed samples:     13894400 | elapsed time per iteration (ms): 618.5 | learning rate: 4.356370E-05 | global batch size:    64 | lm loss: 3.014361E+00 | loss scale: 1048576.0 | grad norm: 0.466 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-25 17:12:51] iteration   217200/  500000 | consumed samples:     13900800 | elapsed time per iteration (ms): 620.1 | learning rate: 4.350444E-05 | global batch size:    64 | lm loss: 3.012743E+00 | loss scale: 1048576.0 | grad norm: 0.456 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 17:13:53] iteration   217300/  500000 | consumed samples:     13907200 | elapsed time per iteration (ms): 619.1 | learning rate: 4.344523E-05 | global batch size:    64 | lm loss: 3.011598E+00 | loss scale: 1048576.0 | grad norm: 0.456 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 17:14:55] iteration   217400/  500000 | consumed samples:     13913600 | elapsed time per iteration (ms): 618.4 | learning rate: 4.338604E-05 | global batch size:    64 | lm loss: 3.027542E+00 | loss scale: 1048576.0 | grad norm: 0.446 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 17:15:57] iteration   217500/  500000 | consumed samples:     13920000 | elapsed time per iteration (ms): 619.5 | learning rate: 4.332690E-05 | global batch size:    64 | lm loss: 3.015839E+00 | loss scale: 1048576.0 | grad norm: 0.450 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 17:16:59] iteration   217600/  500000 | consumed samples:     13926400 | elapsed time per iteration (ms): 617.6 | learning rate: 4.326838E-05 | global batch size:    64 | lm loss: 3.024807E+00 | loss scale: 524288.0 | grad norm: 0.465 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-25 17:18:01] iteration   217700/  500000 | consumed samples:     13932800 | elapsed time per iteration (ms): 619.1 | learning rate: 4.320931E-05 | global batch size:    64 | lm loss: 3.027466E+00 | loss scale: 524288.0 | grad norm: 0.466 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 17:19:03] iteration   217800/  500000 | consumed samples:     13939200 | elapsed time per iteration (ms): 619.4 | learning rate: 4.315027E-05 | global batch size:    64 | lm loss: 3.020564E+00 | loss scale: 524288.0 | grad norm: 0.458 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 17:20:04] iteration   217900/  500000 | consumed samples:     13945600 | elapsed time per iteration (ms): 619.3 | learning rate: 4.309127E-05 | global batch size:    64 | lm loss: 3.013179E+00 | loss scale: 524288.0 | grad norm: 0.455 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 17:21:07] iteration   218000/  500000 | consumed samples:     13952000 | elapsed time per iteration (ms): 620.2 | learning rate: 4.303230E-05 | global batch size:    64 | lm loss: 3.021955E+00 | loss scale: 524288.0 | grad norm: 0.455 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2462.72, 2462.77)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 218000 | lm loss value: 3.672139E+00 | lm loss PPL: 3.933595E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-25 17:22:11] iteration   218100/  500000 | consumed samples:     13958400 | elapsed time per iteration (ms): 619.6 | learning rate: 4.297337E-05 | global batch size:    64 | lm loss: 3.024185E+00 | loss scale: 524288.0 | grad norm: 0.449 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 17:23:13] iteration   218200/  500000 | consumed samples:     13964800 | elapsed time per iteration (ms): 622.9 | learning rate: 4.291448E-05 | global batch size:    64 | lm loss: 3.042254E+00 | loss scale: 524288.0 | grad norm: 0.445 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 17:24:15] iteration   218300/  500000 | consumed samples:     13971200 | elapsed time per iteration (ms): 621.2 | learning rate: 4.285563E-05 | global batch size:    64 | lm loss: 3.016897E+00 | loss scale: 524288.0 | grad norm: 0.446 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 17:25:17] iteration   218400/  500000 | consumed samples:     13977600 | elapsed time per iteration (ms): 619.5 | learning rate: 4.279681E-05 | global batch size:    64 | lm loss: 3.029051E+00 | loss scale: 524288.0 | grad norm: 0.445 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 17:26:19] iteration   218500/  500000 | consumed samples:     13984000 | elapsed time per iteration (ms): 621.6 | learning rate: 4.273802E-05 | global batch size:    64 | lm loss: 3.022649E+00 | loss scale: 524288.0 | grad norm: 0.475 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 17:27:21] iteration   218600/  500000 | consumed samples:     13990400 | elapsed time per iteration (ms): 618.1 | learning rate: 4.267928E-05 | global batch size:    64 | lm loss: 3.000579E+00 | loss scale: 1048576.0 | grad norm: 0.448 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 17:28:23] iteration   218700/  500000 | consumed samples:     13996800 | elapsed time per iteration (ms): 618.6 | learning rate: 4.262057E-05 | global batch size:    64 | lm loss: 3.022921E+00 | loss scale: 1048576.0 | grad norm: 0.450 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 17:29:25] iteration   218800/  500000 | consumed samples:     14003200 | elapsed time per iteration (ms): 619.6 | learning rate: 4.256190E-05 | global batch size:    64 | lm loss: 3.025234E+00 | loss scale: 1048576.0 | grad norm: 0.451 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 17:30:27] iteration   218900/  500000 | consumed samples:     14009600 | elapsed time per iteration (ms): 621.8 | learning rate: 4.250326E-05 | global batch size:    64 | lm loss: 3.023934E+00 | loss scale: 1048576.0 | grad norm: 0.451 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 17:31:29] iteration   219000/  500000 | consumed samples:     14016000 | elapsed time per iteration (ms): 621.7 | learning rate: 4.244466E-05 | global batch size:    64 | lm loss: 3.018311E+00 | loss scale: 1048576.0 | grad norm: 0.465 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2465.88, 2465.93)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 219000 | lm loss value: 3.750063E+00 | lm loss PPL: 4.252376E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-25 17:32:34] iteration   219100/  500000 | consumed samples:     14022400 | elapsed time per iteration (ms): 619.5 | learning rate: 4.238610E-05 | global batch size:    64 | lm loss: 3.032206E+00 | loss scale: 1048576.0 | grad norm: 0.456 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 17:33:36] iteration   219200/  500000 | consumed samples:     14028800 | elapsed time per iteration (ms): 618.1 | learning rate: 4.232758E-05 | global batch size:    64 | lm loss: 3.028633E+00 | loss scale: 1048576.0 | grad norm: 0.461 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 17:34:37] iteration   219300/  500000 | consumed samples:     14035200 | elapsed time per iteration (ms): 617.6 | learning rate: 4.226909E-05 | global batch size:    64 | lm loss: 3.023186E+00 | loss scale: 1048576.0 | grad norm: 0.456 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 17:35:39] iteration   219400/  500000 | consumed samples:     14041600 | elapsed time per iteration (ms): 617.7 | learning rate: 4.221064E-05 | global batch size:    64 | lm loss: 3.019397E+00 | loss scale: 1048576.0 | grad norm: 0.461 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 17:36:41] iteration   219500/  500000 | consumed samples:     14048000 | elapsed time per iteration (ms): 620.1 | learning rate: 4.215222E-05 | global batch size:    64 | lm loss: 3.019838E+00 | loss scale: 1048576.0 | grad norm: 0.455 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 17:37:43] iteration   219600/  500000 | consumed samples:     14054400 | elapsed time per iteration (ms): 618.2 | learning rate: 4.209385E-05 | global batch size:    64 | lm loss: 3.030901E+00 | loss scale: 2097152.0 | grad norm: 0.459 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 17:38:45] iteration   219700/  500000 | consumed samples:     14060800 | elapsed time per iteration (ms): 618.0 | learning rate: 4.203609E-05 | global batch size:    64 | lm loss: 3.014922E+00 | loss scale: 2097152.0 | grad norm: 0.455 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-25 17:39:47] iteration   219800/  500000 | consumed samples:     14067200 | elapsed time per iteration (ms): 618.3 | learning rate: 4.197837E-05 | global batch size:    64 | lm loss: 3.017704E+00 | loss scale: 1048576.0 | grad norm: 0.450 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-25 17:40:49] iteration   219900/  500000 | consumed samples:     14073600 | elapsed time per iteration (ms): 619.7 | learning rate: 4.192011E-05 | global batch size:    64 | lm loss: 3.018703E+00 | loss scale: 1048576.0 | grad norm: 0.453 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 17:41:50] iteration   220000/  500000 | consumed samples:     14080000 | elapsed time per iteration (ms): 617.9 | learning rate: 4.186188E-05 | global batch size:    64 | lm loss: 3.011926E+00 | loss scale: 1048576.0 | grad norm: 0.455 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2464.72, 2464.83)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 220000 | lm loss value: 3.727164E+00 | lm loss PPL: 4.156107E+01 | 
--------------------------------------------------------------------------------------------------
saving checkpoint at iteration  220000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-distribution in torch format
  successfully saved checkpoint at iteration  220000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-distribution
(min, max) time across ranks (ms):
    save-checkpoint ................................: (2305.43, 2305.43)
 [2024-06-25 17:42:57] iteration   220100/  500000 | consumed samples:     14086400 | elapsed time per iteration (ms): 619.5 | learning rate: 4.180369E-05 | global batch size:    64 | lm loss: 3.019803E+00 | loss scale: 1048576.0 | grad norm: 0.461 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 17:43:59] iteration   220200/  500000 | consumed samples:     14092800 | elapsed time per iteration (ms): 617.9 | learning rate: 4.174554E-05 | global batch size:    64 | lm loss: 3.028235E+00 | loss scale: 1048576.0 | grad norm: 0.473 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 17:45:01] iteration   220300/  500000 | consumed samples:     14099200 | elapsed time per iteration (ms): 619.6 | learning rate: 4.168800E-05 | global batch size:    64 | lm loss: 3.017673E+00 | loss scale: 524288.0 | grad norm: 0.450 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-25 17:46:03] iteration   220400/  500000 | consumed samples:     14105600 | elapsed time per iteration (ms): 619.3 | learning rate: 4.162992E-05 | global batch size:    64 | lm loss: 3.009205E+00 | loss scale: 524288.0 | grad norm: 0.441 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 17:47:05] iteration   220500/  500000 | consumed samples:     14112000 | elapsed time per iteration (ms): 620.5 | learning rate: 4.157188E-05 | global batch size:    64 | lm loss: 3.018920E+00 | loss scale: 524288.0 | grad norm: 0.457 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 17:48:07] iteration   220600/  500000 | consumed samples:     14118400 | elapsed time per iteration (ms): 622.4 | learning rate: 4.151388E-05 | global batch size:    64 | lm loss: 3.023124E+00 | loss scale: 524288.0 | grad norm: 0.461 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 17:49:09] iteration   220700/  500000 | consumed samples:     14124800 | elapsed time per iteration (ms): 620.7 | learning rate: 4.145592E-05 | global batch size:    64 | lm loss: 3.027235E+00 | loss scale: 524288.0 | grad norm: 0.440 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 17:50:11] iteration   220800/  500000 | consumed samples:     14131200 | elapsed time per iteration (ms): 619.9 | learning rate: 4.139799E-05 | global batch size:    64 | lm loss: 3.008363E+00 | loss scale: 524288.0 | grad norm: 0.459 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 17:51:13] iteration   220900/  500000 | consumed samples:     14137600 | elapsed time per iteration (ms): 619.6 | learning rate: 4.134010E-05 | global batch size:    64 | lm loss: 3.016641E+00 | loss scale: 524288.0 | grad norm: 0.456 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 17:52:15] iteration   221000/  500000 | consumed samples:     14144000 | elapsed time per iteration (ms): 618.8 | learning rate: 4.128225E-05 | global batch size:    64 | lm loss: 3.024688E+00 | loss scale: 524288.0 | grad norm: 0.462 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2462.28, 2462.31)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 221000 | lm loss value: 3.712523E+00 | lm loss PPL: 4.095699E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-25 17:53:19] iteration   221100/  500000 | consumed samples:     14150400 | elapsed time per iteration (ms): 617.1 | learning rate: 4.122444E-05 | global batch size:    64 | lm loss: 3.032223E+00 | loss scale: 524288.0 | grad norm: 0.456 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 17:54:21] iteration   221200/  500000 | consumed samples:     14156800 | elapsed time per iteration (ms): 620.2 | learning rate: 4.116667E-05 | global batch size:    64 | lm loss: 3.020830E+00 | loss scale: 524288.0 | grad norm: 0.467 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 17:55:23] iteration   221300/  500000 | consumed samples:     14163200 | elapsed time per iteration (ms): 620.0 | learning rate: 4.110893E-05 | global batch size:    64 | lm loss: 3.004742E+00 | loss scale: 1048576.0 | grad norm: 0.457 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 17:56:25] iteration   221400/  500000 | consumed samples:     14169600 | elapsed time per iteration (ms): 619.2 | learning rate: 4.105123E-05 | global batch size:    64 | lm loss: 3.032652E+00 | loss scale: 1048576.0 | grad norm: 0.454 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 17:57:27] iteration   221500/  500000 | consumed samples:     14176000 | elapsed time per iteration (ms): 620.7 | learning rate: 4.099357E-05 | global batch size:    64 | lm loss: 3.025164E+00 | loss scale: 1048576.0 | grad norm: 0.472 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 17:58:29] iteration   221600/  500000 | consumed samples:     14182400 | elapsed time per iteration (ms): 621.0 | learning rate: 4.093595E-05 | global batch size:    64 | lm loss: 3.029286E+00 | loss scale: 1048576.0 | grad norm: 0.432 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 17:59:31] iteration   221700/  500000 | consumed samples:     14188800 | elapsed time per iteration (ms): 618.5 | learning rate: 4.087837E-05 | global batch size:    64 | lm loss: 3.029203E+00 | loss scale: 1048576.0 | grad norm: 0.452 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 18:00:33] iteration   221800/  500000 | consumed samples:     14195200 | elapsed time per iteration (ms): 619.1 | learning rate: 4.082082E-05 | global batch size:    64 | lm loss: 3.011917E+00 | loss scale: 1048576.0 | grad norm: 0.443 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 18:01:35] iteration   221900/  500000 | consumed samples:     14201600 | elapsed time per iteration (ms): 619.6 | learning rate: 4.076332E-05 | global batch size:    64 | lm loss: 3.029062E+00 | loss scale: 1048576.0 | grad norm: 0.476 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 18:02:37] iteration   222000/  500000 | consumed samples:     14208000 | elapsed time per iteration (ms): 618.5 | learning rate: 4.070585E-05 | global batch size:    64 | lm loss: 3.031810E+00 | loss scale: 1048576.0 | grad norm: 0.452 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2462.25, 2462.25)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 222000 | lm loss value: 3.717349E+00 | lm loss PPL: 4.115514E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-25 18:03:41] iteration   222100/  500000 | consumed samples:     14214400 | elapsed time per iteration (ms): 619.6 | learning rate: 4.064842E-05 | global batch size:    64 | lm loss: 3.016867E+00 | loss scale: 1048576.0 | grad norm: 0.465 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 18:04:43] iteration   222200/  500000 | consumed samples:     14220800 | elapsed time per iteration (ms): 619.4 | learning rate: 4.059103E-05 | global batch size:    64 | lm loss: 3.011343E+00 | loss scale: 1048576.0 | grad norm: 0.444 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 18:05:45] iteration   222300/  500000 | consumed samples:     14227200 | elapsed time per iteration (ms): 618.2 | learning rate: 4.053368E-05 | global batch size:    64 | lm loss: 3.018355E+00 | loss scale: 2097152.0 | grad norm: 0.452 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 18:06:47] iteration   222400/  500000 | consumed samples:     14233600 | elapsed time per iteration (ms): 617.8 | learning rate: 4.047752E-05 | global batch size:    64 | lm loss: 3.011861E+00 | loss scale: 1048576.0 | grad norm: 0.451 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-25 18:07:49] iteration   222500/  500000 | consumed samples:     14240000 | elapsed time per iteration (ms): 618.6 | learning rate: 4.042024E-05 | global batch size:    64 | lm loss: 3.009176E+00 | loss scale: 1048576.0 | grad norm: 0.453 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 18:08:51] iteration   222600/  500000 | consumed samples:     14246400 | elapsed time per iteration (ms): 618.7 | learning rate: 4.036301E-05 | global batch size:    64 | lm loss: 3.021050E+00 | loss scale: 1048576.0 | grad norm: 0.456 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 18:09:52] iteration   222700/  500000 | consumed samples:     14252800 | elapsed time per iteration (ms): 619.3 | learning rate: 4.030581E-05 | global batch size:    64 | lm loss: 3.020771E+00 | loss scale: 1048576.0 | grad norm: 0.463 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 18:10:55] iteration   222800/  500000 | consumed samples:     14259200 | elapsed time per iteration (ms): 621.4 | learning rate: 4.024865E-05 | global batch size:    64 | lm loss: 3.034807E+00 | loss scale: 1048576.0 | grad norm: 0.465 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 18:11:57] iteration   222900/  500000 | consumed samples:     14265600 | elapsed time per iteration (ms): 619.4 | learning rate: 4.019153E-05 | global batch size:    64 | lm loss: 3.026406E+00 | loss scale: 1048576.0 | grad norm: 0.451 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 18:12:59] iteration   223000/  500000 | consumed samples:     14272000 | elapsed time per iteration (ms): 621.6 | learning rate: 4.013446E-05 | global batch size:    64 | lm loss: 3.028597E+00 | loss scale: 1048576.0 | grad norm: 0.456 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2463.96, 2464.10)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 223000 | lm loss value: 3.721439E+00 | lm loss PPL: 4.132383E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-25 18:14:03] iteration   223100/  500000 | consumed samples:     14278400 | elapsed time per iteration (ms): 620.2 | learning rate: 4.007742E-05 | global batch size:    64 | lm loss: 3.021601E+00 | loss scale: 1048576.0 | grad norm: 0.447 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 18:15:05] iteration   223200/  500000 | consumed samples:     14284800 | elapsed time per iteration (ms): 619.4 | learning rate: 4.002041E-05 | global batch size:    64 | lm loss: 3.013215E+00 | loss scale: 1048576.0 | grad norm: 0.461 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 18:16:07] iteration   223300/  500000 | consumed samples:     14291200 | elapsed time per iteration (ms): 622.2 | learning rate: 3.996345E-05 | global batch size:    64 | lm loss: 3.026044E+00 | loss scale: 1048576.0 | grad norm: 0.475 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 18:17:09] iteration   223400/  500000 | consumed samples:     14297600 | elapsed time per iteration (ms): 617.8 | learning rate: 3.990767E-05 | global batch size:    64 | lm loss: 3.007746E+00 | loss scale: 1048576.0 | grad norm: 0.451 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-25 18:18:11] iteration   223500/  500000 | consumed samples:     14304000 | elapsed time per iteration (ms): 620.7 | learning rate: 3.985079E-05 | global batch size:    64 | lm loss: 3.005345E+00 | loss scale: 1048576.0 | grad norm: 0.434 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 18:19:13] iteration   223600/  500000 | consumed samples:     14310400 | elapsed time per iteration (ms): 618.4 | learning rate: 3.979394E-05 | global batch size:    64 | lm loss: 3.022463E+00 | loss scale: 1048576.0 | grad norm: 0.457 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 18:20:15] iteration   223700/  500000 | consumed samples:     14316800 | elapsed time per iteration (ms): 616.7 | learning rate: 3.973714E-05 | global batch size:    64 | lm loss: 3.015039E+00 | loss scale: 1048576.0 | grad norm: 0.445 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 18:21:16] iteration   223800/  500000 | consumed samples:     14323200 | elapsed time per iteration (ms): 617.0 | learning rate: 3.968037E-05 | global batch size:    64 | lm loss: 3.025590E+00 | loss scale: 1048576.0 | grad norm: 0.444 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 18:22:18] iteration   223900/  500000 | consumed samples:     14329600 | elapsed time per iteration (ms): 620.5 | learning rate: 3.962365E-05 | global batch size:    64 | lm loss: 3.003742E+00 | loss scale: 1048576.0 | grad norm: 0.468 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 18:23:20] iteration   224000/  500000 | consumed samples:     14336000 | elapsed time per iteration (ms): 618.7 | learning rate: 3.956696E-05 | global batch size:    64 | lm loss: 3.023161E+00 | loss scale: 1048576.0 | grad norm: 0.442 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2463.12, 2463.17)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 224000 | lm loss value: 3.681435E+00 | lm loss PPL: 3.970331E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-25 18:24:25] iteration   224100/  500000 | consumed samples:     14342400 | elapsed time per iteration (ms): 620.0 | learning rate: 3.951032E-05 | global batch size:    64 | lm loss: 3.012270E+00 | loss scale: 1048576.0 | grad norm: 0.454 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 18:25:27] iteration   224200/  500000 | consumed samples:     14348800 | elapsed time per iteration (ms): 621.8 | learning rate: 3.945371E-05 | global batch size:    64 | lm loss: 3.010739E+00 | loss scale: 1048576.0 | grad norm: 0.447 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 18:26:29] iteration   224300/  500000 | consumed samples:     14355200 | elapsed time per iteration (ms): 619.9 | learning rate: 3.939715E-05 | global batch size:    64 | lm loss: 3.024509E+00 | loss scale: 1048576.0 | grad norm: 0.451 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 18:27:31] iteration   224400/  500000 | consumed samples:     14361600 | elapsed time per iteration (ms): 618.4 | learning rate: 3.934062E-05 | global batch size:    64 | lm loss: 3.023600E+00 | loss scale: 2097152.0 | grad norm: 0.440 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 18:28:33] iteration   224500/  500000 | consumed samples:     14368000 | elapsed time per iteration (ms): 618.2 | learning rate: 3.928414E-05 | global batch size:    64 | lm loss: 3.018141E+00 | loss scale: 2097152.0 | grad norm: 0.470 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 18:29:35] iteration   224600/  500000 | consumed samples:     14374400 | elapsed time per iteration (ms): 619.2 | learning rate: 3.922825E-05 | global batch size:    64 | lm loss: 3.013383E+00 | loss scale: 2097152.0 | grad norm: 0.450 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-25 18:30:37] iteration   224700/  500000 | consumed samples:     14380800 | elapsed time per iteration (ms): 620.0 | learning rate: 3.917241E-05 | global batch size:    64 | lm loss: 3.016688E+00 | loss scale: 1048576.0 | grad norm: 0.463 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-25 18:31:39] iteration   224800/  500000 | consumed samples:     14387200 | elapsed time per iteration (ms): 620.2 | learning rate: 3.911605E-05 | global batch size:    64 | lm loss: 3.027601E+00 | loss scale: 1048576.0 | grad norm: 0.465 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 18:32:41] iteration   224900/  500000 | consumed samples:     14393600 | elapsed time per iteration (ms): 619.5 | learning rate: 3.905972E-05 | global batch size:    64 | lm loss: 3.013648E+00 | loss scale: 1048576.0 | grad norm: 0.457 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 18:33:42] iteration   225000/  500000 | consumed samples:     14400000 | elapsed time per iteration (ms): 617.5 | learning rate: 3.900343E-05 | global batch size:    64 | lm loss: 3.016127E+00 | loss scale: 1048576.0 | grad norm: 0.463 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2461.11, 2461.14)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 225000 | lm loss value: 3.730273E+00 | lm loss PPL: 4.169051E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-25 18:34:47] iteration   225100/  500000 | consumed samples:     14406400 | elapsed time per iteration (ms): 618.0 | learning rate: 3.894719E-05 | global batch size:    64 | lm loss: 3.026483E+00 | loss scale: 1048576.0 | grad norm: 0.467 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 18:35:49] iteration   225200/  500000 | consumed samples:     14412800 | elapsed time per iteration (ms): 620.5 | learning rate: 3.889098E-05 | global batch size:    64 | lm loss: 3.022396E+00 | loss scale: 1048576.0 | grad norm: 0.465 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 18:36:51] iteration   225300/  500000 | consumed samples:     14419200 | elapsed time per iteration (ms): 619.6 | learning rate: 3.883482E-05 | global batch size:    64 | lm loss: 3.006856E+00 | loss scale: 1048576.0 | grad norm: 0.448 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 18:37:53] iteration   225400/  500000 | consumed samples:     14425600 | elapsed time per iteration (ms): 619.9 | learning rate: 3.877869E-05 | global batch size:    64 | lm loss: 3.009316E+00 | loss scale: 1048576.0 | grad norm: 0.472 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 18:38:54] iteration   225500/  500000 | consumed samples:     14432000 | elapsed time per iteration (ms): 619.4 | learning rate: 3.872261E-05 | global batch size:    64 | lm loss: 3.028246E+00 | loss scale: 1048576.0 | grad norm: 0.447 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 18:39:56] iteration   225600/  500000 | consumed samples:     14438400 | elapsed time per iteration (ms): 618.9 | learning rate: 3.866657E-05 | global batch size:    64 | lm loss: 3.019281E+00 | loss scale: 1048576.0 | grad norm: 0.453 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 18:40:58] iteration   225700/  500000 | consumed samples:     14444800 | elapsed time per iteration (ms): 617.4 | learning rate: 3.861056E-05 | global batch size:    64 | lm loss: 3.031852E+00 | loss scale: 2097152.0 | grad norm: 0.451 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 18:42:00] iteration   225800/  500000 | consumed samples:     14451200 | elapsed time per iteration (ms): 619.1 | learning rate: 3.855460E-05 | global batch size:    64 | lm loss: 3.018546E+00 | loss scale: 2097152.0 | grad norm: 0.459 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 18:43:02] iteration   225900/  500000 | consumed samples:     14457600 | elapsed time per iteration (ms): 617.0 | learning rate: 3.849980E-05 | global batch size:    64 | lm loss: 3.007160E+00 | loss scale: 1048576.0 | grad norm: 0.461 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-25 18:44:04] iteration   226000/  500000 | consumed samples:     14464000 | elapsed time per iteration (ms): 619.5 | learning rate: 3.844392E-05 | global batch size:    64 | lm loss: 2.998010E+00 | loss scale: 1048576.0 | grad norm: 0.481 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2463.05, 2463.05)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 226000 | lm loss value: 3.666434E+00 | lm loss PPL: 3.911218E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-25 18:45:08] iteration   226100/  500000 | consumed samples:     14470400 | elapsed time per iteration (ms): 618.7 | learning rate: 3.838808E-05 | global batch size:    64 | lm loss: 3.011068E+00 | loss scale: 1048576.0 | grad norm: 0.462 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 18:46:10] iteration   226200/  500000 | consumed samples:     14476800 | elapsed time per iteration (ms): 619.4 | learning rate: 3.833228E-05 | global batch size:    64 | lm loss: 3.017972E+00 | loss scale: 1048576.0 | grad norm: 0.455 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 18:47:12] iteration   226300/  500000 | consumed samples:     14483200 | elapsed time per iteration (ms): 619.6 | learning rate: 3.827652E-05 | global batch size:    64 | lm loss: 3.014644E+00 | loss scale: 1048576.0 | grad norm: 0.462 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 18:48:14] iteration   226400/  500000 | consumed samples:     14489600 | elapsed time per iteration (ms): 617.6 | learning rate: 3.822080E-05 | global batch size:    64 | lm loss: 3.002904E+00 | loss scale: 1048576.0 | grad norm: 0.459 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 18:49:16] iteration   226500/  500000 | consumed samples:     14496000 | elapsed time per iteration (ms): 618.6 | learning rate: 3.816513E-05 | global batch size:    64 | lm loss: 3.012896E+00 | loss scale: 1048576.0 | grad norm: 0.469 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 18:50:17] iteration   226600/  500000 | consumed samples:     14502400 | elapsed time per iteration (ms): 618.2 | learning rate: 3.810949E-05 | global batch size:    64 | lm loss: 3.001623E+00 | loss scale: 1048576.0 | grad norm: 0.462 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 18:51:19] iteration   226700/  500000 | consumed samples:     14508800 | elapsed time per iteration (ms): 617.2 | learning rate: 3.805390E-05 | global batch size:    64 | lm loss: 3.021205E+00 | loss scale: 1048576.0 | grad norm: 0.459 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 18:52:21] iteration   226800/  500000 | consumed samples:     14515200 | elapsed time per iteration (ms): 618.3 | learning rate: 3.799835E-05 | global batch size:    64 | lm loss: 3.019919E+00 | loss scale: 1048576.0 | grad norm: 0.466 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 18:53:23] iteration   226900/  500000 | consumed samples:     14521600 | elapsed time per iteration (ms): 617.7 | learning rate: 3.794283E-05 | global batch size:    64 | lm loss: 3.013336E+00 | loss scale: 2097152.0 | grad norm: 0.448 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 18:54:25] iteration   227000/  500000 | consumed samples:     14528000 | elapsed time per iteration (ms): 620.6 | learning rate: 3.788792E-05 | global batch size:    64 | lm loss: 3.012657E+00 | loss scale: 2097152.0 | grad norm: 0.481 | number of skipped iterations:   1 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2463.02, 2463.26)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 227000 | lm loss value: 3.688984E+00 | lm loss PPL: 4.000417E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-25 18:55:29] iteration   227100/  500000 | consumed samples:     14534400 | elapsed time per iteration (ms): 619.2 | learning rate: 3.783249E-05 | global batch size:    64 | lm loss: 3.014836E+00 | loss scale: 2097152.0 | grad norm: 0.457 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 18:56:31] iteration   227200/  500000 | consumed samples:     14540800 | elapsed time per iteration (ms): 620.8 | learning rate: 3.777766E-05 | global batch size:    64 | lm loss: 3.008747E+00 | loss scale: 1048576.0 | grad norm: 0.460 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-25 18:57:33] iteration   227300/  500000 | consumed samples:     14547200 | elapsed time per iteration (ms): 619.2 | learning rate: 3.772231E-05 | global batch size:    64 | lm loss: 3.022068E+00 | loss scale: 1048576.0 | grad norm: 0.446 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 18:58:35] iteration   227400/  500000 | consumed samples:     14553600 | elapsed time per iteration (ms): 618.6 | learning rate: 3.766700E-05 | global batch size:    64 | lm loss: 3.017575E+00 | loss scale: 1048576.0 | grad norm: 0.466 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 18:59:37] iteration   227500/  500000 | consumed samples:     14560000 | elapsed time per iteration (ms): 618.6 | learning rate: 3.761174E-05 | global batch size:    64 | lm loss: 3.000258E+00 | loss scale: 1048576.0 | grad norm: 0.458 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 19:00:39] iteration   227600/  500000 | consumed samples:     14566400 | elapsed time per iteration (ms): 619.7 | learning rate: 3.755652E-05 | global batch size:    64 | lm loss: 2.995938E+00 | loss scale: 1048576.0 | grad norm: 0.453 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 19:01:41] iteration   227700/  500000 | consumed samples:     14572800 | elapsed time per iteration (ms): 618.5 | learning rate: 3.750134E-05 | global batch size:    64 | lm loss: 3.000835E+00 | loss scale: 1048576.0 | grad norm: 0.457 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 19:02:43] iteration   227800/  500000 | consumed samples:     14579200 | elapsed time per iteration (ms): 618.8 | learning rate: 3.744620E-05 | global batch size:    64 | lm loss: 3.016360E+00 | loss scale: 1048576.0 | grad norm: 0.465 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 19:03:44] iteration   227900/  500000 | consumed samples:     14585600 | elapsed time per iteration (ms): 619.5 | learning rate: 3.739111E-05 | global batch size:    64 | lm loss: 3.024941E+00 | loss scale: 1048576.0 | grad norm: 0.460 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 19:04:46] iteration   228000/  500000 | consumed samples:     14592000 | elapsed time per iteration (ms): 617.8 | learning rate: 3.733605E-05 | global batch size:    64 | lm loss: 3.014032E+00 | loss scale: 1048576.0 | grad norm: 0.455 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2461.78, 2461.96)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 228000 | lm loss value: 3.770809E+00 | lm loss PPL: 4.341518E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-25 19:05:51] iteration   228100/  500000 | consumed samples:     14598400 | elapsed time per iteration (ms): 619.4 | learning rate: 3.728104E-05 | global batch size:    64 | lm loss: 3.003773E+00 | loss scale: 1048576.0 | grad norm: 0.454 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 19:06:52] iteration   228200/  500000 | consumed samples:     14604800 | elapsed time per iteration (ms): 618.2 | learning rate: 3.722607E-05 | global batch size:    64 | lm loss: 2.998520E+00 | loss scale: 2097152.0 | grad norm: 0.484 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 19:07:54] iteration   228300/  500000 | consumed samples:     14611200 | elapsed time per iteration (ms): 618.7 | learning rate: 3.717224E-05 | global batch size:    64 | lm loss: 3.017457E+00 | loss scale: 1048576.0 | grad norm: 0.454 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-25 19:08:56] iteration   228400/  500000 | consumed samples:     14617600 | elapsed time per iteration (ms): 617.6 | learning rate: 3.711735E-05 | global batch size:    64 | lm loss: 3.013308E+00 | loss scale: 1048576.0 | grad norm: 0.456 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 19:09:58] iteration   228500/  500000 | consumed samples:     14624000 | elapsed time per iteration (ms): 620.0 | learning rate: 3.706306E-05 | global batch size:    64 | lm loss: 3.020766E+00 | loss scale: 524288.0 | grad norm: 0.454 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-25 19:11:00] iteration   228600/  500000 | consumed samples:     14630400 | elapsed time per iteration (ms): 619.2 | learning rate: 3.700825E-05 | global batch size:    64 | lm loss: 3.018106E+00 | loss scale: 524288.0 | grad norm: 0.470 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 19:12:02] iteration   228700/  500000 | consumed samples:     14636800 | elapsed time per iteration (ms): 620.2 | learning rate: 3.695349E-05 | global batch size:    64 | lm loss: 3.012783E+00 | loss scale: 524288.0 | grad norm: 0.449 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 19:13:04] iteration   228800/  500000 | consumed samples:     14643200 | elapsed time per iteration (ms): 620.1 | learning rate: 3.689877E-05 | global batch size:    64 | lm loss: 3.002830E+00 | loss scale: 524288.0 | grad norm: 0.470 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 19:14:06] iteration   228900/  500000 | consumed samples:     14649600 | elapsed time per iteration (ms): 617.7 | learning rate: 3.684410E-05 | global batch size:    64 | lm loss: 3.015112E+00 | loss scale: 524288.0 | grad norm: 0.456 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 19:15:08] iteration   229000/  500000 | consumed samples:     14656000 | elapsed time per iteration (ms): 618.7 | learning rate: 3.678946E-05 | global batch size:    64 | lm loss: 2.996543E+00 | loss scale: 524288.0 | grad norm: 0.478 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2465.42, 2465.43)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 229000 | lm loss value: 3.758980E+00 | lm loss PPL: 4.290462E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-25 19:16:12] iteration   229100/  500000 | consumed samples:     14662400 | elapsed time per iteration (ms): 617.3 | learning rate: 3.673487E-05 | global batch size:    64 | lm loss: 3.020270E+00 | loss scale: 524288.0 | grad norm: 0.464 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 19:17:14] iteration   229200/  500000 | consumed samples:     14668800 | elapsed time per iteration (ms): 620.4 | learning rate: 3.668032E-05 | global batch size:    64 | lm loss: 3.012950E+00 | loss scale: 524288.0 | grad norm: 0.452 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 19:18:16] iteration   229300/  500000 | consumed samples:     14675200 | elapsed time per iteration (ms): 617.3 | learning rate: 3.662582E-05 | global batch size:    64 | lm loss: 3.022194E+00 | loss scale: 524288.0 | grad norm: 0.458 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 19:19:18] iteration   229400/  500000 | consumed samples:     14681600 | elapsed time per iteration (ms): 619.0 | learning rate: 3.657136E-05 | global batch size:    64 | lm loss: 3.025153E+00 | loss scale: 524288.0 | grad norm: 0.463 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 19:20:20] iteration   229500/  500000 | consumed samples:     14688000 | elapsed time per iteration (ms): 619.6 | learning rate: 3.651694E-05 | global batch size:    64 | lm loss: 3.007637E+00 | loss scale: 1048576.0 | grad norm: 0.468 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 19:21:21] iteration   229600/  500000 | consumed samples:     14694400 | elapsed time per iteration (ms): 619.6 | learning rate: 3.646256E-05 | global batch size:    64 | lm loss: 3.002148E+00 | loss scale: 1048576.0 | grad norm: 0.454 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 19:22:23] iteration   229700/  500000 | consumed samples:     14700800 | elapsed time per iteration (ms): 617.9 | learning rate: 3.640822E-05 | global batch size:    64 | lm loss: 3.012091E+00 | loss scale: 1048576.0 | grad norm: 0.456 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 19:23:25] iteration   229800/  500000 | consumed samples:     14707200 | elapsed time per iteration (ms): 620.9 | learning rate: 3.635393E-05 | global batch size:    64 | lm loss: 3.013937E+00 | loss scale: 1048576.0 | grad norm: 0.481 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 19:24:27] iteration   229900/  500000 | consumed samples:     14713600 | elapsed time per iteration (ms): 619.7 | learning rate: 3.629968E-05 | global batch size:    64 | lm loss: 3.016683E+00 | loss scale: 1048576.0 | grad norm: 0.473 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 19:25:29] iteration   230000/  500000 | consumed samples:     14720000 | elapsed time per iteration (ms): 618.5 | learning rate: 3.624548E-05 | global batch size:    64 | lm loss: 3.000194E+00 | loss scale: 1048576.0 | grad norm: 0.477 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2462.98, 2463.00)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 230000 | lm loss value: 3.699473E+00 | lm loss PPL: 4.042600E+01 | 
--------------------------------------------------------------------------------------------------
saving checkpoint at iteration  230000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-distribution in torch format
  successfully saved checkpoint at iteration  230000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-distribution
(min, max) time across ranks (ms):
    save-checkpoint ................................: (2313.93, 2313.94)
 [2024-06-25 19:26:36] iteration   230100/  500000 | consumed samples:     14726400 | elapsed time per iteration (ms): 619.4 | learning rate: 3.619131E-05 | global batch size:    64 | lm loss: 2.999038E+00 | loss scale: 1048576.0 | grad norm: 0.455 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 19:27:38] iteration   230200/  500000 | consumed samples:     14732800 | elapsed time per iteration (ms): 619.4 | learning rate: 3.613719E-05 | global batch size:    64 | lm loss: 3.008315E+00 | loss scale: 1048576.0 | grad norm: 0.455 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 19:28:40] iteration   230300/  500000 | consumed samples:     14739200 | elapsed time per iteration (ms): 619.6 | learning rate: 3.608312E-05 | global batch size:    64 | lm loss: 3.018096E+00 | loss scale: 1048576.0 | grad norm: 0.463 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 19:29:42] iteration   230400/  500000 | consumed samples:     14745600 | elapsed time per iteration (ms): 618.2 | learning rate: 3.602908E-05 | global batch size:    64 | lm loss: 3.008542E+00 | loss scale: 1048576.0 | grad norm: 0.456 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 19:30:43] iteration   230500/  500000 | consumed samples:     14752000 | elapsed time per iteration (ms): 618.2 | learning rate: 3.597509E-05 | global batch size:    64 | lm loss: 3.004105E+00 | loss scale: 2097152.0 | grad norm: 0.470 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 19:31:45] iteration   230600/  500000 | consumed samples:     14758400 | elapsed time per iteration (ms): 619.4 | learning rate: 3.592168E-05 | global batch size:    64 | lm loss: 3.019393E+00 | loss scale: 2097152.0 | grad norm: 0.464 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-25 19:32:47] iteration   230700/  500000 | consumed samples:     14764800 | elapsed time per iteration (ms): 619.8 | learning rate: 3.586778E-05 | global batch size:    64 | lm loss: 3.015526E+00 | loss scale: 2097152.0 | grad norm: 0.454 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 19:33:49] iteration   230800/  500000 | consumed samples:     14771200 | elapsed time per iteration (ms): 618.4 | learning rate: 3.581446E-05 | global batch size:    64 | lm loss: 3.002669E+00 | loss scale: 1048576.0 | grad norm: 0.475 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-25 19:34:51] iteration   230900/  500000 | consumed samples:     14777600 | elapsed time per iteration (ms): 618.4 | learning rate: 3.576064E-05 | global batch size:    64 | lm loss: 3.008533E+00 | loss scale: 1048576.0 | grad norm: 0.467 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 19:35:53] iteration   231000/  500000 | consumed samples:     14784000 | elapsed time per iteration (ms): 621.6 | learning rate: 3.570686E-05 | global batch size:    64 | lm loss: 3.006697E+00 | loss scale: 1048576.0 | grad norm: 0.452 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2463.11, 2463.14)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 231000 | lm loss value: 3.697939E+00 | lm loss PPL: 4.036404E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-25 19:36:58] iteration   231100/  500000 | consumed samples:     14790400 | elapsed time per iteration (ms): 618.9 | learning rate: 3.565313E-05 | global batch size:    64 | lm loss: 3.017259E+00 | loss scale: 1048576.0 | grad norm: 0.462 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 19:38:00] iteration   231200/  500000 | consumed samples:     14796800 | elapsed time per iteration (ms): 620.5 | learning rate: 3.559945E-05 | global batch size:    64 | lm loss: 3.007118E+00 | loss scale: 1048576.0 | grad norm: 0.462 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 19:39:02] iteration   231300/  500000 | consumed samples:     14803200 | elapsed time per iteration (ms): 619.2 | learning rate: 3.554580E-05 | global batch size:    64 | lm loss: 3.027451E+00 | loss scale: 1048576.0 | grad norm: 0.469 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 19:40:03] iteration   231400/  500000 | consumed samples:     14809600 | elapsed time per iteration (ms): 616.8 | learning rate: 3.549220E-05 | global batch size:    64 | lm loss: 3.017590E+00 | loss scale: 1048576.0 | grad norm: 0.453 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 19:41:05] iteration   231500/  500000 | consumed samples:     14816000 | elapsed time per iteration (ms): 618.7 | learning rate: 3.543865E-05 | global batch size:    64 | lm loss: 3.008500E+00 | loss scale: 1048576.0 | grad norm: 0.451 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 19:42:07] iteration   231600/  500000 | consumed samples:     14822400 | elapsed time per iteration (ms): 616.6 | learning rate: 3.538513E-05 | global batch size:    64 | lm loss: 3.019565E+00 | loss scale: 1048576.0 | grad norm: 0.464 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 19:43:09] iteration   231700/  500000 | consumed samples:     14828800 | elapsed time per iteration (ms): 619.0 | learning rate: 3.533167E-05 | global batch size:    64 | lm loss: 3.025127E+00 | loss scale: 1048576.0 | grad norm: 0.466 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 19:44:11] iteration   231800/  500000 | consumed samples:     14835200 | elapsed time per iteration (ms): 619.5 | learning rate: 3.527824E-05 | global batch size:    64 | lm loss: 2.994533E+00 | loss scale: 2097152.0 | grad norm: 0.456 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 19:45:13] iteration   231900/  500000 | consumed samples:     14841600 | elapsed time per iteration (ms): 619.6 | learning rate: 3.522593E-05 | global batch size:    64 | lm loss: 3.001890E+00 | loss scale: 1048576.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-25 19:46:14] iteration   232000/  500000 | consumed samples:     14848000 | elapsed time per iteration (ms): 617.8 | learning rate: 3.517259E-05 | global batch size:    64 | lm loss: 3.010878E+00 | loss scale: 1048576.0 | grad norm: 0.457 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2462.69, 2462.69)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 232000 | lm loss value: 3.681641E+00 | lm loss PPL: 3.971151E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-25 19:47:19] iteration   232100/  500000 | consumed samples:     14854400 | elapsed time per iteration (ms): 619.7 | learning rate: 3.511930E-05 | global batch size:    64 | lm loss: 3.021606E+00 | loss scale: 1048576.0 | grad norm: 0.470 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 19:48:21] iteration   232200/  500000 | consumed samples:     14860800 | elapsed time per iteration (ms): 619.2 | learning rate: 3.506605E-05 | global batch size:    64 | lm loss: 3.006288E+00 | loss scale: 1048576.0 | grad norm: 0.463 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 19:49:23] iteration   232300/  500000 | consumed samples:     14867200 | elapsed time per iteration (ms): 618.9 | learning rate: 3.501284E-05 | global batch size:    64 | lm loss: 3.015687E+00 | loss scale: 1048576.0 | grad norm: 0.456 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 19:50:25] iteration   232400/  500000 | consumed samples:     14873600 | elapsed time per iteration (ms): 620.3 | learning rate: 3.495968E-05 | global batch size:    64 | lm loss: 3.006901E+00 | loss scale: 1048576.0 | grad norm: 0.461 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 19:51:27] iteration   232500/  500000 | consumed samples:     14880000 | elapsed time per iteration (ms): 619.8 | learning rate: 3.490657E-05 | global batch size:    64 | lm loss: 3.000946E+00 | loss scale: 1048576.0 | grad norm: 0.460 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 19:52:28] iteration   232600/  500000 | consumed samples:     14886400 | elapsed time per iteration (ms): 618.6 | learning rate: 3.485350E-05 | global batch size:    64 | lm loss: 3.014609E+00 | loss scale: 1048576.0 | grad norm: 0.461 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 19:53:30] iteration   232700/  500000 | consumed samples:     14892800 | elapsed time per iteration (ms): 617.2 | learning rate: 3.480100E-05 | global batch size:    64 | lm loss: 3.008667E+00 | loss scale: 524288.0 | grad norm: 0.468 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-25 19:54:32] iteration   232800/  500000 | consumed samples:     14899200 | elapsed time per iteration (ms): 620.6 | learning rate: 3.474801E-05 | global batch size:    64 | lm loss: 3.004061E+00 | loss scale: 524288.0 | grad norm: 0.454 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 19:55:34] iteration   232900/  500000 | consumed samples:     14905600 | elapsed time per iteration (ms): 617.6 | learning rate: 3.469508E-05 | global batch size:    64 | lm loss: 2.998444E+00 | loss scale: 524288.0 | grad norm: 0.452 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 19:56:36] iteration   233000/  500000 | consumed samples:     14912000 | elapsed time per iteration (ms): 619.1 | learning rate: 3.464218E-05 | global batch size:    64 | lm loss: 2.993000E+00 | loss scale: 524288.0 | grad norm: 0.479 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2460.87, 2461.02)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 233000 | lm loss value: 3.719181E+00 | lm loss PPL: 4.123061E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-25 19:57:40] iteration   233100/  500000 | consumed samples:     14918400 | elapsed time per iteration (ms): 620.5 | learning rate: 3.458933E-05 | global batch size:    64 | lm loss: 3.002140E+00 | loss scale: 524288.0 | grad norm: 0.471 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 19:58:43] iteration   233200/  500000 | consumed samples:     14924800 | elapsed time per iteration (ms): 621.2 | learning rate: 3.453653E-05 | global batch size:    64 | lm loss: 2.989359E+00 | loss scale: 524288.0 | grad norm: 0.466 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 19:59:44] iteration   233300/  500000 | consumed samples:     14931200 | elapsed time per iteration (ms): 619.0 | learning rate: 3.448376E-05 | global batch size:    64 | lm loss: 3.022338E+00 | loss scale: 524288.0 | grad norm: 0.462 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 20:00:46] iteration   233400/  500000 | consumed samples:     14937600 | elapsed time per iteration (ms): 618.3 | learning rate: 3.443105E-05 | global batch size:    64 | lm loss: 2.997874E+00 | loss scale: 524288.0 | grad norm: 0.455 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 20:01:48] iteration   233500/  500000 | consumed samples:     14944000 | elapsed time per iteration (ms): 620.5 | learning rate: 3.437838E-05 | global batch size:    64 | lm loss: 2.999779E+00 | loss scale: 524288.0 | grad norm: 0.455 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 20:02:50] iteration   233600/  500000 | consumed samples:     14950400 | elapsed time per iteration (ms): 620.0 | learning rate: 3.432575E-05 | global batch size:    64 | lm loss: 3.002753E+00 | loss scale: 524288.0 | grad norm: 0.464 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 20:03:52] iteration   233700/  500000 | consumed samples:     14956800 | elapsed time per iteration (ms): 621.5 | learning rate: 3.427317E-05 | global batch size:    64 | lm loss: 3.006860E+00 | loss scale: 1048576.0 | grad norm: 0.465 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 20:04:55] iteration   233800/  500000 | consumed samples:     14963200 | elapsed time per iteration (ms): 620.9 | learning rate: 3.422063E-05 | global batch size:    64 | lm loss: 2.995005E+00 | loss scale: 1048576.0 | grad norm: 0.463 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 20:05:56] iteration   233900/  500000 | consumed samples:     14969600 | elapsed time per iteration (ms): 618.4 | learning rate: 3.416814E-05 | global batch size:    64 | lm loss: 3.005532E+00 | loss scale: 1048576.0 | grad norm: 0.461 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 20:06:58] iteration   234000/  500000 | consumed samples:     14976000 | elapsed time per iteration (ms): 616.2 | learning rate: 3.411570E-05 | global batch size:    64 | lm loss: 3.005146E+00 | loss scale: 1048576.0 | grad norm: 0.454 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2463.38, 2463.45)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 234000 | lm loss value: 3.714909E+00 | lm loss PPL: 4.105486E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-25 20:08:02] iteration   234100/  500000 | consumed samples:     14982400 | elapsed time per iteration (ms): 619.7 | learning rate: 3.406330E-05 | global batch size:    64 | lm loss: 3.002869E+00 | loss scale: 1048576.0 | grad norm: 0.454 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 20:09:04] iteration   234200/  500000 | consumed samples:     14988800 | elapsed time per iteration (ms): 619.1 | learning rate: 3.401094E-05 | global batch size:    64 | lm loss: 3.008025E+00 | loss scale: 1048576.0 | grad norm: 0.463 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 20:10:06] iteration   234300/  500000 | consumed samples:     14995200 | elapsed time per iteration (ms): 619.0 | learning rate: 3.395863E-05 | global batch size:    64 | lm loss: 3.002402E+00 | loss scale: 1048576.0 | grad norm: 0.463 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 20:11:08] iteration   234400/  500000 | consumed samples:     15001600 | elapsed time per iteration (ms): 619.3 | learning rate: 3.390636E-05 | global batch size:    64 | lm loss: 3.018019E+00 | loss scale: 1048576.0 | grad norm: 0.452 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 20:12:10] iteration   234500/  500000 | consumed samples:     15008000 | elapsed time per iteration (ms): 620.7 | learning rate: 3.385414E-05 | global batch size:    64 | lm loss: 3.007616E+00 | loss scale: 1048576.0 | grad norm: 0.467 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 20:13:12] iteration   234600/  500000 | consumed samples:     15014400 | elapsed time per iteration (ms): 620.5 | learning rate: 3.380197E-05 | global batch size:    64 | lm loss: 3.004804E+00 | loss scale: 1048576.0 | grad norm: 0.473 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 20:14:14] iteration   234700/  500000 | consumed samples:     15020800 | elapsed time per iteration (ms): 619.1 | learning rate: 3.374984E-05 | global batch size:    64 | lm loss: 3.010283E+00 | loss scale: 2097152.0 | grad norm: 0.464 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 20:15:16] iteration   234800/  500000 | consumed samples:     15027200 | elapsed time per iteration (ms): 620.2 | learning rate: 3.369776E-05 | global batch size:    64 | lm loss: 3.003858E+00 | loss scale: 2097152.0 | grad norm: 0.463 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 20:16:18] iteration   234900/  500000 | consumed samples:     15033600 | elapsed time per iteration (ms): 619.5 | learning rate: 3.364572E-05 | global batch size:    64 | lm loss: 2.997638E+00 | loss scale: 2097152.0 | grad norm: 0.476 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 20:17:20] iteration   235000/  500000 | consumed samples:     15040000 | elapsed time per iteration (ms): 622.2 | learning rate: 3.359373E-05 | global batch size:    64 | lm loss: 3.002276E+00 | loss scale: 2097152.0 | grad norm: 0.470 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2461.11, 2461.39)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 235000 | lm loss value: 3.718043E+00 | lm loss PPL: 4.118372E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-25 20:18:25] iteration   235100/  500000 | consumed samples:     15046400 | elapsed time per iteration (ms): 621.2 | learning rate: 3.354178E-05 | global batch size:    64 | lm loss: 3.006735E+00 | loss scale: 2097152.0 | grad norm: 0.476 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 20:19:27] iteration   235200/  500000 | consumed samples:     15052800 | elapsed time per iteration (ms): 620.4 | learning rate: 3.349040E-05 | global batch size:    64 | lm loss: 2.994977E+00 | loss scale: 2097152.0 | grad norm: 0.444 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-25 20:20:29] iteration   235300/  500000 | consumed samples:     15059200 | elapsed time per iteration (ms): 619.3 | learning rate: 3.343906E-05 | global batch size:    64 | lm loss: 3.007283E+00 | loss scale: 1048576.0 | grad norm: 0.457 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-25 20:21:31] iteration   235400/  500000 | consumed samples:     15065600 | elapsed time per iteration (ms): 619.1 | learning rate: 3.338725E-05 | global batch size:    64 | lm loss: 3.000654E+00 | loss scale: 1048576.0 | grad norm: 0.459 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 20:22:33] iteration   235500/  500000 | consumed samples:     15072000 | elapsed time per iteration (ms): 619.8 | learning rate: 3.333548E-05 | global batch size:    64 | lm loss: 2.999292E+00 | loss scale: 1048576.0 | grad norm: 0.467 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 20:23:35] iteration   235600/  500000 | consumed samples:     15078400 | elapsed time per iteration (ms): 618.4 | learning rate: 3.328376E-05 | global batch size:    64 | lm loss: 2.996261E+00 | loss scale: 1048576.0 | grad norm: 0.453 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 20:24:37] iteration   235700/  500000 | consumed samples:     15084800 | elapsed time per iteration (ms): 620.3 | learning rate: 3.323209E-05 | global batch size:    64 | lm loss: 2.995897E+00 | loss scale: 1048576.0 | grad norm: 0.483 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 20:25:39] iteration   235800/  500000 | consumed samples:     15091200 | elapsed time per iteration (ms): 618.9 | learning rate: 3.318046E-05 | global batch size:    64 | lm loss: 3.013477E+00 | loss scale: 1048576.0 | grad norm: 0.467 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 20:26:41] iteration   235900/  500000 | consumed samples:     15097600 | elapsed time per iteration (ms): 621.8 | learning rate: 3.312888E-05 | global batch size:    64 | lm loss: 3.003140E+00 | loss scale: 1048576.0 | grad norm: 0.461 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 20:27:43] iteration   236000/  500000 | consumed samples:     15104000 | elapsed time per iteration (ms): 618.3 | learning rate: 3.307735E-05 | global batch size:    64 | lm loss: 3.004644E+00 | loss scale: 1048576.0 | grad norm: 0.476 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2463.22, 2463.22)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 236000 | lm loss value: 3.729284E+00 | lm loss PPL: 4.164926E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-25 20:28:47] iteration   236100/  500000 | consumed samples:     15110400 | elapsed time per iteration (ms): 618.8 | learning rate: 3.302586E-05 | global batch size:    64 | lm loss: 3.008626E+00 | loss scale: 1048576.0 | grad norm: 0.462 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 20:29:49] iteration   236200/  500000 | consumed samples:     15116800 | elapsed time per iteration (ms): 620.7 | learning rate: 3.297442E-05 | global batch size:    64 | lm loss: 3.008372E+00 | loss scale: 1048576.0 | grad norm: 0.466 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 20:30:51] iteration   236300/  500000 | consumed samples:     15123200 | elapsed time per iteration (ms): 619.8 | learning rate: 3.292302E-05 | global batch size:    64 | lm loss: 3.003226E+00 | loss scale: 2097152.0 | grad norm: 0.462 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 20:31:53] iteration   236400/  500000 | consumed samples:     15129600 | elapsed time per iteration (ms): 619.8 | learning rate: 3.287167E-05 | global batch size:    64 | lm loss: 3.014516E+00 | loss scale: 2097152.0 | grad norm: 0.467 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 20:32:55] iteration   236500/  500000 | consumed samples:     15136000 | elapsed time per iteration (ms): 620.7 | learning rate: 3.282139E-05 | global batch size:    64 | lm loss: 3.000432E+00 | loss scale: 1048576.0 | grad norm: 0.463 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-25 20:33:57] iteration   236600/  500000 | consumed samples:     15142400 | elapsed time per iteration (ms): 617.3 | learning rate: 3.277013E-05 | global batch size:    64 | lm loss: 3.003357E+00 | loss scale: 1048576.0 | grad norm: 0.470 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 20:34:59] iteration   236700/  500000 | consumed samples:     15148800 | elapsed time per iteration (ms): 619.5 | learning rate: 3.271892E-05 | global batch size:    64 | lm loss: 3.016961E+00 | loss scale: 1048576.0 | grad norm: 0.449 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 20:36:01] iteration   236800/  500000 | consumed samples:     15155200 | elapsed time per iteration (ms): 622.8 | learning rate: 3.266776E-05 | global batch size:    64 | lm loss: 2.999786E+00 | loss scale: 1048576.0 | grad norm: 0.462 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 20:37:03] iteration   236900/  500000 | consumed samples:     15161600 | elapsed time per iteration (ms): 619.6 | learning rate: 3.261664E-05 | global batch size:    64 | lm loss: 2.993674E+00 | loss scale: 1048576.0 | grad norm: 0.456 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 20:38:05] iteration   237000/  500000 | consumed samples:     15168000 | elapsed time per iteration (ms): 616.7 | learning rate: 3.256557E-05 | global batch size:    64 | lm loss: 3.013560E+00 | loss scale: 1048576.0 | grad norm: 0.450 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2462.12, 2462.26)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 237000 | lm loss value: 3.666853E+00 | lm loss PPL: 3.912857E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-25 20:39:09] iteration   237100/  500000 | consumed samples:     15174400 | elapsed time per iteration (ms): 618.4 | learning rate: 3.251454E-05 | global batch size:    64 | lm loss: 3.003411E+00 | loss scale: 1048576.0 | grad norm: 0.472 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 20:40:11] iteration   237200/  500000 | consumed samples:     15180800 | elapsed time per iteration (ms): 619.8 | learning rate: 3.246356E-05 | global batch size:    64 | lm loss: 3.014912E+00 | loss scale: 1048576.0 | grad norm: 0.465 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 20:41:13] iteration   237300/  500000 | consumed samples:     15187200 | elapsed time per iteration (ms): 618.8 | learning rate: 3.241263E-05 | global batch size:    64 | lm loss: 3.009968E+00 | loss scale: 1048576.0 | grad norm: 0.464 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 20:42:15] iteration   237400/  500000 | consumed samples:     15193600 | elapsed time per iteration (ms): 619.6 | learning rate: 3.236174E-05 | global batch size:    64 | lm loss: 3.002001E+00 | loss scale: 1048576.0 | grad norm: 0.486 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 20:43:17] iteration   237500/  500000 | consumed samples:     15200000 | elapsed time per iteration (ms): 619.7 | learning rate: 3.231192E-05 | global batch size:    64 | lm loss: 3.007176E+00 | loss scale: 1048576.0 | grad norm: 0.483 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-25 20:44:19] iteration   237600/  500000 | consumed samples:     15206400 | elapsed time per iteration (ms): 618.8 | learning rate: 3.226113E-05 | global batch size:    64 | lm loss: 3.004626E+00 | loss scale: 1048576.0 | grad norm: 0.469 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 20:45:21] iteration   237700/  500000 | consumed samples:     15212800 | elapsed time per iteration (ms): 618.9 | learning rate: 3.221038E-05 | global batch size:    64 | lm loss: 3.000107E+00 | loss scale: 1048576.0 | grad norm: 0.452 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 20:46:22] iteration   237800/  500000 | consumed samples:     15219200 | elapsed time per iteration (ms): 618.9 | learning rate: 3.215969E-05 | global batch size:    64 | lm loss: 3.004471E+00 | loss scale: 1048576.0 | grad norm: 0.456 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 20:47:24] iteration   237900/  500000 | consumed samples:     15225600 | elapsed time per iteration (ms): 618.2 | learning rate: 3.210903E-05 | global batch size:    64 | lm loss: 3.008068E+00 | loss scale: 1048576.0 | grad norm: 0.474 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 20:48:26] iteration   238000/  500000 | consumed samples:     15232000 | elapsed time per iteration (ms): 618.2 | learning rate: 3.205843E-05 | global batch size:    64 | lm loss: 3.010830E+00 | loss scale: 1048576.0 | grad norm: 0.475 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2463.28, 2463.34)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 238000 | lm loss value: 3.705052E+00 | lm loss PPL: 4.065216E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-25 20:49:30] iteration   238100/  500000 | consumed samples:     15238400 | elapsed time per iteration (ms): 618.1 | learning rate: 3.200787E-05 | global batch size:    64 | lm loss: 3.002948E+00 | loss scale: 1048576.0 | grad norm: 0.449 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 20:50:32] iteration   238200/  500000 | consumed samples:     15244800 | elapsed time per iteration (ms): 619.3 | learning rate: 3.195736E-05 | global batch size:    64 | lm loss: 3.003746E+00 | loss scale: 1048576.0 | grad norm: 0.464 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 20:51:34] iteration   238300/  500000 | consumed samples:     15251200 | elapsed time per iteration (ms): 620.1 | learning rate: 3.190690E-05 | global batch size:    64 | lm loss: 2.992407E+00 | loss scale: 1048576.0 | grad norm: 0.454 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 20:52:36] iteration   238400/  500000 | consumed samples:     15257600 | elapsed time per iteration (ms): 621.5 | learning rate: 3.185649E-05 | global batch size:    64 | lm loss: 3.008208E+00 | loss scale: 1048576.0 | grad norm: 0.467 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 20:53:38] iteration   238500/  500000 | consumed samples:     15264000 | elapsed time per iteration (ms): 620.1 | learning rate: 3.180612E-05 | global batch size:    64 | lm loss: 3.005251E+00 | loss scale: 2097152.0 | grad norm: 0.477 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 20:54:40] iteration   238600/  500000 | consumed samples:     15270400 | elapsed time per iteration (ms): 618.6 | learning rate: 3.175630E-05 | global batch size:    64 | lm loss: 3.007166E+00 | loss scale: 2097152.0 | grad norm: 0.466 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-25 20:55:42] iteration   238700/  500000 | consumed samples:     15276800 | elapsed time per iteration (ms): 620.3 | learning rate: 3.170653E-05 | global batch size:    64 | lm loss: 2.985384E+00 | loss scale: 1048576.0 | grad norm: 0.456 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-25 20:56:44] iteration   238800/  500000 | consumed samples:     15283200 | elapsed time per iteration (ms): 619.1 | learning rate: 3.165630E-05 | global batch size:    64 | lm loss: 3.006373E+00 | loss scale: 1048576.0 | grad norm: 0.456 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 20:57:46] iteration   238900/  500000 | consumed samples:     15289600 | elapsed time per iteration (ms): 619.7 | learning rate: 3.160612E-05 | global batch size:    64 | lm loss: 2.990145E+00 | loss scale: 1048576.0 | grad norm: 0.468 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 20:58:48] iteration   239000/  500000 | consumed samples:     15296000 | elapsed time per iteration (ms): 620.6 | learning rate: 3.155599E-05 | global batch size:    64 | lm loss: 3.016750E+00 | loss scale: 1048576.0 | grad norm: 0.462 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2462.56, 2462.57)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 239000 | lm loss value: 3.702104E+00 | lm loss PPL: 4.053249E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-25 20:59:53] iteration   239100/  500000 | consumed samples:     15302400 | elapsed time per iteration (ms): 621.1 | learning rate: 3.150591E-05 | global batch size:    64 | lm loss: 3.000198E+00 | loss scale: 1048576.0 | grad norm: 0.481 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 21:00:55] iteration   239200/  500000 | consumed samples:     15308800 | elapsed time per iteration (ms): 619.6 | learning rate: 3.145587E-05 | global batch size:    64 | lm loss: 3.003258E+00 | loss scale: 1048576.0 | grad norm: 0.463 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 21:01:57] iteration   239300/  500000 | consumed samples:     15315200 | elapsed time per iteration (ms): 617.7 | learning rate: 3.140588E-05 | global batch size:    64 | lm loss: 3.019474E+00 | loss scale: 1048576.0 | grad norm: 0.469 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 21:02:58] iteration   239400/  500000 | consumed samples:     15321600 | elapsed time per iteration (ms): 618.2 | learning rate: 3.135594E-05 | global batch size:    64 | lm loss: 2.999361E+00 | loss scale: 1048576.0 | grad norm: 0.463 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 21:04:00] iteration   239500/  500000 | consumed samples:     15328000 | elapsed time per iteration (ms): 618.6 | learning rate: 3.130605E-05 | global batch size:    64 | lm loss: 3.008185E+00 | loss scale: 1048576.0 | grad norm: 0.460 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 21:05:02] iteration   239600/  500000 | consumed samples:     15334400 | elapsed time per iteration (ms): 617.7 | learning rate: 3.125620E-05 | global batch size:    64 | lm loss: 2.991357E+00 | loss scale: 1048576.0 | grad norm: 0.470 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 21:06:04] iteration   239700/  500000 | consumed samples:     15340800 | elapsed time per iteration (ms): 619.3 | learning rate: 3.120641E-05 | global batch size:    64 | lm loss: 3.022043E+00 | loss scale: 2097152.0 | grad norm: 0.446 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 21:07:06] iteration   239800/  500000 | consumed samples:     15347200 | elapsed time per iteration (ms): 617.9 | learning rate: 3.115765E-05 | global batch size:    64 | lm loss: 3.002622E+00 | loss scale: 1048576.0 | grad norm: 0.465 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-25 21:08:07] iteration   239900/  500000 | consumed samples:     15353600 | elapsed time per iteration (ms): 617.5 | learning rate: 3.110795E-05 | global batch size:    64 | lm loss: 2.992844E+00 | loss scale: 1048576.0 | grad norm: 0.468 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 21:09:09] iteration   240000/  500000 | consumed samples:     15360000 | elapsed time per iteration (ms): 619.2 | learning rate: 3.105830E-05 | global batch size:    64 | lm loss: 3.018239E+00 | loss scale: 1048576.0 | grad norm: 0.481 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2462.96, 2463.09)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 240000 | lm loss value: 3.650433E+00 | lm loss PPL: 3.849134E+01 | 
--------------------------------------------------------------------------------------------------
saving checkpoint at iteration  240000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-distribution in torch format
  successfully saved checkpoint at iteration  240000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-distribution
(min, max) time across ranks (ms):
    save-checkpoint ................................: (2256.35, 2256.36)
 [2024-06-25 21:10:16] iteration   240100/  500000 | consumed samples:     15366400 | elapsed time per iteration (ms): 622.1 | learning rate: 3.100869E-05 | global batch size:    64 | lm loss: 3.006388E+00 | loss scale: 1048576.0 | grad norm: 0.453 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 21:11:18] iteration   240200/  500000 | consumed samples:     15372800 | elapsed time per iteration (ms): 619.0 | learning rate: 3.095913E-05 | global batch size:    64 | lm loss: 2.996030E+00 | loss scale: 1048576.0 | grad norm: 0.469 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 21:12:20] iteration   240300/  500000 | consumed samples:     15379200 | elapsed time per iteration (ms): 620.7 | learning rate: 3.090962E-05 | global batch size:    64 | lm loss: 2.994232E+00 | loss scale: 1048576.0 | grad norm: 0.464 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 21:13:22] iteration   240400/  500000 | consumed samples:     15385600 | elapsed time per iteration (ms): 619.7 | learning rate: 3.086016E-05 | global batch size:    64 | lm loss: 2.997148E+00 | loss scale: 1048576.0 | grad norm: 0.455 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 21:14:24] iteration   240500/  500000 | consumed samples:     15392000 | elapsed time per iteration (ms): 620.8 | learning rate: 3.081075E-05 | global batch size:    64 | lm loss: 3.003591E+00 | loss scale: 1048576.0 | grad norm: 0.487 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 21:15:26] iteration   240600/  500000 | consumed samples:     15398400 | elapsed time per iteration (ms): 618.8 | learning rate: 3.076138E-05 | global batch size:    64 | lm loss: 2.995772E+00 | loss scale: 1048576.0 | grad norm: 0.474 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 21:16:28] iteration   240700/  500000 | consumed samples:     15404800 | elapsed time per iteration (ms): 622.4 | learning rate: 3.071207E-05 | global batch size:    64 | lm loss: 2.992682E+00 | loss scale: 1048576.0 | grad norm: 0.455 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 21:17:30] iteration   240800/  500000 | consumed samples:     15411200 | elapsed time per iteration (ms): 619.3 | learning rate: 3.066280E-05 | global batch size:    64 | lm loss: 3.004133E+00 | loss scale: 2097152.0 | grad norm: 0.464 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 21:18:32] iteration   240900/  500000 | consumed samples:     15417600 | elapsed time per iteration (ms): 620.7 | learning rate: 3.061358E-05 | global batch size:    64 | lm loss: 2.984254E+00 | loss scale: 2097152.0 | grad norm: 0.464 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 21:19:34] iteration   241000/  500000 | consumed samples:     15424000 | elapsed time per iteration (ms): 620.2 | learning rate: 3.056441E-05 | global batch size:    64 | lm loss: 3.009714E+00 | loss scale: 2097152.0 | grad norm: 0.470 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2461.15, 2461.21)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 241000 | lm loss value: 3.701599E+00 | lm loss PPL: 4.051203E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-25 21:20:39] iteration   241100/  500000 | consumed samples:     15430400 | elapsed time per iteration (ms): 618.5 | learning rate: 3.051529E-05 | global batch size:    64 | lm loss: 3.003038E+00 | loss scale: 2097152.0 | grad norm: 0.456 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 21:21:41] iteration   241200/  500000 | consumed samples:     15436800 | elapsed time per iteration (ms): 619.7 | learning rate: 3.046671E-05 | global batch size:    64 | lm loss: 3.000344E+00 | loss scale: 2097152.0 | grad norm: 0.462 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-25 21:22:43] iteration   241300/  500000 | consumed samples:     15443200 | elapsed time per iteration (ms): 618.3 | learning rate: 3.041817E-05 | global batch size:    64 | lm loss: 3.005098E+00 | loss scale: 1048576.0 | grad norm: 0.470 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-25 21:23:45] iteration   241400/  500000 | consumed samples:     15449600 | elapsed time per iteration (ms): 619.7 | learning rate: 3.036919E-05 | global batch size:    64 | lm loss: 3.004450E+00 | loss scale: 1048576.0 | grad norm: 0.456 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 21:24:46] iteration   241500/  500000 | consumed samples:     15456000 | elapsed time per iteration (ms): 618.6 | learning rate: 3.032027E-05 | global batch size:    64 | lm loss: 3.000371E+00 | loss scale: 1048576.0 | grad norm: 0.471 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 21:25:48] iteration   241600/  500000 | consumed samples:     15462400 | elapsed time per iteration (ms): 618.5 | learning rate: 3.027139E-05 | global batch size:    64 | lm loss: 3.005689E+00 | loss scale: 1048576.0 | grad norm: 0.474 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 21:26:50] iteration   241700/  500000 | consumed samples:     15468800 | elapsed time per iteration (ms): 618.2 | learning rate: 3.022256E-05 | global batch size:    64 | lm loss: 3.011302E+00 | loss scale: 1048576.0 | grad norm: 0.457 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 21:27:52] iteration   241800/  500000 | consumed samples:     15475200 | elapsed time per iteration (ms): 619.3 | learning rate: 3.017378E-05 | global batch size:    64 | lm loss: 2.996609E+00 | loss scale: 1048576.0 | grad norm: 0.471 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 21:28:54] iteration   241900/  500000 | consumed samples:     15481600 | elapsed time per iteration (ms): 617.9 | learning rate: 3.012504E-05 | global batch size:    64 | lm loss: 2.998513E+00 | loss scale: 1048576.0 | grad norm: 0.461 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 21:29:56] iteration   242000/  500000 | consumed samples:     15488000 | elapsed time per iteration (ms): 617.7 | learning rate: 3.007636E-05 | global batch size:    64 | lm loss: 3.001890E+00 | loss scale: 1048576.0 | grad norm: 0.468 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2460.24, 2460.25)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 242000 | lm loss value: 3.731796E+00 | lm loss PPL: 4.175401E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-25 21:31:00] iteration   242100/  500000 | consumed samples:     15494400 | elapsed time per iteration (ms): 621.2 | learning rate: 3.002773E-05 | global batch size:    64 | lm loss: 3.007511E+00 | loss scale: 1048576.0 | grad norm: 0.466 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 21:32:02] iteration   242200/  500000 | consumed samples:     15500800 | elapsed time per iteration (ms): 620.1 | learning rate: 2.997914E-05 | global batch size:    64 | lm loss: 3.014136E+00 | loss scale: 1048576.0 | grad norm: 0.466 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 21:33:04] iteration   242300/  500000 | consumed samples:     15507200 | elapsed time per iteration (ms): 619.1 | learning rate: 2.993061E-05 | global batch size:    64 | lm loss: 3.017020E+00 | loss scale: 2097152.0 | grad norm: 0.472 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 21:34:06] iteration   242400/  500000 | consumed samples:     15513600 | elapsed time per iteration (ms): 619.1 | learning rate: 2.988260E-05 | global batch size:    64 | lm loss: 3.011181E+00 | loss scale: 2097152.0 | grad norm: 0.461 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-25 21:35:08] iteration   242500/  500000 | consumed samples:     15520000 | elapsed time per iteration (ms): 617.7 | learning rate: 2.983465E-05 | global batch size:    64 | lm loss: 3.006412E+00 | loss scale: 1048576.0 | grad norm: 0.464 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-25 21:36:10] iteration   242600/  500000 | consumed samples:     15526400 | elapsed time per iteration (ms): 620.0 | learning rate: 2.978626E-05 | global batch size:    64 | lm loss: 3.000287E+00 | loss scale: 1048576.0 | grad norm: 0.479 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 21:37:12] iteration   242700/  500000 | consumed samples:     15532800 | elapsed time per iteration (ms): 620.6 | learning rate: 2.973792E-05 | global batch size:    64 | lm loss: 3.012738E+00 | loss scale: 1048576.0 | grad norm: 0.463 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 21:38:14] iteration   242800/  500000 | consumed samples:     15539200 | elapsed time per iteration (ms): 622.0 | learning rate: 2.968963E-05 | global batch size:    64 | lm loss: 3.011620E+00 | loss scale: 1048576.0 | grad norm: 0.465 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 21:39:16] iteration   242900/  500000 | consumed samples:     15545600 | elapsed time per iteration (ms): 619.0 | learning rate: 2.964139E-05 | global batch size:    64 | lm loss: 2.986924E+00 | loss scale: 1048576.0 | grad norm: 0.462 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 21:40:18] iteration   243000/  500000 | consumed samples:     15552000 | elapsed time per iteration (ms): 618.8 | learning rate: 2.959320E-05 | global batch size:    64 | lm loss: 3.004371E+00 | loss scale: 1048576.0 | grad norm: 0.463 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2464.01, 2464.19)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 243000 | lm loss value: 3.737957E+00 | lm loss PPL: 4.201209E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-25 21:41:22] iteration   243100/  500000 | consumed samples:     15558400 | elapsed time per iteration (ms): 619.9 | learning rate: 2.954506E-05 | global batch size:    64 | lm loss: 3.006393E+00 | loss scale: 1048576.0 | grad norm: 0.469 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 21:42:24] iteration   243200/  500000 | consumed samples:     15564800 | elapsed time per iteration (ms): 621.1 | learning rate: 2.949697E-05 | global batch size:    64 | lm loss: 3.003357E+00 | loss scale: 1048576.0 | grad norm: 0.458 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 21:43:26] iteration   243300/  500000 | consumed samples:     15571200 | elapsed time per iteration (ms): 618.5 | learning rate: 2.944893E-05 | global batch size:    64 | lm loss: 3.003658E+00 | loss scale: 1048576.0 | grad norm: 0.477 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 21:44:28] iteration   243400/  500000 | consumed samples:     15577600 | elapsed time per iteration (ms): 620.0 | learning rate: 2.940093E-05 | global batch size:    64 | lm loss: 3.003954E+00 | loss scale: 1048576.0 | grad norm: 0.479 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 21:45:30] iteration   243500/  500000 | consumed samples:     15584000 | elapsed time per iteration (ms): 619.0 | learning rate: 2.935347E-05 | global batch size:    64 | lm loss: 2.997986E+00 | loss scale: 524288.0 | grad norm: 0.473 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-25 21:46:32] iteration   243600/  500000 | consumed samples:     15590400 | elapsed time per iteration (ms): 619.7 | learning rate: 2.930558E-05 | global batch size:    64 | lm loss: 3.001470E+00 | loss scale: 524288.0 | grad norm: 0.462 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 21:47:34] iteration   243700/  500000 | consumed samples:     15596800 | elapsed time per iteration (ms): 619.0 | learning rate: 2.925773E-05 | global batch size:    64 | lm loss: 3.017862E+00 | loss scale: 524288.0 | grad norm: 0.465 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 21:48:36] iteration   243800/  500000 | consumed samples:     15603200 | elapsed time per iteration (ms): 618.5 | learning rate: 2.920994E-05 | global batch size:    64 | lm loss: 3.009713E+00 | loss scale: 524288.0 | grad norm: 0.462 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 21:49:38] iteration   243900/  500000 | consumed samples:     15609600 | elapsed time per iteration (ms): 618.3 | learning rate: 2.916220E-05 | global batch size:    64 | lm loss: 3.000594E+00 | loss scale: 524288.0 | grad norm: 0.473 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 21:50:40] iteration   244000/  500000 | consumed samples:     15616000 | elapsed time per iteration (ms): 619.2 | learning rate: 2.911450E-05 | global batch size:    64 | lm loss: 2.980729E+00 | loss scale: 524288.0 | grad norm: 0.465 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2462.78, 2462.80)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 244000 | lm loss value: 3.754496E+00 | lm loss PPL: 4.271267E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-25 21:51:44] iteration   244100/  500000 | consumed samples:     15622400 | elapsed time per iteration (ms): 618.4 | learning rate: 2.906686E-05 | global batch size:    64 | lm loss: 2.990151E+00 | loss scale: 524288.0 | grad norm: 0.462 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 21:52:46] iteration   244200/  500000 | consumed samples:     15628800 | elapsed time per iteration (ms): 619.4 | learning rate: 2.901926E-05 | global batch size:    64 | lm loss: 3.001909E+00 | loss scale: 524288.0 | grad norm: 0.450 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 21:53:48] iteration   244300/  500000 | consumed samples:     15635200 | elapsed time per iteration (ms): 619.1 | learning rate: 2.897172E-05 | global batch size:    64 | lm loss: 3.001930E+00 | loss scale: 524288.0 | grad norm: 0.459 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 21:54:50] iteration   244400/  500000 | consumed samples:     15641600 | elapsed time per iteration (ms): 619.4 | learning rate: 2.892423E-05 | global batch size:    64 | lm loss: 2.994590E+00 | loss scale: 524288.0 | grad norm: 0.459 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 21:55:51] iteration   244500/  500000 | consumed samples:     15648000 | elapsed time per iteration (ms): 617.7 | learning rate: 2.887678E-05 | global batch size:    64 | lm loss: 3.000115E+00 | loss scale: 1048576.0 | grad norm: 0.460 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 21:56:53] iteration   244600/  500000 | consumed samples:     15654400 | elapsed time per iteration (ms): 619.5 | learning rate: 2.882939E-05 | global batch size:    64 | lm loss: 2.990488E+00 | loss scale: 1048576.0 | grad norm: 0.477 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 21:57:55] iteration   244700/  500000 | consumed samples:     15660800 | elapsed time per iteration (ms): 619.6 | learning rate: 2.878205E-05 | global batch size:    64 | lm loss: 3.008757E+00 | loss scale: 1048576.0 | grad norm: 0.461 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 21:58:57] iteration   244800/  500000 | consumed samples:     15667200 | elapsed time per iteration (ms): 620.3 | learning rate: 2.873476E-05 | global batch size:    64 | lm loss: 3.002632E+00 | loss scale: 1048576.0 | grad norm: 0.460 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 21:59:59] iteration   244900/  500000 | consumed samples:     15673600 | elapsed time per iteration (ms): 619.5 | learning rate: 2.868752E-05 | global batch size:    64 | lm loss: 3.007230E+00 | loss scale: 1048576.0 | grad norm: 0.482 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 22:01:01] iteration   245000/  500000 | consumed samples:     15680000 | elapsed time per iteration (ms): 619.3 | learning rate: 2.864032E-05 | global batch size:    64 | lm loss: 3.011683E+00 | loss scale: 1048576.0 | grad norm: 0.455 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2464.47, 2464.59)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 245000 | lm loss value: 3.661839E+00 | lm loss PPL: 3.893287E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-25 22:02:06] iteration   245100/  500000 | consumed samples:     15686400 | elapsed time per iteration (ms): 621.0 | learning rate: 2.859318E-05 | global batch size:    64 | lm loss: 2.998352E+00 | loss scale: 1048576.0 | grad norm: 0.460 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 22:03:08] iteration   245200/  500000 | consumed samples:     15692800 | elapsed time per iteration (ms): 619.7 | learning rate: 2.854609E-05 | global batch size:    64 | lm loss: 3.017027E+00 | loss scale: 1048576.0 | grad norm: 0.452 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 22:04:10] iteration   245300/  500000 | consumed samples:     15699200 | elapsed time per iteration (ms): 620.4 | learning rate: 2.849905E-05 | global batch size:    64 | lm loss: 2.994095E+00 | loss scale: 1048576.0 | grad norm: 0.480 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 22:05:12] iteration   245400/  500000 | consumed samples:     15705600 | elapsed time per iteration (ms): 620.5 | learning rate: 2.845207E-05 | global batch size:    64 | lm loss: 2.989146E+00 | loss scale: 1048576.0 | grad norm: 0.471 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 22:06:14] iteration   245500/  500000 | consumed samples:     15712000 | elapsed time per iteration (ms): 619.8 | learning rate: 2.840513E-05 | global batch size:    64 | lm loss: 2.997771E+00 | loss scale: 2097152.0 | grad norm: 0.448 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 22:07:16] iteration   245600/  500000 | consumed samples:     15718400 | elapsed time per iteration (ms): 619.5 | learning rate: 2.835918E-05 | global batch size:    64 | lm loss: 2.996542E+00 | loss scale: 1048576.0 | grad norm: 0.482 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-25 22:08:18] iteration   245700/  500000 | consumed samples:     15724800 | elapsed time per iteration (ms): 620.5 | learning rate: 2.831234E-05 | global batch size:    64 | lm loss: 2.994368E+00 | loss scale: 1048576.0 | grad norm: 0.455 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 22:09:20] iteration   245800/  500000 | consumed samples:     15731200 | elapsed time per iteration (ms): 621.0 | learning rate: 2.826555E-05 | global batch size:    64 | lm loss: 2.997548E+00 | loss scale: 1048576.0 | grad norm: 0.458 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 22:10:22] iteration   245900/  500000 | consumed samples:     15737600 | elapsed time per iteration (ms): 620.7 | learning rate: 2.821882E-05 | global batch size:    64 | lm loss: 2.989508E+00 | loss scale: 1048576.0 | grad norm: 0.461 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 22:11:24] iteration   246000/  500000 | consumed samples:     15744000 | elapsed time per iteration (ms): 620.6 | learning rate: 2.817213E-05 | global batch size:    64 | lm loss: 3.000301E+00 | loss scale: 1048576.0 | grad norm: 0.473 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2462.73, 2462.80)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 246000 | lm loss value: 3.713345E+00 | lm loss PPL: 4.099070E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-25 22:12:29] iteration   246100/  500000 | consumed samples:     15750400 | elapsed time per iteration (ms): 620.1 | learning rate: 2.812550E-05 | global batch size:    64 | lm loss: 3.000410E+00 | loss scale: 1048576.0 | grad norm: 0.478 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 22:13:30] iteration   246200/  500000 | consumed samples:     15756800 | elapsed time per iteration (ms): 618.5 | learning rate: 2.807891E-05 | global batch size:    64 | lm loss: 2.994562E+00 | loss scale: 1048576.0 | grad norm: 0.470 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 22:14:32] iteration   246300/  500000 | consumed samples:     15763200 | elapsed time per iteration (ms): 619.5 | learning rate: 2.803238E-05 | global batch size:    64 | lm loss: 2.994317E+00 | loss scale: 1048576.0 | grad norm: 0.467 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 22:15:34] iteration   246400/  500000 | consumed samples:     15769600 | elapsed time per iteration (ms): 618.5 | learning rate: 2.798590E-05 | global batch size:    64 | lm loss: 2.997963E+00 | loss scale: 1048576.0 | grad norm: 0.467 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 22:16:36] iteration   246500/  500000 | consumed samples:     15776000 | elapsed time per iteration (ms): 617.5 | learning rate: 2.793947E-05 | global batch size:    64 | lm loss: 2.986013E+00 | loss scale: 1048576.0 | grad norm: 0.459 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 22:17:38] iteration   246600/  500000 | consumed samples:     15782400 | elapsed time per iteration (ms): 617.7 | learning rate: 2.789309E-05 | global batch size:    64 | lm loss: 2.996554E+00 | loss scale: 2097152.0 | grad norm: 0.469 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 22:18:40] iteration   246700/  500000 | consumed samples:     15788800 | elapsed time per iteration (ms): 618.1 | learning rate: 2.784677E-05 | global batch size:    64 | lm loss: 3.005230E+00 | loss scale: 2097152.0 | grad norm: 0.458 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 22:19:41] iteration   246800/  500000 | consumed samples:     15795200 | elapsed time per iteration (ms): 617.5 | learning rate: 2.780049E-05 | global batch size:    64 | lm loss: 2.989846E+00 | loss scale: 2097152.0 | grad norm: 0.457 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 22:20:43] iteration   246900/  500000 | consumed samples:     15801600 | elapsed time per iteration (ms): 618.0 | learning rate: 2.775519E-05 | global batch size:    64 | lm loss: 3.003831E+00 | loss scale: 1048576.0 | grad norm: 0.475 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-25 22:21:45] iteration   247000/  500000 | consumed samples:     15808000 | elapsed time per iteration (ms): 618.4 | learning rate: 2.770901E-05 | global batch size:    64 | lm loss: 2.990926E+00 | loss scale: 1048576.0 | grad norm: 0.469 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2461.00, 2461.05)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 247000 | lm loss value: 3.711320E+00 | lm loss PPL: 4.090778E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-25 22:22:50] iteration   247100/  500000 | consumed samples:     15814400 | elapsed time per iteration (ms): 621.0 | learning rate: 2.766289E-05 | global batch size:    64 | lm loss: 2.995199E+00 | loss scale: 1048576.0 | grad norm: 0.461 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 22:23:51] iteration   247200/  500000 | consumed samples:     15820800 | elapsed time per iteration (ms): 618.7 | learning rate: 2.761682E-05 | global batch size:    64 | lm loss: 3.000583E+00 | loss scale: 1048576.0 | grad norm: 0.461 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 22:24:53] iteration   247300/  500000 | consumed samples:     15827200 | elapsed time per iteration (ms): 619.1 | learning rate: 2.757080E-05 | global batch size:    64 | lm loss: 2.992153E+00 | loss scale: 1048576.0 | grad norm: 0.479 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 22:25:55] iteration   247400/  500000 | consumed samples:     15833600 | elapsed time per iteration (ms): 619.6 | learning rate: 2.752483E-05 | global batch size:    64 | lm loss: 2.997018E+00 | loss scale: 1048576.0 | grad norm: 0.468 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 22:26:57] iteration   247500/  500000 | consumed samples:     15840000 | elapsed time per iteration (ms): 621.1 | learning rate: 2.747891E-05 | global batch size:    64 | lm loss: 3.010987E+00 | loss scale: 1048576.0 | grad norm: 0.467 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 22:27:59] iteration   247600/  500000 | consumed samples:     15846400 | elapsed time per iteration (ms): 620.1 | learning rate: 2.743305E-05 | global batch size:    64 | lm loss: 2.992472E+00 | loss scale: 1048576.0 | grad norm: 0.485 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 22:29:01] iteration   247700/  500000 | consumed samples:     15852800 | elapsed time per iteration (ms): 618.8 | learning rate: 2.738724E-05 | global batch size:    64 | lm loss: 2.983199E+00 | loss scale: 1048576.0 | grad norm: 0.461 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 22:30:03] iteration   247800/  500000 | consumed samples:     15859200 | elapsed time per iteration (ms): 618.1 | learning rate: 2.734147E-05 | global batch size:    64 | lm loss: 2.999343E+00 | loss scale: 1048576.0 | grad norm: 0.462 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 22:31:05] iteration   247900/  500000 | consumed samples:     15865600 | elapsed time per iteration (ms): 620.3 | learning rate: 2.729576E-05 | global batch size:    64 | lm loss: 2.993957E+00 | loss scale: 2097152.0 | grad norm: 0.470 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 22:32:07] iteration   248000/  500000 | consumed samples:     15872000 | elapsed time per iteration (ms): 619.5 | learning rate: 2.725056E-05 | global batch size:    64 | lm loss: 2.986863E+00 | loss scale: 2097152.0 | grad norm: 0.469 | number of skipped iterations:   1 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2462.85, 2462.89)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 248000 | lm loss value: 3.724859E+00 | lm loss PPL: 4.146539E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-25 22:33:12] iteration   248100/  500000 | consumed samples:     15878400 | elapsed time per iteration (ms): 620.5 | learning rate: 2.720541E-05 | global batch size:    64 | lm loss: 3.002123E+00 | loss scale: 1048576.0 | grad norm: 0.465 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-25 22:34:14] iteration   248200/  500000 | consumed samples:     15884800 | elapsed time per iteration (ms): 619.8 | learning rate: 2.715986E-05 | global batch size:    64 | lm loss: 2.993035E+00 | loss scale: 1048576.0 | grad norm: 0.460 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 22:35:16] iteration   248300/  500000 | consumed samples:     15891200 | elapsed time per iteration (ms): 619.9 | learning rate: 2.711435E-05 | global batch size:    64 | lm loss: 3.000389E+00 | loss scale: 1048576.0 | grad norm: 0.467 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 22:36:18] iteration   248400/  500000 | consumed samples:     15897600 | elapsed time per iteration (ms): 621.8 | learning rate: 2.706890E-05 | global batch size:    64 | lm loss: 2.998179E+00 | loss scale: 1048576.0 | grad norm: 0.473 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 22:37:20] iteration   248500/  500000 | consumed samples:     15904000 | elapsed time per iteration (ms): 620.5 | learning rate: 2.702350E-05 | global batch size:    64 | lm loss: 3.012578E+00 | loss scale: 1048576.0 | grad norm: 0.463 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 22:38:22] iteration   248600/  500000 | consumed samples:     15910400 | elapsed time per iteration (ms): 619.4 | learning rate: 2.697815E-05 | global batch size:    64 | lm loss: 2.997064E+00 | loss scale: 1048576.0 | grad norm: 0.472 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 22:39:24] iteration   248700/  500000 | consumed samples:     15916800 | elapsed time per iteration (ms): 618.8 | learning rate: 2.693286E-05 | global batch size:    64 | lm loss: 3.010743E+00 | loss scale: 1048576.0 | grad norm: 0.465 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 22:40:26] iteration   248800/  500000 | consumed samples:     15923200 | elapsed time per iteration (ms): 620.4 | learning rate: 2.688762E-05 | global batch size:    64 | lm loss: 3.001593E+00 | loss scale: 1048576.0 | grad norm: 0.471 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 22:41:28] iteration   248900/  500000 | consumed samples:     15929600 | elapsed time per iteration (ms): 618.4 | learning rate: 2.684243E-05 | global batch size:    64 | lm loss: 3.002960E+00 | loss scale: 1048576.0 | grad norm: 0.457 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 22:42:29] iteration   249000/  500000 | consumed samples:     15936000 | elapsed time per iteration (ms): 618.3 | learning rate: 2.679729E-05 | global batch size:    64 | lm loss: 2.974428E+00 | loss scale: 1048576.0 | grad norm: 0.458 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2463.64, 2463.69)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 249000 | lm loss value: 3.723437E+00 | lm loss PPL: 4.140647E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-25 22:43:34] iteration   249100/  500000 | consumed samples:     15942400 | elapsed time per iteration (ms): 617.8 | learning rate: 2.675220E-05 | global batch size:    64 | lm loss: 3.003101E+00 | loss scale: 2097152.0 | grad norm: 0.463 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 22:44:36] iteration   249200/  500000 | consumed samples:     15948800 | elapsed time per iteration (ms): 619.8 | learning rate: 2.670807E-05 | global batch size:    64 | lm loss: 2.993037E+00 | loss scale: 1048576.0 | grad norm: 0.465 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-25 22:45:38] iteration   249300/  500000 | consumed samples:     15955200 | elapsed time per iteration (ms): 619.4 | learning rate: 2.666309E-05 | global batch size:    64 | lm loss: 2.994268E+00 | loss scale: 1048576.0 | grad norm: 0.472 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 22:46:40] iteration   249400/  500000 | consumed samples:     15961600 | elapsed time per iteration (ms): 620.2 | learning rate: 2.661816E-05 | global batch size:    64 | lm loss: 2.982315E+00 | loss scale: 1048576.0 | grad norm: 0.470 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 22:47:42] iteration   249500/  500000 | consumed samples:     15968000 | elapsed time per iteration (ms): 620.2 | learning rate: 2.657328E-05 | global batch size:    64 | lm loss: 3.017938E+00 | loss scale: 1048576.0 | grad norm: 0.468 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 22:48:43] iteration   249600/  500000 | consumed samples:     15974400 | elapsed time per iteration (ms): 617.3 | learning rate: 2.652845E-05 | global batch size:    64 | lm loss: 2.986784E+00 | loss scale: 1048576.0 | grad norm: 0.468 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 22:49:45] iteration   249700/  500000 | consumed samples:     15980800 | elapsed time per iteration (ms): 617.9 | learning rate: 2.648368E-05 | global batch size:    64 | lm loss: 2.985520E+00 | loss scale: 1048576.0 | grad norm: 0.465 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 22:50:47] iteration   249800/  500000 | consumed samples:     15987200 | elapsed time per iteration (ms): 620.2 | learning rate: 2.643896E-05 | global batch size:    64 | lm loss: 2.983123E+00 | loss scale: 1048576.0 | grad norm: 0.456 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 22:51:49] iteration   249900/  500000 | consumed samples:     15993600 | elapsed time per iteration (ms): 618.2 | learning rate: 2.639429E-05 | global batch size:    64 | lm loss: 2.990182E+00 | loss scale: 1048576.0 | grad norm: 0.469 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 22:52:51] iteration   250000/  500000 | consumed samples:     16000000 | elapsed time per iteration (ms): 620.9 | learning rate: 2.634968E-05 | global batch size:    64 | lm loss: 3.005246E+00 | loss scale: 1048576.0 | grad norm: 0.455 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2467.15, 2467.23)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 250000 | lm loss value: 3.715958E+00 | lm loss PPL: 4.109794E+01 | 
--------------------------------------------------------------------------------------------------
saving checkpoint at iteration  250000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-distribution in torch format
  successfully saved checkpoint at iteration  250000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-distribution
(min, max) time across ranks (ms):
    save-checkpoint ................................: (2393.50, 2393.51)
 [2024-06-25 22:53:58] iteration   250100/  500000 | consumed samples:     16006400 | elapsed time per iteration (ms): 619.7 | learning rate: 2.630512E-05 | global batch size:    64 | lm loss: 2.987186E+00 | loss scale: 1048576.0 | grad norm: 0.470 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 22:55:00] iteration   250200/  500000 | consumed samples:     16012800 | elapsed time per iteration (ms): 620.3 | learning rate: 2.626150E-05 | global batch size:    64 | lm loss: 2.998855E+00 | loss scale: 1048576.0 | grad norm: 0.466 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-25 22:56:02] iteration   250300/  500000 | consumed samples:     16019200 | elapsed time per iteration (ms): 619.7 | learning rate: 2.621704E-05 | global batch size:    64 | lm loss: 2.996660E+00 | loss scale: 1048576.0 | grad norm: 0.465 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 22:57:04] iteration   250400/  500000 | consumed samples:     16025600 | elapsed time per iteration (ms): 620.2 | learning rate: 2.617264E-05 | global batch size:    64 | lm loss: 2.985200E+00 | loss scale: 1048576.0 | grad norm: 0.471 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 22:58:06] iteration   250500/  500000 | consumed samples:     16032000 | elapsed time per iteration (ms): 618.4 | learning rate: 2.612829E-05 | global batch size:    64 | lm loss: 2.998856E+00 | loss scale: 1048576.0 | grad norm: 0.455 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 22:59:08] iteration   250600/  500000 | consumed samples:     16038400 | elapsed time per iteration (ms): 619.1 | learning rate: 2.608443E-05 | global batch size:    64 | lm loss: 3.008657E+00 | loss scale: 524288.0 | grad norm: 0.481 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-25 23:00:10] iteration   250700/  500000 | consumed samples:     16044800 | elapsed time per iteration (ms): 619.8 | learning rate: 2.604019E-05 | global batch size:    64 | lm loss: 2.988634E+00 | loss scale: 524288.0 | grad norm: 0.465 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 23:01:12] iteration   250800/  500000 | consumed samples:     16051200 | elapsed time per iteration (ms): 619.9 | learning rate: 2.599599E-05 | global batch size:    64 | lm loss: 2.990502E+00 | loss scale: 524288.0 | grad norm: 0.466 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 23:02:13] iteration   250900/  500000 | consumed samples:     16057600 | elapsed time per iteration (ms): 619.1 | learning rate: 2.595185E-05 | global batch size:    64 | lm loss: 2.997142E+00 | loss scale: 524288.0 | grad norm: 0.467 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 23:03:15] iteration   251000/  500000 | consumed samples:     16064000 | elapsed time per iteration (ms): 618.7 | learning rate: 2.590777E-05 | global batch size:    64 | lm loss: 2.999273E+00 | loss scale: 524288.0 | grad norm: 0.469 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2461.75, 2461.77)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 251000 | lm loss value: 3.723363E+00 | lm loss PPL: 4.140341E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-25 23:04:20] iteration   251100/  500000 | consumed samples:     16070400 | elapsed time per iteration (ms): 618.7 | learning rate: 2.586374E-05 | global batch size:    64 | lm loss: 3.006048E+00 | loss scale: 524288.0 | grad norm: 0.470 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 23:05:22] iteration   251200/  500000 | consumed samples:     16076800 | elapsed time per iteration (ms): 621.4 | learning rate: 2.581976E-05 | global batch size:    64 | lm loss: 2.995561E+00 | loss scale: 524288.0 | grad norm: 0.473 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 23:06:24] iteration   251300/  500000 | consumed samples:     16083200 | elapsed time per iteration (ms): 619.1 | learning rate: 2.577583E-05 | global batch size:    64 | lm loss: 3.002944E+00 | loss scale: 524288.0 | grad norm: 0.475 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 23:07:26] iteration   251400/  500000 | consumed samples:     16089600 | elapsed time per iteration (ms): 619.1 | learning rate: 2.573196E-05 | global batch size:    64 | lm loss: 2.994682E+00 | loss scale: 524288.0 | grad norm: 0.488 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 23:08:28] iteration   251500/  500000 | consumed samples:     16096000 | elapsed time per iteration (ms): 619.1 | learning rate: 2.568814E-05 | global batch size:    64 | lm loss: 2.986114E+00 | loss scale: 524288.0 | grad norm: 0.470 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 23:09:30] iteration   251600/  500000 | consumed samples:     16102400 | elapsed time per iteration (ms): 619.7 | learning rate: 2.564437E-05 | global batch size:    64 | lm loss: 2.999856E+00 | loss scale: 1048576.0 | grad norm: 0.473 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 23:10:31] iteration   251700/  500000 | consumed samples:     16108800 | elapsed time per iteration (ms): 619.2 | learning rate: 2.560066E-05 | global batch size:    64 | lm loss: 3.006434E+00 | loss scale: 1048576.0 | grad norm: 0.464 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 23:11:33] iteration   251800/  500000 | consumed samples:     16115200 | elapsed time per iteration (ms): 619.2 | learning rate: 2.555700E-05 | global batch size:    64 | lm loss: 2.996248E+00 | loss scale: 1048576.0 | grad norm: 0.461 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 23:12:35] iteration   251900/  500000 | consumed samples:     16121600 | elapsed time per iteration (ms): 618.0 | learning rate: 2.551339E-05 | global batch size:    64 | lm loss: 3.004179E+00 | loss scale: 1048576.0 | grad norm: 0.468 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 23:13:37] iteration   252000/  500000 | consumed samples:     16128000 | elapsed time per iteration (ms): 618.8 | learning rate: 2.546984E-05 | global batch size:    64 | lm loss: 2.988443E+00 | loss scale: 1048576.0 | grad norm: 0.479 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2462.91, 2462.98)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 252000 | lm loss value: 3.706369E+00 | lm loss PPL: 4.070572E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-25 23:14:41] iteration   252100/  500000 | consumed samples:     16134400 | elapsed time per iteration (ms): 619.8 | learning rate: 2.542634E-05 | global batch size:    64 | lm loss: 3.009761E+00 | loss scale: 1048576.0 | grad norm: 0.470 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 23:15:44] iteration   252200/  500000 | consumed samples:     16140800 | elapsed time per iteration (ms): 620.5 | learning rate: 2.538289E-05 | global batch size:    64 | lm loss: 2.990914E+00 | loss scale: 1048576.0 | grad norm: 0.466 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 23:16:45] iteration   252300/  500000 | consumed samples:     16147200 | elapsed time per iteration (ms): 618.5 | learning rate: 2.533950E-05 | global batch size:    64 | lm loss: 2.996228E+00 | loss scale: 1048576.0 | grad norm: 0.487 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 23:17:47] iteration   252400/  500000 | consumed samples:     16153600 | elapsed time per iteration (ms): 619.4 | learning rate: 2.529617E-05 | global batch size:    64 | lm loss: 2.984146E+00 | loss scale: 1048576.0 | grad norm: 0.471 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 23:18:49] iteration   252500/  500000 | consumed samples:     16160000 | elapsed time per iteration (ms): 620.3 | learning rate: 2.525288E-05 | global batch size:    64 | lm loss: 3.003427E+00 | loss scale: 1048576.0 | grad norm: 0.461 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 23:19:51] iteration   252600/  500000 | consumed samples:     16166400 | elapsed time per iteration (ms): 620.1 | learning rate: 2.520965E-05 | global batch size:    64 | lm loss: 3.001958E+00 | loss scale: 2097152.0 | grad norm: 0.457 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 23:20:53] iteration   252700/  500000 | consumed samples:     16172800 | elapsed time per iteration (ms): 620.7 | learning rate: 2.516691E-05 | global batch size:    64 | lm loss: 3.013720E+00 | loss scale: 2097152.0 | grad norm: 0.489 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-25 23:21:56] iteration   252800/  500000 | consumed samples:     16179200 | elapsed time per iteration (ms): 622.0 | learning rate: 2.512422E-05 | global batch size:    64 | lm loss: 2.994661E+00 | loss scale: 1048576.0 | grad norm: 0.471 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-25 23:22:58] iteration   252900/  500000 | consumed samples:     16185600 | elapsed time per iteration (ms): 622.4 | learning rate: 2.508115E-05 | global batch size:    64 | lm loss: 2.980683E+00 | loss scale: 1048576.0 | grad norm: 0.479 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 23:24:00] iteration   253000/  500000 | consumed samples:     16192000 | elapsed time per iteration (ms): 617.8 | learning rate: 2.503813E-05 | global batch size:    64 | lm loss: 2.997857E+00 | loss scale: 1048576.0 | grad norm: 0.465 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2462.76, 2462.78)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 253000 | lm loss value: 3.702232E+00 | lm loss PPL: 4.053770E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-25 23:25:04] iteration   253100/  500000 | consumed samples:     16198400 | elapsed time per iteration (ms): 619.2 | learning rate: 2.499517E-05 | global batch size:    64 | lm loss: 2.994890E+00 | loss scale: 1048576.0 | grad norm: 0.474 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 23:26:06] iteration   253200/  500000 | consumed samples:     16204800 | elapsed time per iteration (ms): 618.6 | learning rate: 2.495226E-05 | global batch size:    64 | lm loss: 3.002963E+00 | loss scale: 1048576.0 | grad norm: 0.470 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 23:27:08] iteration   253300/  500000 | consumed samples:     16211200 | elapsed time per iteration (ms): 620.6 | learning rate: 2.490941E-05 | global batch size:    64 | lm loss: 2.988919E+00 | loss scale: 1048576.0 | grad norm: 0.467 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 23:28:10] iteration   253400/  500000 | consumed samples:     16217600 | elapsed time per iteration (ms): 619.4 | learning rate: 2.486661E-05 | global batch size:    64 | lm loss: 2.994890E+00 | loss scale: 1048576.0 | grad norm: 0.464 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 23:29:12] iteration   253500/  500000 | consumed samples:     16224000 | elapsed time per iteration (ms): 620.3 | learning rate: 2.482387E-05 | global batch size:    64 | lm loss: 2.997645E+00 | loss scale: 1048576.0 | grad norm: 0.469 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 23:30:14] iteration   253600/  500000 | consumed samples:     16230400 | elapsed time per iteration (ms): 619.0 | learning rate: 2.478118E-05 | global batch size:    64 | lm loss: 3.001516E+00 | loss scale: 1048576.0 | grad norm: 0.467 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 23:31:16] iteration   253700/  500000 | consumed samples:     16236800 | elapsed time per iteration (ms): 619.7 | learning rate: 2.473854E-05 | global batch size:    64 | lm loss: 3.001122E+00 | loss scale: 1048576.0 | grad norm: 0.452 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 23:32:18] iteration   253800/  500000 | consumed samples:     16243200 | elapsed time per iteration (ms): 618.9 | learning rate: 2.469681E-05 | global batch size:    64 | lm loss: 2.962778E+00 | loss scale: 1048576.0 | grad norm: 0.482 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-25 23:33:20] iteration   253900/  500000 | consumed samples:     16249600 | elapsed time per iteration (ms): 619.3 | learning rate: 2.465428E-05 | global batch size:    64 | lm loss: 2.977003E+00 | loss scale: 1048576.0 | grad norm: 0.463 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 23:34:22] iteration   254000/  500000 | consumed samples:     16256000 | elapsed time per iteration (ms): 620.2 | learning rate: 2.461181E-05 | global batch size:    64 | lm loss: 3.010169E+00 | loss scale: 1048576.0 | grad norm: 0.466 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2462.10, 2462.10)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 254000 | lm loss value: 3.745493E+00 | lm loss PPL: 4.232987E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-25 23:35:26] iteration   254100/  500000 | consumed samples:     16262400 | elapsed time per iteration (ms): 619.1 | learning rate: 2.456939E-05 | global batch size:    64 | lm loss: 2.982149E+00 | loss scale: 1048576.0 | grad norm: 0.458 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 23:36:28] iteration   254200/  500000 | consumed samples:     16268800 | elapsed time per iteration (ms): 618.9 | learning rate: 2.452702E-05 | global batch size:    64 | lm loss: 2.993107E+00 | loss scale: 1048576.0 | grad norm: 0.482 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 23:37:30] iteration   254300/  500000 | consumed samples:     16275200 | elapsed time per iteration (ms): 620.3 | learning rate: 2.448471E-05 | global batch size:    64 | lm loss: 2.997834E+00 | loss scale: 1048576.0 | grad norm: 0.479 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 23:38:32] iteration   254400/  500000 | consumed samples:     16281600 | elapsed time per iteration (ms): 620.4 | learning rate: 2.444245E-05 | global batch size:    64 | lm loss: 2.992486E+00 | loss scale: 1048576.0 | grad norm: 0.479 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 23:39:34] iteration   254500/  500000 | consumed samples:     16288000 | elapsed time per iteration (ms): 620.3 | learning rate: 2.440025E-05 | global batch size:    64 | lm loss: 2.999012E+00 | loss scale: 1048576.0 | grad norm: 0.469 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 23:40:36] iteration   254600/  500000 | consumed samples:     16294400 | elapsed time per iteration (ms): 619.9 | learning rate: 2.435811E-05 | global batch size:    64 | lm loss: 2.989162E+00 | loss scale: 1048576.0 | grad norm: 0.463 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 23:41:38] iteration   254700/  500000 | consumed samples:     16300800 | elapsed time per iteration (ms): 621.5 | learning rate: 2.431602E-05 | global batch size:    64 | lm loss: 2.983751E+00 | loss scale: 1048576.0 | grad norm: 0.473 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 23:42:40] iteration   254800/  500000 | consumed samples:     16307200 | elapsed time per iteration (ms): 618.7 | learning rate: 2.427440E-05 | global batch size:    64 | lm loss: 2.995711E+00 | loss scale: 2097152.0 | grad norm: 0.477 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-25 23:43:42] iteration   254900/  500000 | consumed samples:     16313600 | elapsed time per iteration (ms): 619.9 | learning rate: 2.423283E-05 | global batch size:    64 | lm loss: 2.989409E+00 | loss scale: 1048576.0 | grad norm: 0.483 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-25 23:44:44] iteration   255000/  500000 | consumed samples:     16320000 | elapsed time per iteration (ms): 620.2 | learning rate: 2.419091E-05 | global batch size:    64 | lm loss: 2.982085E+00 | loss scale: 1048576.0 | grad norm: 0.472 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2461.05, 2461.07)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 255000 | lm loss value: 3.716112E+00 | lm loss PPL: 4.110427E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-25 23:45:48] iteration   255100/  500000 | consumed samples:     16326400 | elapsed time per iteration (ms): 618.3 | learning rate: 2.414903E-05 | global batch size:    64 | lm loss: 2.992552E+00 | loss scale: 1048576.0 | grad norm: 0.470 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 23:46:50] iteration   255200/  500000 | consumed samples:     16332800 | elapsed time per iteration (ms): 617.7 | learning rate: 2.410721E-05 | global batch size:    64 | lm loss: 2.990812E+00 | loss scale: 1048576.0 | grad norm: 0.460 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 23:47:52] iteration   255300/  500000 | consumed samples:     16339200 | elapsed time per iteration (ms): 620.9 | learning rate: 2.406545E-05 | global batch size:    64 | lm loss: 2.993327E+00 | loss scale: 1048576.0 | grad norm: 0.466 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 23:48:54] iteration   255400/  500000 | consumed samples:     16345600 | elapsed time per iteration (ms): 619.4 | learning rate: 2.402374E-05 | global batch size:    64 | lm loss: 2.999239E+00 | loss scale: 1048576.0 | grad norm: 0.458 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 23:49:56] iteration   255500/  500000 | consumed samples:     16352000 | elapsed time per iteration (ms): 620.0 | learning rate: 2.398209E-05 | global batch size:    64 | lm loss: 2.999381E+00 | loss scale: 1048576.0 | grad norm: 0.468 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 23:50:58] iteration   255600/  500000 | consumed samples:     16358400 | elapsed time per iteration (ms): 618.2 | learning rate: 2.394049E-05 | global batch size:    64 | lm loss: 2.991596E+00 | loss scale: 1048576.0 | grad norm: 0.473 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 23:52:00] iteration   255700/  500000 | consumed samples:     16364800 | elapsed time per iteration (ms): 617.2 | learning rate: 2.389895E-05 | global batch size:    64 | lm loss: 2.989616E+00 | loss scale: 1048576.0 | grad norm: 0.468 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 23:53:01] iteration   255800/  500000 | consumed samples:     16371200 | elapsed time per iteration (ms): 617.6 | learning rate: 2.385746E-05 | global batch size:    64 | lm loss: 2.982589E+00 | loss scale: 1048576.0 | grad norm: 0.462 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 23:54:03] iteration   255900/  500000 | consumed samples:     16377600 | elapsed time per iteration (ms): 618.4 | learning rate: 2.381602E-05 | global batch size:    64 | lm loss: 2.997566E+00 | loss scale: 2097152.0 | grad norm: 0.474 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 23:55:05] iteration   256000/  500000 | consumed samples:     16384000 | elapsed time per iteration (ms): 616.1 | learning rate: 2.377506E-05 | global batch size:    64 | lm loss: 2.982441E+00 | loss scale: 2097152.0 | grad norm: 0.460 | number of skipped iterations:   1 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2460.87, 2460.89)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 256000 | lm loss value: 3.726090E+00 | lm loss PPL: 4.151647E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-25 23:56:09] iteration   256100/  500000 | consumed samples:     16390400 | elapsed time per iteration (ms): 618.3 | learning rate: 2.373415E-05 | global batch size:    64 | lm loss: 2.989449E+00 | loss scale: 1048576.0 | grad norm: 0.460 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-25 23:57:11] iteration   256200/  500000 | consumed samples:     16396800 | elapsed time per iteration (ms): 618.6 | learning rate: 2.369288E-05 | global batch size:    64 | lm loss: 2.996374E+00 | loss scale: 1048576.0 | grad norm: 0.466 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 23:58:13] iteration   256300/  500000 | consumed samples:     16403200 | elapsed time per iteration (ms): 619.2 | learning rate: 2.365167E-05 | global batch size:    64 | lm loss: 2.982057E+00 | loss scale: 1048576.0 | grad norm: 0.481 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-25 23:59:15] iteration   256400/  500000 | consumed samples:     16409600 | elapsed time per iteration (ms): 620.6 | learning rate: 2.361051E-05 | global batch size:    64 | lm loss: 2.993292E+00 | loss scale: 1048576.0 | grad norm: 0.465 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 00:00:17] iteration   256500/  500000 | consumed samples:     16416000 | elapsed time per iteration (ms): 620.8 | learning rate: 2.356941E-05 | global batch size:    64 | lm loss: 2.993485E+00 | loss scale: 1048576.0 | grad norm: 0.468 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 00:01:19] iteration   256600/  500000 | consumed samples:     16422400 | elapsed time per iteration (ms): 617.4 | learning rate: 2.352836E-05 | global batch size:    64 | lm loss: 2.983893E+00 | loss scale: 1048576.0 | grad norm: 0.488 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 00:02:21] iteration   256700/  500000 | consumed samples:     16428800 | elapsed time per iteration (ms): 619.6 | learning rate: 2.348737E-05 | global batch size:    64 | lm loss: 3.008535E+00 | loss scale: 1048576.0 | grad norm: 0.475 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 00:03:23] iteration   256800/  500000 | consumed samples:     16435200 | elapsed time per iteration (ms): 619.6 | learning rate: 2.344643E-05 | global batch size:    64 | lm loss: 2.984639E+00 | loss scale: 1048576.0 | grad norm: 0.471 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 00:04:25] iteration   256900/  500000 | consumed samples:     16441600 | elapsed time per iteration (ms): 619.0 | learning rate: 2.340555E-05 | global batch size:    64 | lm loss: 2.983597E+00 | loss scale: 1048576.0 | grad norm: 0.495 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 00:05:27] iteration   257000/  500000 | consumed samples:     16448000 | elapsed time per iteration (ms): 619.7 | learning rate: 2.336473E-05 | global batch size:    64 | lm loss: 2.993892E+00 | loss scale: 1048576.0 | grad norm: 0.474 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2462.74, 2462.77)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 257000 | lm loss value: 3.663587E+00 | lm loss PPL: 3.900100E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-26 00:06:31] iteration   257100/  500000 | consumed samples:     16454400 | elapsed time per iteration (ms): 618.6 | learning rate: 2.332396E-05 | global batch size:    64 | lm loss: 2.999930E+00 | loss scale: 2097152.0 | grad norm: 0.472 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 00:07:33] iteration   257200/  500000 | consumed samples:     16460800 | elapsed time per iteration (ms): 619.0 | learning rate: 2.328325E-05 | global batch size:    64 | lm loss: 2.988289E+00 | loss scale: 2097152.0 | grad norm: 0.471 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 00:08:35] iteration   257300/  500000 | consumed samples:     16467200 | elapsed time per iteration (ms): 619.8 | learning rate: 2.324259E-05 | global batch size:    64 | lm loss: 2.995300E+00 | loss scale: 2097152.0 | grad norm: 0.481 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 00:09:37] iteration   257400/  500000 | consumed samples:     16473600 | elapsed time per iteration (ms): 619.1 | learning rate: 2.320280E-05 | global batch size:    64 | lm loss: 2.993754E+00 | loss scale: 1048576.0 | grad norm: 0.471 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-26 00:10:39] iteration   257500/  500000 | consumed samples:     16480000 | elapsed time per iteration (ms): 620.5 | learning rate: 2.316226E-05 | global batch size:    64 | lm loss: 2.988484E+00 | loss scale: 1048576.0 | grad norm: 0.472 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 00:11:41] iteration   257600/  500000 | consumed samples:     16486400 | elapsed time per iteration (ms): 618.6 | learning rate: 2.312177E-05 | global batch size:    64 | lm loss: 2.987242E+00 | loss scale: 1048576.0 | grad norm: 0.475 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 00:12:42] iteration   257700/  500000 | consumed samples:     16492800 | elapsed time per iteration (ms): 618.4 | learning rate: 2.308133E-05 | global batch size:    64 | lm loss: 2.989200E+00 | loss scale: 1048576.0 | grad norm: 0.464 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 00:13:44] iteration   257800/  500000 | consumed samples:     16499200 | elapsed time per iteration (ms): 619.5 | learning rate: 2.304095E-05 | global batch size:    64 | lm loss: 2.986602E+00 | loss scale: 1048576.0 | grad norm: 0.465 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 00:14:46] iteration   257900/  500000 | consumed samples:     16505600 | elapsed time per iteration (ms): 618.0 | learning rate: 2.300063E-05 | global batch size:    64 | lm loss: 2.991839E+00 | loss scale: 1048576.0 | grad norm: 0.467 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 00:15:48] iteration   258000/  500000 | consumed samples:     16512000 | elapsed time per iteration (ms): 620.6 | learning rate: 2.296036E-05 | global batch size:    64 | lm loss: 2.976956E+00 | loss scale: 1048576.0 | grad norm: 0.470 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2462.88, 2462.91)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 258000 | lm loss value: 3.711759E+00 | lm loss PPL: 4.092573E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-26 00:16:53] iteration   258100/  500000 | consumed samples:     16518400 | elapsed time per iteration (ms): 617.9 | learning rate: 2.292015E-05 | global batch size:    64 | lm loss: 2.996982E+00 | loss scale: 1048576.0 | grad norm: 0.472 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 00:17:54] iteration   258200/  500000 | consumed samples:     16524800 | elapsed time per iteration (ms): 618.3 | learning rate: 2.288000E-05 | global batch size:    64 | lm loss: 2.989186E+00 | loss scale: 1048576.0 | grad norm: 0.477 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 00:18:56] iteration   258300/  500000 | consumed samples:     16531200 | elapsed time per iteration (ms): 619.0 | learning rate: 2.283990E-05 | global batch size:    64 | lm loss: 3.002882E+00 | loss scale: 1048576.0 | grad norm: 0.466 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 00:19:58] iteration   258400/  500000 | consumed samples:     16537600 | elapsed time per iteration (ms): 618.9 | learning rate: 2.280026E-05 | global batch size:    64 | lm loss: 2.987877E+00 | loss scale: 2097152.0 | grad norm: 0.452 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-26 00:21:00] iteration   258500/  500000 | consumed samples:     16544000 | elapsed time per iteration (ms): 618.5 | learning rate: 2.276067E-05 | global batch size:    64 | lm loss: 2.983556E+00 | loss scale: 1048576.0 | grad norm: 0.459 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-26 00:22:02] iteration   258600/  500000 | consumed samples:     16550400 | elapsed time per iteration (ms): 618.9 | learning rate: 2.272074E-05 | global batch size:    64 | lm loss: 2.985482E+00 | loss scale: 1048576.0 | grad norm: 0.475 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 00:23:04] iteration   258700/  500000 | consumed samples:     16556800 | elapsed time per iteration (ms): 619.5 | learning rate: 2.268087E-05 | global batch size:    64 | lm loss: 2.981229E+00 | loss scale: 1048576.0 | grad norm: 0.480 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 00:24:06] iteration   258800/  500000 | consumed samples:     16563200 | elapsed time per iteration (ms): 618.1 | learning rate: 2.264105E-05 | global batch size:    64 | lm loss: 2.995591E+00 | loss scale: 1048576.0 | grad norm: 0.480 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 00:25:08] iteration   258900/  500000 | consumed samples:     16569600 | elapsed time per iteration (ms): 619.1 | learning rate: 2.260129E-05 | global batch size:    64 | lm loss: 2.992357E+00 | loss scale: 1048576.0 | grad norm: 0.475 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 00:26:10] iteration   259000/  500000 | consumed samples:     16576000 | elapsed time per iteration (ms): 619.8 | learning rate: 2.256158E-05 | global batch size:    64 | lm loss: 2.985630E+00 | loss scale: 1048576.0 | grad norm: 0.489 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2462.00, 2462.03)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 259000 | lm loss value: 3.739203E+00 | lm loss PPL: 4.206445E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-26 00:27:14] iteration   259100/  500000 | consumed samples:     16582400 | elapsed time per iteration (ms): 619.6 | learning rate: 2.252193E-05 | global batch size:    64 | lm loss: 2.996993E+00 | loss scale: 1048576.0 | grad norm: 0.472 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 00:28:16] iteration   259200/  500000 | consumed samples:     16588800 | elapsed time per iteration (ms): 618.4 | learning rate: 2.248234E-05 | global batch size:    64 | lm loss: 2.997138E+00 | loss scale: 1048576.0 | grad norm: 0.451 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 00:29:18] iteration   259300/  500000 | consumed samples:     16595200 | elapsed time per iteration (ms): 618.9 | learning rate: 2.244280E-05 | global batch size:    64 | lm loss: 2.988635E+00 | loss scale: 1048576.0 | grad norm: 0.478 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 00:30:20] iteration   259400/  500000 | consumed samples:     16601600 | elapsed time per iteration (ms): 618.2 | learning rate: 2.240333E-05 | global batch size:    64 | lm loss: 2.993026E+00 | loss scale: 1048576.0 | grad norm: 0.479 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 00:31:21] iteration   259500/  500000 | consumed samples:     16608000 | elapsed time per iteration (ms): 617.7 | learning rate: 2.236390E-05 | global batch size:    64 | lm loss: 2.992997E+00 | loss scale: 2097152.0 | grad norm: 0.465 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 00:32:23] iteration   259600/  500000 | consumed samples:     16614400 | elapsed time per iteration (ms): 618.3 | learning rate: 2.232493E-05 | global batch size:    64 | lm loss: 2.994990E+00 | loss scale: 2097152.0 | grad norm: 0.487 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-26 00:33:25] iteration   259700/  500000 | consumed samples:     16620800 | elapsed time per iteration (ms): 619.5 | learning rate: 2.228562E-05 | global batch size:    64 | lm loss: 2.989174E+00 | loss scale: 2097152.0 | grad norm: 0.488 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 00:34:27] iteration   259800/  500000 | consumed samples:     16627200 | elapsed time per iteration (ms): 618.9 | learning rate: 2.224676E-05 | global batch size:    64 | lm loss: 2.993753E+00 | loss scale: 1048576.0 | grad norm: 0.470 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-26 00:35:29] iteration   259900/  500000 | consumed samples:     16633600 | elapsed time per iteration (ms): 619.9 | learning rate: 2.220757E-05 | global batch size:    64 | lm loss: 2.987702E+00 | loss scale: 1048576.0 | grad norm: 0.476 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 00:36:31] iteration   260000/  500000 | consumed samples:     16640000 | elapsed time per iteration (ms): 618.9 | learning rate: 2.216843E-05 | global batch size:    64 | lm loss: 3.000828E+00 | loss scale: 1048576.0 | grad norm: 0.475 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2461.49, 2461.50)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 260000 | lm loss value: 3.738688E+00 | lm loss PPL: 4.204279E+01 | 
--------------------------------------------------------------------------------------------------
saving checkpoint at iteration  260000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-distribution in torch format
  successfully saved checkpoint at iteration  260000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-distribution
(min, max) time across ranks (ms):
    save-checkpoint ................................: (2400.84, 2400.85)
 [2024-06-26 00:37:38] iteration   260100/  500000 | consumed samples:     16646400 | elapsed time per iteration (ms): 618.9 | learning rate: 2.212934E-05 | global batch size:    64 | lm loss: 2.991493E+00 | loss scale: 1048576.0 | grad norm: 0.466 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 00:38:40] iteration   260200/  500000 | consumed samples:     16652800 | elapsed time per iteration (ms): 619.8 | learning rate: 2.209032E-05 | global batch size:    64 | lm loss: 2.995232E+00 | loss scale: 1048576.0 | grad norm: 0.476 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 00:39:42] iteration   260300/  500000 | consumed samples:     16659200 | elapsed time per iteration (ms): 619.7 | learning rate: 2.205135E-05 | global batch size:    64 | lm loss: 2.972399E+00 | loss scale: 1048576.0 | grad norm: 0.464 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 00:40:43] iteration   260400/  500000 | consumed samples:     16665600 | elapsed time per iteration (ms): 619.4 | learning rate: 2.201244E-05 | global batch size:    64 | lm loss: 2.988284E+00 | loss scale: 1048576.0 | grad norm: 0.476 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 00:41:46] iteration   260500/  500000 | consumed samples:     16672000 | elapsed time per iteration (ms): 620.5 | learning rate: 2.197358E-05 | global batch size:    64 | lm loss: 2.983524E+00 | loss scale: 1048576.0 | grad norm: 0.479 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 00:42:47] iteration   260600/  500000 | consumed samples:     16678400 | elapsed time per iteration (ms): 618.5 | learning rate: 2.193517E-05 | global batch size:    64 | lm loss: 2.994043E+00 | loss scale: 524288.0 | grad norm: 0.457 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-26 00:43:49] iteration   260700/  500000 | consumed samples:     16684800 | elapsed time per iteration (ms): 619.5 | learning rate: 2.189643E-05 | global batch size:    64 | lm loss: 2.989889E+00 | loss scale: 524288.0 | grad norm: 0.470 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 00:44:51] iteration   260800/  500000 | consumed samples:     16691200 | elapsed time per iteration (ms): 617.6 | learning rate: 2.185775E-05 | global batch size:    64 | lm loss: 2.980096E+00 | loss scale: 524288.0 | grad norm: 0.480 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 00:45:53] iteration   260900/  500000 | consumed samples:     16697600 | elapsed time per iteration (ms): 619.6 | learning rate: 2.181912E-05 | global batch size:    64 | lm loss: 2.975009E+00 | loss scale: 524288.0 | grad norm: 0.471 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 00:46:55] iteration   261000/  500000 | consumed samples:     16704000 | elapsed time per iteration (ms): 618.1 | learning rate: 2.178055E-05 | global batch size:    64 | lm loss: 2.983799E+00 | loss scale: 524288.0 | grad norm: 0.457 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2462.20, 2462.21)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 261000 | lm loss value: 3.718573E+00 | lm loss PPL: 4.120554E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-26 00:47:59] iteration   261100/  500000 | consumed samples:     16710400 | elapsed time per iteration (ms): 618.7 | learning rate: 2.174204E-05 | global batch size:    64 | lm loss: 2.995179E+00 | loss scale: 524288.0 | grad norm: 0.466 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 00:49:01] iteration   261200/  500000 | consumed samples:     16716800 | elapsed time per iteration (ms): 616.4 | learning rate: 2.170358E-05 | global batch size:    64 | lm loss: 2.986640E+00 | loss scale: 524288.0 | grad norm: 0.466 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 00:50:03] iteration   261300/  500000 | consumed samples:     16723200 | elapsed time per iteration (ms): 618.2 | learning rate: 2.166518E-05 | global batch size:    64 | lm loss: 2.978167E+00 | loss scale: 524288.0 | grad norm: 0.462 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 00:51:04] iteration   261400/  500000 | consumed samples:     16729600 | elapsed time per iteration (ms): 618.0 | learning rate: 2.162684E-05 | global batch size:    64 | lm loss: 2.983319E+00 | loss scale: 524288.0 | grad norm: 0.457 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 00:52:06] iteration   261500/  500000 | consumed samples:     16736000 | elapsed time per iteration (ms): 617.9 | learning rate: 2.158856E-05 | global batch size:    64 | lm loss: 2.984001E+00 | loss scale: 524288.0 | grad norm: 0.482 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 00:53:08] iteration   261600/  500000 | consumed samples:     16742400 | elapsed time per iteration (ms): 618.2 | learning rate: 2.155033E-05 | global batch size:    64 | lm loss: 2.972603E+00 | loss scale: 1048576.0 | grad norm: 0.470 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 00:54:10] iteration   261700/  500000 | consumed samples:     16748800 | elapsed time per iteration (ms): 618.7 | learning rate: 2.151217E-05 | global batch size:    64 | lm loss: 2.981603E+00 | loss scale: 1048576.0 | grad norm: 0.492 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 00:55:12] iteration   261800/  500000 | consumed samples:     16755200 | elapsed time per iteration (ms): 618.0 | learning rate: 2.147406E-05 | global batch size:    64 | lm loss: 2.978743E+00 | loss scale: 1048576.0 | grad norm: 0.474 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 00:56:14] iteration   261900/  500000 | consumed samples:     16761600 | elapsed time per iteration (ms): 619.4 | learning rate: 2.143600E-05 | global batch size:    64 | lm loss: 2.985803E+00 | loss scale: 1048576.0 | grad norm: 0.469 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 00:57:15] iteration   262000/  500000 | consumed samples:     16768000 | elapsed time per iteration (ms): 617.6 | learning rate: 2.139801E-05 | global batch size:    64 | lm loss: 2.984011E+00 | loss scale: 1048576.0 | grad norm: 0.471 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2461.38, 2461.50)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 262000 | lm loss value: 3.714164E+00 | lm loss PPL: 4.102430E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-26 00:58:20] iteration   262100/  500000 | consumed samples:     16774400 | elapsed time per iteration (ms): 620.2 | learning rate: 2.136007E-05 | global batch size:    64 | lm loss: 3.002713E+00 | loss scale: 1048576.0 | grad norm: 0.472 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 00:59:22] iteration   262200/  500000 | consumed samples:     16780800 | elapsed time per iteration (ms): 617.7 | learning rate: 2.132219E-05 | global batch size:    64 | lm loss: 2.996689E+00 | loss scale: 1048576.0 | grad norm: 0.461 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 01:00:24] iteration   262300/  500000 | consumed samples:     16787200 | elapsed time per iteration (ms): 618.7 | learning rate: 2.128437E-05 | global batch size:    64 | lm loss: 2.989431E+00 | loss scale: 1048576.0 | grad norm: 0.479 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 01:01:25] iteration   262400/  500000 | consumed samples:     16793600 | elapsed time per iteration (ms): 619.2 | learning rate: 2.124660E-05 | global batch size:    64 | lm loss: 2.989030E+00 | loss scale: 1048576.0 | grad norm: 0.465 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 01:02:27] iteration   262500/  500000 | consumed samples:     16800000 | elapsed time per iteration (ms): 619.7 | learning rate: 2.120889E-05 | global batch size:    64 | lm loss: 2.991393E+00 | loss scale: 1048576.0 | grad norm: 0.468 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 01:03:30] iteration   262600/  500000 | consumed samples:     16806400 | elapsed time per iteration (ms): 621.3 | learning rate: 2.117125E-05 | global batch size:    64 | lm loss: 2.991182E+00 | loss scale: 2097152.0 | grad norm: 0.477 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 01:04:31] iteration   262700/  500000 | consumed samples:     16812800 | elapsed time per iteration (ms): 618.7 | learning rate: 2.113441E-05 | global batch size:    64 | lm loss: 2.976272E+00 | loss scale: 1048576.0 | grad norm: 0.464 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-26 01:05:33] iteration   262800/  500000 | consumed samples:     16819200 | elapsed time per iteration (ms): 619.3 | learning rate: 2.109687E-05 | global batch size:    64 | lm loss: 2.988545E+00 | loss scale: 1048576.0 | grad norm: 0.467 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 01:06:35] iteration   262900/  500000 | consumed samples:     16825600 | elapsed time per iteration (ms): 621.1 | learning rate: 2.105939E-05 | global batch size:    64 | lm loss: 2.982898E+00 | loss scale: 1048576.0 | grad norm: 0.471 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 01:07:37] iteration   263000/  500000 | consumed samples:     16832000 | elapsed time per iteration (ms): 618.5 | learning rate: 2.102198E-05 | global batch size:    64 | lm loss: 2.984407E+00 | loss scale: 1048576.0 | grad norm: 0.458 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2461.61, 2461.74)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 263000 | lm loss value: 3.712091E+00 | lm loss PPL: 4.093934E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-26 01:08:42] iteration   263100/  500000 | consumed samples:     16838400 | elapsed time per iteration (ms): 621.8 | learning rate: 2.098461E-05 | global batch size:    64 | lm loss: 2.990045E+00 | loss scale: 1048576.0 | grad norm: 0.473 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 01:09:44] iteration   263200/  500000 | consumed samples:     16844800 | elapsed time per iteration (ms): 619.3 | learning rate: 2.094731E-05 | global batch size:    64 | lm loss: 2.994576E+00 | loss scale: 1048576.0 | grad norm: 0.473 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 01:10:46] iteration   263300/  500000 | consumed samples:     16851200 | elapsed time per iteration (ms): 617.4 | learning rate: 2.091007E-05 | global batch size:    64 | lm loss: 2.989174E+00 | loss scale: 1048576.0 | grad norm: 0.485 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 01:11:47] iteration   263400/  500000 | consumed samples:     16857600 | elapsed time per iteration (ms): 618.6 | learning rate: 2.087288E-05 | global batch size:    64 | lm loss: 2.993970E+00 | loss scale: 1048576.0 | grad norm: 0.480 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 01:12:50] iteration   263500/  500000 | consumed samples:     16864000 | elapsed time per iteration (ms): 621.1 | learning rate: 2.083575E-05 | global batch size:    64 | lm loss: 2.972387E+00 | loss scale: 1048576.0 | grad norm: 0.470 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 01:13:52] iteration   263600/  500000 | consumed samples:     16870400 | elapsed time per iteration (ms): 619.3 | learning rate: 2.079868E-05 | global batch size:    64 | lm loss: 2.978490E+00 | loss scale: 1048576.0 | grad norm: 0.463 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 01:14:53] iteration   263700/  500000 | consumed samples:     16876800 | elapsed time per iteration (ms): 618.8 | learning rate: 2.076167E-05 | global batch size:    64 | lm loss: 2.982302E+00 | loss scale: 2097152.0 | grad norm: 0.472 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 01:15:56] iteration   263800/  500000 | consumed samples:     16883200 | elapsed time per iteration (ms): 621.8 | learning rate: 2.072472E-05 | global batch size:    64 | lm loss: 2.978529E+00 | loss scale: 2097152.0 | grad norm: 0.472 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 01:16:57] iteration   263900/  500000 | consumed samples:     16889600 | elapsed time per iteration (ms): 618.6 | learning rate: 2.068856E-05 | global batch size:    64 | lm loss: 2.991567E+00 | loss scale: 1048576.0 | grad norm: 0.477 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-26 01:17:59] iteration   264000/  500000 | consumed samples:     16896000 | elapsed time per iteration (ms): 619.2 | learning rate: 2.065172E-05 | global batch size:    64 | lm loss: 2.995717E+00 | loss scale: 1048576.0 | grad norm: 0.463 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2462.77, 2462.93)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 264000 | lm loss value: 3.748892E+00 | lm loss PPL: 4.247398E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-26 01:19:04] iteration   264100/  500000 | consumed samples:     16902400 | elapsed time per iteration (ms): 620.7 | learning rate: 2.061494E-05 | global batch size:    64 | lm loss: 2.971837E+00 | loss scale: 1048576.0 | grad norm: 0.474 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 01:20:06] iteration   264200/  500000 | consumed samples:     16908800 | elapsed time per iteration (ms): 620.1 | learning rate: 2.057822E-05 | global batch size:    64 | lm loss: 2.978212E+00 | loss scale: 1048576.0 | grad norm: 0.479 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 01:21:08] iteration   264300/  500000 | consumed samples:     16915200 | elapsed time per iteration (ms): 618.3 | learning rate: 2.054156E-05 | global batch size:    64 | lm loss: 2.989047E+00 | loss scale: 1048576.0 | grad norm: 0.469 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 01:22:10] iteration   264400/  500000 | consumed samples:     16921600 | elapsed time per iteration (ms): 618.7 | learning rate: 2.050495E-05 | global batch size:    64 | lm loss: 2.990144E+00 | loss scale: 1048576.0 | grad norm: 0.470 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 01:23:11] iteration   264500/  500000 | consumed samples:     16928000 | elapsed time per iteration (ms): 618.7 | learning rate: 2.046841E-05 | global batch size:    64 | lm loss: 3.002169E+00 | loss scale: 1048576.0 | grad norm: 0.481 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 01:24:14] iteration   264600/  500000 | consumed samples:     16934400 | elapsed time per iteration (ms): 620.3 | learning rate: 2.043192E-05 | global batch size:    64 | lm loss: 2.979453E+00 | loss scale: 1048576.0 | grad norm: 0.476 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 01:25:15] iteration   264700/  500000 | consumed samples:     16940800 | elapsed time per iteration (ms): 618.8 | learning rate: 2.039549E-05 | global batch size:    64 | lm loss: 2.996843E+00 | loss scale: 1048576.0 | grad norm: 0.463 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 01:26:17] iteration   264800/  500000 | consumed samples:     16947200 | elapsed time per iteration (ms): 620.2 | learning rate: 2.035912E-05 | global batch size:    64 | lm loss: 2.998327E+00 | loss scale: 1048576.0 | grad norm: 0.471 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 01:27:19] iteration   264900/  500000 | consumed samples:     16953600 | elapsed time per iteration (ms): 619.9 | learning rate: 2.032353E-05 | global batch size:    64 | lm loss: 2.991315E+00 | loss scale: 1048576.0 | grad norm: 0.474 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-26 01:28:21] iteration   265000/  500000 | consumed samples:     16960000 | elapsed time per iteration (ms): 617.7 | learning rate: 2.028728E-05 | global batch size:    64 | lm loss: 2.983806E+00 | loss scale: 1048576.0 | grad norm: 0.473 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2460.18, 2460.30)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 265000 | lm loss value: 3.740470E+00 | lm loss PPL: 4.211779E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-26 01:29:26] iteration   265100/  500000 | consumed samples:     16966400 | elapsed time per iteration (ms): 618.6 | learning rate: 2.025108E-05 | global batch size:    64 | lm loss: 2.987730E+00 | loss scale: 1048576.0 | grad norm: 0.469 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 01:30:27] iteration   265200/  500000 | consumed samples:     16972800 | elapsed time per iteration (ms): 618.2 | learning rate: 2.021495E-05 | global batch size:    64 | lm loss: 2.989043E+00 | loss scale: 1048576.0 | grad norm: 0.473 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 01:31:29] iteration   265300/  500000 | consumed samples:     16979200 | elapsed time per iteration (ms): 617.7 | learning rate: 2.017887E-05 | global batch size:    64 | lm loss: 2.989644E+00 | loss scale: 1048576.0 | grad norm: 0.481 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 01:32:31] iteration   265400/  500000 | consumed samples:     16985600 | elapsed time per iteration (ms): 620.7 | learning rate: 2.014285E-05 | global batch size:    64 | lm loss: 2.983876E+00 | loss scale: 1048576.0 | grad norm: 0.467 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 01:33:33] iteration   265500/  500000 | consumed samples:     16992000 | elapsed time per iteration (ms): 619.5 | learning rate: 2.010689E-05 | global batch size:    64 | lm loss: 2.977439E+00 | loss scale: 1048576.0 | grad norm: 0.476 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 01:34:35] iteration   265600/  500000 | consumed samples:     16998400 | elapsed time per iteration (ms): 616.4 | learning rate: 2.007099E-05 | global batch size:    64 | lm loss: 2.995197E+00 | loss scale: 1048576.0 | grad norm: 0.488 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 01:35:37] iteration   265700/  500000 | consumed samples:     17004800 | elapsed time per iteration (ms): 617.7 | learning rate: 2.003514E-05 | global batch size:    64 | lm loss: 2.999275E+00 | loss scale: 1048576.0 | grad norm: 0.467 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 01:36:38] iteration   265800/  500000 | consumed samples:     17011200 | elapsed time per iteration (ms): 619.0 | learning rate: 1.999936E-05 | global batch size:    64 | lm loss: 2.977539E+00 | loss scale: 1048576.0 | grad norm: 0.479 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 01:37:40] iteration   265900/  500000 | consumed samples:     17017600 | elapsed time per iteration (ms): 618.0 | learning rate: 1.996364E-05 | global batch size:    64 | lm loss: 2.999553E+00 | loss scale: 2097152.0 | grad norm: 0.469 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 01:38:42] iteration   266000/  500000 | consumed samples:     17024000 | elapsed time per iteration (ms): 618.3 | learning rate: 1.992833E-05 | global batch size:    64 | lm loss: 2.991309E+00 | loss scale: 2097152.0 | grad norm: 0.471 | number of skipped iterations:   1 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2461.51, 2461.58)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 266000 | lm loss value: 3.679376E+00 | lm loss PPL: 3.962166E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-26 01:39:47] iteration   266100/  500000 | consumed samples:     17030400 | elapsed time per iteration (ms): 620.3 | learning rate: 1.989272E-05 | global batch size:    64 | lm loss: 2.977175E+00 | loss scale: 2097152.0 | grad norm: 0.483 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 01:40:48] iteration   266200/  500000 | consumed samples:     17036800 | elapsed time per iteration (ms): 618.4 | learning rate: 1.985717E-05 | global batch size:    64 | lm loss: 2.976629E+00 | loss scale: 2097152.0 | grad norm: 0.485 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 01:41:50] iteration   266300/  500000 | consumed samples:     17043200 | elapsed time per iteration (ms): 619.0 | learning rate: 1.982168E-05 | global batch size:    64 | lm loss: 2.988733E+00 | loss scale: 2097152.0 | grad norm: 0.465 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 01:42:52] iteration   266400/  500000 | consumed samples:     17049600 | elapsed time per iteration (ms): 619.8 | learning rate: 1.978661E-05 | global batch size:    64 | lm loss: 3.000494E+00 | loss scale: 1048576.0 | grad norm: 0.461 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-26 01:43:54] iteration   266500/  500000 | consumed samples:     17056000 | elapsed time per iteration (ms): 620.5 | learning rate: 1.975124E-05 | global batch size:    64 | lm loss: 2.988206E+00 | loss scale: 1048576.0 | grad norm: 0.479 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 01:44:56] iteration   266600/  500000 | consumed samples:     17062400 | elapsed time per iteration (ms): 617.3 | learning rate: 1.971593E-05 | global batch size:    64 | lm loss: 2.989390E+00 | loss scale: 1048576.0 | grad norm: 0.462 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 01:45:58] iteration   266700/  500000 | consumed samples:     17068800 | elapsed time per iteration (ms): 618.2 | learning rate: 1.968067E-05 | global batch size:    64 | lm loss: 2.978433E+00 | loss scale: 1048576.0 | grad norm: 0.473 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 01:47:00] iteration   266800/  500000 | consumed samples:     17075200 | elapsed time per iteration (ms): 619.2 | learning rate: 1.964548E-05 | global batch size:    64 | lm loss: 2.970071E+00 | loss scale: 1048576.0 | grad norm: 0.475 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 01:48:02] iteration   266900/  500000 | consumed samples:     17081600 | elapsed time per iteration (ms): 621.6 | learning rate: 1.961035E-05 | global batch size:    64 | lm loss: 2.974350E+00 | loss scale: 1048576.0 | grad norm: 0.486 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 01:49:04] iteration   267000/  500000 | consumed samples:     17088000 | elapsed time per iteration (ms): 619.8 | learning rate: 1.957527E-05 | global batch size:    64 | lm loss: 2.975575E+00 | loss scale: 1048576.0 | grad norm: 0.459 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2461.59, 2461.64)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 267000 | lm loss value: 3.725642E+00 | lm loss PPL: 4.149785E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-26 01:50:08] iteration   267100/  500000 | consumed samples:     17094400 | elapsed time per iteration (ms): 619.3 | learning rate: 1.954026E-05 | global batch size:    64 | lm loss: 2.964869E+00 | loss scale: 1048576.0 | grad norm: 0.469 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 01:51:10] iteration   267200/  500000 | consumed samples:     17100800 | elapsed time per iteration (ms): 620.8 | learning rate: 1.950530E-05 | global batch size:    64 | lm loss: 2.992966E+00 | loss scale: 1048576.0 | grad norm: 0.474 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 01:52:12] iteration   267300/  500000 | consumed samples:     17107200 | elapsed time per iteration (ms): 617.4 | learning rate: 1.947041E-05 | global batch size:    64 | lm loss: 2.992534E+00 | loss scale: 1048576.0 | grad norm: 0.474 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 01:53:14] iteration   267400/  500000 | consumed samples:     17113600 | elapsed time per iteration (ms): 621.0 | learning rate: 1.943627E-05 | global batch size:    64 | lm loss: 2.975482E+00 | loss scale: 1048576.0 | grad norm: 0.466 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-26 01:54:16] iteration   267500/  500000 | consumed samples:     17120000 | elapsed time per iteration (ms): 617.3 | learning rate: 1.940149E-05 | global batch size:    64 | lm loss: 2.980438E+00 | loss scale: 1048576.0 | grad norm: 0.456 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 01:55:18] iteration   267600/  500000 | consumed samples:     17126400 | elapsed time per iteration (ms): 618.2 | learning rate: 1.936677E-05 | global batch size:    64 | lm loss: 2.990428E+00 | loss scale: 1048576.0 | grad norm: 0.468 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 01:56:20] iteration   267700/  500000 | consumed samples:     17132800 | elapsed time per iteration (ms): 617.2 | learning rate: 1.933211E-05 | global batch size:    64 | lm loss: 2.986628E+00 | loss scale: 1048576.0 | grad norm: 0.467 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 01:57:21] iteration   267800/  500000 | consumed samples:     17139200 | elapsed time per iteration (ms): 619.7 | learning rate: 1.929751E-05 | global batch size:    64 | lm loss: 2.987305E+00 | loss scale: 1048576.0 | grad norm: 0.464 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 01:58:23] iteration   267900/  500000 | consumed samples:     17145600 | elapsed time per iteration (ms): 617.7 | learning rate: 1.926297E-05 | global batch size:    64 | lm loss: 2.984881E+00 | loss scale: 1048576.0 | grad norm: 0.469 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 01:59:25] iteration   268000/  500000 | consumed samples:     17152000 | elapsed time per iteration (ms): 617.9 | learning rate: 1.922849E-05 | global batch size:    64 | lm loss: 2.984783E+00 | loss scale: 1048576.0 | grad norm: 0.475 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2461.01, 2461.06)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 268000 | lm loss value: 3.756675E+00 | lm loss PPL: 4.280588E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-26 02:00:29] iteration   268100/  500000 | consumed samples:     17158400 | elapsed time per iteration (ms): 618.7 | learning rate: 1.919442E-05 | global batch size:    64 | lm loss: 2.975753E+00 | loss scale: 524288.0 | grad norm: 0.467 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-26 02:01:31] iteration   268200/  500000 | consumed samples:     17164800 | elapsed time per iteration (ms): 619.9 | learning rate: 1.916006E-05 | global batch size:    64 | lm loss: 2.972667E+00 | loss scale: 524288.0 | grad norm: 0.465 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 02:02:33] iteration   268300/  500000 | consumed samples:     17171200 | elapsed time per iteration (ms): 616.2 | learning rate: 1.912576E-05 | global batch size:    64 | lm loss: 2.984755E+00 | loss scale: 524288.0 | grad norm: 0.463 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 02:03:35] iteration   268400/  500000 | consumed samples:     17177600 | elapsed time per iteration (ms): 619.8 | learning rate: 1.909152E-05 | global batch size:    64 | lm loss: 2.989345E+00 | loss scale: 524288.0 | grad norm: 0.461 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 02:04:37] iteration   268500/  500000 | consumed samples:     17184000 | elapsed time per iteration (ms): 619.3 | learning rate: 1.905733E-05 | global batch size:    64 | lm loss: 2.990135E+00 | loss scale: 524288.0 | grad norm: 0.474 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 02:05:39] iteration   268600/  500000 | consumed samples:     17190400 | elapsed time per iteration (ms): 620.8 | learning rate: 1.902321E-05 | global batch size:    64 | lm loss: 2.979942E+00 | loss scale: 524288.0 | grad norm: 0.462 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 02:06:41] iteration   268700/  500000 | consumed samples:     17196800 | elapsed time per iteration (ms): 618.8 | learning rate: 1.898915E-05 | global batch size:    64 | lm loss: 2.982959E+00 | loss scale: 524288.0 | grad norm: 0.482 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 02:07:43] iteration   268800/  500000 | consumed samples:     17203200 | elapsed time per iteration (ms): 618.8 | learning rate: 1.895515E-05 | global batch size:    64 | lm loss: 2.992337E+00 | loss scale: 524288.0 | grad norm: 0.471 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 02:08:45] iteration   268900/  500000 | consumed samples:     17209600 | elapsed time per iteration (ms): 620.6 | learning rate: 1.892121E-05 | global batch size:    64 | lm loss: 2.970295E+00 | loss scale: 524288.0 | grad norm: 0.476 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 02:09:47] iteration   269000/  500000 | consumed samples:     17216000 | elapsed time per iteration (ms): 619.2 | learning rate: 1.888733E-05 | global batch size:    64 | lm loss: 2.965806E+00 | loss scale: 524288.0 | grad norm: 0.484 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2460.27, 2460.43)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 269000 | lm loss value: 3.686697E+00 | lm loss PPL: 3.991279E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-26 02:10:51] iteration   269100/  500000 | consumed samples:     17222400 | elapsed time per iteration (ms): 619.1 | learning rate: 1.885351E-05 | global batch size:    64 | lm loss: 2.980956E+00 | loss scale: 1048576.0 | grad norm: 0.469 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 02:11:53] iteration   269200/  500000 | consumed samples:     17228800 | elapsed time per iteration (ms): 617.5 | learning rate: 1.881975E-05 | global batch size:    64 | lm loss: 2.989536E+00 | loss scale: 1048576.0 | grad norm: 0.489 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 02:12:55] iteration   269300/  500000 | consumed samples:     17235200 | elapsed time per iteration (ms): 618.6 | learning rate: 1.878605E-05 | global batch size:    64 | lm loss: 2.985372E+00 | loss scale: 1048576.0 | grad norm: 0.480 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 02:13:56] iteration   269400/  500000 | consumed samples:     17241600 | elapsed time per iteration (ms): 617.4 | learning rate: 1.875241E-05 | global batch size:    64 | lm loss: 2.969729E+00 | loss scale: 1048576.0 | grad norm: 0.468 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 02:14:58] iteration   269500/  500000 | consumed samples:     17248000 | elapsed time per iteration (ms): 618.7 | learning rate: 1.871883E-05 | global batch size:    64 | lm loss: 2.988384E+00 | loss scale: 1048576.0 | grad norm: 0.480 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 02:16:00] iteration   269600/  500000 | consumed samples:     17254400 | elapsed time per iteration (ms): 617.9 | learning rate: 1.868531E-05 | global batch size:    64 | lm loss: 2.975781E+00 | loss scale: 1048576.0 | grad norm: 0.485 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 02:17:02] iteration   269700/  500000 | consumed samples:     17260800 | elapsed time per iteration (ms): 618.5 | learning rate: 1.865185E-05 | global batch size:    64 | lm loss: 2.980470E+00 | loss scale: 1048576.0 | grad norm: 0.483 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 02:18:04] iteration   269800/  500000 | consumed samples:     17267200 | elapsed time per iteration (ms): 618.3 | learning rate: 1.861845E-05 | global batch size:    64 | lm loss: 2.984400E+00 | loss scale: 1048576.0 | grad norm: 0.464 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 02:19:06] iteration   269900/  500000 | consumed samples:     17273600 | elapsed time per iteration (ms): 618.1 | learning rate: 1.858511E-05 | global batch size:    64 | lm loss: 2.985138E+00 | loss scale: 1048576.0 | grad norm: 0.476 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 02:20:07] iteration   270000/  500000 | consumed samples:     17280000 | elapsed time per iteration (ms): 617.6 | learning rate: 1.855183E-05 | global batch size:    64 | lm loss: 2.979341E+00 | loss scale: 1048576.0 | grad norm: 0.470 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2460.76, 2460.97)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 270000 | lm loss value: 3.738720E+00 | lm loss PPL: 4.204416E+01 | 
--------------------------------------------------------------------------------------------------
saving checkpoint at iteration  270000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-distribution in torch format
  successfully saved checkpoint at iteration  270000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-distribution
(min, max) time across ranks (ms):
    save-checkpoint ................................: (2366.83, 2366.85)
 [2024-06-26 02:21:14] iteration   270100/  500000 | consumed samples:     17286400 | elapsed time per iteration (ms): 618.0 | learning rate: 1.851894E-05 | global batch size:    64 | lm loss: 2.972813E+00 | loss scale: 2097152.0 | grad norm: 0.487 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-26 02:22:16] iteration   270200/  500000 | consumed samples:     17292800 | elapsed time per iteration (ms): 621.5 | learning rate: 1.848611E-05 | global batch size:    64 | lm loss: 2.971518E+00 | loss scale: 1048576.0 | grad norm: 0.468 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-26 02:23:18] iteration   270300/  500000 | consumed samples:     17299200 | elapsed time per iteration (ms): 618.6 | learning rate: 1.845302E-05 | global batch size:    64 | lm loss: 2.972842E+00 | loss scale: 1048576.0 | grad norm: 0.481 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 02:24:20] iteration   270400/  500000 | consumed samples:     17305600 | elapsed time per iteration (ms): 618.1 | learning rate: 1.841998E-05 | global batch size:    64 | lm loss: 2.978820E+00 | loss scale: 1048576.0 | grad norm: 0.479 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 02:25:22] iteration   270500/  500000 | consumed samples:     17312000 | elapsed time per iteration (ms): 618.5 | learning rate: 1.838700E-05 | global batch size:    64 | lm loss: 2.976193E+00 | loss scale: 1048576.0 | grad norm: 0.482 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 02:26:23] iteration   270600/  500000 | consumed samples:     17318400 | elapsed time per iteration (ms): 618.0 | learning rate: 1.835408E-05 | global batch size:    64 | lm loss: 2.988499E+00 | loss scale: 1048576.0 | grad norm: 0.479 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 02:27:25] iteration   270700/  500000 | consumed samples:     17324800 | elapsed time per iteration (ms): 618.2 | learning rate: 1.832123E-05 | global batch size:    64 | lm loss: 2.981874E+00 | loss scale: 1048576.0 | grad norm: 0.470 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 02:28:27] iteration   270800/  500000 | consumed samples:     17331200 | elapsed time per iteration (ms): 617.5 | learning rate: 1.828843E-05 | global batch size:    64 | lm loss: 2.971027E+00 | loss scale: 1048576.0 | grad norm: 0.485 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 02:29:29] iteration   270900/  500000 | consumed samples:     17337600 | elapsed time per iteration (ms): 617.3 | learning rate: 1.825570E-05 | global batch size:    64 | lm loss: 2.996345E+00 | loss scale: 1048576.0 | grad norm: 0.472 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 02:30:31] iteration   271000/  500000 | consumed samples:     17344000 | elapsed time per iteration (ms): 618.1 | learning rate: 1.822302E-05 | global batch size:    64 | lm loss: 2.981311E+00 | loss scale: 1048576.0 | grad norm: 0.463 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2461.80, 2461.89)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 271000 | lm loss value: 3.702836E+00 | lm loss PPL: 4.056217E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-26 02:31:35] iteration   271100/  500000 | consumed samples:     17350400 | elapsed time per iteration (ms): 617.1 | learning rate: 1.819041E-05 | global batch size:    64 | lm loss: 2.972705E+00 | loss scale: 1048576.0 | grad norm: 0.487 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 02:32:36] iteration   271200/  500000 | consumed samples:     17356800 | elapsed time per iteration (ms): 617.6 | learning rate: 1.815851E-05 | global batch size:    64 | lm loss: 2.991044E+00 | loss scale: 1048576.0 | grad norm: 0.477 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-26 02:33:38] iteration   271300/  500000 | consumed samples:     17363200 | elapsed time per iteration (ms): 618.5 | learning rate: 1.812601E-05 | global batch size:    64 | lm loss: 2.986288E+00 | loss scale: 1048576.0 | grad norm: 0.467 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 02:34:40] iteration   271400/  500000 | consumed samples:     17369600 | elapsed time per iteration (ms): 619.6 | learning rate: 1.809358E-05 | global batch size:    64 | lm loss: 2.968863E+00 | loss scale: 1048576.0 | grad norm: 0.470 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 02:35:42] iteration   271500/  500000 | consumed samples:     17376000 | elapsed time per iteration (ms): 620.7 | learning rate: 1.806121E-05 | global batch size:    64 | lm loss: 2.967418E+00 | loss scale: 1048576.0 | grad norm: 0.471 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 02:36:44] iteration   271600/  500000 | consumed samples:     17382400 | elapsed time per iteration (ms): 619.1 | learning rate: 1.802890E-05 | global batch size:    64 | lm loss: 2.993853E+00 | loss scale: 1048576.0 | grad norm: 0.487 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 02:37:46] iteration   271700/  500000 | consumed samples:     17388800 | elapsed time per iteration (ms): 619.1 | learning rate: 1.799665E-05 | global batch size:    64 | lm loss: 2.982018E+00 | loss scale: 1048576.0 | grad norm: 0.469 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 02:38:48] iteration   271800/  500000 | consumed samples:     17395200 | elapsed time per iteration (ms): 619.0 | learning rate: 1.796446E-05 | global batch size:    64 | lm loss: 2.982260E+00 | loss scale: 1048576.0 | grad norm: 0.471 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 02:39:50] iteration   271900/  500000 | consumed samples:     17401600 | elapsed time per iteration (ms): 617.6 | learning rate: 1.793234E-05 | global batch size:    64 | lm loss: 2.956210E+00 | loss scale: 1048576.0 | grad norm: 0.474 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 02:40:52] iteration   272000/  500000 | consumed samples:     17408000 | elapsed time per iteration (ms): 619.3 | learning rate: 1.790027E-05 | global batch size:    64 | lm loss: 2.970565E+00 | loss scale: 1048576.0 | grad norm: 0.477 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2462.48, 2462.50)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 272000 | lm loss value: 3.752342E+00 | lm loss PPL: 4.262079E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-26 02:41:56] iteration   272100/  500000 | consumed samples:     17414400 | elapsed time per iteration (ms): 619.1 | learning rate: 1.786826E-05 | global batch size:    64 | lm loss: 2.992166E+00 | loss scale: 1048576.0 | grad norm: 0.474 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 02:42:58] iteration   272200/  500000 | consumed samples:     17420800 | elapsed time per iteration (ms): 619.2 | learning rate: 1.783664E-05 | global batch size:    64 | lm loss: 2.982029E+00 | loss scale: 2097152.0 | grad norm: 0.480 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-26 02:44:00] iteration   272300/  500000 | consumed samples:     17427200 | elapsed time per iteration (ms): 619.0 | learning rate: 1.780507E-05 | global batch size:    64 | lm loss: 2.999890E+00 | loss scale: 1048576.0 | grad norm: 0.477 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-26 02:45:02] iteration   272400/  500000 | consumed samples:     17433600 | elapsed time per iteration (ms): 620.0 | learning rate: 1.777325E-05 | global batch size:    64 | lm loss: 2.984332E+00 | loss scale: 1048576.0 | grad norm: 0.466 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 02:46:04] iteration   272500/  500000 | consumed samples:     17440000 | elapsed time per iteration (ms): 617.8 | learning rate: 1.774149E-05 | global batch size:    64 | lm loss: 2.980790E+00 | loss scale: 1048576.0 | grad norm: 0.475 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 02:47:06] iteration   272600/  500000 | consumed samples:     17446400 | elapsed time per iteration (ms): 618.2 | learning rate: 1.770979E-05 | global batch size:    64 | lm loss: 2.979687E+00 | loss scale: 1048576.0 | grad norm: 0.481 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 02:48:07] iteration   272700/  500000 | consumed samples:     17452800 | elapsed time per iteration (ms): 618.5 | learning rate: 1.767815E-05 | global batch size:    64 | lm loss: 2.987310E+00 | loss scale: 1048576.0 | grad norm: 0.471 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 02:49:10] iteration   272800/  500000 | consumed samples:     17459200 | elapsed time per iteration (ms): 622.2 | learning rate: 1.764657E-05 | global batch size:    64 | lm loss: 2.999874E+00 | loss scale: 1048576.0 | grad norm: 0.466 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 02:50:12] iteration   272900/  500000 | consumed samples:     17465600 | elapsed time per iteration (ms): 619.5 | learning rate: 1.761505E-05 | global batch size:    64 | lm loss: 2.980865E+00 | loss scale: 1048576.0 | grad norm: 0.496 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 02:51:13] iteration   273000/  500000 | consumed samples:     17472000 | elapsed time per iteration (ms): 618.0 | learning rate: 1.758360E-05 | global batch size:    64 | lm loss: 2.989435E+00 | loss scale: 1048576.0 | grad norm: 0.468 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2462.34, 2462.39)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 273000 | lm loss value: 3.681962E+00 | lm loss PPL: 3.972424E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-26 02:52:18] iteration   273100/  500000 | consumed samples:     17478400 | elapsed time per iteration (ms): 620.7 | learning rate: 1.755220E-05 | global batch size:    64 | lm loss: 2.980576E+00 | loss scale: 1048576.0 | grad norm: 0.480 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 02:53:20] iteration   273200/  500000 | consumed samples:     17484800 | elapsed time per iteration (ms): 617.0 | learning rate: 1.752087E-05 | global batch size:    64 | lm loss: 2.980567E+00 | loss scale: 1048576.0 | grad norm: 0.466 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 02:54:21] iteration   273300/  500000 | consumed samples:     17491200 | elapsed time per iteration (ms): 618.6 | learning rate: 1.748960E-05 | global batch size:    64 | lm loss: 2.968476E+00 | loss scale: 2097152.0 | grad norm: 0.484 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 02:55:23] iteration   273400/  500000 | consumed samples:     17497600 | elapsed time per iteration (ms): 619.1 | learning rate: 1.745839E-05 | global batch size:    64 | lm loss: 2.988898E+00 | loss scale: 2097152.0 | grad norm: 0.467 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 02:56:25] iteration   273500/  500000 | consumed samples:     17504000 | elapsed time per iteration (ms): 618.4 | learning rate: 1.742724E-05 | global batch size:    64 | lm loss: 2.983121E+00 | loss scale: 2097152.0 | grad norm: 0.470 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 02:57:27] iteration   273600/  500000 | consumed samples:     17510400 | elapsed time per iteration (ms): 618.0 | learning rate: 1.739615E-05 | global batch size:    64 | lm loss: 2.969284E+00 | loss scale: 2097152.0 | grad norm: 0.498 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 02:58:29] iteration   273700/  500000 | consumed samples:     17516800 | elapsed time per iteration (ms): 619.0 | learning rate: 1.736575E-05 | global batch size:    64 | lm loss: 2.984217E+00 | loss scale: 1048576.0 | grad norm: 0.465 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-26 02:59:31] iteration   273800/  500000 | consumed samples:     17523200 | elapsed time per iteration (ms): 621.8 | learning rate: 1.733478E-05 | global batch size:    64 | lm loss: 2.979784E+00 | loss scale: 1048576.0 | grad norm: 0.484 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 03:00:33] iteration   273900/  500000 | consumed samples:     17529600 | elapsed time per iteration (ms): 620.1 | learning rate: 1.730388E-05 | global batch size:    64 | lm loss: 2.970087E+00 | loss scale: 1048576.0 | grad norm: 0.475 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 03:01:35] iteration   274000/  500000 | consumed samples:     17536000 | elapsed time per iteration (ms): 619.3 | learning rate: 1.727304E-05 | global batch size:    64 | lm loss: 2.982841E+00 | loss scale: 1048576.0 | grad norm: 0.475 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2460.29, 2460.41)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 274000 | lm loss value: 3.740304E+00 | lm loss PPL: 4.211080E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-26 03:02:39] iteration   274100/  500000 | consumed samples:     17542400 | elapsed time per iteration (ms): 618.2 | learning rate: 1.724226E-05 | global batch size:    64 | lm loss: 2.959062E+00 | loss scale: 1048576.0 | grad norm: 0.478 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 03:03:41] iteration   274200/  500000 | consumed samples:     17548800 | elapsed time per iteration (ms): 618.9 | learning rate: 1.721154E-05 | global batch size:    64 | lm loss: 2.966718E+00 | loss scale: 1048576.0 | grad norm: 0.478 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 03:04:43] iteration   274300/  500000 | consumed samples:     17555200 | elapsed time per iteration (ms): 618.4 | learning rate: 1.718088E-05 | global batch size:    64 | lm loss: 2.974465E+00 | loss scale: 1048576.0 | grad norm: 0.477 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 03:05:45] iteration   274400/  500000 | consumed samples:     17561600 | elapsed time per iteration (ms): 618.7 | learning rate: 1.715029E-05 | global batch size:    64 | lm loss: 2.971037E+00 | loss scale: 1048576.0 | grad norm: 0.470 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 03:06:47] iteration   274500/  500000 | consumed samples:     17568000 | elapsed time per iteration (ms): 619.0 | learning rate: 1.711976E-05 | global batch size:    64 | lm loss: 2.972132E+00 | loss scale: 1048576.0 | grad norm: 0.487 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 03:07:49] iteration   274600/  500000 | consumed samples:     17574400 | elapsed time per iteration (ms): 617.8 | learning rate: 1.708929E-05 | global batch size:    64 | lm loss: 2.992855E+00 | loss scale: 1048576.0 | grad norm: 0.467 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 03:08:50] iteration   274700/  500000 | consumed samples:     17580800 | elapsed time per iteration (ms): 618.2 | learning rate: 1.705888E-05 | global batch size:    64 | lm loss: 2.979907E+00 | loss scale: 2097152.0 | grad norm: 0.485 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 03:09:52] iteration   274800/  500000 | consumed samples:     17587200 | elapsed time per iteration (ms): 618.5 | learning rate: 1.702914E-05 | global batch size:    64 | lm loss: 2.984216E+00 | loss scale: 1048576.0 | grad norm: 0.473 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-26 03:10:54] iteration   274900/  500000 | consumed samples:     17593600 | elapsed time per iteration (ms): 618.1 | learning rate: 1.699885E-05 | global batch size:    64 | lm loss: 2.978752E+00 | loss scale: 1048576.0 | grad norm: 0.473 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 03:11:56] iteration   275000/  500000 | consumed samples:     17600000 | elapsed time per iteration (ms): 617.5 | learning rate: 1.696863E-05 | global batch size:    64 | lm loss: 2.999318E+00 | loss scale: 1048576.0 | grad norm: 0.479 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2460.48, 2460.49)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 275000 | lm loss value: 3.760432E+00 | lm loss PPL: 4.296698E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-26 03:13:00] iteration   275100/  500000 | consumed samples:     17606400 | elapsed time per iteration (ms): 619.6 | learning rate: 1.693846E-05 | global batch size:    64 | lm loss: 2.983882E+00 | loss scale: 1048576.0 | grad norm: 0.478 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 03:14:02] iteration   275200/  500000 | consumed samples:     17612800 | elapsed time per iteration (ms): 620.2 | learning rate: 1.690836E-05 | global batch size:    64 | lm loss: 2.979479E+00 | loss scale: 1048576.0 | grad norm: 0.483 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 03:15:04] iteration   275300/  500000 | consumed samples:     17619200 | elapsed time per iteration (ms): 618.3 | learning rate: 1.687832E-05 | global batch size:    64 | lm loss: 2.991779E+00 | loss scale: 1048576.0 | grad norm: 0.477 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 03:16:06] iteration   275400/  500000 | consumed samples:     17625600 | elapsed time per iteration (ms): 618.6 | learning rate: 1.684835E-05 | global batch size:    64 | lm loss: 2.989676E+00 | loss scale: 1048576.0 | grad norm: 0.484 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 03:17:08] iteration   275500/  500000 | consumed samples:     17632000 | elapsed time per iteration (ms): 620.0 | learning rate: 1.681843E-05 | global batch size:    64 | lm loss: 2.973166E+00 | loss scale: 1048576.0 | grad norm: 0.476 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 03:18:10] iteration   275600/  500000 | consumed samples:     17638400 | elapsed time per iteration (ms): 620.0 | learning rate: 1.678858E-05 | global batch size:    64 | lm loss: 2.974195E+00 | loss scale: 1048576.0 | grad norm: 0.454 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 03:19:12] iteration   275700/  500000 | consumed samples:     17644800 | elapsed time per iteration (ms): 617.1 | learning rate: 1.675879E-05 | global batch size:    64 | lm loss: 2.968090E+00 | loss scale: 1048576.0 | grad norm: 0.506 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 03:20:13] iteration   275800/  500000 | consumed samples:     17651200 | elapsed time per iteration (ms): 617.6 | learning rate: 1.672906E-05 | global batch size:    64 | lm loss: 2.987940E+00 | loss scale: 2097152.0 | grad norm: 0.480 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 03:21:15] iteration   275900/  500000 | consumed samples:     17657600 | elapsed time per iteration (ms): 618.1 | learning rate: 1.669969E-05 | global batch size:    64 | lm loss: 2.982107E+00 | loss scale: 2097152.0 | grad norm: 0.471 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-26 03:22:17] iteration   276000/  500000 | consumed samples:     17664000 | elapsed time per iteration (ms): 617.9 | learning rate: 1.667038E-05 | global batch size:    64 | lm loss: 2.979992E+00 | loss scale: 1048576.0 | grad norm: 0.497 | number of skipped iterations:   1 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2462.71, 2462.72)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 276000 | lm loss value: 3.700708E+00 | lm loss PPL: 4.047596E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-26 03:23:21] iteration   276100/  500000 | consumed samples:     17670400 | elapsed time per iteration (ms): 618.2 | learning rate: 1.664084E-05 | global batch size:    64 | lm loss: 2.975926E+00 | loss scale: 1048576.0 | grad norm: 0.491 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 03:24:23] iteration   276200/  500000 | consumed samples:     17676800 | elapsed time per iteration (ms): 619.4 | learning rate: 1.661136E-05 | global batch size:    64 | lm loss: 2.989285E+00 | loss scale: 1048576.0 | grad norm: 0.480 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 03:25:25] iteration   276300/  500000 | consumed samples:     17683200 | elapsed time per iteration (ms): 618.7 | learning rate: 1.658194E-05 | global batch size:    64 | lm loss: 2.972677E+00 | loss scale: 1048576.0 | grad norm: 0.479 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 03:26:27] iteration   276400/  500000 | consumed samples:     17689600 | elapsed time per iteration (ms): 618.1 | learning rate: 1.655259E-05 | global batch size:    64 | lm loss: 2.978058E+00 | loss scale: 1048576.0 | grad norm: 0.460 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 03:27:29] iteration   276500/  500000 | consumed samples:     17696000 | elapsed time per iteration (ms): 618.8 | learning rate: 1.652330E-05 | global batch size:    64 | lm loss: 2.970157E+00 | loss scale: 1048576.0 | grad norm: 0.469 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 03:28:31] iteration   276600/  500000 | consumed samples:     17702400 | elapsed time per iteration (ms): 620.4 | learning rate: 1.649407E-05 | global batch size:    64 | lm loss: 2.984567E+00 | loss scale: 1048576.0 | grad norm: 0.466 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 03:29:33] iteration   276700/  500000 | consumed samples:     17708800 | elapsed time per iteration (ms): 620.6 | learning rate: 1.646490E-05 | global batch size:    64 | lm loss: 2.966363E+00 | loss scale: 1048576.0 | grad norm: 0.485 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 03:30:35] iteration   276800/  500000 | consumed samples:     17715200 | elapsed time per iteration (ms): 619.8 | learning rate: 1.643579E-05 | global batch size:    64 | lm loss: 2.962484E+00 | loss scale: 1048576.0 | grad norm: 0.474 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 03:31:37] iteration   276900/  500000 | consumed samples:     17721600 | elapsed time per iteration (ms): 618.7 | learning rate: 1.640704E-05 | global batch size:    64 | lm loss: 2.977943E+00 | loss scale: 524288.0 | grad norm: 0.486 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-26 03:32:39] iteration   277000/  500000 | consumed samples:     17728000 | elapsed time per iteration (ms): 618.9 | learning rate: 1.637806E-05 | global batch size:    64 | lm loss: 2.971887E+00 | loss scale: 524288.0 | grad norm: 0.476 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2463.89, 2463.90)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 277000 | lm loss value: 3.733290E+00 | lm loss PPL: 4.181648E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-26 03:33:43] iteration   277100/  500000 | consumed samples:     17734400 | elapsed time per iteration (ms): 620.4 | learning rate: 1.634914E-05 | global batch size:    64 | lm loss: 2.983745E+00 | loss scale: 524288.0 | grad norm: 0.466 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 03:34:45] iteration   277200/  500000 | consumed samples:     17740800 | elapsed time per iteration (ms): 619.0 | learning rate: 1.632028E-05 | global batch size:    64 | lm loss: 2.974409E+00 | loss scale: 524288.0 | grad norm: 0.496 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 03:35:47] iteration   277300/  500000 | consumed samples:     17747200 | elapsed time per iteration (ms): 621.1 | learning rate: 1.629149E-05 | global batch size:    64 | lm loss: 2.991720E+00 | loss scale: 524288.0 | grad norm: 0.477 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 03:36:49] iteration   277400/  500000 | consumed samples:     17753600 | elapsed time per iteration (ms): 619.4 | learning rate: 1.626276E-05 | global batch size:    64 | lm loss: 2.979106E+00 | loss scale: 524288.0 | grad norm: 0.472 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 03:37:51] iteration   277500/  500000 | consumed samples:     17760000 | elapsed time per iteration (ms): 617.0 | learning rate: 1.623409E-05 | global batch size:    64 | lm loss: 2.972773E+00 | loss scale: 524288.0 | grad norm: 0.483 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 03:38:53] iteration   277600/  500000 | consumed samples:     17766400 | elapsed time per iteration (ms): 619.5 | learning rate: 1.620548E-05 | global batch size:    64 | lm loss: 2.975725E+00 | loss scale: 524288.0 | grad norm: 0.483 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 03:39:55] iteration   277700/  500000 | consumed samples:     17772800 | elapsed time per iteration (ms): 618.7 | learning rate: 1.617694E-05 | global batch size:    64 | lm loss: 2.974584E+00 | loss scale: 524288.0 | grad norm: 0.485 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 03:40:57] iteration   277800/  500000 | consumed samples:     17779200 | elapsed time per iteration (ms): 619.6 | learning rate: 1.614846E-05 | global batch size:    64 | lm loss: 2.979119E+00 | loss scale: 524288.0 | grad norm: 0.474 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 03:41:59] iteration   277900/  500000 | consumed samples:     17785600 | elapsed time per iteration (ms): 620.4 | learning rate: 1.612005E-05 | global batch size:    64 | lm loss: 2.962932E+00 | loss scale: 1048576.0 | grad norm: 0.473 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 03:43:01] iteration   278000/  500000 | consumed samples:     17792000 | elapsed time per iteration (ms): 618.8 | learning rate: 1.609169E-05 | global batch size:    64 | lm loss: 2.989485E+00 | loss scale: 1048576.0 | grad norm: 0.485 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2462.75, 2462.77)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 278000 | lm loss value: 3.726893E+00 | lm loss PPL: 4.154981E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-26 03:44:05] iteration   278100/  500000 | consumed samples:     17798400 | elapsed time per iteration (ms): 618.7 | learning rate: 1.606340E-05 | global batch size:    64 | lm loss: 2.981729E+00 | loss scale: 1048576.0 | grad norm: 0.483 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 03:45:07] iteration   278200/  500000 | consumed samples:     17804800 | elapsed time per iteration (ms): 618.8 | learning rate: 1.603517E-05 | global batch size:    64 | lm loss: 2.974371E+00 | loss scale: 1048576.0 | grad norm: 0.472 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 03:46:09] iteration   278300/  500000 | consumed samples:     17811200 | elapsed time per iteration (ms): 618.3 | learning rate: 1.600701E-05 | global batch size:    64 | lm loss: 2.980950E+00 | loss scale: 1048576.0 | grad norm: 0.468 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 03:47:10] iteration   278400/  500000 | consumed samples:     17817600 | elapsed time per iteration (ms): 617.4 | learning rate: 1.597890E-05 | global batch size:    64 | lm loss: 2.979229E+00 | loss scale: 1048576.0 | grad norm: 0.476 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 03:48:12] iteration   278500/  500000 | consumed samples:     17824000 | elapsed time per iteration (ms): 617.9 | learning rate: 1.595086E-05 | global batch size:    64 | lm loss: 2.974532E+00 | loss scale: 1048576.0 | grad norm: 0.472 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 03:49:14] iteration   278600/  500000 | consumed samples:     17830400 | elapsed time per iteration (ms): 619.4 | learning rate: 1.592289E-05 | global batch size:    64 | lm loss: 2.978646E+00 | loss scale: 1048576.0 | grad norm: 0.479 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 03:50:16] iteration   278700/  500000 | consumed samples:     17836800 | elapsed time per iteration (ms): 620.0 | learning rate: 1.589497E-05 | global batch size:    64 | lm loss: 2.973359E+00 | loss scale: 1048576.0 | grad norm: 0.473 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 03:51:18] iteration   278800/  500000 | consumed samples:     17843200 | elapsed time per iteration (ms): 619.2 | learning rate: 1.586712E-05 | global batch size:    64 | lm loss: 2.987324E+00 | loss scale: 1048576.0 | grad norm: 0.491 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 03:52:20] iteration   278900/  500000 | consumed samples:     17849600 | elapsed time per iteration (ms): 617.2 | learning rate: 1.583961E-05 | global batch size:    64 | lm loss: 2.973373E+00 | loss scale: 2097152.0 | grad norm: 0.475 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-26 03:53:22] iteration   279000/  500000 | consumed samples:     17856000 | elapsed time per iteration (ms): 619.2 | learning rate: 1.581216E-05 | global batch size:    64 | lm loss: 2.962228E+00 | loss scale: 1048576.0 | grad norm: 0.487 | number of skipped iterations:   1 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2460.65, 2460.77)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 279000 | lm loss value: 3.736516E+00 | lm loss PPL: 4.195157E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-26 03:54:26] iteration   279100/  500000 | consumed samples:     17862400 | elapsed time per iteration (ms): 618.7 | learning rate: 1.578450E-05 | global batch size:    64 | lm loss: 2.975546E+00 | loss scale: 1048576.0 | grad norm: 0.483 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 03:55:28] iteration   279200/  500000 | consumed samples:     17868800 | elapsed time per iteration (ms): 617.8 | learning rate: 1.575690E-05 | global batch size:    64 | lm loss: 2.977401E+00 | loss scale: 1048576.0 | grad norm: 0.483 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 03:56:30] iteration   279300/  500000 | consumed samples:     17875200 | elapsed time per iteration (ms): 620.6 | learning rate: 1.572936E-05 | global batch size:    64 | lm loss: 2.977894E+00 | loss scale: 1048576.0 | grad norm: 0.475 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 03:57:32] iteration   279400/  500000 | consumed samples:     17881600 | elapsed time per iteration (ms): 619.3 | learning rate: 1.570189E-05 | global batch size:    64 | lm loss: 2.967347E+00 | loss scale: 1048576.0 | grad norm: 0.479 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 03:58:34] iteration   279500/  500000 | consumed samples:     17888000 | elapsed time per iteration (ms): 620.5 | learning rate: 1.567448E-05 | global batch size:    64 | lm loss: 2.982180E+00 | loss scale: 1048576.0 | grad norm: 0.481 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 03:59:36] iteration   279600/  500000 | consumed samples:     17894400 | elapsed time per iteration (ms): 618.4 | learning rate: 1.564713E-05 | global batch size:    64 | lm loss: 2.977260E+00 | loss scale: 1048576.0 | grad norm: 0.470 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 04:00:37] iteration   279700/  500000 | consumed samples:     17900800 | elapsed time per iteration (ms): 619.0 | learning rate: 1.561985E-05 | global batch size:    64 | lm loss: 3.002625E+00 | loss scale: 1048576.0 | grad norm: 0.464 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 04:01:39] iteration   279800/  500000 | consumed samples:     17907200 | elapsed time per iteration (ms): 618.5 | learning rate: 1.559263E-05 | global batch size:    64 | lm loss: 2.983715E+00 | loss scale: 1048576.0 | grad norm: 0.481 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 04:02:41] iteration   279900/  500000 | consumed samples:     17913600 | elapsed time per iteration (ms): 618.8 | learning rate: 1.556547E-05 | global batch size:    64 | lm loss: 2.982726E+00 | loss scale: 1048576.0 | grad norm: 0.474 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 04:03:43] iteration   280000/  500000 | consumed samples:     17920000 | elapsed time per iteration (ms): 617.9 | learning rate: 1.553865E-05 | global batch size:    64 | lm loss: 2.955671E+00 | loss scale: 2097152.0 | grad norm: 0.480 | number of skipped iterations:   1 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2461.41, 2461.41)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 280000 | lm loss value: 3.716571E+00 | lm loss PPL: 4.112313E+01 | 
--------------------------------------------------------------------------------------------------
saving checkpoint at iteration  280000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-distribution in torch format
  successfully saved checkpoint at iteration  280000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-distribution
(min, max) time across ranks (ms):
    save-checkpoint ................................: (2335.49, 2335.51)
 [2024-06-26 04:04:50] iteration   280100/  500000 | consumed samples:     17926400 | elapsed time per iteration (ms): 617.3 | learning rate: 1.551162E-05 | global batch size:    64 | lm loss: 2.964483E+00 | loss scale: 2097152.0 | grad norm: 0.482 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 04:05:52] iteration   280200/  500000 | consumed samples:     17932800 | elapsed time per iteration (ms): 620.0 | learning rate: 1.548492E-05 | global batch size:    64 | lm loss: 2.976499E+00 | loss scale: 1048576.0 | grad norm: 0.483 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-26 04:06:54] iteration   280300/  500000 | consumed samples:     17939200 | elapsed time per iteration (ms): 620.1 | learning rate: 1.545802E-05 | global batch size:    64 | lm loss: 2.975328E+00 | loss scale: 1048576.0 | grad norm: 0.470 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 04:07:55] iteration   280400/  500000 | consumed samples:     17945600 | elapsed time per iteration (ms): 618.9 | learning rate: 1.543118E-05 | global batch size:    64 | lm loss: 2.980506E+00 | loss scale: 1048576.0 | grad norm: 0.472 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 04:08:57] iteration   280500/  500000 | consumed samples:     17952000 | elapsed time per iteration (ms): 618.4 | learning rate: 1.540440E-05 | global batch size:    64 | lm loss: 2.974011E+00 | loss scale: 1048576.0 | grad norm: 0.480 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 04:09:59] iteration   280600/  500000 | consumed samples:     17958400 | elapsed time per iteration (ms): 619.3 | learning rate: 1.537769E-05 | global batch size:    64 | lm loss: 2.978246E+00 | loss scale: 1048576.0 | grad norm: 0.480 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 04:11:01] iteration   280700/  500000 | consumed samples:     17964800 | elapsed time per iteration (ms): 620.0 | learning rate: 1.535104E-05 | global batch size:    64 | lm loss: 2.980179E+00 | loss scale: 1048576.0 | grad norm: 0.486 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 04:12:03] iteration   280800/  500000 | consumed samples:     17971200 | elapsed time per iteration (ms): 617.4 | learning rate: 1.532445E-05 | global batch size:    64 | lm loss: 2.980130E+00 | loss scale: 1048576.0 | grad norm: 0.491 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 04:13:05] iteration   280900/  500000 | consumed samples:     17977600 | elapsed time per iteration (ms): 618.7 | learning rate: 1.529793E-05 | global batch size:    64 | lm loss: 2.982975E+00 | loss scale: 1048576.0 | grad norm: 0.464 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 04:14:07] iteration   281000/  500000 | consumed samples:     17984000 | elapsed time per iteration (ms): 619.0 | learning rate: 1.527147E-05 | global batch size:    64 | lm loss: 2.982489E+00 | loss scale: 1048576.0 | grad norm: 0.483 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2463.09, 2463.13)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 281000 | lm loss value: 3.772088E+00 | lm loss PPL: 4.347075E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-26 04:15:11] iteration   281100/  500000 | consumed samples:     17990400 | elapsed time per iteration (ms): 620.2 | learning rate: 1.524507E-05 | global batch size:    64 | lm loss: 2.977992E+00 | loss scale: 1048576.0 | grad norm: 0.466 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 04:16:13] iteration   281200/  500000 | consumed samples:     17996800 | elapsed time per iteration (ms): 619.0 | learning rate: 1.521874E-05 | global batch size:    64 | lm loss: 2.976693E+00 | loss scale: 2097152.0 | grad norm: 0.485 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 04:17:15] iteration   281300/  500000 | consumed samples:     18003200 | elapsed time per iteration (ms): 620.4 | learning rate: 1.519299E-05 | global batch size:    64 | lm loss: 2.962645E+00 | loss scale: 1048576.0 | grad norm: 0.477 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-26 04:18:17] iteration   281400/  500000 | consumed samples:     18009600 | elapsed time per iteration (ms): 620.8 | learning rate: 1.516679E-05 | global batch size:    64 | lm loss: 2.977603E+00 | loss scale: 1048576.0 | grad norm: 0.478 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 04:19:19] iteration   281500/  500000 | consumed samples:     18016000 | elapsed time per iteration (ms): 619.8 | learning rate: 1.514065E-05 | global batch size:    64 | lm loss: 2.982441E+00 | loss scale: 1048576.0 | grad norm: 0.477 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 04:20:21] iteration   281600/  500000 | consumed samples:     18022400 | elapsed time per iteration (ms): 618.4 | learning rate: 1.511457E-05 | global batch size:    64 | lm loss: 2.970533E+00 | loss scale: 1048576.0 | grad norm: 0.476 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 04:21:23] iteration   281700/  500000 | consumed samples:     18028800 | elapsed time per iteration (ms): 618.6 | learning rate: 1.508855E-05 | global batch size:    64 | lm loss: 2.974376E+00 | loss scale: 1048576.0 | grad norm: 0.488 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 04:22:25] iteration   281800/  500000 | consumed samples:     18035200 | elapsed time per iteration (ms): 619.6 | learning rate: 1.506260E-05 | global batch size:    64 | lm loss: 2.982685E+00 | loss scale: 1048576.0 | grad norm: 0.471 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 04:23:27] iteration   281900/  500000 | consumed samples:     18041600 | elapsed time per iteration (ms): 618.1 | learning rate: 1.503671E-05 | global batch size:    64 | lm loss: 2.987479E+00 | loss scale: 1048576.0 | grad norm: 0.473 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 04:24:28] iteration   282000/  500000 | consumed samples:     18048000 | elapsed time per iteration (ms): 618.2 | learning rate: 1.501089E-05 | global batch size:    64 | lm loss: 2.983495E+00 | loss scale: 1048576.0 | grad norm: 0.475 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2462.30, 2462.33)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 282000 | lm loss value: 3.722785E+00 | lm loss PPL: 4.137947E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-26 04:25:33] iteration   282100/  500000 | consumed samples:     18054400 | elapsed time per iteration (ms): 620.6 | learning rate: 1.498513E-05 | global batch size:    64 | lm loss: 2.987382E+00 | loss scale: 1048576.0 | grad norm: 0.485 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 04:26:35] iteration   282200/  500000 | consumed samples:     18060800 | elapsed time per iteration (ms): 618.7 | learning rate: 1.495944E-05 | global batch size:    64 | lm loss: 2.982698E+00 | loss scale: 1048576.0 | grad norm: 0.485 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 04:27:37] iteration   282300/  500000 | consumed samples:     18067200 | elapsed time per iteration (ms): 619.7 | learning rate: 1.493381E-05 | global batch size:    64 | lm loss: 2.993788E+00 | loss scale: 2097152.0 | grad norm: 0.484 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 04:28:39] iteration   282400/  500000 | consumed samples:     18073600 | elapsed time per iteration (ms): 618.0 | learning rate: 1.490824E-05 | global batch size:    64 | lm loss: 2.981528E+00 | loss scale: 2097152.0 | grad norm: 0.471 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 04:29:41] iteration   282500/  500000 | consumed samples:     18080000 | elapsed time per iteration (ms): 618.5 | learning rate: 1.488273E-05 | global batch size:    64 | lm loss: 2.964686E+00 | loss scale: 2097152.0 | grad norm: 0.477 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 04:30:42] iteration   282600/  500000 | consumed samples:     18086400 | elapsed time per iteration (ms): 618.5 | learning rate: 1.485755E-05 | global batch size:    64 | lm loss: 2.990633E+00 | loss scale: 2097152.0 | grad norm: 0.479 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-26 04:31:44] iteration   282700/  500000 | consumed samples:     18092800 | elapsed time per iteration (ms): 619.5 | learning rate: 1.483243E-05 | global batch size:    64 | lm loss: 2.970856E+00 | loss scale: 1048576.0 | grad norm: 0.482 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-26 04:32:46] iteration   282800/  500000 | consumed samples:     18099200 | elapsed time per iteration (ms): 618.3 | learning rate: 1.480711E-05 | global batch size:    64 | lm loss: 2.988083E+00 | loss scale: 1048576.0 | grad norm: 0.488 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 04:33:48] iteration   282900/  500000 | consumed samples:     18105600 | elapsed time per iteration (ms): 619.4 | learning rate: 1.478187E-05 | global batch size:    64 | lm loss: 2.978733E+00 | loss scale: 1048576.0 | grad norm: 0.477 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 04:34:50] iteration   283000/  500000 | consumed samples:     18112000 | elapsed time per iteration (ms): 618.6 | learning rate: 1.475668E-05 | global batch size:    64 | lm loss: 2.984178E+00 | loss scale: 1048576.0 | grad norm: 0.453 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2464.01, 2464.03)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 283000 | lm loss value: 3.683936E+00 | lm loss PPL: 3.980274E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-26 04:35:54] iteration   283100/  500000 | consumed samples:     18118400 | elapsed time per iteration (ms): 618.4 | learning rate: 1.473156E-05 | global batch size:    64 | lm loss: 2.983741E+00 | loss scale: 1048576.0 | grad norm: 0.474 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 04:36:56] iteration   283200/  500000 | consumed samples:     18124800 | elapsed time per iteration (ms): 619.6 | learning rate: 1.470651E-05 | global batch size:    64 | lm loss: 2.980136E+00 | loss scale: 1048576.0 | grad norm: 0.467 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 04:37:58] iteration   283300/  500000 | consumed samples:     18131200 | elapsed time per iteration (ms): 619.2 | learning rate: 1.468151E-05 | global batch size:    64 | lm loss: 2.958396E+00 | loss scale: 1048576.0 | grad norm: 0.479 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 04:39:00] iteration   283400/  500000 | consumed samples:     18137600 | elapsed time per iteration (ms): 619.3 | learning rate: 1.465659E-05 | global batch size:    64 | lm loss: 2.979689E+00 | loss scale: 1048576.0 | grad norm: 0.474 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 04:40:02] iteration   283500/  500000 | consumed samples:     18144000 | elapsed time per iteration (ms): 617.4 | learning rate: 1.463172E-05 | global batch size:    64 | lm loss: 2.978934E+00 | loss scale: 1048576.0 | grad norm: 0.477 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 04:41:04] iteration   283600/  500000 | consumed samples:     18150400 | elapsed time per iteration (ms): 618.1 | learning rate: 1.460693E-05 | global batch size:    64 | lm loss: 2.971748E+00 | loss scale: 1048576.0 | grad norm: 0.477 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 04:42:05] iteration   283700/  500000 | consumed samples:     18156800 | elapsed time per iteration (ms): 617.3 | learning rate: 1.458268E-05 | global batch size:    64 | lm loss: 2.969830E+00 | loss scale: 1048576.0 | grad norm: 0.480 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-26 04:43:07] iteration   283800/  500000 | consumed samples:     18163200 | elapsed time per iteration (ms): 619.4 | learning rate: 1.455801E-05 | global batch size:    64 | lm loss: 2.982202E+00 | loss scale: 1048576.0 | grad norm: 0.471 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 04:44:09] iteration   283900/  500000 | consumed samples:     18169600 | elapsed time per iteration (ms): 618.2 | learning rate: 1.453341E-05 | global batch size:    64 | lm loss: 2.985157E+00 | loss scale: 1048576.0 | grad norm: 0.484 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 04:45:11] iteration   284000/  500000 | consumed samples:     18176000 | elapsed time per iteration (ms): 619.0 | learning rate: 1.450886E-05 | global batch size:    64 | lm loss: 2.985154E+00 | loss scale: 1048576.0 | grad norm: 0.481 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2467.30, 2467.45)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 284000 | lm loss value: 3.724485E+00 | lm loss PPL: 4.144989E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-26 04:46:15] iteration   284100/  500000 | consumed samples:     18182400 | elapsed time per iteration (ms): 617.7 | learning rate: 1.448438E-05 | global batch size:    64 | lm loss: 2.984680E+00 | loss scale: 1048576.0 | grad norm: 0.480 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 04:47:17] iteration   284200/  500000 | consumed samples:     18188800 | elapsed time per iteration (ms): 619.2 | learning rate: 1.445997E-05 | global batch size:    64 | lm loss: 2.983706E+00 | loss scale: 1048576.0 | grad norm: 0.491 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 04:48:19] iteration   284300/  500000 | consumed samples:     18195200 | elapsed time per iteration (ms): 619.9 | learning rate: 1.443562E-05 | global batch size:    64 | lm loss: 2.979053E+00 | loss scale: 1048576.0 | grad norm: 0.482 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 04:49:21] iteration   284400/  500000 | consumed samples:     18201600 | elapsed time per iteration (ms): 619.1 | learning rate: 1.441134E-05 | global batch size:    64 | lm loss: 2.990713E+00 | loss scale: 1048576.0 | grad norm: 0.501 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 04:50:23] iteration   284500/  500000 | consumed samples:     18208000 | elapsed time per iteration (ms): 617.6 | learning rate: 1.438712E-05 | global batch size:    64 | lm loss: 2.967582E+00 | loss scale: 1048576.0 | grad norm: 0.481 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 04:51:25] iteration   284600/  500000 | consumed samples:     18214400 | elapsed time per iteration (ms): 618.8 | learning rate: 1.436296E-05 | global batch size:    64 | lm loss: 2.972794E+00 | loss scale: 1048576.0 | grad norm: 0.477 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 04:52:27] iteration   284700/  500000 | consumed samples:     18220800 | elapsed time per iteration (ms): 619.7 | learning rate: 1.433887E-05 | global batch size:    64 | lm loss: 2.976365E+00 | loss scale: 2097152.0 | grad norm: 0.473 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 04:53:29] iteration   284800/  500000 | consumed samples:     18227200 | elapsed time per iteration (ms): 618.5 | learning rate: 1.431532E-05 | global batch size:    64 | lm loss: 2.969682E+00 | loss scale: 1048576.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-26 04:54:30] iteration   284900/  500000 | consumed samples:     18233600 | elapsed time per iteration (ms): 618.4 | learning rate: 1.429136E-05 | global batch size:    64 | lm loss: 2.976471E+00 | loss scale: 1048576.0 | grad norm: 0.486 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 04:55:32] iteration   285000/  500000 | consumed samples:     18240000 | elapsed time per iteration (ms): 618.8 | learning rate: 1.426746E-05 | global batch size:    64 | lm loss: 2.981371E+00 | loss scale: 1048576.0 | grad norm: 0.465 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2461.36, 2461.42)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 285000 | lm loss value: 3.740626E+00 | lm loss PPL: 4.212436E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-26 04:56:37] iteration   285100/  500000 | consumed samples:     18246400 | elapsed time per iteration (ms): 619.5 | learning rate: 1.424362E-05 | global batch size:    64 | lm loss: 2.982332E+00 | loss scale: 1048576.0 | grad norm: 0.477 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 04:57:38] iteration   285200/  500000 | consumed samples:     18252800 | elapsed time per iteration (ms): 618.6 | learning rate: 1.421985E-05 | global batch size:    64 | lm loss: 2.972687E+00 | loss scale: 1048576.0 | grad norm: 0.485 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 04:58:40] iteration   285300/  500000 | consumed samples:     18259200 | elapsed time per iteration (ms): 618.3 | learning rate: 1.419615E-05 | global batch size:    64 | lm loss: 2.961003E+00 | loss scale: 1048576.0 | grad norm: 0.486 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 04:59:42] iteration   285400/  500000 | consumed samples:     18265600 | elapsed time per iteration (ms): 620.4 | learning rate: 1.417251E-05 | global batch size:    64 | lm loss: 2.977385E+00 | loss scale: 1048576.0 | grad norm: 0.478 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 05:00:44] iteration   285500/  500000 | consumed samples:     18272000 | elapsed time per iteration (ms): 617.4 | learning rate: 1.414893E-05 | global batch size:    64 | lm loss: 2.975434E+00 | loss scale: 1048576.0 | grad norm: 0.473 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 05:01:46] iteration   285600/  500000 | consumed samples:     18278400 | elapsed time per iteration (ms): 620.3 | learning rate: 1.412542E-05 | global batch size:    64 | lm loss: 2.977138E+00 | loss scale: 1048576.0 | grad norm: 0.478 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 05:02:48] iteration   285700/  500000 | consumed samples:     18284800 | elapsed time per iteration (ms): 618.4 | learning rate: 1.410198E-05 | global batch size:    64 | lm loss: 2.985333E+00 | loss scale: 1048576.0 | grad norm: 0.471 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 05:03:50] iteration   285800/  500000 | consumed samples:     18291200 | elapsed time per iteration (ms): 618.8 | learning rate: 1.407860E-05 | global batch size:    64 | lm loss: 2.984511E+00 | loss scale: 2097152.0 | grad norm: 0.477 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 05:04:52] iteration   285900/  500000 | consumed samples:     18297600 | elapsed time per iteration (ms): 618.9 | learning rate: 1.405528E-05 | global batch size:    64 | lm loss: 3.000295E+00 | loss scale: 2097152.0 | grad norm: 0.471 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 05:05:54] iteration   286000/  500000 | consumed samples:     18304000 | elapsed time per iteration (ms): 620.7 | learning rate: 1.403203E-05 | global batch size:    64 | lm loss: 2.978795E+00 | loss scale: 2097152.0 | grad norm: 0.475 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2463.61, 2465.42)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 286000 | lm loss value: 3.733701E+00 | lm loss PPL: 4.183363E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-26 05:06:58] iteration   286100/  500000 | consumed samples:     18310400 | elapsed time per iteration (ms): 617.1 | learning rate: 1.400884E-05 | global batch size:    64 | lm loss: 2.983607E+00 | loss scale: 2097152.0 | grad norm: 0.489 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 05:08:00] iteration   286200/  500000 | consumed samples:     18316800 | elapsed time per iteration (ms): 617.2 | learning rate: 1.398618E-05 | global batch size:    64 | lm loss: 2.963223E+00 | loss scale: 1048576.0 | grad norm: 0.474 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-26 05:09:02] iteration   286300/  500000 | consumed samples:     18323200 | elapsed time per iteration (ms): 619.0 | learning rate: 1.396312E-05 | global batch size:    64 | lm loss: 2.982870E+00 | loss scale: 1048576.0 | grad norm: 0.480 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 05:10:03] iteration   286400/  500000 | consumed samples:     18329600 | elapsed time per iteration (ms): 617.8 | learning rate: 1.394013E-05 | global batch size:    64 | lm loss: 2.976797E+00 | loss scale: 1048576.0 | grad norm: 0.478 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 05:11:05] iteration   286500/  500000 | consumed samples:     18336000 | elapsed time per iteration (ms): 618.5 | learning rate: 1.391720E-05 | global batch size:    64 | lm loss: 2.988557E+00 | loss scale: 1048576.0 | grad norm: 0.489 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 05:12:07] iteration   286600/  500000 | consumed samples:     18342400 | elapsed time per iteration (ms): 618.8 | learning rate: 1.389434E-05 | global batch size:    64 | lm loss: 2.970915E+00 | loss scale: 1048576.0 | grad norm: 0.479 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 05:13:09] iteration   286700/  500000 | consumed samples:     18348800 | elapsed time per iteration (ms): 619.7 | learning rate: 1.387154E-05 | global batch size:    64 | lm loss: 2.965435E+00 | loss scale: 1048576.0 | grad norm: 0.470 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 05:14:11] iteration   286800/  500000 | consumed samples:     18355200 | elapsed time per iteration (ms): 619.6 | learning rate: 1.384881E-05 | global batch size:    64 | lm loss: 2.964688E+00 | loss scale: 1048576.0 | grad norm: 0.487 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 05:15:13] iteration   286900/  500000 | consumed samples:     18361600 | elapsed time per iteration (ms): 619.6 | learning rate: 1.382614E-05 | global batch size:    64 | lm loss: 2.971218E+00 | loss scale: 1048576.0 | grad norm: 0.483 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 05:16:15] iteration   287000/  500000 | consumed samples:     18368000 | elapsed time per iteration (ms): 618.1 | learning rate: 1.380354E-05 | global batch size:    64 | lm loss: 2.978973E+00 | loss scale: 1048576.0 | grad norm: 0.498 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2462.36, 2462.39)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 287000 | lm loss value: 3.678840E+00 | lm loss PPL: 3.960043E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-26 05:17:19] iteration   287100/  500000 | consumed samples:     18374400 | elapsed time per iteration (ms): 618.9 | learning rate: 1.378100E-05 | global batch size:    64 | lm loss: 2.971509E+00 | loss scale: 1048576.0 | grad norm: 0.478 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 05:18:21] iteration   287200/  500000 | consumed samples:     18380800 | elapsed time per iteration (ms): 619.2 | learning rate: 1.375853E-05 | global batch size:    64 | lm loss: 2.979068E+00 | loss scale: 2097152.0 | grad norm: 0.478 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 05:19:23] iteration   287300/  500000 | consumed samples:     18387200 | elapsed time per iteration (ms): 620.2 | learning rate: 1.373657E-05 | global batch size:    64 | lm loss: 2.978348E+00 | loss scale: 1048576.0 | grad norm: 0.483 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-26 05:20:25] iteration   287400/  500000 | consumed samples:     18393600 | elapsed time per iteration (ms): 616.8 | learning rate: 1.371422E-05 | global batch size:    64 | lm loss: 2.970225E+00 | loss scale: 1048576.0 | grad norm: 0.476 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 05:21:27] iteration   287500/  500000 | consumed samples:     18400000 | elapsed time per iteration (ms): 617.7 | learning rate: 1.369194E-05 | global batch size:    64 | lm loss: 2.981356E+00 | loss scale: 1048576.0 | grad norm: 0.475 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 05:22:29] iteration   287600/  500000 | consumed samples:     18406400 | elapsed time per iteration (ms): 619.5 | learning rate: 1.366973E-05 | global batch size:    64 | lm loss: 2.958979E+00 | loss scale: 1048576.0 | grad norm: 0.487 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 05:23:30] iteration   287700/  500000 | consumed samples:     18412800 | elapsed time per iteration (ms): 619.7 | learning rate: 1.364758E-05 | global batch size:    64 | lm loss: 2.981729E+00 | loss scale: 1048576.0 | grad norm: 0.471 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 05:24:32] iteration   287800/  500000 | consumed samples:     18419200 | elapsed time per iteration (ms): 619.7 | learning rate: 1.362550E-05 | global batch size:    64 | lm loss: 2.973597E+00 | loss scale: 1048576.0 | grad norm: 0.478 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 05:25:34] iteration   287900/  500000 | consumed samples:     18425600 | elapsed time per iteration (ms): 619.4 | learning rate: 1.360348E-05 | global batch size:    64 | lm loss: 2.976746E+00 | loss scale: 1048576.0 | grad norm: 0.483 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 05:26:36] iteration   288000/  500000 | consumed samples:     18432000 | elapsed time per iteration (ms): 619.1 | learning rate: 1.358153E-05 | global batch size:    64 | lm loss: 2.951083E+00 | loss scale: 1048576.0 | grad norm: 0.487 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2460.78, 2460.84)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 288000 | lm loss value: 3.704978E+00 | lm loss PPL: 4.064913E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-26 05:27:41] iteration   288100/  500000 | consumed samples:     18438400 | elapsed time per iteration (ms): 618.8 | learning rate: 1.355964E-05 | global batch size:    64 | lm loss: 2.972483E+00 | loss scale: 1048576.0 | grad norm: 0.464 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 05:28:43] iteration   288200/  500000 | consumed samples:     18444800 | elapsed time per iteration (ms): 620.7 | learning rate: 1.353782E-05 | global batch size:    64 | lm loss: 2.976127E+00 | loss scale: 1048576.0 | grad norm: 0.470 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 05:29:45] iteration   288300/  500000 | consumed samples:     18451200 | elapsed time per iteration (ms): 620.4 | learning rate: 1.351650E-05 | global batch size:    64 | lm loss: 2.969519E+00 | loss scale: 1048576.0 | grad norm: 0.487 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-26 05:30:47] iteration   288400/  500000 | consumed samples:     18457600 | elapsed time per iteration (ms): 620.7 | learning rate: 1.349481E-05 | global batch size:    64 | lm loss: 2.967411E+00 | loss scale: 1048576.0 | grad norm: 0.480 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 05:31:49] iteration   288500/  500000 | consumed samples:     18464000 | elapsed time per iteration (ms): 619.4 | learning rate: 1.347318E-05 | global batch size:    64 | lm loss: 2.952291E+00 | loss scale: 1048576.0 | grad norm: 0.492 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 05:32:51] iteration   288600/  500000 | consumed samples:     18470400 | elapsed time per iteration (ms): 620.2 | learning rate: 1.345162E-05 | global batch size:    64 | lm loss: 2.993773E+00 | loss scale: 1048576.0 | grad norm: 0.487 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 05:33:53] iteration   288700/  500000 | consumed samples:     18476800 | elapsed time per iteration (ms): 621.6 | learning rate: 1.343012E-05 | global batch size:    64 | lm loss: 2.987678E+00 | loss scale: 1048576.0 | grad norm: 0.475 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 05:34:55] iteration   288800/  500000 | consumed samples:     18483200 | elapsed time per iteration (ms): 617.4 | learning rate: 1.340869E-05 | global batch size:    64 | lm loss: 2.975214E+00 | loss scale: 1048576.0 | grad norm: 0.479 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 05:35:56] iteration   288900/  500000 | consumed samples:     18489600 | elapsed time per iteration (ms): 617.6 | learning rate: 1.338733E-05 | global batch size:    64 | lm loss: 2.975908E+00 | loss scale: 1048576.0 | grad norm: 0.481 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 05:36:58] iteration   289000/  500000 | consumed samples:     18496000 | elapsed time per iteration (ms): 618.8 | learning rate: 1.336624E-05 | global batch size:    64 | lm loss: 2.966232E+00 | loss scale: 524288.0 | grad norm: 0.472 | number of skipped iterations:   1 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2465.17, 2465.19)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 289000 | lm loss value: 3.752911E+00 | lm loss PPL: 4.264505E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-26 05:38:02] iteration   289100/  500000 | consumed samples:     18502400 | elapsed time per iteration (ms): 617.2 | learning rate: 1.334500E-05 | global batch size:    64 | lm loss: 2.969189E+00 | loss scale: 524288.0 | grad norm: 0.473 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 05:39:05] iteration   289200/  500000 | consumed samples:     18508800 | elapsed time per iteration (ms): 620.4 | learning rate: 1.332383E-05 | global batch size:    64 | lm loss: 2.979677E+00 | loss scale: 524288.0 | grad norm: 0.477 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 05:40:06] iteration   289300/  500000 | consumed samples:     18515200 | elapsed time per iteration (ms): 618.8 | learning rate: 1.330273E-05 | global batch size:    64 | lm loss: 2.975224E+00 | loss scale: 524288.0 | grad norm: 0.477 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 05:41:08] iteration   289400/  500000 | consumed samples:     18521600 | elapsed time per iteration (ms): 618.2 | learning rate: 1.328169E-05 | global batch size:    64 | lm loss: 2.968994E+00 | loss scale: 524288.0 | grad norm: 0.478 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 05:42:10] iteration   289500/  500000 | consumed samples:     18528000 | elapsed time per iteration (ms): 619.6 | learning rate: 1.326072E-05 | global batch size:    64 | lm loss: 2.979949E+00 | loss scale: 524288.0 | grad norm: 0.479 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 05:43:12] iteration   289600/  500000 | consumed samples:     18534400 | elapsed time per iteration (ms): 619.9 | learning rate: 1.323981E-05 | global batch size:    64 | lm loss: 2.966998E+00 | loss scale: 524288.0 | grad norm: 0.487 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 05:44:14] iteration   289700/  500000 | consumed samples:     18540800 | elapsed time per iteration (ms): 618.3 | learning rate: 1.321897E-05 | global batch size:    64 | lm loss: 2.954702E+00 | loss scale: 524288.0 | grad norm: 0.485 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 05:45:16] iteration   289800/  500000 | consumed samples:     18547200 | elapsed time per iteration (ms): 619.4 | learning rate: 1.319820E-05 | global batch size:    64 | lm loss: 2.963971E+00 | loss scale: 524288.0 | grad norm: 0.502 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 05:46:18] iteration   289900/  500000 | consumed samples:     18553600 | elapsed time per iteration (ms): 620.3 | learning rate: 1.317749E-05 | global batch size:    64 | lm loss: 2.958714E+00 | loss scale: 524288.0 | grad norm: 0.484 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 05:47:20] iteration   290000/  500000 | consumed samples:     18560000 | elapsed time per iteration (ms): 619.1 | learning rate: 1.315684E-05 | global batch size:    64 | lm loss: 2.966105E+00 | loss scale: 1048576.0 | grad norm: 0.480 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2460.72, 2460.81)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 290000 | lm loss value: 3.733773E+00 | lm loss PPL: 4.183665E+01 | 
--------------------------------------------------------------------------------------------------
saving checkpoint at iteration  290000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-distribution in torch format
  successfully saved checkpoint at iteration  290000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-distribution
(min, max) time across ranks (ms):
    save-checkpoint ................................: (2331.83, 2331.84)
 [2024-06-26 05:48:27] iteration   290100/  500000 | consumed samples:     18566400 | elapsed time per iteration (ms): 619.2 | learning rate: 1.313626E-05 | global batch size:    64 | lm loss: 2.971541E+00 | loss scale: 1048576.0 | grad norm: 0.485 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 05:49:29] iteration   290200/  500000 | consumed samples:     18572800 | elapsed time per iteration (ms): 620.4 | learning rate: 1.311575E-05 | global batch size:    64 | lm loss: 2.968604E+00 | loss scale: 1048576.0 | grad norm: 0.481 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 05:50:31] iteration   290300/  500000 | consumed samples:     18579200 | elapsed time per iteration (ms): 622.3 | learning rate: 1.309531E-05 | global batch size:    64 | lm loss: 2.972419E+00 | loss scale: 1048576.0 | grad norm: 0.481 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 05:51:33] iteration   290400/  500000 | consumed samples:     18585600 | elapsed time per iteration (ms): 619.5 | learning rate: 1.307492E-05 | global batch size:    64 | lm loss: 2.972351E+00 | loss scale: 1048576.0 | grad norm: 0.467 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 05:52:35] iteration   290500/  500000 | consumed samples:     18592000 | elapsed time per iteration (ms): 618.3 | learning rate: 1.305461E-05 | global batch size:    64 | lm loss: 2.967194E+00 | loss scale: 1048576.0 | grad norm: 0.476 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 05:53:37] iteration   290600/  500000 | consumed samples:     18598400 | elapsed time per iteration (ms): 619.1 | learning rate: 1.303436E-05 | global batch size:    64 | lm loss: 2.971461E+00 | loss scale: 1048576.0 | grad norm: 0.487 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 05:54:38] iteration   290700/  500000 | consumed samples:     18604800 | elapsed time per iteration (ms): 618.2 | learning rate: 1.301418E-05 | global batch size:    64 | lm loss: 2.953397E+00 | loss scale: 1048576.0 | grad norm: 0.490 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 05:55:40] iteration   290800/  500000 | consumed samples:     18611200 | elapsed time per iteration (ms): 619.9 | learning rate: 1.299406E-05 | global batch size:    64 | lm loss: 2.963349E+00 | loss scale: 1048576.0 | grad norm: 0.480 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 05:56:42] iteration   290900/  500000 | consumed samples:     18617600 | elapsed time per iteration (ms): 619.7 | learning rate: 1.297401E-05 | global batch size:    64 | lm loss: 2.980175E+00 | loss scale: 1048576.0 | grad norm: 0.481 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 05:57:44] iteration   291000/  500000 | consumed samples:     18624000 | elapsed time per iteration (ms): 617.0 | learning rate: 1.295422E-05 | global batch size:    64 | lm loss: 2.973641E+00 | loss scale: 2097152.0 | grad norm: 0.476 | number of skipped iterations:   1 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2461.47, 2461.48)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 291000 | lm loss value: 3.722687E+00 | lm loss PPL: 4.137541E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-26 05:58:48] iteration   291100/  500000 | consumed samples:     18630400 | elapsed time per iteration (ms): 617.8 | learning rate: 1.293450E-05 | global batch size:    64 | lm loss: 2.966230E+00 | loss scale: 1048576.0 | grad norm: 0.489 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-26 05:59:50] iteration   291200/  500000 | consumed samples:     18636800 | elapsed time per iteration (ms): 620.2 | learning rate: 1.291464E-05 | global batch size:    64 | lm loss: 2.972403E+00 | loss scale: 1048576.0 | grad norm: 0.473 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 06:00:52] iteration   291300/  500000 | consumed samples:     18643200 | elapsed time per iteration (ms): 619.5 | learning rate: 1.289485E-05 | global batch size:    64 | lm loss: 2.952657E+00 | loss scale: 1048576.0 | grad norm: 0.483 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 06:01:54] iteration   291400/  500000 | consumed samples:     18649600 | elapsed time per iteration (ms): 618.0 | learning rate: 1.287513E-05 | global batch size:    64 | lm loss: 2.978743E+00 | loss scale: 1048576.0 | grad norm: 0.475 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 06:02:56] iteration   291500/  500000 | consumed samples:     18656000 | elapsed time per iteration (ms): 617.9 | learning rate: 1.285547E-05 | global batch size:    64 | lm loss: 2.972178E+00 | loss scale: 1048576.0 | grad norm: 0.481 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 06:03:58] iteration   291600/  500000 | consumed samples:     18662400 | elapsed time per iteration (ms): 618.6 | learning rate: 1.283588E-05 | global batch size:    64 | lm loss: 2.987514E+00 | loss scale: 1048576.0 | grad norm: 0.487 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 06:05:00] iteration   291700/  500000 | consumed samples:     18668800 | elapsed time per iteration (ms): 618.7 | learning rate: 1.281636E-05 | global batch size:    64 | lm loss: 2.976728E+00 | loss scale: 1048576.0 | grad norm: 0.488 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 06:06:02] iteration   291800/  500000 | consumed samples:     18675200 | elapsed time per iteration (ms): 620.5 | learning rate: 1.279690E-05 | global batch size:    64 | lm loss: 2.987423E+00 | loss scale: 1048576.0 | grad norm: 0.466 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 06:07:04] iteration   291900/  500000 | consumed samples:     18681600 | elapsed time per iteration (ms): 619.7 | learning rate: 1.277751E-05 | global batch size:    64 | lm loss: 2.976574E+00 | loss scale: 1048576.0 | grad norm: 0.486 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 06:08:05] iteration   292000/  500000 | consumed samples:     18688000 | elapsed time per iteration (ms): 618.6 | learning rate: 1.275818E-05 | global batch size:    64 | lm loss: 2.958179E+00 | loss scale: 1048576.0 | grad norm: 0.467 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2461.81, 2461.83)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 292000 | lm loss value: 3.734233E+00 | lm loss PPL: 4.185590E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-26 06:09:10] iteration   292100/  500000 | consumed samples:     18694400 | elapsed time per iteration (ms): 620.5 | learning rate: 1.273930E-05 | global batch size:    64 | lm loss: 2.984305E+00 | loss scale: 1048576.0 | grad norm: 0.469 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-26 06:10:12] iteration   292200/  500000 | consumed samples:     18700800 | elapsed time per iteration (ms): 618.9 | learning rate: 1.272011E-05 | global batch size:    64 | lm loss: 2.966134E+00 | loss scale: 1048576.0 | grad norm: 0.471 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 06:11:14] iteration   292300/  500000 | consumed samples:     18707200 | elapsed time per iteration (ms): 619.9 | learning rate: 1.270098E-05 | global batch size:    64 | lm loss: 2.971357E+00 | loss scale: 1048576.0 | grad norm: 0.480 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 06:12:16] iteration   292400/  500000 | consumed samples:     18713600 | elapsed time per iteration (ms): 620.2 | learning rate: 1.268191E-05 | global batch size:    64 | lm loss: 2.978982E+00 | loss scale: 1048576.0 | grad norm: 0.476 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 06:13:18] iteration   292500/  500000 | consumed samples:     18720000 | elapsed time per iteration (ms): 618.5 | learning rate: 1.266292E-05 | global batch size:    64 | lm loss: 2.979705E+00 | loss scale: 1048576.0 | grad norm: 0.490 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 06:14:20] iteration   292600/  500000 | consumed samples:     18726400 | elapsed time per iteration (ms): 620.6 | learning rate: 1.264398E-05 | global batch size:    64 | lm loss: 2.982282E+00 | loss scale: 1048576.0 | grad norm: 0.479 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 06:15:22] iteration   292700/  500000 | consumed samples:     18732800 | elapsed time per iteration (ms): 619.6 | learning rate: 1.262512E-05 | global batch size:    64 | lm loss: 2.987957E+00 | loss scale: 1048576.0 | grad norm: 0.480 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 06:16:24] iteration   292800/  500000 | consumed samples:     18739200 | elapsed time per iteration (ms): 621.7 | learning rate: 1.260632E-05 | global batch size:    64 | lm loss: 2.967163E+00 | loss scale: 1048576.0 | grad norm: 0.468 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 06:17:26] iteration   292900/  500000 | consumed samples:     18745600 | elapsed time per iteration (ms): 618.6 | learning rate: 1.258759E-05 | global batch size:    64 | lm loss: 2.970235E+00 | loss scale: 1048576.0 | grad norm: 0.480 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 06:18:28] iteration   293000/  500000 | consumed samples:     18752000 | elapsed time per iteration (ms): 619.8 | learning rate: 1.256892E-05 | global batch size:    64 | lm loss: 2.973402E+00 | loss scale: 1048576.0 | grad norm: 0.477 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2463.54, 2463.63)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 293000 | lm loss value: 3.684371E+00 | lm loss PPL: 3.982006E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-26 06:19:32] iteration   293100/  500000 | consumed samples:     18758400 | elapsed time per iteration (ms): 619.9 | learning rate: 1.255051E-05 | global batch size:    64 | lm loss: 2.973643E+00 | loss scale: 2097152.0 | grad norm: 0.473 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-26 06:20:34] iteration   293200/  500000 | consumed samples:     18764800 | elapsed time per iteration (ms): 617.9 | learning rate: 1.253216E-05 | global batch size:    64 | lm loss: 2.965044E+00 | loss scale: 1048576.0 | grad norm: 0.470 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-26 06:21:36] iteration   293300/  500000 | consumed samples:     18771200 | elapsed time per iteration (ms): 620.8 | learning rate: 1.251369E-05 | global batch size:    64 | lm loss: 2.999301E+00 | loss scale: 1048576.0 | grad norm: 0.481 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 06:22:38] iteration   293400/  500000 | consumed samples:     18777600 | elapsed time per iteration (ms): 618.9 | learning rate: 1.249529E-05 | global batch size:    64 | lm loss: 2.983425E+00 | loss scale: 1048576.0 | grad norm: 0.463 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 06:23:40] iteration   293500/  500000 | consumed samples:     18784000 | elapsed time per iteration (ms): 620.5 | learning rate: 1.247695E-05 | global batch size:    64 | lm loss: 2.979222E+00 | loss scale: 1048576.0 | grad norm: 0.482 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 06:24:42] iteration   293600/  500000 | consumed samples:     18790400 | elapsed time per iteration (ms): 618.9 | learning rate: 1.245868E-05 | global batch size:    64 | lm loss: 2.954290E+00 | loss scale: 1048576.0 | grad norm: 0.478 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 06:25:44] iteration   293700/  500000 | consumed samples:     18796800 | elapsed time per iteration (ms): 618.6 | learning rate: 1.244048E-05 | global batch size:    64 | lm loss: 2.962434E+00 | loss scale: 1048576.0 | grad norm: 0.478 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 06:26:46] iteration   293800/  500000 | consumed samples:     18803200 | elapsed time per iteration (ms): 619.7 | learning rate: 1.242234E-05 | global batch size:    64 | lm loss: 2.978049E+00 | loss scale: 1048576.0 | grad norm: 0.487 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 06:27:48] iteration   293900/  500000 | consumed samples:     18809600 | elapsed time per iteration (ms): 619.5 | learning rate: 1.240427E-05 | global batch size:    64 | lm loss: 2.972700E+00 | loss scale: 1048576.0 | grad norm: 0.488 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 06:28:50] iteration   294000/  500000 | consumed samples:     18816000 | elapsed time per iteration (ms): 619.8 | learning rate: 1.238627E-05 | global batch size:    64 | lm loss: 2.973049E+00 | loss scale: 1048576.0 | grad norm: 0.479 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2466.43, 2466.57)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 294000 | lm loss value: 3.753494E+00 | lm loss PPL: 4.266992E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-26 06:29:54] iteration   294100/  500000 | consumed samples:     18822400 | elapsed time per iteration (ms): 619.5 | learning rate: 1.236833E-05 | global batch size:    64 | lm loss: 2.968229E+00 | loss scale: 1048576.0 | grad norm: 0.508 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 06:30:56] iteration   294200/  500000 | consumed samples:     18828800 | elapsed time per iteration (ms): 618.9 | learning rate: 1.235082E-05 | global batch size:    64 | lm loss: 2.973789E+00 | loss scale: 1048576.0 | grad norm: 0.486 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-26 06:31:58] iteration   294300/  500000 | consumed samples:     18835200 | elapsed time per iteration (ms): 618.5 | learning rate: 1.233301E-05 | global batch size:    64 | lm loss: 2.984287E+00 | loss scale: 1048576.0 | grad norm: 0.487 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 06:33:00] iteration   294400/  500000 | consumed samples:     18841600 | elapsed time per iteration (ms): 619.3 | learning rate: 1.231528E-05 | global batch size:    64 | lm loss: 2.979058E+00 | loss scale: 1048576.0 | grad norm: 0.487 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 06:34:01] iteration   294500/  500000 | consumed samples:     18848000 | elapsed time per iteration (ms): 617.1 | learning rate: 1.229760E-05 | global batch size:    64 | lm loss: 2.969948E+00 | loss scale: 1048576.0 | grad norm: 0.490 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 06:35:03] iteration   294600/  500000 | consumed samples:     18854400 | elapsed time per iteration (ms): 617.6 | learning rate: 1.228000E-05 | global batch size:    64 | lm loss: 2.983439E+00 | loss scale: 1048576.0 | grad norm: 0.482 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 06:36:05] iteration   294700/  500000 | consumed samples:     18860800 | elapsed time per iteration (ms): 618.2 | learning rate: 1.226246E-05 | global batch size:    64 | lm loss: 2.960351E+00 | loss scale: 1048576.0 | grad norm: 0.470 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 06:37:07] iteration   294800/  500000 | consumed samples:     18867200 | elapsed time per iteration (ms): 619.6 | learning rate: 1.224499E-05 | global batch size:    64 | lm loss: 2.963608E+00 | loss scale: 1048576.0 | grad norm: 0.497 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 06:38:09] iteration   294900/  500000 | consumed samples:     18873600 | elapsed time per iteration (ms): 619.3 | learning rate: 1.222758E-05 | global batch size:    64 | lm loss: 2.964458E+00 | loss scale: 1048576.0 | grad norm: 0.477 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 06:39:11] iteration   295000/  500000 | consumed samples:     18880000 | elapsed time per iteration (ms): 619.8 | learning rate: 1.221024E-05 | global batch size:    64 | lm loss: 2.957996E+00 | loss scale: 1048576.0 | grad norm: 0.477 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2462.97, 2462.98)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 295000 | lm loss value: 3.702489E+00 | lm loss PPL: 4.054809E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-26 06:40:15] iteration   295100/  500000 | consumed samples:     18886400 | elapsed time per iteration (ms): 619.1 | learning rate: 1.219297E-05 | global batch size:    64 | lm loss: 2.981332E+00 | loss scale: 1048576.0 | grad norm: 0.474 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 06:41:17] iteration   295200/  500000 | consumed samples:     18892800 | elapsed time per iteration (ms): 619.1 | learning rate: 1.217576E-05 | global batch size:    64 | lm loss: 2.967340E+00 | loss scale: 2097152.0 | grad norm: 0.501 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 06:42:19] iteration   295300/  500000 | consumed samples:     18899200 | elapsed time per iteration (ms): 620.4 | learning rate: 1.215862E-05 | global batch size:    64 | lm loss: 2.978428E+00 | loss scale: 2097152.0 | grad norm: 0.466 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 06:43:21] iteration   295400/  500000 | consumed samples:     18905600 | elapsed time per iteration (ms): 618.9 | learning rate: 1.214172E-05 | global batch size:    64 | lm loss: 2.973873E+00 | loss scale: 2097152.0 | grad norm: 0.477 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-26 06:44:23] iteration   295500/  500000 | consumed samples:     18912000 | elapsed time per iteration (ms): 620.6 | learning rate: 1.212488E-05 | global batch size:    64 | lm loss: 2.977387E+00 | loss scale: 1048576.0 | grad norm: 0.481 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-26 06:45:25] iteration   295600/  500000 | consumed samples:     18918400 | elapsed time per iteration (ms): 620.6 | learning rate: 1.210794E-05 | global batch size:    64 | lm loss: 2.972641E+00 | loss scale: 1048576.0 | grad norm: 0.477 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 06:46:27] iteration   295700/  500000 | consumed samples:     18924800 | elapsed time per iteration (ms): 618.0 | learning rate: 1.209107E-05 | global batch size:    64 | lm loss: 2.997011E+00 | loss scale: 1048576.0 | grad norm: 0.473 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 06:47:29] iteration   295800/  500000 | consumed samples:     18931200 | elapsed time per iteration (ms): 619.2 | learning rate: 1.207426E-05 | global batch size:    64 | lm loss: 2.968679E+00 | loss scale: 1048576.0 | grad norm: 0.470 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 06:48:31] iteration   295900/  500000 | consumed samples:     18937600 | elapsed time per iteration (ms): 620.0 | learning rate: 1.205752E-05 | global batch size:    64 | lm loss: 2.956154E+00 | loss scale: 1048576.0 | grad norm: 0.476 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 06:49:33] iteration   296000/  500000 | consumed samples:     18944000 | elapsed time per iteration (ms): 619.4 | learning rate: 1.204085E-05 | global batch size:    64 | lm loss: 2.977825E+00 | loss scale: 1048576.0 | grad norm: 0.489 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2461.26, 2461.35)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 296000 | lm loss value: 3.749687E+00 | lm loss PPL: 4.250778E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-26 06:50:37] iteration   296100/  500000 | consumed samples:     18950400 | elapsed time per iteration (ms): 619.4 | learning rate: 1.202424E-05 | global batch size:    64 | lm loss: 2.971652E+00 | loss scale: 1048576.0 | grad norm: 0.488 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 06:51:39] iteration   296200/  500000 | consumed samples:     18956800 | elapsed time per iteration (ms): 618.2 | learning rate: 1.200771E-05 | global batch size:    64 | lm loss: 2.963344E+00 | loss scale: 1048576.0 | grad norm: 0.472 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 06:52:41] iteration   296300/  500000 | consumed samples:     18963200 | elapsed time per iteration (ms): 618.1 | learning rate: 1.199123E-05 | global batch size:    64 | lm loss: 2.955579E+00 | loss scale: 1048576.0 | grad norm: 0.496 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 06:53:43] iteration   296400/  500000 | consumed samples:     18969600 | elapsed time per iteration (ms): 618.3 | learning rate: 1.197483E-05 | global batch size:    64 | lm loss: 2.971164E+00 | loss scale: 1048576.0 | grad norm: 0.488 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 06:54:44] iteration   296500/  500000 | consumed samples:     18976000 | elapsed time per iteration (ms): 617.3 | learning rate: 1.195849E-05 | global batch size:    64 | lm loss: 2.979385E+00 | loss scale: 2097152.0 | grad norm: 0.476 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 06:55:46] iteration   296600/  500000 | consumed samples:     18982400 | elapsed time per iteration (ms): 619.7 | learning rate: 1.194254E-05 | global batch size:    64 | lm loss: 2.973788E+00 | loss scale: 1048576.0 | grad norm: 0.499 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-26 06:56:48] iteration   296700/  500000 | consumed samples:     18988800 | elapsed time per iteration (ms): 619.2 | learning rate: 1.192633E-05 | global batch size:    64 | lm loss: 2.977347E+00 | loss scale: 1048576.0 | grad norm: 0.480 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 06:57:50] iteration   296800/  500000 | consumed samples:     18995200 | elapsed time per iteration (ms): 619.0 | learning rate: 1.191020E-05 | global batch size:    64 | lm loss: 2.967489E+00 | loss scale: 1048576.0 | grad norm: 0.486 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 06:58:52] iteration   296900/  500000 | consumed samples:     19001600 | elapsed time per iteration (ms): 618.8 | learning rate: 1.189412E-05 | global batch size:    64 | lm loss: 2.971760E+00 | loss scale: 1048576.0 | grad norm: 0.475 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 06:59:54] iteration   297000/  500000 | consumed samples:     19008000 | elapsed time per iteration (ms): 618.2 | learning rate: 1.187812E-05 | global batch size:    64 | lm loss: 2.984415E+00 | loss scale: 1048576.0 | grad norm: 0.488 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2460.95, 2460.98)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 297000 | lm loss value: 3.726880E+00 | lm loss PPL: 4.154927E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-26 07:00:58] iteration   297100/  500000 | consumed samples:     19014400 | elapsed time per iteration (ms): 620.3 | learning rate: 1.186218E-05 | global batch size:    64 | lm loss: 2.957776E+00 | loss scale: 1048576.0 | grad norm: 0.474 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 07:02:01] iteration   297200/  500000 | consumed samples:     19020800 | elapsed time per iteration (ms): 621.6 | learning rate: 1.184631E-05 | global batch size:    64 | lm loss: 2.974159E+00 | loss scale: 1048576.0 | grad norm: 0.481 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 07:03:03] iteration   297300/  500000 | consumed samples:     19027200 | elapsed time per iteration (ms): 619.4 | learning rate: 1.183050E-05 | global batch size:    64 | lm loss: 2.960359E+00 | loss scale: 1048576.0 | grad norm: 0.490 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 07:04:05] iteration   297400/  500000 | consumed samples:     19033600 | elapsed time per iteration (ms): 621.7 | learning rate: 1.181477E-05 | global batch size:    64 | lm loss: 2.951998E+00 | loss scale: 1048576.0 | grad norm: 0.480 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 07:05:06] iteration   297500/  500000 | consumed samples:     19040000 | elapsed time per iteration (ms): 617.4 | learning rate: 1.179910E-05 | global batch size:    64 | lm loss: 2.972723E+00 | loss scale: 1048576.0 | grad norm: 0.477 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 07:06:08] iteration   297600/  500000 | consumed samples:     19046400 | elapsed time per iteration (ms): 616.9 | learning rate: 1.178349E-05 | global batch size:    64 | lm loss: 2.973586E+00 | loss scale: 2097152.0 | grad norm: 0.491 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 07:07:10] iteration   297700/  500000 | consumed samples:     19052800 | elapsed time per iteration (ms): 619.8 | learning rate: 1.176811E-05 | global batch size:    64 | lm loss: 2.959434E+00 | loss scale: 2097152.0 | grad norm: 0.479 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-26 07:08:12] iteration   297800/  500000 | consumed samples:     19059200 | elapsed time per iteration (ms): 618.9 | learning rate: 1.175264E-05 | global batch size:    64 | lm loss: 2.974506E+00 | loss scale: 2097152.0 | grad norm: 0.476 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 07:09:14] iteration   297900/  500000 | consumed samples:     19065600 | elapsed time per iteration (ms): 619.8 | learning rate: 1.173724E-05 | global batch size:    64 | lm loss: 2.963668E+00 | loss scale: 2097152.0 | grad norm: 0.486 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 07:10:16] iteration   298000/  500000 | consumed samples:     19072000 | elapsed time per iteration (ms): 619.3 | learning rate: 1.172206E-05 | global batch size:    64 | lm loss: 2.980441E+00 | loss scale: 1048576.0 | grad norm: 0.494 | number of skipped iterations:   1 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2460.42, 2460.51)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 298000 | lm loss value: 3.706816E+00 | lm loss PPL: 4.072395E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-26 07:11:20] iteration   298100/  500000 | consumed samples:     19078400 | elapsed time per iteration (ms): 620.2 | learning rate: 1.170679E-05 | global batch size:    64 | lm loss: 2.974614E+00 | loss scale: 1048576.0 | grad norm: 0.478 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 07:12:22] iteration   298200/  500000 | consumed samples:     19084800 | elapsed time per iteration (ms): 618.9 | learning rate: 1.169159E-05 | global batch size:    64 | lm loss: 2.971633E+00 | loss scale: 1048576.0 | grad norm: 0.480 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 07:13:24] iteration   298300/  500000 | consumed samples:     19091200 | elapsed time per iteration (ms): 618.5 | learning rate: 1.167645E-05 | global batch size:    64 | lm loss: 2.971159E+00 | loss scale: 1048576.0 | grad norm: 0.475 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 07:14:26] iteration   298400/  500000 | consumed samples:     19097600 | elapsed time per iteration (ms): 620.2 | learning rate: 1.166138E-05 | global batch size:    64 | lm loss: 2.973656E+00 | loss scale: 1048576.0 | grad norm: 0.500 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 07:15:28] iteration   298500/  500000 | consumed samples:     19104000 | elapsed time per iteration (ms): 618.3 | learning rate: 1.164638E-05 | global batch size:    64 | lm loss: 2.973155E+00 | loss scale: 1048576.0 | grad norm: 0.477 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 07:16:30] iteration   298600/  500000 | consumed samples:     19110400 | elapsed time per iteration (ms): 620.0 | learning rate: 1.163145E-05 | global batch size:    64 | lm loss: 2.966952E+00 | loss scale: 1048576.0 | grad norm: 0.470 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 07:17:32] iteration   298700/  500000 | consumed samples:     19116800 | elapsed time per iteration (ms): 617.8 | learning rate: 1.161658E-05 | global batch size:    64 | lm loss: 2.972579E+00 | loss scale: 1048576.0 | grad norm: 0.465 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 07:18:34] iteration   298800/  500000 | consumed samples:     19123200 | elapsed time per iteration (ms): 620.3 | learning rate: 1.160179E-05 | global batch size:    64 | lm loss: 2.981277E+00 | loss scale: 1048576.0 | grad norm: 0.478 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 07:19:36] iteration   298900/  500000 | consumed samples:     19129600 | elapsed time per iteration (ms): 617.6 | learning rate: 1.158705E-05 | global batch size:    64 | lm loss: 2.959639E+00 | loss scale: 1048576.0 | grad norm: 0.490 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 07:20:38] iteration   299000/  500000 | consumed samples:     19136000 | elapsed time per iteration (ms): 619.5 | learning rate: 1.157254E-05 | global batch size:    64 | lm loss: 2.963123E+00 | loss scale: 2097152.0 | grad norm: 0.476 | number of skipped iterations:   1 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2464.80, 2465.06)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 299000 | lm loss value: 3.764956E+00 | lm loss PPL: 4.316182E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-26 07:21:42] iteration   299100/  500000 | consumed samples:     19142400 | elapsed time per iteration (ms): 618.3 | learning rate: 1.155808E-05 | global batch size:    64 | lm loss: 2.969806E+00 | loss scale: 1048576.0 | grad norm: 0.483 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-26 07:22:44] iteration   299200/  500000 | consumed samples:     19148800 | elapsed time per iteration (ms): 618.9 | learning rate: 1.154355E-05 | global batch size:    64 | lm loss: 2.950204E+00 | loss scale: 1048576.0 | grad norm: 0.490 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 07:23:46] iteration   299300/  500000 | consumed samples:     19155200 | elapsed time per iteration (ms): 619.6 | learning rate: 1.152909E-05 | global batch size:    64 | lm loss: 2.962029E+00 | loss scale: 1048576.0 | grad norm: 0.487 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 07:24:47] iteration   299400/  500000 | consumed samples:     19161600 | elapsed time per iteration (ms): 618.0 | learning rate: 1.151469E-05 | global batch size:    64 | lm loss: 2.983300E+00 | loss scale: 1048576.0 | grad norm: 0.483 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 07:25:49] iteration   299500/  500000 | consumed samples:     19168000 | elapsed time per iteration (ms): 618.0 | learning rate: 1.150037E-05 | global batch size:    64 | lm loss: 2.957687E+00 | loss scale: 1048576.0 | grad norm: 0.468 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 07:26:51] iteration   299600/  500000 | consumed samples:     19174400 | elapsed time per iteration (ms): 619.6 | learning rate: 1.148610E-05 | global batch size:    64 | lm loss: 2.958546E+00 | loss scale: 1048576.0 | grad norm: 0.483 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 07:27:53] iteration   299700/  500000 | consumed samples:     19180800 | elapsed time per iteration (ms): 617.4 | learning rate: 1.147191E-05 | global batch size:    64 | lm loss: 2.957842E+00 | loss scale: 1048576.0 | grad norm: 0.486 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 07:28:55] iteration   299800/  500000 | consumed samples:     19187200 | elapsed time per iteration (ms): 618.3 | learning rate: 1.145778E-05 | global batch size:    64 | lm loss: 2.958784E+00 | loss scale: 1048576.0 | grad norm: 0.491 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 07:29:57] iteration   299900/  500000 | consumed samples:     19193600 | elapsed time per iteration (ms): 618.6 | learning rate: 1.144372E-05 | global batch size:    64 | lm loss: 2.976703E+00 | loss scale: 1048576.0 | grad norm: 0.488 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 07:30:59] iteration   300000/  500000 | consumed samples:     19200000 | elapsed time per iteration (ms): 618.4 | learning rate: 1.142973E-05 | global batch size:    64 | lm loss: 2.977195E+00 | loss scale: 1048576.0 | grad norm: 0.490 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2465.08, 2465.10)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 300000 | lm loss value: 3.773171E+00 | lm loss PPL: 4.351784E+01 | 
--------------------------------------------------------------------------------------------------
saving checkpoint at iteration  300000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-distribution in torch format
  successfully saved checkpoint at iteration  300000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-distribution
(min, max) time across ranks (ms):
    save-checkpoint ................................: (2319.74, 2319.75)
 [2024-06-26 07:32:05] iteration   300100/  500000 | consumed samples:     19206400 | elapsed time per iteration (ms): 619.0 | learning rate: 1.141595E-05 | global batch size:    64 | lm loss: 2.971152E+00 | loss scale: 2097152.0 | grad norm: 0.486 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-26 07:33:07] iteration   300200/  500000 | consumed samples:     19212800 | elapsed time per iteration (ms): 619.5 | learning rate: 1.140223E-05 | global batch size:    64 | lm loss: 2.966703E+00 | loss scale: 1048576.0 | grad norm: 0.479 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-26 07:34:09] iteration   300300/  500000 | consumed samples:     19219200 | elapsed time per iteration (ms): 618.3 | learning rate: 1.138844E-05 | global batch size:    64 | lm loss: 2.974491E+00 | loss scale: 1048576.0 | grad norm: 0.472 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 07:35:11] iteration   300400/  500000 | consumed samples:     19225600 | elapsed time per iteration (ms): 620.1 | learning rate: 1.137471E-05 | global batch size:    64 | lm loss: 2.975779E+00 | loss scale: 1048576.0 | grad norm: 0.480 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 07:36:13] iteration   300500/  500000 | consumed samples:     19232000 | elapsed time per iteration (ms): 620.1 | learning rate: 1.136106E-05 | global batch size:    64 | lm loss: 2.970086E+00 | loss scale: 1048576.0 | grad norm: 0.473 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 07:37:15] iteration   300600/  500000 | consumed samples:     19238400 | elapsed time per iteration (ms): 618.6 | learning rate: 1.134747E-05 | global batch size:    64 | lm loss: 2.974892E+00 | loss scale: 1048576.0 | grad norm: 0.485 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 07:38:17] iteration   300700/  500000 | consumed samples:     19244800 | elapsed time per iteration (ms): 620.3 | learning rate: 1.133395E-05 | global batch size:    64 | lm loss: 2.961425E+00 | loss scale: 1048576.0 | grad norm: 0.481 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 07:39:19] iteration   300800/  500000 | consumed samples:     19251200 | elapsed time per iteration (ms): 618.8 | learning rate: 1.132049E-05 | global batch size:    64 | lm loss: 2.965963E+00 | loss scale: 1048576.0 | grad norm: 0.489 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 07:40:21] iteration   300900/  500000 | consumed samples:     19257600 | elapsed time per iteration (ms): 618.8 | learning rate: 1.130711E-05 | global batch size:    64 | lm loss: 2.976515E+00 | loss scale: 1048576.0 | grad norm: 0.480 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 07:41:23] iteration   301000/  500000 | consumed samples:     19264000 | elapsed time per iteration (ms): 620.7 | learning rate: 1.129379E-05 | global batch size:    64 | lm loss: 2.973339E+00 | loss scale: 1048576.0 | grad norm: 0.500 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2463.03, 2463.11)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 301000 | lm loss value: 3.739053E+00 | lm loss PPL: 4.205812E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-26 07:42:27] iteration   301100/  500000 | consumed samples:     19270400 | elapsed time per iteration (ms): 619.2 | learning rate: 1.128054E-05 | global batch size:    64 | lm loss: 2.967691E+00 | loss scale: 1048576.0 | grad norm: 0.479 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 07:43:29] iteration   301200/  500000 | consumed samples:     19276800 | elapsed time per iteration (ms): 622.3 | learning rate: 1.126736E-05 | global batch size:    64 | lm loss: 2.976142E+00 | loss scale: 2097152.0 | grad norm: 0.478 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 07:44:31] iteration   301300/  500000 | consumed samples:     19283200 | elapsed time per iteration (ms): 620.0 | learning rate: 1.125450E-05 | global batch size:    64 | lm loss: 2.984155E+00 | loss scale: 1048576.0 | grad norm: 0.489 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-26 07:45:33] iteration   301400/  500000 | consumed samples:     19289600 | elapsed time per iteration (ms): 621.2 | learning rate: 1.124145E-05 | global batch size:    64 | lm loss: 2.967360E+00 | loss scale: 1048576.0 | grad norm: 0.481 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 07:46:35] iteration   301500/  500000 | consumed samples:     19296000 | elapsed time per iteration (ms): 617.2 | learning rate: 1.122847E-05 | global batch size:    64 | lm loss: 2.967148E+00 | loss scale: 1048576.0 | grad norm: 0.486 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 07:47:37] iteration   301600/  500000 | consumed samples:     19302400 | elapsed time per iteration (ms): 617.9 | learning rate: 1.121556E-05 | global batch size:    64 | lm loss: 2.971895E+00 | loss scale: 1048576.0 | grad norm: 0.475 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 07:48:39] iteration   301700/  500000 | consumed samples:     19308800 | elapsed time per iteration (ms): 619.1 | learning rate: 1.120271E-05 | global batch size:    64 | lm loss: 2.962683E+00 | loss scale: 1048576.0 | grad norm: 0.479 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 07:49:41] iteration   301800/  500000 | consumed samples:     19315200 | elapsed time per iteration (ms): 618.4 | learning rate: 1.118993E-05 | global batch size:    64 | lm loss: 2.969861E+00 | loss scale: 1048576.0 | grad norm: 0.494 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 07:50:43] iteration   301900/  500000 | consumed samples:     19321600 | elapsed time per iteration (ms): 619.2 | learning rate: 1.117722E-05 | global batch size:    64 | lm loss: 2.966472E+00 | loss scale: 1048576.0 | grad norm: 0.483 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 07:51:44] iteration   302000/  500000 | consumed samples:     19328000 | elapsed time per iteration (ms): 617.3 | learning rate: 1.116458E-05 | global batch size:    64 | lm loss: 2.974127E+00 | loss scale: 1048576.0 | grad norm: 0.473 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2463.10, 2463.11)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 302000 | lm loss value: 3.745875E+00 | lm loss PPL: 4.234604E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-26 07:52:49] iteration   302100/  500000 | consumed samples:     19334400 | elapsed time per iteration (ms): 619.1 | learning rate: 1.115200E-05 | global batch size:    64 | lm loss: 2.976631E+00 | loss scale: 1048576.0 | grad norm: 0.479 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 07:53:51] iteration   302200/  500000 | consumed samples:     19340800 | elapsed time per iteration (ms): 618.2 | learning rate: 1.113949E-05 | global batch size:    64 | lm loss: 2.961165E+00 | loss scale: 1048576.0 | grad norm: 0.494 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 07:54:53] iteration   302300/  500000 | consumed samples:     19347200 | elapsed time per iteration (ms): 620.2 | learning rate: 1.112705E-05 | global batch size:    64 | lm loss: 2.976583E+00 | loss scale: 2097152.0 | grad norm: 0.484 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 07:55:55] iteration   302400/  500000 | consumed samples:     19353600 | elapsed time per iteration (ms): 620.8 | learning rate: 1.111481E-05 | global batch size:    64 | lm loss: 2.969200E+00 | loss scale: 2097152.0 | grad norm: 0.474 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-26 07:56:56] iteration   302500/  500000 | consumed samples:     19360000 | elapsed time per iteration (ms): 618.3 | learning rate: 1.110262E-05 | global batch size:    64 | lm loss: 2.973456E+00 | loss scale: 1048576.0 | grad norm: 0.485 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-26 07:57:58] iteration   302600/  500000 | consumed samples:     19366400 | elapsed time per iteration (ms): 618.0 | learning rate: 1.109038E-05 | global batch size:    64 | lm loss: 2.972438E+00 | loss scale: 1048576.0 | grad norm: 0.474 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 07:59:00] iteration   302700/  500000 | consumed samples:     19372800 | elapsed time per iteration (ms): 620.0 | learning rate: 1.107821E-05 | global batch size:    64 | lm loss: 2.973787E+00 | loss scale: 1048576.0 | grad norm: 0.487 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 08:00:02] iteration   302800/  500000 | consumed samples:     19379200 | elapsed time per iteration (ms): 618.2 | learning rate: 1.106611E-05 | global batch size:    64 | lm loss: 2.965811E+00 | loss scale: 1048576.0 | grad norm: 0.488 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 08:01:04] iteration   302900/  500000 | consumed samples:     19385600 | elapsed time per iteration (ms): 619.0 | learning rate: 1.105408E-05 | global batch size:    64 | lm loss: 2.963238E+00 | loss scale: 1048576.0 | grad norm: 0.471 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 08:02:06] iteration   303000/  500000 | consumed samples:     19392000 | elapsed time per iteration (ms): 617.2 | learning rate: 1.104211E-05 | global batch size:    64 | lm loss: 2.965879E+00 | loss scale: 1048576.0 | grad norm: 0.472 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2469.67, 2469.70)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 303000 | lm loss value: 3.699444E+00 | lm loss PPL: 4.042483E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-26 08:03:10] iteration   303100/  500000 | consumed samples:     19398400 | elapsed time per iteration (ms): 617.9 | learning rate: 1.103021E-05 | global batch size:    64 | lm loss: 2.968113E+00 | loss scale: 1048576.0 | grad norm: 0.487 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 08:04:12] iteration   303200/  500000 | consumed samples:     19404800 | elapsed time per iteration (ms): 619.1 | learning rate: 1.101838E-05 | global batch size:    64 | lm loss: 2.976019E+00 | loss scale: 1048576.0 | grad norm: 0.484 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 08:05:14] iteration   303300/  500000 | consumed samples:     19411200 | elapsed time per iteration (ms): 621.0 | learning rate: 1.100661E-05 | global batch size:    64 | lm loss: 2.961078E+00 | loss scale: 1048576.0 | grad norm: 0.478 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 08:06:16] iteration   303400/  500000 | consumed samples:     19417600 | elapsed time per iteration (ms): 619.5 | learning rate: 1.099492E-05 | global batch size:    64 | lm loss: 2.978535E+00 | loss scale: 1048576.0 | grad norm: 0.476 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 08:07:18] iteration   303500/  500000 | consumed samples:     19424000 | elapsed time per iteration (ms): 618.1 | learning rate: 1.098341E-05 | global batch size:    64 | lm loss: 2.955979E+00 | loss scale: 2097152.0 | grad norm: 0.485 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-26 08:08:20] iteration   303600/  500000 | consumed samples:     19430400 | elapsed time per iteration (ms): 619.5 | learning rate: 1.097196E-05 | global batch size:    64 | lm loss: 2.969744E+00 | loss scale: 1048576.0 | grad norm: 0.472 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-26 08:09:21] iteration   303700/  500000 | consumed samples:     19436800 | elapsed time per iteration (ms): 617.9 | learning rate: 1.096047E-05 | global batch size:    64 | lm loss: 2.979741E+00 | loss scale: 1048576.0 | grad norm: 0.479 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 08:10:23] iteration   303800/  500000 | consumed samples:     19443200 | elapsed time per iteration (ms): 618.9 | learning rate: 1.094904E-05 | global batch size:    64 | lm loss: 2.980155E+00 | loss scale: 1048576.0 | grad norm: 0.476 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 08:11:25] iteration   303900/  500000 | consumed samples:     19449600 | elapsed time per iteration (ms): 619.6 | learning rate: 1.093768E-05 | global batch size:    64 | lm loss: 2.971406E+00 | loss scale: 1048576.0 | grad norm: 0.477 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 08:12:27] iteration   304000/  500000 | consumed samples:     19456000 | elapsed time per iteration (ms): 620.1 | learning rate: 1.092639E-05 | global batch size:    64 | lm loss: 2.971326E+00 | loss scale: 1048576.0 | grad norm: 0.479 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2464.39, 2464.40)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 304000 | lm loss value: 3.739223E+00 | lm loss PPL: 4.206530E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-26 08:13:32] iteration   304100/  500000 | consumed samples:     19462400 | elapsed time per iteration (ms): 617.8 | learning rate: 1.091517E-05 | global batch size:    64 | lm loss: 2.973584E+00 | loss scale: 1048576.0 | grad norm: 0.482 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 08:14:33] iteration   304200/  500000 | consumed samples:     19468800 | elapsed time per iteration (ms): 618.9 | learning rate: 1.090402E-05 | global batch size:    64 | lm loss: 2.980800E+00 | loss scale: 1048576.0 | grad norm: 0.480 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 08:15:35] iteration   304300/  500000 | consumed samples:     19475200 | elapsed time per iteration (ms): 619.6 | learning rate: 1.089293E-05 | global batch size:    64 | lm loss: 2.971948E+00 | loss scale: 1048576.0 | grad norm: 0.478 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 08:16:37] iteration   304400/  500000 | consumed samples:     19481600 | elapsed time per iteration (ms): 619.8 | learning rate: 1.088191E-05 | global batch size:    64 | lm loss: 2.957411E+00 | loss scale: 1048576.0 | grad norm: 0.469 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 08:17:39] iteration   304500/  500000 | consumed samples:     19488000 | elapsed time per iteration (ms): 617.9 | learning rate: 1.087096E-05 | global batch size:    64 | lm loss: 2.977141E+00 | loss scale: 1048576.0 | grad norm: 0.503 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 08:18:41] iteration   304600/  500000 | consumed samples:     19494400 | elapsed time per iteration (ms): 617.4 | learning rate: 1.086008E-05 | global batch size:    64 | lm loss: 2.967892E+00 | loss scale: 2097152.0 | grad norm: 0.481 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 08:19:43] iteration   304700/  500000 | consumed samples:     19500800 | elapsed time per iteration (ms): 618.5 | learning rate: 1.084937E-05 | global batch size:    64 | lm loss: 2.951532E+00 | loss scale: 2097152.0 | grad norm: 0.474 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-26 08:20:45] iteration   304800/  500000 | consumed samples:     19507200 | elapsed time per iteration (ms): 617.7 | learning rate: 1.083873E-05 | global batch size:    64 | lm loss: 2.970363E+00 | loss scale: 1048576.0 | grad norm: 0.480 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-26 08:21:47] iteration   304900/  500000 | consumed samples:     19513600 | elapsed time per iteration (ms): 620.5 | learning rate: 1.082805E-05 | global batch size:    64 | lm loss: 2.965139E+00 | loss scale: 1048576.0 | grad norm: 0.483 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 08:22:49] iteration   305000/  500000 | consumed samples:     19520000 | elapsed time per iteration (ms): 619.9 | learning rate: 1.081744E-05 | global batch size:    64 | lm loss: 2.972391E+00 | loss scale: 1048576.0 | grad norm: 0.484 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2462.56, 2462.59)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 305000 | lm loss value: 3.758840E+00 | lm loss PPL: 4.289863E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-26 08:23:53] iteration   305100/  500000 | consumed samples:     19526400 | elapsed time per iteration (ms): 619.2 | learning rate: 1.080690E-05 | global batch size:    64 | lm loss: 2.967317E+00 | loss scale: 1048576.0 | grad norm: 0.472 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 08:24:55] iteration   305200/  500000 | consumed samples:     19532800 | elapsed time per iteration (ms): 619.8 | learning rate: 1.079642E-05 | global batch size:    64 | lm loss: 2.957979E+00 | loss scale: 1048576.0 | grad norm: 0.476 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 08:25:57] iteration   305300/  500000 | consumed samples:     19539200 | elapsed time per iteration (ms): 620.2 | learning rate: 1.078602E-05 | global batch size:    64 | lm loss: 2.986790E+00 | loss scale: 1048576.0 | grad norm: 0.485 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 08:26:59] iteration   305400/  500000 | consumed samples:     19545600 | elapsed time per iteration (ms): 621.7 | learning rate: 1.077568E-05 | global batch size:    64 | lm loss: 2.965175E+00 | loss scale: 1048576.0 | grad norm: 0.480 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 08:28:01] iteration   305500/  500000 | consumed samples:     19552000 | elapsed time per iteration (ms): 619.1 | learning rate: 1.076540E-05 | global batch size:    64 | lm loss: 2.966138E+00 | loss scale: 1048576.0 | grad norm: 0.486 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 08:29:03] iteration   305600/  500000 | consumed samples:     19558400 | elapsed time per iteration (ms): 618.2 | learning rate: 1.075520E-05 | global batch size:    64 | lm loss: 2.970762E+00 | loss scale: 1048576.0 | grad norm: 0.485 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 08:30:05] iteration   305700/  500000 | consumed samples:     19564800 | elapsed time per iteration (ms): 618.9 | learning rate: 1.074507E-05 | global batch size:    64 | lm loss: 2.984048E+00 | loss scale: 1048576.0 | grad norm: 0.487 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 08:31:07] iteration   305800/  500000 | consumed samples:     19571200 | elapsed time per iteration (ms): 619.1 | learning rate: 1.073500E-05 | global batch size:    64 | lm loss: 2.967827E+00 | loss scale: 2097152.0 | grad norm: 0.485 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 08:32:09] iteration   305900/  500000 | consumed samples:     19577600 | elapsed time per iteration (ms): 618.9 | learning rate: 1.072520E-05 | global batch size:    64 | lm loss: 2.976597E+00 | loss scale: 1048576.0 | grad norm: 0.491 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-26 08:33:10] iteration   306000/  500000 | consumed samples:     19584000 | elapsed time per iteration (ms): 618.1 | learning rate: 1.071527E-05 | global batch size:    64 | lm loss: 2.968410E+00 | loss scale: 1048576.0 | grad norm: 0.482 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2462.32, 2462.49)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 306000 | lm loss value: 3.755917E+00 | lm loss PPL: 4.277341E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-26 08:34:15] iteration   306100/  500000 | consumed samples:     19590400 | elapsed time per iteration (ms): 618.8 | learning rate: 1.070540E-05 | global batch size:    64 | lm loss: 2.982368E+00 | loss scale: 1048576.0 | grad norm: 0.481 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 08:35:17] iteration   306200/  500000 | consumed samples:     19596800 | elapsed time per iteration (ms): 619.8 | learning rate: 1.069561E-05 | global batch size:    64 | lm loss: 2.977446E+00 | loss scale: 1048576.0 | grad norm: 0.472 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 08:36:19] iteration   306300/  500000 | consumed samples:     19603200 | elapsed time per iteration (ms): 619.2 | learning rate: 1.068588E-05 | global batch size:    64 | lm loss: 2.965396E+00 | loss scale: 1048576.0 | grad norm: 0.476 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 08:37:21] iteration   306400/  500000 | consumed samples:     19609600 | elapsed time per iteration (ms): 620.7 | learning rate: 1.067622E-05 | global batch size:    64 | lm loss: 2.971645E+00 | loss scale: 1048576.0 | grad norm: 0.497 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 08:38:23] iteration   306500/  500000 | consumed samples:     19616000 | elapsed time per iteration (ms): 621.4 | learning rate: 1.066663E-05 | global batch size:    64 | lm loss: 2.979818E+00 | loss scale: 1048576.0 | grad norm: 0.473 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 08:39:25] iteration   306600/  500000 | consumed samples:     19622400 | elapsed time per iteration (ms): 619.8 | learning rate: 1.065711E-05 | global batch size:    64 | lm loss: 2.973528E+00 | loss scale: 1048576.0 | grad norm: 0.475 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 08:40:27] iteration   306700/  500000 | consumed samples:     19628800 | elapsed time per iteration (ms): 619.1 | learning rate: 1.064765E-05 | global batch size:    64 | lm loss: 2.974124E+00 | loss scale: 1048576.0 | grad norm: 0.484 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 08:41:29] iteration   306800/  500000 | consumed samples:     19635200 | elapsed time per iteration (ms): 618.2 | learning rate: 1.063826E-05 | global batch size:    64 | lm loss: 2.953609E+00 | loss scale: 1048576.0 | grad norm: 0.494 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 08:42:31] iteration   306900/  500000 | consumed samples:     19641600 | elapsed time per iteration (ms): 622.7 | learning rate: 1.062895E-05 | global batch size:    64 | lm loss: 2.965454E+00 | loss scale: 2097152.0 | grad norm: 0.481 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 08:43:33] iteration   307000/  500000 | consumed samples:     19648000 | elapsed time per iteration (ms): 620.6 | learning rate: 1.061988E-05 | global batch size:    64 | lm loss: 2.960218E+00 | loss scale: 1048576.0 | grad norm: 0.484 | number of skipped iterations:   2 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2464.19, 2464.23)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 307000 | lm loss value: 3.769664E+00 | lm loss PPL: 4.336547E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-26 08:44:37] iteration   307100/  500000 | consumed samples:     19654400 | elapsed time per iteration (ms): 618.1 | learning rate: 1.061070E-05 | global batch size:    64 | lm loss: 2.965691E+00 | loss scale: 1048576.0 | grad norm: 0.479 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 08:45:39] iteration   307200/  500000 | consumed samples:     19660800 | elapsed time per iteration (ms): 618.8 | learning rate: 1.060158E-05 | global batch size:    64 | lm loss: 2.984772E+00 | loss scale: 1048576.0 | grad norm: 0.477 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 08:46:41] iteration   307300/  500000 | consumed samples:     19667200 | elapsed time per iteration (ms): 619.2 | learning rate: 1.059253E-05 | global batch size:    64 | lm loss: 2.963472E+00 | loss scale: 1048576.0 | grad norm: 0.493 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 08:47:43] iteration   307400/  500000 | consumed samples:     19673600 | elapsed time per iteration (ms): 618.6 | learning rate: 1.058356E-05 | global batch size:    64 | lm loss: 2.965354E+00 | loss scale: 1048576.0 | grad norm: 0.492 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 08:48:45] iteration   307500/  500000 | consumed samples:     19680000 | elapsed time per iteration (ms): 618.1 | learning rate: 1.057464E-05 | global batch size:    64 | lm loss: 2.970976E+00 | loss scale: 1048576.0 | grad norm: 0.487 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 08:49:47] iteration   307600/  500000 | consumed samples:     19686400 | elapsed time per iteration (ms): 618.5 | learning rate: 1.056580E-05 | global batch size:    64 | lm loss: 2.970095E+00 | loss scale: 1048576.0 | grad norm: 0.466 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 08:50:48] iteration   307700/  500000 | consumed samples:     19692800 | elapsed time per iteration (ms): 617.8 | learning rate: 1.055703E-05 | global batch size:    64 | lm loss: 2.961878E+00 | loss scale: 1048576.0 | grad norm: 0.480 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 08:51:50] iteration   307800/  500000 | consumed samples:     19699200 | elapsed time per iteration (ms): 618.3 | learning rate: 1.054832E-05 | global batch size:    64 | lm loss: 2.953903E+00 | loss scale: 1048576.0 | grad norm: 0.477 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 08:52:52] iteration   307900/  500000 | consumed samples:     19705600 | elapsed time per iteration (ms): 618.7 | learning rate: 1.053969E-05 | global batch size:    64 | lm loss: 2.972024E+00 | loss scale: 1048576.0 | grad norm: 0.481 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 08:53:54] iteration   308000/  500000 | consumed samples:     19712000 | elapsed time per iteration (ms): 622.3 | learning rate: 1.053120E-05 | global batch size:    64 | lm loss: 2.963212E+00 | loss scale: 2097152.0 | grad norm: 0.495 | number of skipped iterations:   1 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2461.06, 2461.07)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 308000 | lm loss value: 3.719910E+00 | lm loss PPL: 4.126069E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-26 08:54:59] iteration   308100/  500000 | consumed samples:     19718400 | elapsed time per iteration (ms): 619.4 | learning rate: 1.052279E-05 | global batch size:    64 | lm loss: 2.950795E+00 | loss scale: 1048576.0 | grad norm: 0.478 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-26 08:56:01] iteration   308200/  500000 | consumed samples:     19724800 | elapsed time per iteration (ms): 619.5 | learning rate: 1.051435E-05 | global batch size:    64 | lm loss: 2.971106E+00 | loss scale: 1048576.0 | grad norm: 0.493 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 08:57:03] iteration   308300/  500000 | consumed samples:     19731200 | elapsed time per iteration (ms): 619.9 | learning rate: 1.050599E-05 | global batch size:    64 | lm loss: 2.961367E+00 | loss scale: 1048576.0 | grad norm: 0.489 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 08:58:04] iteration   308400/  500000 | consumed samples:     19737600 | elapsed time per iteration (ms): 619.0 | learning rate: 1.049769E-05 | global batch size:    64 | lm loss: 2.963111E+00 | loss scale: 1048576.0 | grad norm: 0.479 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 08:59:06] iteration   308500/  500000 | consumed samples:     19744000 | elapsed time per iteration (ms): 619.9 | learning rate: 1.048946E-05 | global batch size:    64 | lm loss: 2.952973E+00 | loss scale: 1048576.0 | grad norm: 0.481 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 09:00:08] iteration   308600/  500000 | consumed samples:     19750400 | elapsed time per iteration (ms): 619.6 | learning rate: 1.048130E-05 | global batch size:    64 | lm loss: 2.958422E+00 | loss scale: 1048576.0 | grad norm: 0.474 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 09:01:10] iteration   308700/  500000 | consumed samples:     19756800 | elapsed time per iteration (ms): 617.3 | learning rate: 1.047321E-05 | global batch size:    64 | lm loss: 2.966493E+00 | loss scale: 1048576.0 | grad norm: 0.494 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 09:02:12] iteration   308800/  500000 | consumed samples:     19763200 | elapsed time per iteration (ms): 617.8 | learning rate: 1.046518E-05 | global batch size:    64 | lm loss: 2.955511E+00 | loss scale: 1048576.0 | grad norm: 0.480 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 09:03:14] iteration   308900/  500000 | consumed samples:     19769600 | elapsed time per iteration (ms): 619.4 | learning rate: 1.045723E-05 | global batch size:    64 | lm loss: 2.958103E+00 | loss scale: 1048576.0 | grad norm: 0.483 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 09:04:16] iteration   309000/  500000 | consumed samples:     19776000 | elapsed time per iteration (ms): 618.7 | learning rate: 1.044934E-05 | global batch size:    64 | lm loss: 2.960099E+00 | loss scale: 1048576.0 | grad norm: 0.478 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2463.58, 2463.63)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 309000 | lm loss value: 3.724499E+00 | lm loss PPL: 4.145047E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-26 09:05:20] iteration   309100/  500000 | consumed samples:     19782400 | elapsed time per iteration (ms): 618.2 | learning rate: 1.044152E-05 | global batch size:    64 | lm loss: 2.959089E+00 | loss scale: 2097152.0 | grad norm: 0.486 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 09:06:22] iteration   309200/  500000 | consumed samples:     19788800 | elapsed time per iteration (ms): 619.3 | learning rate: 1.043393E-05 | global batch size:    64 | lm loss: 2.973267E+00 | loss scale: 1048576.0 | grad norm: 0.478 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-26 09:07:24] iteration   309300/  500000 | consumed samples:     19795200 | elapsed time per iteration (ms): 619.3 | learning rate: 1.042624E-05 | global batch size:    64 | lm loss: 2.956226E+00 | loss scale: 1048576.0 | grad norm: 0.494 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 09:08:26] iteration   309400/  500000 | consumed samples:     19801600 | elapsed time per iteration (ms): 619.6 | learning rate: 1.041863E-05 | global batch size:    64 | lm loss: 2.963004E+00 | loss scale: 1048576.0 | grad norm: 0.488 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 09:09:28] iteration   309500/  500000 | consumed samples:     19808000 | elapsed time per iteration (ms): 620.3 | learning rate: 1.041108E-05 | global batch size:    64 | lm loss: 2.968947E+00 | loss scale: 1048576.0 | grad norm: 0.477 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 09:10:30] iteration   309600/  500000 | consumed samples:     19814400 | elapsed time per iteration (ms): 620.4 | learning rate: 1.040361E-05 | global batch size:    64 | lm loss: 2.972464E+00 | loss scale: 1048576.0 | grad norm: 0.491 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 09:11:32] iteration   309700/  500000 | consumed samples:     19820800 | elapsed time per iteration (ms): 619.6 | learning rate: 1.039620E-05 | global batch size:    64 | lm loss: 2.974246E+00 | loss scale: 1048576.0 | grad norm: 0.489 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 09:12:34] iteration   309800/  500000 | consumed samples:     19827200 | elapsed time per iteration (ms): 618.6 | learning rate: 1.038886E-05 | global batch size:    64 | lm loss: 2.977347E+00 | loss scale: 1048576.0 | grad norm: 0.485 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 09:13:36] iteration   309900/  500000 | consumed samples:     19833600 | elapsed time per iteration (ms): 620.0 | learning rate: 1.038158E-05 | global batch size:    64 | lm loss: 2.969893E+00 | loss scale: 1048576.0 | grad norm: 0.496 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 09:14:38] iteration   310000/  500000 | consumed samples:     19840000 | elapsed time per iteration (ms): 619.8 | learning rate: 1.037438E-05 | global batch size:    64 | lm loss: 2.969922E+00 | loss scale: 1048576.0 | grad norm: 0.477 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2466.12, 2466.38)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 310000 | lm loss value: 3.718178E+00 | lm loss PPL: 4.118929E+01 | 
--------------------------------------------------------------------------------------------------
saving checkpoint at iteration  310000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-distribution in torch format
  successfully saved checkpoint at iteration  310000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-distribution
(min, max) time across ranks (ms):
    save-checkpoint ................................: (2316.95, 2317.03)
 [2024-06-26 09:15:44] iteration   310100/  500000 | consumed samples:     19846400 | elapsed time per iteration (ms): 619.4 | learning rate: 1.036724E-05 | global batch size:    64 | lm loss: 2.963962E+00 | loss scale: 1048576.0 | grad norm: 0.494 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 09:16:46] iteration   310200/  500000 | consumed samples:     19852800 | elapsed time per iteration (ms): 618.3 | learning rate: 1.036032E-05 | global batch size:    64 | lm loss: 2.968990E+00 | loss scale: 1048576.0 | grad norm: 0.497 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-26 09:17:48] iteration   310300/  500000 | consumed samples:     19859200 | elapsed time per iteration (ms): 620.3 | learning rate: 1.035339E-05 | global batch size:    64 | lm loss: 2.978167E+00 | loss scale: 524288.0 | grad norm: 0.492 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-26 09:18:50] iteration   310400/  500000 | consumed samples:     19865600 | elapsed time per iteration (ms): 618.6 | learning rate: 1.034645E-05 | global batch size:    64 | lm loss: 2.977794E+00 | loss scale: 524288.0 | grad norm: 0.490 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 09:19:52] iteration   310500/  500000 | consumed samples:     19872000 | elapsed time per iteration (ms): 620.8 | learning rate: 1.033959E-05 | global batch size:    64 | lm loss: 2.958335E+00 | loss scale: 524288.0 | grad norm: 0.478 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 09:20:54] iteration   310600/  500000 | consumed samples:     19878400 | elapsed time per iteration (ms): 620.1 | learning rate: 1.033280E-05 | global batch size:    64 | lm loss: 2.971846E+00 | loss scale: 524288.0 | grad norm: 0.490 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 09:21:56] iteration   310700/  500000 | consumed samples:     19884800 | elapsed time per iteration (ms): 619.9 | learning rate: 1.032607E-05 | global batch size:    64 | lm loss: 2.958131E+00 | loss scale: 524288.0 | grad norm: 0.482 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 09:22:58] iteration   310800/  500000 | consumed samples:     19891200 | elapsed time per iteration (ms): 618.7 | learning rate: 1.031941E-05 | global batch size:    64 | lm loss: 2.975218E+00 | loss scale: 524288.0 | grad norm: 0.479 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 09:24:00] iteration   310900/  500000 | consumed samples:     19897600 | elapsed time per iteration (ms): 620.2 | learning rate: 1.031282E-05 | global batch size:    64 | lm loss: 2.974425E+00 | loss scale: 524288.0 | grad norm: 0.488 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 09:25:02] iteration   311000/  500000 | consumed samples:     19904000 | elapsed time per iteration (ms): 619.0 | learning rate: 1.030630E-05 | global batch size:    64 | lm loss: 2.976547E+00 | loss scale: 524288.0 | grad norm: 0.480 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2464.41, 2464.44)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 311000 | lm loss value: 3.752035E+00 | lm loss PPL: 4.260771E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-26 09:26:06] iteration   311100/  500000 | consumed samples:     19910400 | elapsed time per iteration (ms): 619.6 | learning rate: 1.029985E-05 | global batch size:    64 | lm loss: 2.961765E+00 | loss scale: 524288.0 | grad norm: 0.492 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 09:27:08] iteration   311200/  500000 | consumed samples:     19916800 | elapsed time per iteration (ms): 618.7 | learning rate: 1.029346E-05 | global batch size:    64 | lm loss: 2.960456E+00 | loss scale: 524288.0 | grad norm: 0.498 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 09:28:10] iteration   311300/  500000 | consumed samples:     19923200 | elapsed time per iteration (ms): 617.3 | learning rate: 1.028715E-05 | global batch size:    64 | lm loss: 2.972818E+00 | loss scale: 1048576.0 | grad norm: 0.485 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 09:29:12] iteration   311400/  500000 | consumed samples:     19929600 | elapsed time per iteration (ms): 620.2 | learning rate: 1.028090E-05 | global batch size:    64 | lm loss: 2.965028E+00 | loss scale: 1048576.0 | grad norm: 0.481 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 09:30:14] iteration   311500/  500000 | consumed samples:     19936000 | elapsed time per iteration (ms): 621.1 | learning rate: 1.027472E-05 | global batch size:    64 | lm loss: 2.977097E+00 | loss scale: 1048576.0 | grad norm: 0.462 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 09:31:16] iteration   311600/  500000 | consumed samples:     19942400 | elapsed time per iteration (ms): 621.1 | learning rate: 1.026861E-05 | global batch size:    64 | lm loss: 2.957440E+00 | loss scale: 1048576.0 | grad norm: 0.477 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 09:32:18] iteration   311700/  500000 | consumed samples:     19948800 | elapsed time per iteration (ms): 619.6 | learning rate: 1.026257E-05 | global batch size:    64 | lm loss: 2.967394E+00 | loss scale: 1048576.0 | grad norm: 0.489 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 09:33:20] iteration   311800/  500000 | consumed samples:     19955200 | elapsed time per iteration (ms): 617.6 | learning rate: 1.025660E-05 | global batch size:    64 | lm loss: 2.962398E+00 | loss scale: 1048576.0 | grad norm: 0.479 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 09:34:22] iteration   311900/  500000 | consumed samples:     19961600 | elapsed time per iteration (ms): 617.6 | learning rate: 1.025070E-05 | global batch size:    64 | lm loss: 2.970580E+00 | loss scale: 1048576.0 | grad norm: 0.477 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 09:35:24] iteration   312000/  500000 | consumed samples:     19968000 | elapsed time per iteration (ms): 618.9 | learning rate: 1.024486E-05 | global batch size:    64 | lm loss: 2.958161E+00 | loss scale: 1048576.0 | grad norm: 0.493 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2462.98, 2463.07)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 312000 | lm loss value: 3.723475E+00 | lm loss PPL: 4.140804E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-26 09:36:28] iteration   312100/  500000 | consumed samples:     19974400 | elapsed time per iteration (ms): 620.4 | learning rate: 1.023909E-05 | global batch size:    64 | lm loss: 2.968449E+00 | loss scale: 1048576.0 | grad norm: 0.490 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 09:37:30] iteration   312200/  500000 | consumed samples:     19980800 | elapsed time per iteration (ms): 617.5 | learning rate: 1.023340E-05 | global batch size:    64 | lm loss: 2.972851E+00 | loss scale: 1048576.0 | grad norm: 0.493 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 09:38:32] iteration   312300/  500000 | consumed samples:     19987200 | elapsed time per iteration (ms): 619.0 | learning rate: 1.022777E-05 | global batch size:    64 | lm loss: 2.966426E+00 | loss scale: 2097152.0 | grad norm: 0.482 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 09:39:34] iteration   312400/  500000 | consumed samples:     19993600 | elapsed time per iteration (ms): 619.3 | learning rate: 1.022232E-05 | global batch size:    64 | lm loss: 2.965977E+00 | loss scale: 1048576.0 | grad norm: 0.495 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-26 09:40:36] iteration   312500/  500000 | consumed samples:     20000000 | elapsed time per iteration (ms): 619.9 | learning rate: 1.021682E-05 | global batch size:    64 | lm loss: 2.981339E+00 | loss scale: 1048576.0 | grad norm: 0.470 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 09:41:38] iteration   312600/  500000 | consumed samples:     20006400 | elapsed time per iteration (ms): 621.1 | learning rate: 1.021140E-05 | global batch size:    64 | lm loss: 2.960499E+00 | loss scale: 1048576.0 | grad norm: 0.484 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 09:42:40] iteration   312700/  500000 | consumed samples:     20012800 | elapsed time per iteration (ms): 619.1 | learning rate: 1.020604E-05 | global batch size:    64 | lm loss: 2.964167E+00 | loss scale: 1048576.0 | grad norm: 0.496 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 09:43:42] iteration   312800/  500000 | consumed samples:     20019200 | elapsed time per iteration (ms): 620.8 | learning rate: 1.020075E-05 | global batch size:    64 | lm loss: 2.977353E+00 | loss scale: 1048576.0 | grad norm: 0.486 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 09:44:44] iteration   312900/  500000 | consumed samples:     20025600 | elapsed time per iteration (ms): 620.1 | learning rate: 1.019553E-05 | global batch size:    64 | lm loss: 2.973103E+00 | loss scale: 1048576.0 | grad norm: 0.489 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 09:45:46] iteration   313000/  500000 | consumed samples:     20032000 | elapsed time per iteration (ms): 620.7 | learning rate: 1.019038E-05 | global batch size:    64 | lm loss: 2.970501E+00 | loss scale: 1048576.0 | grad norm: 0.481 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2461.86, 2461.88)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 313000 | lm loss value: 3.730170E+00 | lm loss PPL: 4.168618E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-26 09:46:50] iteration   313100/  500000 | consumed samples:     20038400 | elapsed time per iteration (ms): 618.6 | learning rate: 1.018530E-05 | global batch size:    64 | lm loss: 2.967607E+00 | loss scale: 1048576.0 | grad norm: 0.486 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 09:47:52] iteration   313200/  500000 | consumed samples:     20044800 | elapsed time per iteration (ms): 618.7 | learning rate: 1.018029E-05 | global batch size:    64 | lm loss: 2.944558E+00 | loss scale: 1048576.0 | grad norm: 0.472 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 09:48:54] iteration   313300/  500000 | consumed samples:     20051200 | elapsed time per iteration (ms): 619.9 | learning rate: 1.017534E-05 | global batch size:    64 | lm loss: 2.961170E+00 | loss scale: 1048576.0 | grad norm: 0.482 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 09:49:56] iteration   313400/  500000 | consumed samples:     20057600 | elapsed time per iteration (ms): 619.9 | learning rate: 1.017047E-05 | global batch size:    64 | lm loss: 2.973563E+00 | loss scale: 2097152.0 | grad norm: 0.476 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 09:50:58] iteration   313500/  500000 | consumed samples:     20064000 | elapsed time per iteration (ms): 618.2 | learning rate: 1.016571E-05 | global batch size:    64 | lm loss: 2.977441E+00 | loss scale: 2097152.0 | grad norm: 0.476 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-26 09:52:00] iteration   313600/  500000 | consumed samples:     20070400 | elapsed time per iteration (ms): 621.5 | learning rate: 1.016097E-05 | global batch size:    64 | lm loss: 2.968248E+00 | loss scale: 2097152.0 | grad norm: 0.474 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 09:53:02] iteration   313700/  500000 | consumed samples:     20076800 | elapsed time per iteration (ms): 619.6 | learning rate: 1.015635E-05 | global batch size:    64 | lm loss: 2.962800E+00 | loss scale: 1048576.0 | grad norm: 0.492 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-26 09:54:04] iteration   313800/  500000 | consumed samples:     20083200 | elapsed time per iteration (ms): 618.7 | learning rate: 1.015174E-05 | global batch size:    64 | lm loss: 2.968103E+00 | loss scale: 1048576.0 | grad norm: 0.493 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 09:55:06] iteration   313900/  500000 | consumed samples:     20089600 | elapsed time per iteration (ms): 619.6 | learning rate: 1.014721E-05 | global batch size:    64 | lm loss: 2.983028E+00 | loss scale: 1048576.0 | grad norm: 0.500 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 09:56:08] iteration   314000/  500000 | consumed samples:     20096000 | elapsed time per iteration (ms): 621.3 | learning rate: 1.014274E-05 | global batch size:    64 | lm loss: 2.967145E+00 | loss scale: 1048576.0 | grad norm: 0.491 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2463.00, 2463.05)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 314000 | lm loss value: 3.733647E+00 | lm loss PPL: 4.183139E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-26 09:57:12] iteration   314100/  500000 | consumed samples:     20102400 | elapsed time per iteration (ms): 619.6 | learning rate: 1.013835E-05 | global batch size:    64 | lm loss: 2.989967E+00 | loss scale: 1048576.0 | grad norm: 0.491 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 09:58:14] iteration   314200/  500000 | consumed samples:     20108800 | elapsed time per iteration (ms): 618.6 | learning rate: 1.013402E-05 | global batch size:    64 | lm loss: 2.950766E+00 | loss scale: 1048576.0 | grad norm: 0.491 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 09:59:16] iteration   314300/  500000 | consumed samples:     20115200 | elapsed time per iteration (ms): 620.4 | learning rate: 1.012976E-05 | global batch size:    64 | lm loss: 2.954088E+00 | loss scale: 1048576.0 | grad norm: 0.481 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 10:00:18] iteration   314400/  500000 | consumed samples:     20121600 | elapsed time per iteration (ms): 620.3 | learning rate: 1.012557E-05 | global batch size:    64 | lm loss: 2.970485E+00 | loss scale: 1048576.0 | grad norm: 0.492 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 10:01:20] iteration   314500/  500000 | consumed samples:     20128000 | elapsed time per iteration (ms): 619.4 | learning rate: 1.012145E-05 | global batch size:    64 | lm loss: 2.966684E+00 | loss scale: 1048576.0 | grad norm: 0.481 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 10:02:22] iteration   314600/  500000 | consumed samples:     20134400 | elapsed time per iteration (ms): 619.2 | learning rate: 1.011740E-05 | global batch size:    64 | lm loss: 2.961048E+00 | loss scale: 1048576.0 | grad norm: 0.476 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 10:03:24] iteration   314700/  500000 | consumed samples:     20140800 | elapsed time per iteration (ms): 618.3 | learning rate: 1.011345E-05 | global batch size:    64 | lm loss: 2.963537E+00 | loss scale: 2097152.0 | grad norm: 0.496 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-26 10:04:26] iteration   314800/  500000 | consumed samples:     20147200 | elapsed time per iteration (ms): 618.4 | learning rate: 1.010957E-05 | global batch size:    64 | lm loss: 2.974682E+00 | loss scale: 1048576.0 | grad norm: 0.487 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-26 10:05:28] iteration   314900/  500000 | consumed samples:     20153600 | elapsed time per iteration (ms): 619.4 | learning rate: 1.010573E-05 | global batch size:    64 | lm loss: 2.973548E+00 | loss scale: 1048576.0 | grad norm: 0.485 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 10:06:30] iteration   315000/  500000 | consumed samples:     20160000 | elapsed time per iteration (ms): 620.7 | learning rate: 1.010195E-05 | global batch size:    64 | lm loss: 2.965057E+00 | loss scale: 1048576.0 | grad norm: 0.488 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2461.41, 2461.42)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 315000 | lm loss value: 3.739708E+00 | lm loss PPL: 4.208572E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-26 10:07:34] iteration   315100/  500000 | consumed samples:     20166400 | elapsed time per iteration (ms): 618.5 | learning rate: 1.009823E-05 | global batch size:    64 | lm loss: 2.967758E+00 | loss scale: 1048576.0 | grad norm: 0.494 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 10:08:36] iteration   315200/  500000 | consumed samples:     20172800 | elapsed time per iteration (ms): 618.2 | learning rate: 1.009459E-05 | global batch size:    64 | lm loss: 2.991229E+00 | loss scale: 1048576.0 | grad norm: 0.482 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 10:09:38] iteration   315300/  500000 | consumed samples:     20179200 | elapsed time per iteration (ms): 616.6 | learning rate: 1.009102E-05 | global batch size:    64 | lm loss: 2.979574E+00 | loss scale: 1048576.0 | grad norm: 0.496 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 10:10:40] iteration   315400/  500000 | consumed samples:     20185600 | elapsed time per iteration (ms): 618.5 | learning rate: 1.008752E-05 | global batch size:    64 | lm loss: 2.972339E+00 | loss scale: 1048576.0 | grad norm: 0.489 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 10:11:41] iteration   315500/  500000 | consumed samples:     20192000 | elapsed time per iteration (ms): 618.3 | learning rate: 1.008408E-05 | global batch size:    64 | lm loss: 2.968027E+00 | loss scale: 1048576.0 | grad norm: 0.481 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 10:12:43] iteration   315600/  500000 | consumed samples:     20198400 | elapsed time per iteration (ms): 619.3 | learning rate: 1.008071E-05 | global batch size:    64 | lm loss: 2.972634E+00 | loss scale: 1048576.0 | grad norm: 0.483 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 10:13:45] iteration   315700/  500000 | consumed samples:     20204800 | elapsed time per iteration (ms): 619.1 | learning rate: 1.007741E-05 | global batch size:    64 | lm loss: 2.966371E+00 | loss scale: 1048576.0 | grad norm: 0.503 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 10:14:47] iteration   315800/  500000 | consumed samples:     20211200 | elapsed time per iteration (ms): 617.3 | learning rate: 1.007425E-05 | global batch size:    64 | lm loss: 2.969158E+00 | loss scale: 1048576.0 | grad norm: 0.481 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-26 10:15:49] iteration   315900/  500000 | consumed samples:     20217600 | elapsed time per iteration (ms): 618.3 | learning rate: 1.007109E-05 | global batch size:    64 | lm loss: 2.962726E+00 | loss scale: 1048576.0 | grad norm: 0.492 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 10:16:51] iteration   316000/  500000 | consumed samples:     20224000 | elapsed time per iteration (ms): 618.8 | learning rate: 1.006799E-05 | global batch size:    64 | lm loss: 2.969391E+00 | loss scale: 1048576.0 | grad norm: 0.485 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2463.37, 2463.40)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 316000 | lm loss value: 3.791534E+00 | lm loss PPL: 4.432436E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-26 10:17:55] iteration   316100/  500000 | consumed samples:     20230400 | elapsed time per iteration (ms): 619.8 | learning rate: 1.006497E-05 | global batch size:    64 | lm loss: 2.964303E+00 | loss scale: 1048576.0 | grad norm: 0.480 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 10:18:57] iteration   316200/  500000 | consumed samples:     20236800 | elapsed time per iteration (ms): 620.2 | learning rate: 1.006201E-05 | global batch size:    64 | lm loss: 2.957522E+00 | loss scale: 1048576.0 | grad norm: 0.481 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 10:19:59] iteration   316300/  500000 | consumed samples:     20243200 | elapsed time per iteration (ms): 618.9 | learning rate: 1.005913E-05 | global batch size:    64 | lm loss: 2.981213E+00 | loss scale: 1048576.0 | grad norm: 0.474 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 10:21:01] iteration   316400/  500000 | consumed samples:     20249600 | elapsed time per iteration (ms): 617.0 | learning rate: 1.005631E-05 | global batch size:    64 | lm loss: 2.965692E+00 | loss scale: 1048576.0 | grad norm: 0.491 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 10:22:03] iteration   316500/  500000 | consumed samples:     20256000 | elapsed time per iteration (ms): 619.0 | learning rate: 1.005356E-05 | global batch size:    64 | lm loss: 2.972344E+00 | loss scale: 1048576.0 | grad norm: 0.501 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 10:23:05] iteration   316600/  500000 | consumed samples:     20262400 | elapsed time per iteration (ms): 621.2 | learning rate: 1.005088E-05 | global batch size:    64 | lm loss: 2.963725E+00 | loss scale: 1048576.0 | grad norm: 0.502 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 10:24:07] iteration   316700/  500000 | consumed samples:     20268800 | elapsed time per iteration (ms): 621.1 | learning rate: 1.004827E-05 | global batch size:    64 | lm loss: 2.969991E+00 | loss scale: 1048576.0 | grad norm: 0.499 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 10:25:09] iteration   316800/  500000 | consumed samples:     20275200 | elapsed time per iteration (ms): 620.0 | learning rate: 1.004572E-05 | global batch size:    64 | lm loss: 2.965227E+00 | loss scale: 2097152.0 | grad norm: 0.479 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 10:26:11] iteration   316900/  500000 | consumed samples:     20281600 | elapsed time per iteration (ms): 619.4 | learning rate: 1.004330E-05 | global batch size:    64 | lm loss: 2.963645E+00 | loss scale: 1048576.0 | grad norm: 0.475 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-26 10:27:13] iteration   317000/  500000 | consumed samples:     20288000 | elapsed time per iteration (ms): 617.7 | learning rate: 1.004089E-05 | global batch size:    64 | lm loss: 2.977176E+00 | loss scale: 1048576.0 | grad norm: 0.491 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2462.57, 2462.63)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 317000 | lm loss value: 3.691177E+00 | lm loss PPL: 4.009201E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-26 10:28:17] iteration   317100/  500000 | consumed samples:     20294400 | elapsed time per iteration (ms): 621.0 | learning rate: 1.003855E-05 | global batch size:    64 | lm loss: 2.974362E+00 | loss scale: 1048576.0 | grad norm: 0.491 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 10:29:19] iteration   317200/  500000 | consumed samples:     20300800 | elapsed time per iteration (ms): 619.7 | learning rate: 1.003628E-05 | global batch size:    64 | lm loss: 2.962778E+00 | loss scale: 1048576.0 | grad norm: 0.487 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 10:30:21] iteration   317300/  500000 | consumed samples:     20307200 | elapsed time per iteration (ms): 619.2 | learning rate: 1.003408E-05 | global batch size:    64 | lm loss: 2.960538E+00 | loss scale: 1048576.0 | grad norm: 0.506 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 10:31:23] iteration   317400/  500000 | consumed samples:     20313600 | elapsed time per iteration (ms): 618.9 | learning rate: 1.003195E-05 | global batch size:    64 | lm loss: 2.975204E+00 | loss scale: 1048576.0 | grad norm: 0.491 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 10:32:25] iteration   317500/  500000 | consumed samples:     20320000 | elapsed time per iteration (ms): 617.9 | learning rate: 1.002989E-05 | global batch size:    64 | lm loss: 2.968718E+00 | loss scale: 1048576.0 | grad norm: 0.485 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 10:33:27] iteration   317600/  500000 | consumed samples:     20326400 | elapsed time per iteration (ms): 619.3 | learning rate: 1.002790E-05 | global batch size:    64 | lm loss: 2.977325E+00 | loss scale: 1048576.0 | grad norm: 0.487 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 10:34:28] iteration   317700/  500000 | consumed samples:     20332800 | elapsed time per iteration (ms): 618.2 | learning rate: 1.002597E-05 | global batch size:    64 | lm loss: 2.953464E+00 | loss scale: 1048576.0 | grad norm: 0.476 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 10:35:30] iteration   317800/  500000 | consumed samples:     20339200 | elapsed time per iteration (ms): 616.7 | learning rate: 1.002411E-05 | global batch size:    64 | lm loss: 2.952613E+00 | loss scale: 1048576.0 | grad norm: 0.507 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 10:36:32] iteration   317900/  500000 | consumed samples:     20345600 | elapsed time per iteration (ms): 619.4 | learning rate: 1.002236E-05 | global batch size:    64 | lm loss: 2.966866E+00 | loss scale: 1048576.0 | grad norm: 0.488 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-26 10:37:34] iteration   318000/  500000 | consumed samples:     20352000 | elapsed time per iteration (ms): 620.0 | learning rate: 1.002064E-05 | global batch size:    64 | lm loss: 2.971903E+00 | loss scale: 1048576.0 | grad norm: 0.478 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2462.05, 2462.07)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 318000 | lm loss value: 3.758137E+00 | lm loss PPL: 4.286850E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-26 10:38:38] iteration   318100/  500000 | consumed samples:     20358400 | elapsed time per iteration (ms): 619.2 | learning rate: 1.001899E-05 | global batch size:    64 | lm loss: 2.983692E+00 | loss scale: 1048576.0 | grad norm: 0.485 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 10:39:40] iteration   318200/  500000 | consumed samples:     20364800 | elapsed time per iteration (ms): 618.7 | learning rate: 1.001741E-05 | global batch size:    64 | lm loss: 2.971692E+00 | loss scale: 1048576.0 | grad norm: 0.504 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 10:40:42] iteration   318300/  500000 | consumed samples:     20371200 | elapsed time per iteration (ms): 618.2 | learning rate: 1.001589E-05 | global batch size:    64 | lm loss: 2.972884E+00 | loss scale: 1048576.0 | grad norm: 0.478 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 10:41:44] iteration   318400/  500000 | consumed samples:     20377600 | elapsed time per iteration (ms): 618.2 | learning rate: 1.001445E-05 | global batch size:    64 | lm loss: 2.963215E+00 | loss scale: 1048576.0 | grad norm: 0.479 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 10:42:46] iteration   318500/  500000 | consumed samples:     20384000 | elapsed time per iteration (ms): 619.2 | learning rate: 1.001307E-05 | global batch size:    64 | lm loss: 2.952438E+00 | loss scale: 1048576.0 | grad norm: 0.480 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 10:43:48] iteration   318600/  500000 | consumed samples:     20390400 | elapsed time per iteration (ms): 620.3 | learning rate: 1.001177E-05 | global batch size:    64 | lm loss: 2.961899E+00 | loss scale: 1048576.0 | grad norm: 0.484 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 10:44:50] iteration   318700/  500000 | consumed samples:     20396800 | elapsed time per iteration (ms): 618.6 | learning rate: 1.001053E-05 | global batch size:    64 | lm loss: 2.963996E+00 | loss scale: 1048576.0 | grad norm: 0.496 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 10:45:52] iteration   318800/  500000 | consumed samples:     20403200 | elapsed time per iteration (ms): 619.8 | learning rate: 1.000936E-05 | global batch size:    64 | lm loss: 2.961879E+00 | loss scale: 1048576.0 | grad norm: 0.490 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 10:46:54] iteration   318900/  500000 | consumed samples:     20409600 | elapsed time per iteration (ms): 617.9 | learning rate: 1.000826E-05 | global batch size:    64 | lm loss: 2.955739E+00 | loss scale: 2097152.0 | grad norm: 0.498 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 10:47:56] iteration   319000/  500000 | consumed samples:     20416000 | elapsed time per iteration (ms): 620.3 | learning rate: 1.000725E-05 | global batch size:    64 | lm loss: 2.974403E+00 | loss scale: 1048576.0 | grad norm: 0.483 | number of skipped iterations:   2 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2461.05, 2461.10)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 319000 | lm loss value: 3.692520E+00 | lm loss PPL: 4.014588E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-26 10:49:00] iteration   319100/  500000 | consumed samples:     20422400 | elapsed time per iteration (ms): 618.9 | learning rate: 1.000628E-05 | global batch size:    64 | lm loss: 2.965992E+00 | loss scale: 1048576.0 | grad norm: 0.482 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 10:50:02] iteration   319200/  500000 | consumed samples:     20428800 | elapsed time per iteration (ms): 619.4 | learning rate: 1.000539E-05 | global batch size:    64 | lm loss: 2.964965E+00 | loss scale: 1048576.0 | grad norm: 0.505 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 10:51:04] iteration   319300/  500000 | consumed samples:     20435200 | elapsed time per iteration (ms): 617.9 | learning rate: 1.000456E-05 | global batch size:    64 | lm loss: 2.967354E+00 | loss scale: 1048576.0 | grad norm: 0.483 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 10:52:05] iteration   319400/  500000 | consumed samples:     20441600 | elapsed time per iteration (ms): 618.9 | learning rate: 1.000380E-05 | global batch size:    64 | lm loss: 2.967268E+00 | loss scale: 1048576.0 | grad norm: 0.492 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 10:53:07] iteration   319500/  500000 | consumed samples:     20448000 | elapsed time per iteration (ms): 618.8 | learning rate: 1.000311E-05 | global batch size:    64 | lm loss: 2.975462E+00 | loss scale: 1048576.0 | grad norm: 0.496 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 10:54:09] iteration   319600/  500000 | consumed samples:     20454400 | elapsed time per iteration (ms): 619.4 | learning rate: 1.000249E-05 | global batch size:    64 | lm loss: 2.966835E+00 | loss scale: 1048576.0 | grad norm: 0.492 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 10:55:11] iteration   319700/  500000 | consumed samples:     20460800 | elapsed time per iteration (ms): 618.3 | learning rate: 1.000194E-05 | global batch size:    64 | lm loss: 2.961289E+00 | loss scale: 1048576.0 | grad norm: 0.489 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 10:56:13] iteration   319800/  500000 | consumed samples:     20467200 | elapsed time per iteration (ms): 618.6 | learning rate: 1.000146E-05 | global batch size:    64 | lm loss: 2.955341E+00 | loss scale: 1048576.0 | grad norm: 0.489 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 10:57:15] iteration   319900/  500000 | consumed samples:     20473600 | elapsed time per iteration (ms): 619.4 | learning rate: 1.000104E-05 | global batch size:    64 | lm loss: 2.954599E+00 | loss scale: 1048576.0 | grad norm: 0.479 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 10:58:17] iteration   320000/  500000 | consumed samples:     20480000 | elapsed time per iteration (ms): 620.0 | learning rate: 1.000070E-05 | global batch size:    64 | lm loss: 2.979271E+00 | loss scale: 2097152.0 | grad norm: 0.481 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2460.64, 2460.68)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 320000 | lm loss value: 3.689339E+00 | lm loss PPL: 4.001837E+01 | 
--------------------------------------------------------------------------------------------------
saving checkpoint at iteration  320000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-distribution in torch format
  successfully saved checkpoint at iteration  320000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-distribution
(min, max) time across ranks (ms):
    save-checkpoint ................................: (2301.26, 2301.35)
 [2024-06-26 10:59:24] iteration   320100/  500000 | consumed samples:     20486400 | elapsed time per iteration (ms): 620.0 | learning rate: 1.000043E-05 | global batch size:    64 | lm loss: 2.969418E+00 | loss scale: 2097152.0 | grad norm: 0.492 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-26 11:00:26] iteration   320200/  500000 | consumed samples:     20492800 | elapsed time per iteration (ms): 620.6 | learning rate: 1.000022E-05 | global batch size:    64 | lm loss: 2.976287E+00 | loss scale: 1048576.0 | grad norm: 0.479 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-26 11:01:28] iteration   320300/  500000 | consumed samples:     20499200 | elapsed time per iteration (ms): 620.5 | learning rate: 1.000008E-05 | global batch size:    64 | lm loss: 2.976135E+00 | loss scale: 1048576.0 | grad norm: 0.485 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 11:02:30] iteration   320400/  500000 | consumed samples:     20505600 | elapsed time per iteration (ms): 620.0 | learning rate: 1.000001E-05 | global batch size:    64 | lm loss: 2.973019E+00 | loss scale: 1048576.0 | grad norm: 0.499 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 11:03:32] iteration   320500/  500000 | consumed samples:     20512000 | elapsed time per iteration (ms): 618.1 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.968725E+00 | loss scale: 1048576.0 | grad norm: 0.493 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 11:04:34] iteration   320600/  500000 | consumed samples:     20518400 | elapsed time per iteration (ms): 619.6 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.974764E+00 | loss scale: 1048576.0 | grad norm: 0.492 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 11:05:36] iteration   320700/  500000 | consumed samples:     20524800 | elapsed time per iteration (ms): 619.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.971203E+00 | loss scale: 1048576.0 | grad norm: 0.493 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 11:06:37] iteration   320800/  500000 | consumed samples:     20531200 | elapsed time per iteration (ms): 617.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.965688E+00 | loss scale: 1048576.0 | grad norm: 0.483 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 11:07:39] iteration   320900/  500000 | consumed samples:     20537600 | elapsed time per iteration (ms): 617.5 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.963492E+00 | loss scale: 1048576.0 | grad norm: 0.499 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 11:08:41] iteration   321000/  500000 | consumed samples:     20544000 | elapsed time per iteration (ms): 619.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.961825E+00 | loss scale: 1048576.0 | grad norm: 0.491 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2461.02, 2461.11)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 321000 | lm loss value: 3.703068E+00 | lm loss PPL: 4.057157E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-26 11:09:45] iteration   321100/  500000 | consumed samples:     20550400 | elapsed time per iteration (ms): 619.5 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.963122E+00 | loss scale: 1048576.0 | grad norm: 0.495 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 11:10:47] iteration   321200/  500000 | consumed samples:     20556800 | elapsed time per iteration (ms): 618.7 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.967752E+00 | loss scale: 2097152.0 | grad norm: 0.479 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-26 11:11:49] iteration   321300/  500000 | consumed samples:     20563200 | elapsed time per iteration (ms): 619.5 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.957619E+00 | loss scale: 1048576.0 | grad norm: 0.487 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-26 11:12:51] iteration   321400/  500000 | consumed samples:     20569600 | elapsed time per iteration (ms): 619.5 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.981978E+00 | loss scale: 1048576.0 | grad norm: 0.499 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 11:13:53] iteration   321500/  500000 | consumed samples:     20576000 | elapsed time per iteration (ms): 618.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.976349E+00 | loss scale: 1048576.0 | grad norm: 0.488 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 11:14:55] iteration   321600/  500000 | consumed samples:     20582400 | elapsed time per iteration (ms): 619.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.957841E+00 | loss scale: 1048576.0 | grad norm: 0.482 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 11:15:57] iteration   321700/  500000 | consumed samples:     20588800 | elapsed time per iteration (ms): 621.1 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.954961E+00 | loss scale: 1048576.0 | grad norm: 0.477 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 11:16:59] iteration   321800/  500000 | consumed samples:     20595200 | elapsed time per iteration (ms): 619.2 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.981675E+00 | loss scale: 1048576.0 | grad norm: 0.490 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 11:18:01] iteration   321900/  500000 | consumed samples:     20601600 | elapsed time per iteration (ms): 619.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.952122E+00 | loss scale: 1048576.0 | grad norm: 0.492 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 11:19:03] iteration   322000/  500000 | consumed samples:     20608000 | elapsed time per iteration (ms): 620.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.969352E+00 | loss scale: 1048576.0 | grad norm: 0.482 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2463.83, 2463.89)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 322000 | lm loss value: 3.721053E+00 | lm loss PPL: 4.130788E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-26 11:20:07] iteration   322100/  500000 | consumed samples:     20614400 | elapsed time per iteration (ms): 618.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.951015E+00 | loss scale: 1048576.0 | grad norm: 0.477 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 11:21:09] iteration   322200/  500000 | consumed samples:     20620800 | elapsed time per iteration (ms): 618.1 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.976911E+00 | loss scale: 1048576.0 | grad norm: 0.488 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 11:22:11] iteration   322300/  500000 | consumed samples:     20627200 | elapsed time per iteration (ms): 618.1 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.974073E+00 | loss scale: 2097152.0 | grad norm: 0.481 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-26 11:23:13] iteration   322400/  500000 | consumed samples:     20633600 | elapsed time per iteration (ms): 619.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.971861E+00 | loss scale: 1048576.0 | grad norm: 0.481 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-26 11:24:15] iteration   322500/  500000 | consumed samples:     20640000 | elapsed time per iteration (ms): 618.3 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.967291E+00 | loss scale: 1048576.0 | grad norm: 0.481 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 11:25:17] iteration   322600/  500000 | consumed samples:     20646400 | elapsed time per iteration (ms): 622.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.968719E+00 | loss scale: 1048576.0 | grad norm: 0.488 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 11:26:19] iteration   322700/  500000 | consumed samples:     20652800 | elapsed time per iteration (ms): 620.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.976620E+00 | loss scale: 1048576.0 | grad norm: 0.486 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 11:27:21] iteration   322800/  500000 | consumed samples:     20659200 | elapsed time per iteration (ms): 619.3 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.972910E+00 | loss scale: 1048576.0 | grad norm: 0.492 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 11:28:23] iteration   322900/  500000 | consumed samples:     20665600 | elapsed time per iteration (ms): 619.1 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.984483E+00 | loss scale: 1048576.0 | grad norm: 0.487 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 11:29:25] iteration   323000/  500000 | consumed samples:     20672000 | elapsed time per iteration (ms): 619.5 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.962263E+00 | loss scale: 1048576.0 | grad norm: 0.493 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2462.05, 2462.22)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 323000 | lm loss value: 3.736310E+00 | lm loss PPL: 4.194292E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-26 11:30:29] iteration   323100/  500000 | consumed samples:     20678400 | elapsed time per iteration (ms): 619.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.975205E+00 | loss scale: 1048576.0 | grad norm: 0.506 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 11:31:31] iteration   323200/  500000 | consumed samples:     20684800 | elapsed time per iteration (ms): 619.2 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.964771E+00 | loss scale: 1048576.0 | grad norm: 0.483 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 11:32:33] iteration   323300/  500000 | consumed samples:     20691200 | elapsed time per iteration (ms): 618.6 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.956937E+00 | loss scale: 1048576.0 | grad norm: 0.483 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 11:33:35] iteration   323400/  500000 | consumed samples:     20697600 | elapsed time per iteration (ms): 617.5 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.965181E+00 | loss scale: 1048576.0 | grad norm: 0.481 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-26 11:34:37] iteration   323500/  500000 | consumed samples:     20704000 | elapsed time per iteration (ms): 619.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.969435E+00 | loss scale: 1048576.0 | grad norm: 0.484 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 11:35:39] iteration   323600/  500000 | consumed samples:     20710400 | elapsed time per iteration (ms): 621.5 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.958012E+00 | loss scale: 1048576.0 | grad norm: 0.502 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 11:36:41] iteration   323700/  500000 | consumed samples:     20716800 | elapsed time per iteration (ms): 621.2 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.975202E+00 | loss scale: 1048576.0 | grad norm: 0.487 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 11:37:43] iteration   323800/  500000 | consumed samples:     20723200 | elapsed time per iteration (ms): 619.7 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.969563E+00 | loss scale: 1048576.0 | grad norm: 0.479 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 11:38:45] iteration   323900/  500000 | consumed samples:     20729600 | elapsed time per iteration (ms): 618.6 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.972932E+00 | loss scale: 1048576.0 | grad norm: 0.500 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 11:39:47] iteration   324000/  500000 | consumed samples:     20736000 | elapsed time per iteration (ms): 619.5 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.977869E+00 | loss scale: 1048576.0 | grad norm: 0.485 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2461.37, 2461.42)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 324000 | lm loss value: 3.768029E+00 | lm loss PPL: 4.329465E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-26 11:40:51] iteration   324100/  500000 | consumed samples:     20742400 | elapsed time per iteration (ms): 617.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.959523E+00 | loss scale: 1048576.0 | grad norm: 0.478 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 11:41:53] iteration   324200/  500000 | consumed samples:     20748800 | elapsed time per iteration (ms): 618.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.961428E+00 | loss scale: 1048576.0 | grad norm: 0.491 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 11:42:55] iteration   324300/  500000 | consumed samples:     20755200 | elapsed time per iteration (ms): 619.7 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.967492E+00 | loss scale: 1048576.0 | grad norm: 0.497 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 11:43:57] iteration   324400/  500000 | consumed samples:     20761600 | elapsed time per iteration (ms): 618.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.975174E+00 | loss scale: 2097152.0 | grad norm: 0.496 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-26 11:44:59] iteration   324500/  500000 | consumed samples:     20768000 | elapsed time per iteration (ms): 618.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.963295E+00 | loss scale: 1048576.0 | grad norm: 0.484 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-26 11:46:00] iteration   324600/  500000 | consumed samples:     20774400 | elapsed time per iteration (ms): 619.3 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.961145E+00 | loss scale: 1048576.0 | grad norm: 0.488 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 11:47:03] iteration   324700/  500000 | consumed samples:     20780800 | elapsed time per iteration (ms): 620.6 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.963727E+00 | loss scale: 1048576.0 | grad norm: 0.482 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 11:48:04] iteration   324800/  500000 | consumed samples:     20787200 | elapsed time per iteration (ms): 617.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.962469E+00 | loss scale: 1048576.0 | grad norm: 0.492 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 11:49:06] iteration   324900/  500000 | consumed samples:     20793600 | elapsed time per iteration (ms): 619.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.963428E+00 | loss scale: 1048576.0 | grad norm: 0.497 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 11:50:08] iteration   325000/  500000 | consumed samples:     20800000 | elapsed time per iteration (ms): 619.4 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.975752E+00 | loss scale: 1048576.0 | grad norm: 0.487 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2461.94, 2461.97)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 325000 | lm loss value: 3.742058E+00 | lm loss PPL: 4.218473E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-26 11:51:13] iteration   325100/  500000 | consumed samples:     20806400 | elapsed time per iteration (ms): 620.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.973175E+00 | loss scale: 1048576.0 | grad norm: 0.523 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 11:52:15] iteration   325200/  500000 | consumed samples:     20812800 | elapsed time per iteration (ms): 619.6 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.960903E+00 | loss scale: 1048576.0 | grad norm: 0.483 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 11:53:17] iteration   325300/  500000 | consumed samples:     20819200 | elapsed time per iteration (ms): 619.7 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.977987E+00 | loss scale: 1048576.0 | grad norm: 0.476 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 11:54:18] iteration   325400/  500000 | consumed samples:     20825600 | elapsed time per iteration (ms): 617.2 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.957863E+00 | loss scale: 1048576.0 | grad norm: 0.502 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 11:55:20] iteration   325500/  500000 | consumed samples:     20832000 | elapsed time per iteration (ms): 620.6 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.970994E+00 | loss scale: 2097152.0 | grad norm: 0.489 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-26 11:56:22] iteration   325600/  500000 | consumed samples:     20838400 | elapsed time per iteration (ms): 620.2 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.968966E+00 | loss scale: 1048576.0 | grad norm: 0.482 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-26 11:57:24] iteration   325700/  500000 | consumed samples:     20844800 | elapsed time per iteration (ms): 620.2 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.970621E+00 | loss scale: 1048576.0 | grad norm: 0.483 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 11:58:26] iteration   325800/  500000 | consumed samples:     20851200 | elapsed time per iteration (ms): 618.5 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.971210E+00 | loss scale: 1048576.0 | grad norm: 0.494 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 11:59:28] iteration   325900/  500000 | consumed samples:     20857600 | elapsed time per iteration (ms): 619.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.957242E+00 | loss scale: 1048576.0 | grad norm: 0.470 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 12:00:30] iteration   326000/  500000 | consumed samples:     20864000 | elapsed time per iteration (ms): 621.4 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.961871E+00 | loss scale: 1048576.0 | grad norm: 0.486 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2462.92, 2463.09)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 326000 | lm loss value: 3.735798E+00 | lm loss PPL: 4.192145E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-26 12:01:35] iteration   326100/  500000 | consumed samples:     20870400 | elapsed time per iteration (ms): 619.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.958776E+00 | loss scale: 1048576.0 | grad norm: 0.478 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 12:02:37] iteration   326200/  500000 | consumed samples:     20876800 | elapsed time per iteration (ms): 621.1 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.959591E+00 | loss scale: 1048576.0 | grad norm: 0.485 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 12:03:39] iteration   326300/  500000 | consumed samples:     20883200 | elapsed time per iteration (ms): 620.7 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.958875E+00 | loss scale: 1048576.0 | grad norm: 0.484 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 12:04:41] iteration   326400/  500000 | consumed samples:     20889600 | elapsed time per iteration (ms): 617.6 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.966786E+00 | loss scale: 1048576.0 | grad norm: 0.492 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 12:05:43] iteration   326500/  500000 | consumed samples:     20896000 | elapsed time per iteration (ms): 619.3 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.970429E+00 | loss scale: 1048576.0 | grad norm: 0.494 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 12:06:44] iteration   326600/  500000 | consumed samples:     20902400 | elapsed time per iteration (ms): 618.3 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.962674E+00 | loss scale: 2097152.0 | grad norm: 0.496 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-26 12:07:46] iteration   326700/  500000 | consumed samples:     20908800 | elapsed time per iteration (ms): 619.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.962438E+00 | loss scale: 1048576.0 | grad norm: 0.482 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-26 12:08:48] iteration   326800/  500000 | consumed samples:     20915200 | elapsed time per iteration (ms): 620.1 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.957788E+00 | loss scale: 1048576.0 | grad norm: 0.489 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 12:09:50] iteration   326900/  500000 | consumed samples:     20921600 | elapsed time per iteration (ms): 620.4 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.965504E+00 | loss scale: 1048576.0 | grad norm: 0.485 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 12:10:52] iteration   327000/  500000 | consumed samples:     20928000 | elapsed time per iteration (ms): 619.4 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.963204E+00 | loss scale: 1048576.0 | grad norm: 0.488 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2462.00, 2462.08)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 327000 | lm loss value: 3.707917E+00 | lm loss PPL: 4.076880E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-26 12:11:57] iteration   327100/  500000 | consumed samples:     20934400 | elapsed time per iteration (ms): 619.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.949484E+00 | loss scale: 1048576.0 | grad norm: 0.487 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 12:12:59] iteration   327200/  500000 | consumed samples:     20940800 | elapsed time per iteration (ms): 619.3 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.980915E+00 | loss scale: 1048576.0 | grad norm: 0.493 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 12:14:00] iteration   327300/  500000 | consumed samples:     20947200 | elapsed time per iteration (ms): 618.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.957078E+00 | loss scale: 1048576.0 | grad norm: 0.485 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 12:15:03] iteration   327400/  500000 | consumed samples:     20953600 | elapsed time per iteration (ms): 620.3 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.956062E+00 | loss scale: 1048576.0 | grad norm: 0.505 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 12:16:04] iteration   327500/  500000 | consumed samples:     20960000 | elapsed time per iteration (ms): 618.3 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.955769E+00 | loss scale: 1048576.0 | grad norm: 0.476 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 12:17:06] iteration   327600/  500000 | consumed samples:     20966400 | elapsed time per iteration (ms): 620.6 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.954825E+00 | loss scale: 524288.0 | grad norm: 0.484 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-26 12:18:08] iteration   327700/  500000 | consumed samples:     20972800 | elapsed time per iteration (ms): 617.6 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.981437E+00 | loss scale: 524288.0 | grad norm: 0.489 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 12:19:10] iteration   327800/  500000 | consumed samples:     20979200 | elapsed time per iteration (ms): 619.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.966644E+00 | loss scale: 524288.0 | grad norm: 0.487 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 12:20:12] iteration   327900/  500000 | consumed samples:     20985600 | elapsed time per iteration (ms): 621.3 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.957300E+00 | loss scale: 524288.0 | grad norm: 0.485 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 12:21:14] iteration   328000/  500000 | consumed samples:     20992000 | elapsed time per iteration (ms): 619.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.975952E+00 | loss scale: 524288.0 | grad norm: 0.472 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2463.27, 2463.28)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 328000 | lm loss value: 3.691115E+00 | lm loss PPL: 4.008952E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-26 12:22:19] iteration   328100/  500000 | consumed samples:     20998400 | elapsed time per iteration (ms): 618.7 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.954676E+00 | loss scale: 524288.0 | grad norm: 0.483 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 12:23:21] iteration   328200/  500000 | consumed samples:     21004800 | elapsed time per iteration (ms): 620.2 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.968843E+00 | loss scale: 524288.0 | grad norm: 0.487 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 12:24:22] iteration   328300/  500000 | consumed samples:     21011200 | elapsed time per iteration (ms): 617.7 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.967776E+00 | loss scale: 524288.0 | grad norm: 0.492 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 12:25:24] iteration   328400/  500000 | consumed samples:     21017600 | elapsed time per iteration (ms): 619.6 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.975167E+00 | loss scale: 524288.0 | grad norm: 0.495 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 12:26:26] iteration   328500/  500000 | consumed samples:     21024000 | elapsed time per iteration (ms): 620.5 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.960385E+00 | loss scale: 524288.0 | grad norm: 0.480 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 12:27:28] iteration   328600/  500000 | consumed samples:     21030400 | elapsed time per iteration (ms): 619.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.969320E+00 | loss scale: 1048576.0 | grad norm: 0.487 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 12:28:30] iteration   328700/  500000 | consumed samples:     21036800 | elapsed time per iteration (ms): 615.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.970672E+00 | loss scale: 1048576.0 | grad norm: 0.477 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 12:29:32] iteration   328800/  500000 | consumed samples:     21043200 | elapsed time per iteration (ms): 617.1 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.959445E+00 | loss scale: 1048576.0 | grad norm: 0.494 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 12:30:34] iteration   328900/  500000 | consumed samples:     21049600 | elapsed time per iteration (ms): 619.3 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.968571E+00 | loss scale: 1048576.0 | grad norm: 0.492 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 12:31:35] iteration   329000/  500000 | consumed samples:     21056000 | elapsed time per iteration (ms): 618.4 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.967932E+00 | loss scale: 1048576.0 | grad norm: 0.502 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2460.85, 2460.96)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 329000 | lm loss value: 3.753487E+00 | lm loss PPL: 4.266963E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-26 12:32:40] iteration   329100/  500000 | consumed samples:     21062400 | elapsed time per iteration (ms): 620.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.971761E+00 | loss scale: 1048576.0 | grad norm: 0.487 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 12:33:42] iteration   329200/  500000 | consumed samples:     21068800 | elapsed time per iteration (ms): 619.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.966165E+00 | loss scale: 1048576.0 | grad norm: 0.477 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 12:34:44] iteration   329300/  500000 | consumed samples:     21075200 | elapsed time per iteration (ms): 620.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.967817E+00 | loss scale: 1048576.0 | grad norm: 0.500 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 12:35:46] iteration   329400/  500000 | consumed samples:     21081600 | elapsed time per iteration (ms): 618.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.958948E+00 | loss scale: 1048576.0 | grad norm: 0.477 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 12:36:48] iteration   329500/  500000 | consumed samples:     21088000 | elapsed time per iteration (ms): 619.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.971925E+00 | loss scale: 1048576.0 | grad norm: 0.494 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 12:37:50] iteration   329600/  500000 | consumed samples:     21094400 | elapsed time per iteration (ms): 619.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.965819E+00 | loss scale: 1048576.0 | grad norm: 0.484 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-26 12:38:52] iteration   329700/  500000 | consumed samples:     21100800 | elapsed time per iteration (ms): 619.4 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.964744E+00 | loss scale: 1048576.0 | grad norm: 0.475 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 12:39:53] iteration   329800/  500000 | consumed samples:     21107200 | elapsed time per iteration (ms): 618.3 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.967328E+00 | loss scale: 1048576.0 | grad norm: 0.499 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 12:40:56] iteration   329900/  500000 | consumed samples:     21113600 | elapsed time per iteration (ms): 622.1 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.960024E+00 | loss scale: 1048576.0 | grad norm: 0.485 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 12:41:57] iteration   330000/  500000 | consumed samples:     21120000 | elapsed time per iteration (ms): 618.6 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.981792E+00 | loss scale: 1048576.0 | grad norm: 0.483 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2461.45, 2461.49)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 330000 | lm loss value: 3.785159E+00 | lm loss PPL: 4.404267E+01 | 
--------------------------------------------------------------------------------------------------
saving checkpoint at iteration  330000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-distribution in torch format
  successfully saved checkpoint at iteration  330000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-distribution
(min, max) time across ranks (ms):
    save-checkpoint ................................: (2318.76, 2318.79)
 [2024-06-26 12:43:04] iteration   330100/  500000 | consumed samples:     21126400 | elapsed time per iteration (ms): 617.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.960681E+00 | loss scale: 1048576.0 | grad norm: 0.492 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 12:44:06] iteration   330200/  500000 | consumed samples:     21132800 | elapsed time per iteration (ms): 619.5 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.956998E+00 | loss scale: 1048576.0 | grad norm: 0.499 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 12:45:08] iteration   330300/  500000 | consumed samples:     21139200 | elapsed time per iteration (ms): 619.5 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.974890E+00 | loss scale: 1048576.0 | grad norm: 0.494 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 12:46:10] iteration   330400/  500000 | consumed samples:     21145600 | elapsed time per iteration (ms): 618.4 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.973776E+00 | loss scale: 1048576.0 | grad norm: 0.488 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 12:47:12] iteration   330500/  500000 | consumed samples:     21152000 | elapsed time per iteration (ms): 619.4 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.956521E+00 | loss scale: 1048576.0 | grad norm: 0.486 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 12:48:14] iteration   330600/  500000 | consumed samples:     21158400 | elapsed time per iteration (ms): 618.6 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.978415E+00 | loss scale: 2097152.0 | grad norm: 0.489 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 12:49:15] iteration   330700/  500000 | consumed samples:     21164800 | elapsed time per iteration (ms): 619.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.959019E+00 | loss scale: 2097152.0 | grad norm: 0.488 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 12:50:17] iteration   330800/  500000 | consumed samples:     21171200 | elapsed time per iteration (ms): 619.4 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.954820E+00 | loss scale: 1048576.0 | grad norm: 0.485 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-26 12:51:19] iteration   330900/  500000 | consumed samples:     21177600 | elapsed time per iteration (ms): 619.1 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.961890E+00 | loss scale: 1048576.0 | grad norm: 0.505 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 12:52:21] iteration   331000/  500000 | consumed samples:     21184000 | elapsed time per iteration (ms): 619.2 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.960853E+00 | loss scale: 1048576.0 | grad norm: 0.488 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2461.11, 2461.23)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 331000 | lm loss value: 3.738663E+00 | lm loss PPL: 4.204173E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-26 12:53:25] iteration   331100/  500000 | consumed samples:     21190400 | elapsed time per iteration (ms): 618.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.964798E+00 | loss scale: 1048576.0 | grad norm: 0.502 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 12:54:27] iteration   331200/  500000 | consumed samples:     21196800 | elapsed time per iteration (ms): 618.5 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.964201E+00 | loss scale: 1048576.0 | grad norm: 0.472 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 12:55:29] iteration   331300/  500000 | consumed samples:     21203200 | elapsed time per iteration (ms): 618.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.969042E+00 | loss scale: 1048576.0 | grad norm: 0.495 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 12:56:31] iteration   331400/  500000 | consumed samples:     21209600 | elapsed time per iteration (ms): 618.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.968126E+00 | loss scale: 1048576.0 | grad norm: 0.483 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 12:57:33] iteration   331500/  500000 | consumed samples:     21216000 | elapsed time per iteration (ms): 617.3 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.966178E+00 | loss scale: 1048576.0 | grad norm: 0.485 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 12:58:35] iteration   331600/  500000 | consumed samples:     21222400 | elapsed time per iteration (ms): 618.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.959710E+00 | loss scale: 1048576.0 | grad norm: 0.505 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 12:59:37] iteration   331700/  500000 | consumed samples:     21228800 | elapsed time per iteration (ms): 619.4 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.962224E+00 | loss scale: 1048576.0 | grad norm: 0.500 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 13:00:38] iteration   331800/  500000 | consumed samples:     21235200 | elapsed time per iteration (ms): 618.3 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.963069E+00 | loss scale: 1048576.0 | grad norm: 0.486 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-26 13:01:40] iteration   331900/  500000 | consumed samples:     21241600 | elapsed time per iteration (ms): 620.5 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.975999E+00 | loss scale: 1048576.0 | grad norm: 0.490 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 13:02:42] iteration   332000/  500000 | consumed samples:     21248000 | elapsed time per iteration (ms): 619.3 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.948874E+00 | loss scale: 1048576.0 | grad norm: 0.504 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2461.52, 2461.77)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 332000 | lm loss value: 3.699626E+00 | lm loss PPL: 4.043217E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-26 13:03:47] iteration   332100/  500000 | consumed samples:     21254400 | elapsed time per iteration (ms): 618.5 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.966474E+00 | loss scale: 1048576.0 | grad norm: 0.488 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 13:04:48] iteration   332200/  500000 | consumed samples:     21260800 | elapsed time per iteration (ms): 617.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.977567E+00 | loss scale: 1048576.0 | grad norm: 0.494 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 13:05:51] iteration   332300/  500000 | consumed samples:     21267200 | elapsed time per iteration (ms): 622.2 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.964546E+00 | loss scale: 1048576.0 | grad norm: 0.482 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 13:06:53] iteration   332400/  500000 | consumed samples:     21273600 | elapsed time per iteration (ms): 618.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.964283E+00 | loss scale: 1048576.0 | grad norm: 0.479 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 13:07:55] iteration   332500/  500000 | consumed samples:     21280000 | elapsed time per iteration (ms): 619.7 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.958800E+00 | loss scale: 1048576.0 | grad norm: 0.488 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 13:08:56] iteration   332600/  500000 | consumed samples:     21286400 | elapsed time per iteration (ms): 619.5 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.965759E+00 | loss scale: 1048576.0 | grad norm: 0.497 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 13:09:58] iteration   332700/  500000 | consumed samples:     21292800 | elapsed time per iteration (ms): 619.3 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.957070E+00 | loss scale: 1048576.0 | grad norm: 0.483 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 13:11:00] iteration   332800/  500000 | consumed samples:     21299200 | elapsed time per iteration (ms): 618.4 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.968628E+00 | loss scale: 2097152.0 | grad norm: 0.484 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 13:12:02] iteration   332900/  500000 | consumed samples:     21305600 | elapsed time per iteration (ms): 619.6 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.967598E+00 | loss scale: 1048576.0 | grad norm: 0.484 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-26 13:13:04] iteration   333000/  500000 | consumed samples:     21312000 | elapsed time per iteration (ms): 617.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.969751E+00 | loss scale: 1048576.0 | grad norm: 0.496 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2462.51, 2462.64)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 333000 | lm loss value: 3.700674E+00 | lm loss PPL: 4.047457E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-26 13:14:08] iteration   333100/  500000 | consumed samples:     21318400 | elapsed time per iteration (ms): 620.2 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.962050E+00 | loss scale: 1048576.0 | grad norm: 0.484 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 13:15:10] iteration   333200/  500000 | consumed samples:     21324800 | elapsed time per iteration (ms): 619.7 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.964052E+00 | loss scale: 1048576.0 | grad norm: 0.493 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 13:16:12] iteration   333300/  500000 | consumed samples:     21331200 | elapsed time per iteration (ms): 620.3 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.965095E+00 | loss scale: 1048576.0 | grad norm: 0.486 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 13:17:14] iteration   333400/  500000 | consumed samples:     21337600 | elapsed time per iteration (ms): 618.2 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.963332E+00 | loss scale: 1048576.0 | grad norm: 0.476 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 13:18:16] iteration   333500/  500000 | consumed samples:     21344000 | elapsed time per iteration (ms): 617.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.986714E+00 | loss scale: 1048576.0 | grad norm: 0.472 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 13:19:18] iteration   333600/  500000 | consumed samples:     21350400 | elapsed time per iteration (ms): 618.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.960874E+00 | loss scale: 1048576.0 | grad norm: 0.479 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 13:20:20] iteration   333700/  500000 | consumed samples:     21356800 | elapsed time per iteration (ms): 619.1 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.942538E+00 | loss scale: 1048576.0 | grad norm: 0.505 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 13:21:22] iteration   333800/  500000 | consumed samples:     21363200 | elapsed time per iteration (ms): 619.5 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.945025E+00 | loss scale: 1048576.0 | grad norm: 0.500 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 13:22:24] iteration   333900/  500000 | consumed samples:     21369600 | elapsed time per iteration (ms): 618.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.962963E+00 | loss scale: 2097152.0 | grad norm: 0.506 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-26 13:23:26] iteration   334000/  500000 | consumed samples:     21376000 | elapsed time per iteration (ms): 619.1 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.954927E+00 | loss scale: 1048576.0 | grad norm: 0.477 | number of skipped iterations:   1 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2461.28, 2461.45)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 334000 | lm loss value: 3.700705E+00 | lm loss PPL: 4.047581E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-26 13:24:30] iteration   334100/  500000 | consumed samples:     21382400 | elapsed time per iteration (ms): 618.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.953898E+00 | loss scale: 1048576.0 | grad norm: 0.483 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 13:25:32] iteration   334200/  500000 | consumed samples:     21388800 | elapsed time per iteration (ms): 620.3 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.970914E+00 | loss scale: 1048576.0 | grad norm: 0.484 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 13:26:34] iteration   334300/  500000 | consumed samples:     21395200 | elapsed time per iteration (ms): 621.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.969914E+00 | loss scale: 1048576.0 | grad norm: 0.485 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 13:27:36] iteration   334400/  500000 | consumed samples:     21401600 | elapsed time per iteration (ms): 617.2 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.985072E+00 | loss scale: 1048576.0 | grad norm: 0.480 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 13:28:38] iteration   334500/  500000 | consumed samples:     21408000 | elapsed time per iteration (ms): 618.4 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.960794E+00 | loss scale: 1048576.0 | grad norm: 0.482 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 13:29:40] iteration   334600/  500000 | consumed samples:     21414400 | elapsed time per iteration (ms): 619.6 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.961797E+00 | loss scale: 1048576.0 | grad norm: 0.497 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 13:30:41] iteration   334700/  500000 | consumed samples:     21420800 | elapsed time per iteration (ms): 617.6 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.955757E+00 | loss scale: 1048576.0 | grad norm: 0.491 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 13:31:43] iteration   334800/  500000 | consumed samples:     21427200 | elapsed time per iteration (ms): 619.5 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.973119E+00 | loss scale: 1048576.0 | grad norm: 0.495 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 13:32:45] iteration   334900/  500000 | consumed samples:     21433600 | elapsed time per iteration (ms): 620.2 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.957327E+00 | loss scale: 1048576.0 | grad norm: 0.484 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 13:33:47] iteration   335000/  500000 | consumed samples:     21440000 | elapsed time per iteration (ms): 619.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.981716E+00 | loss scale: 2097152.0 | grad norm: 0.488 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2463.60, 2463.65)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 335000 | lm loss value: 3.708673E+00 | lm loss PPL: 4.079965E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-26 13:34:52] iteration   335100/  500000 | consumed samples:     21446400 | elapsed time per iteration (ms): 617.6 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.971166E+00 | loss scale: 1048576.0 | grad norm: 0.470 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-26 13:35:54] iteration   335200/  500000 | consumed samples:     21452800 | elapsed time per iteration (ms): 619.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.953201E+00 | loss scale: 1048576.0 | grad norm: 0.497 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 13:36:55] iteration   335300/  500000 | consumed samples:     21459200 | elapsed time per iteration (ms): 617.6 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.965190E+00 | loss scale: 1048576.0 | grad norm: 0.494 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 13:37:57] iteration   335400/  500000 | consumed samples:     21465600 | elapsed time per iteration (ms): 617.6 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.970235E+00 | loss scale: 1048576.0 | grad norm: 0.488 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 13:38:59] iteration   335500/  500000 | consumed samples:     21472000 | elapsed time per iteration (ms): 619.5 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.962267E+00 | loss scale: 1048576.0 | grad norm: 0.488 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 13:40:01] iteration   335600/  500000 | consumed samples:     21478400 | elapsed time per iteration (ms): 619.4 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.966504E+00 | loss scale: 1048576.0 | grad norm: 0.495 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 13:41:03] iteration   335700/  500000 | consumed samples:     21484800 | elapsed time per iteration (ms): 617.5 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.960166E+00 | loss scale: 1048576.0 | grad norm: 0.488 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 13:42:04] iteration   335800/  500000 | consumed samples:     21491200 | elapsed time per iteration (ms): 616.5 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.960052E+00 | loss scale: 1048576.0 | grad norm: 0.488 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 13:43:06] iteration   335900/  500000 | consumed samples:     21497600 | elapsed time per iteration (ms): 616.7 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.953070E+00 | loss scale: 1048576.0 | grad norm: 0.481 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 13:44:08] iteration   336000/  500000 | consumed samples:     21504000 | elapsed time per iteration (ms): 618.2 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.966205E+00 | loss scale: 1048576.0 | grad norm: 0.501 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2461.70, 2461.77)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 336000 | lm loss value: 3.765682E+00 | lm loss PPL: 4.319316E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-26 13:45:12] iteration   336100/  500000 | consumed samples:     21510400 | elapsed time per iteration (ms): 618.6 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.962024E+00 | loss scale: 1048576.0 | grad norm: 0.477 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-26 13:46:14] iteration   336200/  500000 | consumed samples:     21516800 | elapsed time per iteration (ms): 618.4 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.962517E+00 | loss scale: 1048576.0 | grad norm: 0.496 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 13:47:16] iteration   336300/  500000 | consumed samples:     21523200 | elapsed time per iteration (ms): 617.6 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.973925E+00 | loss scale: 1048576.0 | grad norm: 0.486 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 13:48:18] iteration   336400/  500000 | consumed samples:     21529600 | elapsed time per iteration (ms): 620.7 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.960678E+00 | loss scale: 1048576.0 | grad norm: 0.495 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 13:49:20] iteration   336500/  500000 | consumed samples:     21536000 | elapsed time per iteration (ms): 620.3 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.973214E+00 | loss scale: 1048576.0 | grad norm: 0.494 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 13:50:22] iteration   336600/  500000 | consumed samples:     21542400 | elapsed time per iteration (ms): 620.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.959519E+00 | loss scale: 1048576.0 | grad norm: 0.500 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 13:51:24] iteration   336700/  500000 | consumed samples:     21548800 | elapsed time per iteration (ms): 620.4 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.967835E+00 | loss scale: 1048576.0 | grad norm: 0.496 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 13:52:26] iteration   336800/  500000 | consumed samples:     21555200 | elapsed time per iteration (ms): 619.7 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.960414E+00 | loss scale: 1048576.0 | grad norm: 0.498 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 13:53:28] iteration   336900/  500000 | consumed samples:     21561600 | elapsed time per iteration (ms): 619.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.953867E+00 | loss scale: 1048576.0 | grad norm: 0.485 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 13:54:30] iteration   337000/  500000 | consumed samples:     21568000 | elapsed time per iteration (ms): 619.7 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.969213E+00 | loss scale: 1048576.0 | grad norm: 0.485 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2461.45, 2461.53)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 337000 | lm loss value: 3.737031E+00 | lm loss PPL: 4.197317E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-26 13:55:34] iteration   337100/  500000 | consumed samples:     21574400 | elapsed time per iteration (ms): 617.5 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.958360E+00 | loss scale: 2097152.0 | grad norm: 0.478 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 13:56:36] iteration   337200/  500000 | consumed samples:     21580800 | elapsed time per iteration (ms): 617.5 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.953795E+00 | loss scale: 1048576.0 | grad norm: 0.484 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-26 13:57:37] iteration   337300/  500000 | consumed samples:     21587200 | elapsed time per iteration (ms): 617.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.962401E+00 | loss scale: 1048576.0 | grad norm: 0.491 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 13:58:39] iteration   337400/  500000 | consumed samples:     21593600 | elapsed time per iteration (ms): 618.7 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.975760E+00 | loss scale: 1048576.0 | grad norm: 0.490 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 13:59:41] iteration   337500/  500000 | consumed samples:     21600000 | elapsed time per iteration (ms): 618.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.956552E+00 | loss scale: 1048576.0 | grad norm: 0.481 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 14:00:43] iteration   337600/  500000 | consumed samples:     21606400 | elapsed time per iteration (ms): 621.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.959924E+00 | loss scale: 1048576.0 | grad norm: 0.491 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 14:01:45] iteration   337700/  500000 | consumed samples:     21612800 | elapsed time per iteration (ms): 618.7 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.966132E+00 | loss scale: 1048576.0 | grad norm: 0.495 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 14:02:47] iteration   337800/  500000 | consumed samples:     21619200 | elapsed time per iteration (ms): 619.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.964674E+00 | loss scale: 1048576.0 | grad norm: 0.488 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 14:03:49] iteration   337900/  500000 | consumed samples:     21625600 | elapsed time per iteration (ms): 620.7 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.962832E+00 | loss scale: 1048576.0 | grad norm: 0.481 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 14:04:51] iteration   338000/  500000 | consumed samples:     21632000 | elapsed time per iteration (ms): 618.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.973956E+00 | loss scale: 1048576.0 | grad norm: 0.493 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2462.81, 2462.93)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 338000 | lm loss value: 3.749451E+00 | lm loss PPL: 4.249776E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-26 14:05:56] iteration   338100/  500000 | consumed samples:     21638400 | elapsed time per iteration (ms): 620.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.957166E+00 | loss scale: 1048576.0 | grad norm: 0.495 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 14:06:58] iteration   338200/  500000 | consumed samples:     21644800 | elapsed time per iteration (ms): 618.7 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.970359E+00 | loss scale: 2097152.0 | grad norm: 0.516 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 14:07:59] iteration   338300/  500000 | consumed samples:     21651200 | elapsed time per iteration (ms): 619.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.962822E+00 | loss scale: 1048576.0 | grad norm: 0.506 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-26 14:09:02] iteration   338400/  500000 | consumed samples:     21657600 | elapsed time per iteration (ms): 620.2 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.952264E+00 | loss scale: 1048576.0 | grad norm: 0.483 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 14:10:03] iteration   338500/  500000 | consumed samples:     21664000 | elapsed time per iteration (ms): 619.4 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.944538E+00 | loss scale: 1048576.0 | grad norm: 0.505 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 14:11:05] iteration   338600/  500000 | consumed samples:     21670400 | elapsed time per iteration (ms): 618.3 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.950516E+00 | loss scale: 1048576.0 | grad norm: 0.496 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 14:12:07] iteration   338700/  500000 | consumed samples:     21676800 | elapsed time per iteration (ms): 617.6 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.962362E+00 | loss scale: 1048576.0 | grad norm: 0.497 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 14:13:09] iteration   338800/  500000 | consumed samples:     21683200 | elapsed time per iteration (ms): 620.4 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.960432E+00 | loss scale: 1048576.0 | grad norm: 0.489 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 14:14:11] iteration   338900/  500000 | consumed samples:     21689600 | elapsed time per iteration (ms): 618.2 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.966651E+00 | loss scale: 1048576.0 | grad norm: 0.488 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 14:15:13] iteration   339000/  500000 | consumed samples:     21696000 | elapsed time per iteration (ms): 619.5 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.964262E+00 | loss scale: 1048576.0 | grad norm: 0.485 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2462.16, 2462.18)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 339000 | lm loss value: 3.780490E+00 | lm loss PPL: 4.383750E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-26 14:16:17] iteration   339100/  500000 | consumed samples:     21702400 | elapsed time per iteration (ms): 618.1 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.963533E+00 | loss scale: 1048576.0 | grad norm: 0.494 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 14:17:19] iteration   339200/  500000 | consumed samples:     21708800 | elapsed time per iteration (ms): 619.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.956461E+00 | loss scale: 1048576.0 | grad norm: 0.495 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 14:18:21] iteration   339300/  500000 | consumed samples:     21715200 | elapsed time per iteration (ms): 616.6 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.960375E+00 | loss scale: 2097152.0 | grad norm: 0.484 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 14:19:22] iteration   339400/  500000 | consumed samples:     21721600 | elapsed time per iteration (ms): 616.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.954327E+00 | loss scale: 1048576.0 | grad norm: 0.481 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-26 14:20:24] iteration   339500/  500000 | consumed samples:     21728000 | elapsed time per iteration (ms): 620.3 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.969530E+00 | loss scale: 1048576.0 | grad norm: 0.487 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 14:21:26] iteration   339600/  500000 | consumed samples:     21734400 | elapsed time per iteration (ms): 619.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.959412E+00 | loss scale: 1048576.0 | grad norm: 0.493 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 14:22:28] iteration   339700/  500000 | consumed samples:     21740800 | elapsed time per iteration (ms): 619.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.951075E+00 | loss scale: 1048576.0 | grad norm: 0.493 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 14:23:30] iteration   339800/  500000 | consumed samples:     21747200 | elapsed time per iteration (ms): 620.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.984629E+00 | loss scale: 1048576.0 | grad norm: 0.486 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 14:24:32] iteration   339900/  500000 | consumed samples:     21753600 | elapsed time per iteration (ms): 619.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.958619E+00 | loss scale: 1048576.0 | grad norm: 0.484 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 14:25:34] iteration   340000/  500000 | consumed samples:     21760000 | elapsed time per iteration (ms): 617.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.973513E+00 | loss scale: 1048576.0 | grad norm: 0.496 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2462.45, 2462.49)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 340000 | lm loss value: 3.742674E+00 | lm loss PPL: 4.221070E+01 | 
--------------------------------------------------------------------------------------------------
saving checkpoint at iteration  340000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-distribution in torch format
  successfully saved checkpoint at iteration  340000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-distribution
(min, max) time across ranks (ms):
    save-checkpoint ................................: (2340.64, 2340.65)
 [2024-06-26 14:26:41] iteration   340100/  500000 | consumed samples:     21766400 | elapsed time per iteration (ms): 618.1 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.974905E+00 | loss scale: 1048576.0 | grad norm: 0.490 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 14:27:43] iteration   340200/  500000 | consumed samples:     21772800 | elapsed time per iteration (ms): 618.1 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.960001E+00 | loss scale: 1048576.0 | grad norm: 0.500 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 14:28:44] iteration   340300/  500000 | consumed samples:     21779200 | elapsed time per iteration (ms): 618.6 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.954089E+00 | loss scale: 1048576.0 | grad norm: 0.497 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 14:29:46] iteration   340400/  500000 | consumed samples:     21785600 | elapsed time per iteration (ms): 617.6 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.956649E+00 | loss scale: 2097152.0 | grad norm: 0.483 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 14:30:48] iteration   340500/  500000 | consumed samples:     21792000 | elapsed time per iteration (ms): 619.4 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.962426E+00 | loss scale: 1048576.0 | grad norm: 0.482 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-26 14:31:50] iteration   340600/  500000 | consumed samples:     21798400 | elapsed time per iteration (ms): 619.4 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.953784E+00 | loss scale: 1048576.0 | grad norm: 0.491 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 14:32:52] iteration   340700/  500000 | consumed samples:     21804800 | elapsed time per iteration (ms): 620.7 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.960164E+00 | loss scale: 1048576.0 | grad norm: 0.491 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 14:33:54] iteration   340800/  500000 | consumed samples:     21811200 | elapsed time per iteration (ms): 620.2 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.962799E+00 | loss scale: 1048576.0 | grad norm: 0.495 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 14:34:56] iteration   340900/  500000 | consumed samples:     21817600 | elapsed time per iteration (ms): 620.5 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.967999E+00 | loss scale: 1048576.0 | grad norm: 0.488 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 14:35:58] iteration   341000/  500000 | consumed samples:     21824000 | elapsed time per iteration (ms): 618.5 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.971126E+00 | loss scale: 1048576.0 | grad norm: 0.483 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2462.18, 2462.18)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 341000 | lm loss value: 3.704541E+00 | lm loss PPL: 4.063141E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-26 14:37:02] iteration   341100/  500000 | consumed samples:     21830400 | elapsed time per iteration (ms): 619.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.975917E+00 | loss scale: 1048576.0 | grad norm: 0.507 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 14:38:04] iteration   341200/  500000 | consumed samples:     21836800 | elapsed time per iteration (ms): 618.7 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.977620E+00 | loss scale: 1048576.0 | grad norm: 0.506 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 14:39:06] iteration   341300/  500000 | consumed samples:     21843200 | elapsed time per iteration (ms): 618.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.959908E+00 | loss scale: 1048576.0 | grad norm: 0.491 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 14:40:08] iteration   341400/  500000 | consumed samples:     21849600 | elapsed time per iteration (ms): 619.2 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.956426E+00 | loss scale: 1048576.0 | grad norm: 0.501 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 14:41:10] iteration   341500/  500000 | consumed samples:     21856000 | elapsed time per iteration (ms): 619.6 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.965464E+00 | loss scale: 2097152.0 | grad norm: 0.494 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-26 14:42:12] iteration   341600/  500000 | consumed samples:     21862400 | elapsed time per iteration (ms): 618.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.953227E+00 | loss scale: 1048576.0 | grad norm: 0.500 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-26 14:43:14] iteration   341700/  500000 | consumed samples:     21868800 | elapsed time per iteration (ms): 616.1 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.955791E+00 | loss scale: 1048576.0 | grad norm: 0.490 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 14:44:15] iteration   341800/  500000 | consumed samples:     21875200 | elapsed time per iteration (ms): 619.3 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.957475E+00 | loss scale: 1048576.0 | grad norm: 0.497 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 14:45:17] iteration   341900/  500000 | consumed samples:     21881600 | elapsed time per iteration (ms): 617.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.965480E+00 | loss scale: 1048576.0 | grad norm: 0.492 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 14:46:19] iteration   342000/  500000 | consumed samples:     21888000 | elapsed time per iteration (ms): 618.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.966749E+00 | loss scale: 1048576.0 | grad norm: 0.492 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2461.44, 2461.59)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 342000 | lm loss value: 3.693427E+00 | lm loss PPL: 4.018233E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-26 14:47:23] iteration   342100/  500000 | consumed samples:     21894400 | elapsed time per iteration (ms): 617.1 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.975264E+00 | loss scale: 1048576.0 | grad norm: 0.494 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 14:48:25] iteration   342200/  500000 | consumed samples:     21900800 | elapsed time per iteration (ms): 619.1 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.974533E+00 | loss scale: 1048576.0 | grad norm: 0.489 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 14:49:27] iteration   342300/  500000 | consumed samples:     21907200 | elapsed time per iteration (ms): 616.7 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.965000E+00 | loss scale: 1048576.0 | grad norm: 0.494 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 14:50:29] iteration   342400/  500000 | consumed samples:     21913600 | elapsed time per iteration (ms): 617.3 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.961535E+00 | loss scale: 1048576.0 | grad norm: 0.493 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 14:51:30] iteration   342500/  500000 | consumed samples:     21920000 | elapsed time per iteration (ms): 617.2 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.971492E+00 | loss scale: 1048576.0 | grad norm: 0.488 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 14:52:32] iteration   342600/  500000 | consumed samples:     21926400 | elapsed time per iteration (ms): 617.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.961962E+00 | loss scale: 2097152.0 | grad norm: 0.484 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 14:53:34] iteration   342700/  500000 | consumed samples:     21932800 | elapsed time per iteration (ms): 618.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.961665E+00 | loss scale: 2097152.0 | grad norm: 0.486 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-26 14:54:36] iteration   342800/  500000 | consumed samples:     21939200 | elapsed time per iteration (ms): 617.5 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.964753E+00 | loss scale: 1048576.0 | grad norm: 0.489 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-26 14:55:37] iteration   342900/  500000 | consumed samples:     21945600 | elapsed time per iteration (ms): 618.3 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.973935E+00 | loss scale: 1048576.0 | grad norm: 0.494 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 14:56:39] iteration   343000/  500000 | consumed samples:     21952000 | elapsed time per iteration (ms): 617.4 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.969168E+00 | loss scale: 1048576.0 | grad norm: 0.506 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2464.41, 2464.44)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 343000 | lm loss value: 3.729473E+00 | lm loss PPL: 4.165714E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-26 14:57:44] iteration   343100/  500000 | consumed samples:     21958400 | elapsed time per iteration (ms): 620.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.956760E+00 | loss scale: 1048576.0 | grad norm: 0.490 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 14:58:45] iteration   343200/  500000 | consumed samples:     21964800 | elapsed time per iteration (ms): 617.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.950923E+00 | loss scale: 1048576.0 | grad norm: 0.499 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 14:59:47] iteration   343300/  500000 | consumed samples:     21971200 | elapsed time per iteration (ms): 619.4 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.953825E+00 | loss scale: 1048576.0 | grad norm: 0.490 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 15:00:49] iteration   343400/  500000 | consumed samples:     21977600 | elapsed time per iteration (ms): 615.7 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.951631E+00 | loss scale: 1048576.0 | grad norm: 0.504 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 15:01:51] iteration   343500/  500000 | consumed samples:     21984000 | elapsed time per iteration (ms): 618.4 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.970820E+00 | loss scale: 1048576.0 | grad norm: 0.491 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 15:02:53] iteration   343600/  500000 | consumed samples:     21990400 | elapsed time per iteration (ms): 618.2 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.966301E+00 | loss scale: 1048576.0 | grad norm: 0.482 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 15:03:54] iteration   343700/  500000 | consumed samples:     21996800 | elapsed time per iteration (ms): 618.3 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.954383E+00 | loss scale: 1048576.0 | grad norm: 0.488 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 15:04:56] iteration   343800/  500000 | consumed samples:     22003200 | elapsed time per iteration (ms): 619.5 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.973515E+00 | loss scale: 1048576.0 | grad norm: 0.485 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-26 15:05:58] iteration   343900/  500000 | consumed samples:     22009600 | elapsed time per iteration (ms): 618.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.951343E+00 | loss scale: 1048576.0 | grad norm: 0.485 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 15:07:00] iteration   344000/  500000 | consumed samples:     22016000 | elapsed time per iteration (ms): 619.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.955713E+00 | loss scale: 1048576.0 | grad norm: 0.500 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2464.04, 2464.14)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 344000 | lm loss value: 3.762859E+00 | lm loss PPL: 4.307140E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-26 15:08:05] iteration   344100/  500000 | consumed samples:     22022400 | elapsed time per iteration (ms): 620.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.958569E+00 | loss scale: 1048576.0 | grad norm: 0.491 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 15:09:07] iteration   344200/  500000 | consumed samples:     22028800 | elapsed time per iteration (ms): 619.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.962500E+00 | loss scale: 1048576.0 | grad norm: 0.488 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 15:10:09] iteration   344300/  500000 | consumed samples:     22035200 | elapsed time per iteration (ms): 618.6 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.948291E+00 | loss scale: 1048576.0 | grad norm: 0.513 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 15:11:10] iteration   344400/  500000 | consumed samples:     22041600 | elapsed time per iteration (ms): 618.3 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.963090E+00 | loss scale: 1048576.0 | grad norm: 0.482 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 15:12:12] iteration   344500/  500000 | consumed samples:     22048000 | elapsed time per iteration (ms): 620.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.967384E+00 | loss scale: 1048576.0 | grad norm: 0.491 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 15:13:14] iteration   344600/  500000 | consumed samples:     22054400 | elapsed time per iteration (ms): 619.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.949730E+00 | loss scale: 1048576.0 | grad norm: 0.496 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 15:14:16] iteration   344700/  500000 | consumed samples:     22060800 | elapsed time per iteration (ms): 620.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.958531E+00 | loss scale: 1048576.0 | grad norm: 0.496 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 15:15:18] iteration   344800/  500000 | consumed samples:     22067200 | elapsed time per iteration (ms): 619.6 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.964588E+00 | loss scale: 2097152.0 | grad norm: 0.496 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 15:16:21] iteration   344900/  500000 | consumed samples:     22073600 | elapsed time per iteration (ms): 621.4 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.957108E+00 | loss scale: 1048576.0 | grad norm: 0.489 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-26 15:17:22] iteration   345000/  500000 | consumed samples:     22080000 | elapsed time per iteration (ms): 617.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.955931E+00 | loss scale: 1048576.0 | grad norm: 0.487 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2461.60, 2461.89)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 345000 | lm loss value: 3.757765E+00 | lm loss PPL: 4.285256E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-26 15:18:27] iteration   345100/  500000 | consumed samples:     22086400 | elapsed time per iteration (ms): 618.7 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.954193E+00 | loss scale: 1048576.0 | grad norm: 0.500 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 15:19:29] iteration   345200/  500000 | consumed samples:     22092800 | elapsed time per iteration (ms): 618.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.949617E+00 | loss scale: 1048576.0 | grad norm: 0.491 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 15:20:30] iteration   345300/  500000 | consumed samples:     22099200 | elapsed time per iteration (ms): 617.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.965509E+00 | loss scale: 1048576.0 | grad norm: 0.489 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 15:21:32] iteration   345400/  500000 | consumed samples:     22105600 | elapsed time per iteration (ms): 618.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.974756E+00 | loss scale: 1048576.0 | grad norm: 0.492 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 15:22:34] iteration   345500/  500000 | consumed samples:     22112000 | elapsed time per iteration (ms): 618.2 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.949006E+00 | loss scale: 1048576.0 | grad norm: 0.495 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 15:23:36] iteration   345600/  500000 | consumed samples:     22118400 | elapsed time per iteration (ms): 619.5 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.955094E+00 | loss scale: 1048576.0 | grad norm: 0.503 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 15:24:38] iteration   345700/  500000 | consumed samples:     22124800 | elapsed time per iteration (ms): 621.1 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.970470E+00 | loss scale: 1048576.0 | grad norm: 0.502 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 15:25:40] iteration   345800/  500000 | consumed samples:     22131200 | elapsed time per iteration (ms): 619.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.975712E+00 | loss scale: 1048576.0 | grad norm: 0.496 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 15:26:42] iteration   345900/  500000 | consumed samples:     22137600 | elapsed time per iteration (ms): 617.5 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.985864E+00 | loss scale: 2097152.0 | grad norm: 0.492 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-26 15:27:44] iteration   346000/  500000 | consumed samples:     22144000 | elapsed time per iteration (ms): 618.4 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.960960E+00 | loss scale: 1048576.0 | grad norm: 0.487 | number of skipped iterations:   1 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2461.69, 2461.69)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 346000 | lm loss value: 3.689758E+00 | lm loss PPL: 4.003514E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-26 15:28:48] iteration   346100/  500000 | consumed samples:     22150400 | elapsed time per iteration (ms): 618.1 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.945604E+00 | loss scale: 1048576.0 | grad norm: 0.493 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 15:29:50] iteration   346200/  500000 | consumed samples:     22156800 | elapsed time per iteration (ms): 619.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.967847E+00 | loss scale: 1048576.0 | grad norm: 0.488 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 15:30:52] iteration   346300/  500000 | consumed samples:     22163200 | elapsed time per iteration (ms): 617.7 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.955466E+00 | loss scale: 1048576.0 | grad norm: 0.484 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 15:31:53] iteration   346400/  500000 | consumed samples:     22169600 | elapsed time per iteration (ms): 617.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.956023E+00 | loss scale: 1048576.0 | grad norm: 0.486 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 15:32:55] iteration   346500/  500000 | consumed samples:     22176000 | elapsed time per iteration (ms): 619.6 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.959596E+00 | loss scale: 1048576.0 | grad norm: 0.497 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 15:33:57] iteration   346600/  500000 | consumed samples:     22182400 | elapsed time per iteration (ms): 617.4 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.959305E+00 | loss scale: 1048576.0 | grad norm: 0.487 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 15:34:59] iteration   346700/  500000 | consumed samples:     22188800 | elapsed time per iteration (ms): 617.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.972742E+00 | loss scale: 1048576.0 | grad norm: 0.492 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 15:36:00] iteration   346800/  500000 | consumed samples:     22195200 | elapsed time per iteration (ms): 618.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.978970E+00 | loss scale: 1048576.0 | grad norm: 0.492 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 15:37:02] iteration   346900/  500000 | consumed samples:     22201600 | elapsed time per iteration (ms): 615.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.968696E+00 | loss scale: 1048576.0 | grad norm: 0.479 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 15:38:04] iteration   347000/  500000 | consumed samples:     22208000 | elapsed time per iteration (ms): 621.7 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.943144E+00 | loss scale: 1048576.0 | grad norm: 0.485 | number of skipped iterations:   2 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2460.25, 2460.29)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 347000 | lm loss value: 3.721906E+00 | lm loss PPL: 4.134312E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-26 15:39:08] iteration   347100/  500000 | consumed samples:     22214400 | elapsed time per iteration (ms): 617.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.983792E+00 | loss scale: 1048576.0 | grad norm: 0.498 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 15:40:10] iteration   347200/  500000 | consumed samples:     22220800 | elapsed time per iteration (ms): 618.4 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.965702E+00 | loss scale: 1048576.0 | grad norm: 0.500 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 15:41:12] iteration   347300/  500000 | consumed samples:     22227200 | elapsed time per iteration (ms): 621.2 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.958004E+00 | loss scale: 1048576.0 | grad norm: 0.492 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 15:42:14] iteration   347400/  500000 | consumed samples:     22233600 | elapsed time per iteration (ms): 619.6 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.967346E+00 | loss scale: 1048576.0 | grad norm: 0.500 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 15:43:16] iteration   347500/  500000 | consumed samples:     22240000 | elapsed time per iteration (ms): 619.6 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.954009E+00 | loss scale: 1048576.0 | grad norm: 0.493 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 15:44:18] iteration   347600/  500000 | consumed samples:     22246400 | elapsed time per iteration (ms): 619.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.951418E+00 | loss scale: 1048576.0 | grad norm: 0.491 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 15:45:20] iteration   347700/  500000 | consumed samples:     22252800 | elapsed time per iteration (ms): 619.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.967040E+00 | loss scale: 1048576.0 | grad norm: 0.492 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 15:46:22] iteration   347800/  500000 | consumed samples:     22259200 | elapsed time per iteration (ms): 620.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.959774E+00 | loss scale: 1048576.0 | grad norm: 0.493 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 15:47:24] iteration   347900/  500000 | consumed samples:     22265600 | elapsed time per iteration (ms): 618.3 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.970950E+00 | loss scale: 1048576.0 | grad norm: 0.509 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 15:48:26] iteration   348000/  500000 | consumed samples:     22272000 | elapsed time per iteration (ms): 621.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.974435E+00 | loss scale: 2097152.0 | grad norm: 0.495 | number of skipped iterations:   1 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2462.80, 2462.80)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 348000 | lm loss value: 3.715958E+00 | lm loss PPL: 4.109795E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-26 15:49:31] iteration   348100/  500000 | consumed samples:     22278400 | elapsed time per iteration (ms): 620.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.965847E+00 | loss scale: 2097152.0 | grad norm: 0.498 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 15:50:33] iteration   348200/  500000 | consumed samples:     22284800 | elapsed time per iteration (ms): 618.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.963044E+00 | loss scale: 1048576.0 | grad norm: 0.484 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-26 15:51:35] iteration   348300/  500000 | consumed samples:     22291200 | elapsed time per iteration (ms): 619.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.979398E+00 | loss scale: 1048576.0 | grad norm: 0.486 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 15:52:36] iteration   348400/  500000 | consumed samples:     22297600 | elapsed time per iteration (ms): 617.4 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.946071E+00 | loss scale: 1048576.0 | grad norm: 0.508 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 15:53:38] iteration   348500/  500000 | consumed samples:     22304000 | elapsed time per iteration (ms): 619.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.962814E+00 | loss scale: 1048576.0 | grad norm: 0.476 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 15:54:40] iteration   348600/  500000 | consumed samples:     22310400 | elapsed time per iteration (ms): 616.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.951452E+00 | loss scale: 1048576.0 | grad norm: 0.487 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 15:55:42] iteration   348700/  500000 | consumed samples:     22316800 | elapsed time per iteration (ms): 617.6 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.959329E+00 | loss scale: 1048576.0 | grad norm: 0.483 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 15:56:44] iteration   348800/  500000 | consumed samples:     22323200 | elapsed time per iteration (ms): 619.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.971182E+00 | loss scale: 1048576.0 | grad norm: 0.485 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 15:57:45] iteration   348900/  500000 | consumed samples:     22329600 | elapsed time per iteration (ms): 617.5 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.967365E+00 | loss scale: 1048576.0 | grad norm: 0.503 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 15:58:47] iteration   349000/  500000 | consumed samples:     22336000 | elapsed time per iteration (ms): 617.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.954604E+00 | loss scale: 1048576.0 | grad norm: 0.499 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2461.09, 2461.10)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 349000 | lm loss value: 3.730829E+00 | lm loss PPL: 4.171368E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-26 15:59:52] iteration   349100/  500000 | consumed samples:     22342400 | elapsed time per iteration (ms): 618.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.961194E+00 | loss scale: 1048576.0 | grad norm: 0.476 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 16:00:53] iteration   349200/  500000 | consumed samples:     22348800 | elapsed time per iteration (ms): 617.2 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.951657E+00 | loss scale: 1048576.0 | grad norm: 0.495 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-26 16:01:55] iteration   349300/  500000 | consumed samples:     22355200 | elapsed time per iteration (ms): 618.2 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.958263E+00 | loss scale: 1048576.0 | grad norm: 0.502 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 16:02:57] iteration   349400/  500000 | consumed samples:     22361600 | elapsed time per iteration (ms): 619.6 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.982966E+00 | loss scale: 1048576.0 | grad norm: 0.487 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 16:03:59] iteration   349500/  500000 | consumed samples:     22368000 | elapsed time per iteration (ms): 618.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.959752E+00 | loss scale: 1048576.0 | grad norm: 0.515 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 16:05:01] iteration   349600/  500000 | consumed samples:     22374400 | elapsed time per iteration (ms): 617.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.968030E+00 | loss scale: 1048576.0 | grad norm: 0.487 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 16:06:03] iteration   349700/  500000 | consumed samples:     22380800 | elapsed time per iteration (ms): 618.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.946920E+00 | loss scale: 1048576.0 | grad norm: 0.489 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 16:07:04] iteration   349800/  500000 | consumed samples:     22387200 | elapsed time per iteration (ms): 619.3 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.956026E+00 | loss scale: 1048576.0 | grad norm: 0.484 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 16:08:06] iteration   349900/  500000 | consumed samples:     22393600 | elapsed time per iteration (ms): 618.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.972983E+00 | loss scale: 1048576.0 | grad norm: 0.490 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 16:09:08] iteration   350000/  500000 | consumed samples:     22400000 | elapsed time per iteration (ms): 617.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.974044E+00 | loss scale: 1048576.0 | grad norm: 0.482 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2461.48, 2461.49)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 350000 | lm loss value: 3.737537E+00 | lm loss PPL: 4.199442E+01 | 
--------------------------------------------------------------------------------------------------
saving checkpoint at iteration  350000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-distribution in torch format
  successfully saved checkpoint at iteration  350000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-distribution
(min, max) time across ranks (ms):
    save-checkpoint ................................: (2274.81, 2274.82)
 [2024-06-26 16:10:15] iteration   350100/  500000 | consumed samples:     22406400 | elapsed time per iteration (ms): 618.1 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.966063E+00 | loss scale: 1048576.0 | grad norm: 0.500 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 16:11:16] iteration   350200/  500000 | consumed samples:     22412800 | elapsed time per iteration (ms): 617.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.954426E+00 | loss scale: 1048576.0 | grad norm: 0.475 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-26 16:12:18] iteration   350300/  500000 | consumed samples:     22419200 | elapsed time per iteration (ms): 618.1 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.980168E+00 | loss scale: 1048576.0 | grad norm: 0.501 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 16:13:20] iteration   350400/  500000 | consumed samples:     22425600 | elapsed time per iteration (ms): 618.4 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.952901E+00 | loss scale: 1048576.0 | grad norm: 0.486 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 16:14:22] iteration   350500/  500000 | consumed samples:     22432000 | elapsed time per iteration (ms): 618.3 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.974706E+00 | loss scale: 1048576.0 | grad norm: 0.501 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 16:15:24] iteration   350600/  500000 | consumed samples:     22438400 | elapsed time per iteration (ms): 621.7 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.964661E+00 | loss scale: 1048576.0 | grad norm: 0.497 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 16:16:26] iteration   350700/  500000 | consumed samples:     22444800 | elapsed time per iteration (ms): 618.7 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.958018E+00 | loss scale: 1048576.0 | grad norm: 0.501 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 16:17:28] iteration   350800/  500000 | consumed samples:     22451200 | elapsed time per iteration (ms): 618.5 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.961737E+00 | loss scale: 1048576.0 | grad norm: 0.493 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 16:18:30] iteration   350900/  500000 | consumed samples:     22457600 | elapsed time per iteration (ms): 618.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.958673E+00 | loss scale: 1048576.0 | grad norm: 0.493 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 16:19:31] iteration   351000/  500000 | consumed samples:     22464000 | elapsed time per iteration (ms): 617.4 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.965724E+00 | loss scale: 1048576.0 | grad norm: 0.489 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2460.98, 2460.98)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 351000 | lm loss value: 3.724801E+00 | lm loss PPL: 4.146297E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-26 16:20:36] iteration   351100/  500000 | consumed samples:     22470400 | elapsed time per iteration (ms): 618.6 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.955121E+00 | loss scale: 1048576.0 | grad norm: 0.474 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 16:21:37] iteration   351200/  500000 | consumed samples:     22476800 | elapsed time per iteration (ms): 617.1 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.951641E+00 | loss scale: 1048576.0 | grad norm: 0.507 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-26 16:22:39] iteration   351300/  500000 | consumed samples:     22483200 | elapsed time per iteration (ms): 618.4 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.963070E+00 | loss scale: 1048576.0 | grad norm: 0.499 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 16:23:41] iteration   351400/  500000 | consumed samples:     22489600 | elapsed time per iteration (ms): 618.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.967481E+00 | loss scale: 1048576.0 | grad norm: 0.495 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 16:24:43] iteration   351500/  500000 | consumed samples:     22496000 | elapsed time per iteration (ms): 618.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.954178E+00 | loss scale: 1048576.0 | grad norm: 0.486 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 16:25:45] iteration   351600/  500000 | consumed samples:     22502400 | elapsed time per iteration (ms): 617.7 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.963695E+00 | loss scale: 1048576.0 | grad norm: 0.499 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 16:26:46] iteration   351700/  500000 | consumed samples:     22508800 | elapsed time per iteration (ms): 617.1 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.958190E+00 | loss scale: 1048576.0 | grad norm: 0.504 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 16:27:48] iteration   351800/  500000 | consumed samples:     22515200 | elapsed time per iteration (ms): 617.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.965756E+00 | loss scale: 1048576.0 | grad norm: 0.490 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 16:28:50] iteration   351900/  500000 | consumed samples:     22521600 | elapsed time per iteration (ms): 618.3 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.971075E+00 | loss scale: 1048576.0 | grad norm: 0.482 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 16:29:52] iteration   352000/  500000 | consumed samples:     22528000 | elapsed time per iteration (ms): 617.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.959654E+00 | loss scale: 1048576.0 | grad norm: 0.506 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2461.66, 2461.76)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 352000 | lm loss value: 3.740000E+00 | lm loss PPL: 4.209800E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-26 16:30:56] iteration   352100/  500000 | consumed samples:     22534400 | elapsed time per iteration (ms): 618.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.970660E+00 | loss scale: 1048576.0 | grad norm: 0.485 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 16:31:58] iteration   352200/  500000 | consumed samples:     22540800 | elapsed time per iteration (ms): 618.6 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.959423E+00 | loss scale: 2097152.0 | grad norm: 0.488 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-26 16:33:00] iteration   352300/  500000 | consumed samples:     22547200 | elapsed time per iteration (ms): 618.4 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.966869E+00 | loss scale: 1048576.0 | grad norm: 0.495 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-26 16:34:02] iteration   352400/  500000 | consumed samples:     22553600 | elapsed time per iteration (ms): 618.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.950353E+00 | loss scale: 1048576.0 | grad norm: 0.494 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 16:35:04] iteration   352500/  500000 | consumed samples:     22560000 | elapsed time per iteration (ms): 619.3 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.962050E+00 | loss scale: 1048576.0 | grad norm: 0.501 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 16:36:06] iteration   352600/  500000 | consumed samples:     22566400 | elapsed time per iteration (ms): 619.2 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.955256E+00 | loss scale: 1048576.0 | grad norm: 0.490 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 16:37:07] iteration   352700/  500000 | consumed samples:     22572800 | elapsed time per iteration (ms): 618.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.956144E+00 | loss scale: 1048576.0 | grad norm: 0.503 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 16:38:09] iteration   352800/  500000 | consumed samples:     22579200 | elapsed time per iteration (ms): 617.7 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.964606E+00 | loss scale: 1048576.0 | grad norm: 0.490 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 16:39:11] iteration   352900/  500000 | consumed samples:     22585600 | elapsed time per iteration (ms): 618.2 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.966715E+00 | loss scale: 1048576.0 | grad norm: 0.487 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 16:40:13] iteration   353000/  500000 | consumed samples:     22592000 | elapsed time per iteration (ms): 618.2 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.963399E+00 | loss scale: 524288.0 | grad norm: 0.492 | number of skipped iterations:   1 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2461.13, 2461.30)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 353000 | lm loss value: 3.735442E+00 | lm loss PPL: 4.190656E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-26 16:41:17] iteration   353100/  500000 | consumed samples:     22598400 | elapsed time per iteration (ms): 620.4 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.954657E+00 | loss scale: 524288.0 | grad norm: 0.494 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 16:42:19] iteration   353200/  500000 | consumed samples:     22604800 | elapsed time per iteration (ms): 618.3 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.954788E+00 | loss scale: 524288.0 | grad norm: 0.492 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 16:43:21] iteration   353300/  500000 | consumed samples:     22611200 | elapsed time per iteration (ms): 618.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.956427E+00 | loss scale: 524288.0 | grad norm: 0.496 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 16:44:23] iteration   353400/  500000 | consumed samples:     22617600 | elapsed time per iteration (ms): 620.1 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.956568E+00 | loss scale: 524288.0 | grad norm: 0.480 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 16:45:25] iteration   353500/  500000 | consumed samples:     22624000 | elapsed time per iteration (ms): 618.2 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.971282E+00 | loss scale: 524288.0 | grad norm: 0.502 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 16:46:27] iteration   353600/  500000 | consumed samples:     22630400 | elapsed time per iteration (ms): 618.2 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.959197E+00 | loss scale: 524288.0 | grad norm: 0.489 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 16:47:28] iteration   353700/  500000 | consumed samples:     22636800 | elapsed time per iteration (ms): 618.1 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.953849E+00 | loss scale: 524288.0 | grad norm: 0.495 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 16:48:30] iteration   353800/  500000 | consumed samples:     22643200 | elapsed time per iteration (ms): 618.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.953644E+00 | loss scale: 524288.0 | grad norm: 0.508 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 16:49:32] iteration   353900/  500000 | consumed samples:     22649600 | elapsed time per iteration (ms): 617.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.963620E+00 | loss scale: 524288.0 | grad norm: 0.496 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 16:50:34] iteration   354000/  500000 | consumed samples:     22656000 | elapsed time per iteration (ms): 621.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.959778E+00 | loss scale: 1048576.0 | grad norm: 0.484 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2460.90, 2460.97)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 354000 | lm loss value: 3.709105E+00 | lm loss PPL: 4.081727E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-26 16:51:39] iteration   354100/  500000 | consumed samples:     22662400 | elapsed time per iteration (ms): 620.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.955971E+00 | loss scale: 1048576.0 | grad norm: 0.516 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 16:52:41] iteration   354200/  500000 | consumed samples:     22668800 | elapsed time per iteration (ms): 618.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.972060E+00 | loss scale: 1048576.0 | grad norm: 0.484 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 16:53:42] iteration   354300/  500000 | consumed samples:     22675200 | elapsed time per iteration (ms): 617.3 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.953549E+00 | loss scale: 1048576.0 | grad norm: 0.482 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 16:54:44] iteration   354400/  500000 | consumed samples:     22681600 | elapsed time per iteration (ms): 619.6 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.952218E+00 | loss scale: 1048576.0 | grad norm: 0.508 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 16:55:46] iteration   354500/  500000 | consumed samples:     22688000 | elapsed time per iteration (ms): 620.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.960972E+00 | loss scale: 1048576.0 | grad norm: 0.497 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 16:56:48] iteration   354600/  500000 | consumed samples:     22694400 | elapsed time per iteration (ms): 620.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.966412E+00 | loss scale: 1048576.0 | grad norm: 0.481 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 16:57:50] iteration   354700/  500000 | consumed samples:     22700800 | elapsed time per iteration (ms): 617.6 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.952820E+00 | loss scale: 1048576.0 | grad norm: 0.490 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 16:58:52] iteration   354800/  500000 | consumed samples:     22707200 | elapsed time per iteration (ms): 619.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.966973E+00 | loss scale: 1048576.0 | grad norm: 0.493 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 16:59:54] iteration   354900/  500000 | consumed samples:     22713600 | elapsed time per iteration (ms): 621.6 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.961129E+00 | loss scale: 1048576.0 | grad norm: 0.487 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 17:00:56] iteration   355000/  500000 | consumed samples:     22720000 | elapsed time per iteration (ms): 617.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.957454E+00 | loss scale: 1048576.0 | grad norm: 0.497 | number of skipped iterations:   2 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2459.52, 2459.58)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 355000 | lm loss value: 3.723960E+00 | lm loss PPL: 4.142811E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-26 17:02:00] iteration   355100/  500000 | consumed samples:     22726400 | elapsed time per iteration (ms): 618.7 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.950109E+00 | loss scale: 1048576.0 | grad norm: 0.483 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 17:03:02] iteration   355200/  500000 | consumed samples:     22732800 | elapsed time per iteration (ms): 618.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.959944E+00 | loss scale: 1048576.0 | grad norm: 0.497 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 17:04:04] iteration   355300/  500000 | consumed samples:     22739200 | elapsed time per iteration (ms): 618.4 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.955128E+00 | loss scale: 1048576.0 | grad norm: 0.509 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 17:05:06] iteration   355400/  500000 | consumed samples:     22745600 | elapsed time per iteration (ms): 618.3 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.969095E+00 | loss scale: 1048576.0 | grad norm: 0.497 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 17:06:08] iteration   355500/  500000 | consumed samples:     22752000 | elapsed time per iteration (ms): 619.3 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.948352E+00 | loss scale: 1048576.0 | grad norm: 0.508 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 17:07:10] iteration   355600/  500000 | consumed samples:     22758400 | elapsed time per iteration (ms): 618.5 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.973321E+00 | loss scale: 1048576.0 | grad norm: 0.486 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 17:08:11] iteration   355700/  500000 | consumed samples:     22764800 | elapsed time per iteration (ms): 618.1 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.960907E+00 | loss scale: 1048576.0 | grad norm: 0.490 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 17:09:13] iteration   355800/  500000 | consumed samples:     22771200 | elapsed time per iteration (ms): 617.7 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.959381E+00 | loss scale: 1048576.0 | grad norm: 0.495 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 17:10:15] iteration   355900/  500000 | consumed samples:     22777600 | elapsed time per iteration (ms): 618.3 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.970516E+00 | loss scale: 1048576.0 | grad norm: 0.483 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 17:11:17] iteration   356000/  500000 | consumed samples:     22784000 | elapsed time per iteration (ms): 619.5 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.951384E+00 | loss scale: 2097152.0 | grad norm: 0.491 | number of skipped iterations:   1 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2461.98, 2461.99)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 356000 | lm loss value: 3.692286E+00 | lm loss PPL: 4.013649E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-26 17:12:21] iteration   356100/  500000 | consumed samples:     22790400 | elapsed time per iteration (ms): 618.5 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.964617E+00 | loss scale: 1048576.0 | grad norm: 0.489 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-26 17:13:23] iteration   356200/  500000 | consumed samples:     22796800 | elapsed time per iteration (ms): 618.7 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.965844E+00 | loss scale: 1048576.0 | grad norm: 0.489 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 17:14:25] iteration   356300/  500000 | consumed samples:     22803200 | elapsed time per iteration (ms): 619.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.976015E+00 | loss scale: 1048576.0 | grad norm: 0.493 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 17:15:27] iteration   356400/  500000 | consumed samples:     22809600 | elapsed time per iteration (ms): 618.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.963142E+00 | loss scale: 1048576.0 | grad norm: 0.501 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 17:16:29] iteration   356500/  500000 | consumed samples:     22816000 | elapsed time per iteration (ms): 618.3 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.959150E+00 | loss scale: 1048576.0 | grad norm: 0.492 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 17:17:31] iteration   356600/  500000 | consumed samples:     22822400 | elapsed time per iteration (ms): 618.6 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.961782E+00 | loss scale: 1048576.0 | grad norm: 0.485 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 17:18:32] iteration   356700/  500000 | consumed samples:     22828800 | elapsed time per iteration (ms): 618.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.957071E+00 | loss scale: 1048576.0 | grad norm: 0.495 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 17:19:34] iteration   356800/  500000 | consumed samples:     22835200 | elapsed time per iteration (ms): 620.1 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.963672E+00 | loss scale: 1048576.0 | grad norm: 0.507 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 17:20:36] iteration   356900/  500000 | consumed samples:     22841600 | elapsed time per iteration (ms): 618.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.959508E+00 | loss scale: 1048576.0 | grad norm: 0.499 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 17:21:38] iteration   357000/  500000 | consumed samples:     22848000 | elapsed time per iteration (ms): 618.1 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.946840E+00 | loss scale: 1048576.0 | grad norm: 0.484 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2464.76, 2464.97)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 357000 | lm loss value: 3.727603E+00 | lm loss PPL: 4.157931E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-26 17:22:43] iteration   357100/  500000 | consumed samples:     22854400 | elapsed time per iteration (ms): 620.4 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.968310E+00 | loss scale: 1048576.0 | grad norm: 0.493 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-26 17:23:44] iteration   357200/  500000 | consumed samples:     22860800 | elapsed time per iteration (ms): 617.4 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.968485E+00 | loss scale: 1048576.0 | grad norm: 0.494 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 17:24:46] iteration   357300/  500000 | consumed samples:     22867200 | elapsed time per iteration (ms): 619.1 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.965024E+00 | loss scale: 1048576.0 | grad norm: 0.500 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 17:25:48] iteration   357400/  500000 | consumed samples:     22873600 | elapsed time per iteration (ms): 618.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.957938E+00 | loss scale: 1048576.0 | grad norm: 0.493 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 17:26:50] iteration   357500/  500000 | consumed samples:     22880000 | elapsed time per iteration (ms): 621.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.955616E+00 | loss scale: 1048576.0 | grad norm: 0.499 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 17:27:52] iteration   357600/  500000 | consumed samples:     22886400 | elapsed time per iteration (ms): 618.2 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.968938E+00 | loss scale: 1048576.0 | grad norm: 0.489 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 17:28:54] iteration   357700/  500000 | consumed samples:     22892800 | elapsed time per iteration (ms): 619.3 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.962168E+00 | loss scale: 1048576.0 | grad norm: 0.485 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 17:29:56] iteration   357800/  500000 | consumed samples:     22899200 | elapsed time per iteration (ms): 621.2 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.952723E+00 | loss scale: 1048576.0 | grad norm: 0.513 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 17:30:58] iteration   357900/  500000 | consumed samples:     22905600 | elapsed time per iteration (ms): 619.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.945831E+00 | loss scale: 1048576.0 | grad norm: 0.488 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 17:32:00] iteration   358000/  500000 | consumed samples:     22912000 | elapsed time per iteration (ms): 619.1 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.952933E+00 | loss scale: 1048576.0 | grad norm: 0.490 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2464.64, 2464.85)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 358000 | lm loss value: 3.712873E+00 | lm loss PPL: 4.097134E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-26 17:33:04] iteration   358100/  500000 | consumed samples:     22918400 | elapsed time per iteration (ms): 619.7 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.970269E+00 | loss scale: 2097152.0 | grad norm: 0.483 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 17:34:06] iteration   358200/  500000 | consumed samples:     22924800 | elapsed time per iteration (ms): 618.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.970452E+00 | loss scale: 1048576.0 | grad norm: 0.505 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-26 17:35:08] iteration   358300/  500000 | consumed samples:     22931200 | elapsed time per iteration (ms): 621.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.973578E+00 | loss scale: 1048576.0 | grad norm: 0.506 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 17:36:11] iteration   358400/  500000 | consumed samples:     22937600 | elapsed time per iteration (ms): 620.6 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.970131E+00 | loss scale: 1048576.0 | grad norm: 0.492 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 17:37:12] iteration   358500/  500000 | consumed samples:     22944000 | elapsed time per iteration (ms): 618.4 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.974572E+00 | loss scale: 1048576.0 | grad norm: 0.487 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 17:38:14] iteration   358600/  500000 | consumed samples:     22950400 | elapsed time per iteration (ms): 619.5 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.966759E+00 | loss scale: 1048576.0 | grad norm: 0.483 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 17:39:16] iteration   358700/  500000 | consumed samples:     22956800 | elapsed time per iteration (ms): 617.5 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.970666E+00 | loss scale: 1048576.0 | grad norm: 0.480 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 17:40:18] iteration   358800/  500000 | consumed samples:     22963200 | elapsed time per iteration (ms): 619.2 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.960362E+00 | loss scale: 1048576.0 | grad norm: 0.494 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 17:41:20] iteration   358900/  500000 | consumed samples:     22969600 | elapsed time per iteration (ms): 620.3 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.972755E+00 | loss scale: 1048576.0 | grad norm: 0.502 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 17:42:22] iteration   359000/  500000 | consumed samples:     22976000 | elapsed time per iteration (ms): 620.4 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.966887E+00 | loss scale: 1048576.0 | grad norm: 0.509 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2462.30, 2462.32)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 359000 | lm loss value: 3.732123E+00 | lm loss PPL: 4.176768E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-26 17:43:27] iteration   359100/  500000 | consumed samples:     22982400 | elapsed time per iteration (ms): 620.2 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.961714E+00 | loss scale: 1048576.0 | grad norm: 0.497 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 17:44:28] iteration   359200/  500000 | consumed samples:     22988800 | elapsed time per iteration (ms): 619.3 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.954090E+00 | loss scale: 1048576.0 | grad norm: 0.490 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-26 17:45:30] iteration   359300/  500000 | consumed samples:     22995200 | elapsed time per iteration (ms): 617.7 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.962380E+00 | loss scale: 1048576.0 | grad norm: 0.494 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 17:46:32] iteration   359400/  500000 | consumed samples:     23001600 | elapsed time per iteration (ms): 618.7 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.966637E+00 | loss scale: 1048576.0 | grad norm: 0.477 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 17:47:34] iteration   359500/  500000 | consumed samples:     23008000 | elapsed time per iteration (ms): 617.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.952621E+00 | loss scale: 1048576.0 | grad norm: 0.497 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 17:48:36] iteration   359600/  500000 | consumed samples:     23014400 | elapsed time per iteration (ms): 618.4 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.961285E+00 | loss scale: 524288.0 | grad norm: 0.492 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-26 17:49:38] iteration   359700/  500000 | consumed samples:     23020800 | elapsed time per iteration (ms): 619.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.951838E+00 | loss scale: 524288.0 | grad norm: 0.485 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 17:50:39] iteration   359800/  500000 | consumed samples:     23027200 | elapsed time per iteration (ms): 617.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.961932E+00 | loss scale: 524288.0 | grad norm: 0.487 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 17:51:41] iteration   359900/  500000 | consumed samples:     23033600 | elapsed time per iteration (ms): 618.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.954321E+00 | loss scale: 524288.0 | grad norm: 0.490 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 17:52:43] iteration   360000/  500000 | consumed samples:     23040000 | elapsed time per iteration (ms): 618.1 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.960102E+00 | loss scale: 524288.0 | grad norm: 0.492 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2461.28, 2461.28)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 360000 | lm loss value: 3.692674E+00 | lm loss PPL: 4.015207E+01 | 
--------------------------------------------------------------------------------------------------
saving checkpoint at iteration  360000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-distribution in torch format
  successfully saved checkpoint at iteration  360000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-distribution
(min, max) time across ranks (ms):
    save-checkpoint ................................: (2316.17, 2316.34)
 [2024-06-26 17:53:50] iteration   360100/  500000 | consumed samples:     23046400 | elapsed time per iteration (ms): 620.3 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.969562E+00 | loss scale: 524288.0 | grad norm: 0.511 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 17:54:52] iteration   360200/  500000 | consumed samples:     23052800 | elapsed time per iteration (ms): 620.1 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.960155E+00 | loss scale: 524288.0 | grad norm: 0.498 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 17:55:54] iteration   360300/  500000 | consumed samples:     23059200 | elapsed time per iteration (ms): 620.3 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.967655E+00 | loss scale: 524288.0 | grad norm: 0.501 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 17:56:56] iteration   360400/  500000 | consumed samples:     23065600 | elapsed time per iteration (ms): 619.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.979171E+00 | loss scale: 524288.0 | grad norm: 0.481 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 17:57:58] iteration   360500/  500000 | consumed samples:     23072000 | elapsed time per iteration (ms): 619.1 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.970230E+00 | loss scale: 524288.0 | grad norm: 0.502 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 17:59:00] iteration   360600/  500000 | consumed samples:     23078400 | elapsed time per iteration (ms): 619.7 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.955438E+00 | loss scale: 1048576.0 | grad norm: 0.486 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 18:00:01] iteration   360700/  500000 | consumed samples:     23084800 | elapsed time per iteration (ms): 615.7 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.952336E+00 | loss scale: 1048576.0 | grad norm: 0.500 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 18:01:03] iteration   360800/  500000 | consumed samples:     23091200 | elapsed time per iteration (ms): 619.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.972524E+00 | loss scale: 1048576.0 | grad norm: 0.503 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 18:02:05] iteration   360900/  500000 | consumed samples:     23097600 | elapsed time per iteration (ms): 620.5 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.968199E+00 | loss scale: 1048576.0 | grad norm: 0.495 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 18:03:07] iteration   361000/  500000 | consumed samples:     23104000 | elapsed time per iteration (ms): 619.2 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.945661E+00 | loss scale: 1048576.0 | grad norm: 0.494 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2464.48, 2464.50)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 361000 | lm loss value: 3.738301E+00 | lm loss PPL: 4.202652E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-26 18:04:11] iteration   361100/  500000 | consumed samples:     23110400 | elapsed time per iteration (ms): 616.6 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.959614E+00 | loss scale: 1048576.0 | grad norm: 0.501 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 18:05:13] iteration   361200/  500000 | consumed samples:     23116800 | elapsed time per iteration (ms): 620.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.946665E+00 | loss scale: 1048576.0 | grad norm: 0.491 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 18:06:16] iteration   361300/  500000 | consumed samples:     23123200 | elapsed time per iteration (ms): 622.5 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.950737E+00 | loss scale: 1048576.0 | grad norm: 0.499 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 18:07:18] iteration   361400/  500000 | consumed samples:     23129600 | elapsed time per iteration (ms): 618.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.975342E+00 | loss scale: 1048576.0 | grad norm: 0.495 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 18:08:19] iteration   361500/  500000 | consumed samples:     23136000 | elapsed time per iteration (ms): 617.7 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.960842E+00 | loss scale: 1048576.0 | grad norm: 0.501 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 18:09:21] iteration   361600/  500000 | consumed samples:     23142400 | elapsed time per iteration (ms): 618.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.957596E+00 | loss scale: 1048576.0 | grad norm: 0.507 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-26 18:10:23] iteration   361700/  500000 | consumed samples:     23148800 | elapsed time per iteration (ms): 621.4 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.964859E+00 | loss scale: 1048576.0 | grad norm: 0.499 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 18:11:25] iteration   361800/  500000 | consumed samples:     23155200 | elapsed time per iteration (ms): 619.5 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.955546E+00 | loss scale: 1048576.0 | grad norm: 0.483 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 18:12:27] iteration   361900/  500000 | consumed samples:     23161600 | elapsed time per iteration (ms): 617.7 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.974642E+00 | loss scale: 1048576.0 | grad norm: 0.490 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 18:13:29] iteration   362000/  500000 | consumed samples:     23168000 | elapsed time per iteration (ms): 618.7 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.954107E+00 | loss scale: 1048576.0 | grad norm: 0.497 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2463.00, 2463.05)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 362000 | lm loss value: 3.710166E+00 | lm loss PPL: 4.086057E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-26 18:14:33] iteration   362100/  500000 | consumed samples:     23174400 | elapsed time per iteration (ms): 619.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.966187E+00 | loss scale: 1048576.0 | grad norm: 0.491 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 18:15:35] iteration   362200/  500000 | consumed samples:     23180800 | elapsed time per iteration (ms): 619.2 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.948365E+00 | loss scale: 1048576.0 | grad norm: 0.499 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 18:16:37] iteration   362300/  500000 | consumed samples:     23187200 | elapsed time per iteration (ms): 619.7 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.966966E+00 | loss scale: 1048576.0 | grad norm: 0.499 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 18:17:39] iteration   362400/  500000 | consumed samples:     23193600 | elapsed time per iteration (ms): 617.3 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.965559E+00 | loss scale: 1048576.0 | grad norm: 0.502 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 18:18:41] iteration   362500/  500000 | consumed samples:     23200000 | elapsed time per iteration (ms): 619.6 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.964478E+00 | loss scale: 1048576.0 | grad norm: 0.490 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 18:19:43] iteration   362600/  500000 | consumed samples:     23206400 | elapsed time per iteration (ms): 620.2 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.974102E+00 | loss scale: 1048576.0 | grad norm: 0.486 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-26 18:20:45] iteration   362700/  500000 | consumed samples:     23212800 | elapsed time per iteration (ms): 617.4 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.956765E+00 | loss scale: 1048576.0 | grad norm: 0.502 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 18:21:47] iteration   362800/  500000 | consumed samples:     23219200 | elapsed time per iteration (ms): 620.7 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.963499E+00 | loss scale: 1048576.0 | grad norm: 0.497 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 18:22:48] iteration   362900/  500000 | consumed samples:     23225600 | elapsed time per iteration (ms): 616.7 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.957321E+00 | loss scale: 1048576.0 | grad norm: 0.494 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 18:23:50] iteration   363000/  500000 | consumed samples:     23232000 | elapsed time per iteration (ms): 616.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.970143E+00 | loss scale: 1048576.0 | grad norm: 0.503 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2463.67, 2463.71)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 363000 | lm loss value: 3.730629E+00 | lm loss PPL: 4.170532E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-26 18:24:54] iteration   363100/  500000 | consumed samples:     23238400 | elapsed time per iteration (ms): 618.2 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.971976E+00 | loss scale: 1048576.0 | grad norm: 0.508 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 18:25:56] iteration   363200/  500000 | consumed samples:     23244800 | elapsed time per iteration (ms): 620.4 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.950600E+00 | loss scale: 1048576.0 | grad norm: 0.505 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 18:26:58] iteration   363300/  500000 | consumed samples:     23251200 | elapsed time per iteration (ms): 618.4 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.976712E+00 | loss scale: 1048576.0 | grad norm: 0.494 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 18:28:00] iteration   363400/  500000 | consumed samples:     23257600 | elapsed time per iteration (ms): 619.4 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.952143E+00 | loss scale: 1048576.0 | grad norm: 0.508 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 18:29:02] iteration   363500/  500000 | consumed samples:     23264000 | elapsed time per iteration (ms): 618.7 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.969285E+00 | loss scale: 1048576.0 | grad norm: 0.488 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 18:30:04] iteration   363600/  500000 | consumed samples:     23270400 | elapsed time per iteration (ms): 619.4 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.949164E+00 | loss scale: 2097152.0 | grad norm: 0.492 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 18:31:06] iteration   363700/  500000 | consumed samples:     23276800 | elapsed time per iteration (ms): 617.6 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.952362E+00 | loss scale: 2097152.0 | grad norm: 0.504 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-26 18:32:08] iteration   363800/  500000 | consumed samples:     23283200 | elapsed time per iteration (ms): 618.6 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.960074E+00 | loss scale: 1048576.0 | grad norm: 0.479 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-26 18:33:09] iteration   363900/  500000 | consumed samples:     23289600 | elapsed time per iteration (ms): 617.4 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.964818E+00 | loss scale: 1048576.0 | grad norm: 0.507 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 18:34:11] iteration   364000/  500000 | consumed samples:     23296000 | elapsed time per iteration (ms): 618.1 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.950982E+00 | loss scale: 1048576.0 | grad norm: 0.494 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2460.22, 2460.39)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 364000 | lm loss value: 3.719573E+00 | lm loss PPL: 4.124677E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-26 18:35:15] iteration   364100/  500000 | consumed samples:     23302400 | elapsed time per iteration (ms): 617.4 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.963378E+00 | loss scale: 1048576.0 | grad norm: 0.500 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 18:36:18] iteration   364200/  500000 | consumed samples:     23308800 | elapsed time per iteration (ms): 621.6 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.961886E+00 | loss scale: 1048576.0 | grad norm: 0.506 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 18:37:20] iteration   364300/  500000 | consumed samples:     23315200 | elapsed time per iteration (ms): 620.2 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.959617E+00 | loss scale: 1048576.0 | grad norm: 0.484 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 18:38:21] iteration   364400/  500000 | consumed samples:     23321600 | elapsed time per iteration (ms): 619.3 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.948469E+00 | loss scale: 1048576.0 | grad norm: 0.496 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 18:39:23] iteration   364500/  500000 | consumed samples:     23328000 | elapsed time per iteration (ms): 618.7 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.966371E+00 | loss scale: 1048576.0 | grad norm: 0.496 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 18:40:25] iteration   364600/  500000 | consumed samples:     23334400 | elapsed time per iteration (ms): 620.1 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.959913E+00 | loss scale: 1048576.0 | grad norm: 0.494 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 18:41:27] iteration   364700/  500000 | consumed samples:     23340800 | elapsed time per iteration (ms): 618.7 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.964745E+00 | loss scale: 1048576.0 | grad norm: 0.496 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 18:42:29] iteration   364800/  500000 | consumed samples:     23347200 | elapsed time per iteration (ms): 618.4 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.964189E+00 | loss scale: 1048576.0 | grad norm: 0.494 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-26 18:43:31] iteration   364900/  500000 | consumed samples:     23353600 | elapsed time per iteration (ms): 618.4 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.966568E+00 | loss scale: 1048576.0 | grad norm: 0.491 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 18:44:33] iteration   365000/  500000 | consumed samples:     23360000 | elapsed time per iteration (ms): 620.6 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.952125E+00 | loss scale: 1048576.0 | grad norm: 0.489 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2463.13, 2463.20)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 365000 | lm loss value: 3.722787E+00 | lm loss PPL: 4.137956E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-26 18:45:37] iteration   365100/  500000 | consumed samples:     23366400 | elapsed time per iteration (ms): 619.1 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.942708E+00 | loss scale: 1048576.0 | grad norm: 0.501 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 18:46:39] iteration   365200/  500000 | consumed samples:     23372800 | elapsed time per iteration (ms): 620.1 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.969459E+00 | loss scale: 1048576.0 | grad norm: 0.502 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 18:47:41] iteration   365300/  500000 | consumed samples:     23379200 | elapsed time per iteration (ms): 620.4 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.965543E+00 | loss scale: 1048576.0 | grad norm: 0.507 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 18:48:43] iteration   365400/  500000 | consumed samples:     23385600 | elapsed time per iteration (ms): 620.7 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.959045E+00 | loss scale: 1048576.0 | grad norm: 0.503 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 18:49:45] iteration   365500/  500000 | consumed samples:     23392000 | elapsed time per iteration (ms): 619.2 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.959269E+00 | loss scale: 1048576.0 | grad norm: 0.498 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 18:50:47] iteration   365600/  500000 | consumed samples:     23398400 | elapsed time per iteration (ms): 619.2 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.954337E+00 | loss scale: 1048576.0 | grad norm: 0.493 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 18:51:49] iteration   365700/  500000 | consumed samples:     23404800 | elapsed time per iteration (ms): 619.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.963909E+00 | loss scale: 1048576.0 | grad norm: 0.496 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 18:52:51] iteration   365800/  500000 | consumed samples:     23411200 | elapsed time per iteration (ms): 618.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.952071E+00 | loss scale: 2097152.0 | grad norm: 0.494 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 18:53:53] iteration   365900/  500000 | consumed samples:     23417600 | elapsed time per iteration (ms): 619.6 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.956219E+00 | loss scale: 1048576.0 | grad norm: 0.505 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-26 18:54:55] iteration   366000/  500000 | consumed samples:     23424000 | elapsed time per iteration (ms): 618.6 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.958825E+00 | loss scale: 1048576.0 | grad norm: 0.514 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2460.25, 2460.30)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 366000 | lm loss value: 3.745661E+00 | lm loss PPL: 4.233696E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-26 18:55:59] iteration   366100/  500000 | consumed samples:     23430400 | elapsed time per iteration (ms): 619.7 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.958661E+00 | loss scale: 1048576.0 | grad norm: 0.481 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 18:57:01] iteration   366200/  500000 | consumed samples:     23436800 | elapsed time per iteration (ms): 619.5 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.954292E+00 | loss scale: 1048576.0 | grad norm: 0.492 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 18:58:03] iteration   366300/  500000 | consumed samples:     23443200 | elapsed time per iteration (ms): 618.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.953259E+00 | loss scale: 1048576.0 | grad norm: 0.492 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 18:59:05] iteration   366400/  500000 | consumed samples:     23449600 | elapsed time per iteration (ms): 618.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.963523E+00 | loss scale: 1048576.0 | grad norm: 0.495 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 19:00:07] iteration   366500/  500000 | consumed samples:     23456000 | elapsed time per iteration (ms): 619.7 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.958948E+00 | loss scale: 1048576.0 | grad norm: 0.492 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 19:01:09] iteration   366600/  500000 | consumed samples:     23462400 | elapsed time per iteration (ms): 618.6 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.956517E+00 | loss scale: 1048576.0 | grad norm: 0.485 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 19:02:11] iteration   366700/  500000 | consumed samples:     23468800 | elapsed time per iteration (ms): 617.7 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.979651E+00 | loss scale: 1048576.0 | grad norm: 0.498 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 19:03:13] iteration   366800/  500000 | consumed samples:     23475200 | elapsed time per iteration (ms): 618.5 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.955035E+00 | loss scale: 1048576.0 | grad norm: 0.490 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 19:04:15] iteration   366900/  500000 | consumed samples:     23481600 | elapsed time per iteration (ms): 619.5 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.965320E+00 | loss scale: 1048576.0 | grad norm: 0.480 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-26 19:05:17] iteration   367000/  500000 | consumed samples:     23488000 | elapsed time per iteration (ms): 620.4 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.956851E+00 | loss scale: 1048576.0 | grad norm: 0.485 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2461.09, 2461.14)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 367000 | lm loss value: 3.701147E+00 | lm loss PPL: 4.049373E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-26 19:06:21] iteration   367100/  500000 | consumed samples:     23494400 | elapsed time per iteration (ms): 619.6 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.953917E+00 | loss scale: 1048576.0 | grad norm: 0.495 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 19:07:23] iteration   367200/  500000 | consumed samples:     23500800 | elapsed time per iteration (ms): 621.6 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.959223E+00 | loss scale: 1048576.0 | grad norm: 0.498 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 19:08:25] iteration   367300/  500000 | consumed samples:     23507200 | elapsed time per iteration (ms): 618.7 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.964976E+00 | loss scale: 1048576.0 | grad norm: 0.496 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 19:09:27] iteration   367400/  500000 | consumed samples:     23513600 | elapsed time per iteration (ms): 618.6 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.971176E+00 | loss scale: 1048576.0 | grad norm: 0.490 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 19:10:29] iteration   367500/  500000 | consumed samples:     23520000 | elapsed time per iteration (ms): 618.7 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.966723E+00 | loss scale: 1048576.0 | grad norm: 0.491 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 19:11:30] iteration   367600/  500000 | consumed samples:     23526400 | elapsed time per iteration (ms): 617.6 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.960759E+00 | loss scale: 1048576.0 | grad norm: 0.486 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 19:12:32] iteration   367700/  500000 | consumed samples:     23532800 | elapsed time per iteration (ms): 615.7 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.958437E+00 | loss scale: 1048576.0 | grad norm: 0.491 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 19:13:34] iteration   367800/  500000 | consumed samples:     23539200 | elapsed time per iteration (ms): 619.1 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.949500E+00 | loss scale: 1048576.0 | grad norm: 0.498 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 19:14:36] iteration   367900/  500000 | consumed samples:     23545600 | elapsed time per iteration (ms): 620.7 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.967957E+00 | loss scale: 2097152.0 | grad norm: 0.503 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 19:15:38] iteration   368000/  500000 | consumed samples:     23552000 | elapsed time per iteration (ms): 620.4 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.957486E+00 | loss scale: 1048576.0 | grad norm: 0.505 | number of skipped iterations:   2 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2463.83, 2463.96)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 368000 | lm loss value: 3.768950E+00 | lm loss PPL: 4.333452E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-26 19:16:42] iteration   368100/  500000 | consumed samples:     23558400 | elapsed time per iteration (ms): 619.3 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.964286E+00 | loss scale: 1048576.0 | grad norm: 0.497 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 19:17:44] iteration   368200/  500000 | consumed samples:     23564800 | elapsed time per iteration (ms): 618.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.962161E+00 | loss scale: 1048576.0 | grad norm: 0.497 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 19:18:46] iteration   368300/  500000 | consumed samples:     23571200 | elapsed time per iteration (ms): 618.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.963412E+00 | loss scale: 1048576.0 | grad norm: 0.498 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 19:19:48] iteration   368400/  500000 | consumed samples:     23577600 | elapsed time per iteration (ms): 618.2 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.955592E+00 | loss scale: 1048576.0 | grad norm: 0.507 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 19:20:50] iteration   368500/  500000 | consumed samples:     23584000 | elapsed time per iteration (ms): 619.4 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.961796E+00 | loss scale: 1048576.0 | grad norm: 0.511 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 19:21:52] iteration   368600/  500000 | consumed samples:     23590400 | elapsed time per iteration (ms): 620.5 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.958739E+00 | loss scale: 1048576.0 | grad norm: 0.498 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 19:22:54] iteration   368700/  500000 | consumed samples:     23596800 | elapsed time per iteration (ms): 619.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.962367E+00 | loss scale: 1048576.0 | grad norm: 0.492 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 19:23:56] iteration   368800/  500000 | consumed samples:     23603200 | elapsed time per iteration (ms): 617.1 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.967726E+00 | loss scale: 1048576.0 | grad norm: 0.505 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 19:24:58] iteration   368900/  500000 | consumed samples:     23609600 | elapsed time per iteration (ms): 620.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.971404E+00 | loss scale: 1048576.0 | grad norm: 0.485 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 19:26:00] iteration   369000/  500000 | consumed samples:     23616000 | elapsed time per iteration (ms): 619.2 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.967966E+00 | loss scale: 2097152.0 | grad norm: 0.494 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2462.69, 2462.74)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 369000 | lm loss value: 3.762235E+00 | lm loss PPL: 4.304454E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-26 19:27:04] iteration   369100/  500000 | consumed samples:     23622400 | elapsed time per iteration (ms): 621.3 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.948434E+00 | loss scale: 1048576.0 | grad norm: 0.500 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-26 19:28:06] iteration   369200/  500000 | consumed samples:     23628800 | elapsed time per iteration (ms): 619.4 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.956642E+00 | loss scale: 1048576.0 | grad norm: 0.487 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 19:29:08] iteration   369300/  500000 | consumed samples:     23635200 | elapsed time per iteration (ms): 620.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.961036E+00 | loss scale: 1048576.0 | grad norm: 0.497 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 19:30:10] iteration   369400/  500000 | consumed samples:     23641600 | elapsed time per iteration (ms): 618.4 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.971350E+00 | loss scale: 1048576.0 | grad norm: 0.508 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 19:31:12] iteration   369500/  500000 | consumed samples:     23648000 | elapsed time per iteration (ms): 618.2 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.972966E+00 | loss scale: 1048576.0 | grad norm: 0.489 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 19:32:14] iteration   369600/  500000 | consumed samples:     23654400 | elapsed time per iteration (ms): 618.2 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.950088E+00 | loss scale: 1048576.0 | grad norm: 0.490 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 19:33:15] iteration   369700/  500000 | consumed samples:     23660800 | elapsed time per iteration (ms): 617.6 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.950649E+00 | loss scale: 1048576.0 | grad norm: 0.492 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 19:34:17] iteration   369800/  500000 | consumed samples:     23667200 | elapsed time per iteration (ms): 617.5 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.974162E+00 | loss scale: 1048576.0 | grad norm: 0.504 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 19:35:19] iteration   369900/  500000 | consumed samples:     23673600 | elapsed time per iteration (ms): 619.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.960462E+00 | loss scale: 1048576.0 | grad norm: 0.504 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 19:36:21] iteration   370000/  500000 | consumed samples:     23680000 | elapsed time per iteration (ms): 619.4 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.942862E+00 | loss scale: 1048576.0 | grad norm: 0.487 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2460.82, 2460.86)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 370000 | lm loss value: 3.740678E+00 | lm loss PPL: 4.212653E+01 | 
--------------------------------------------------------------------------------------------------
saving checkpoint at iteration  370000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-distribution in torch format
  successfully saved checkpoint at iteration  370000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-distribution
(min, max) time across ranks (ms):
    save-checkpoint ................................: (2273.86, 2273.87)
 [2024-06-26 19:37:28] iteration   370100/  500000 | consumed samples:     23686400 | elapsed time per iteration (ms): 617.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.961087E+00 | loss scale: 1048576.0 | grad norm: 0.487 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-26 19:38:30] iteration   370200/  500000 | consumed samples:     23692800 | elapsed time per iteration (ms): 618.7 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.967085E+00 | loss scale: 1048576.0 | grad norm: 0.499 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 19:39:31] iteration   370300/  500000 | consumed samples:     23699200 | elapsed time per iteration (ms): 617.5 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.963928E+00 | loss scale: 1048576.0 | grad norm: 0.503 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 19:40:33] iteration   370400/  500000 | consumed samples:     23705600 | elapsed time per iteration (ms): 616.5 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.963613E+00 | loss scale: 1048576.0 | grad norm: 0.503 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 19:41:35] iteration   370500/  500000 | consumed samples:     23712000 | elapsed time per iteration (ms): 619.4 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.958580E+00 | loss scale: 1048576.0 | grad norm: 0.496 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 19:42:37] iteration   370600/  500000 | consumed samples:     23718400 | elapsed time per iteration (ms): 619.3 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.959000E+00 | loss scale: 1048576.0 | grad norm: 0.517 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 19:43:39] iteration   370700/  500000 | consumed samples:     23724800 | elapsed time per iteration (ms): 618.2 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.956723E+00 | loss scale: 1048576.0 | grad norm: 0.491 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 19:44:41] iteration   370800/  500000 | consumed samples:     23731200 | elapsed time per iteration (ms): 622.1 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.971758E+00 | loss scale: 1048576.0 | grad norm: 0.511 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 19:45:43] iteration   370900/  500000 | consumed samples:     23737600 | elapsed time per iteration (ms): 618.5 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.964798E+00 | loss scale: 1048576.0 | grad norm: 0.492 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 19:46:44] iteration   371000/  500000 | consumed samples:     23744000 | elapsed time per iteration (ms): 617.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.967455E+00 | loss scale: 1048576.0 | grad norm: 0.495 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2462.43, 2462.43)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 371000 | lm loss value: 3.687618E+00 | lm loss PPL: 3.994956E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-26 19:47:49] iteration   371100/  500000 | consumed samples:     23750400 | elapsed time per iteration (ms): 619.2 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.961716E+00 | loss scale: 2097152.0 | grad norm: 0.492 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 19:48:51] iteration   371200/  500000 | consumed samples:     23756800 | elapsed time per iteration (ms): 617.4 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.947188E+00 | loss scale: 1048576.0 | grad norm: 0.485 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-26 19:49:52] iteration   371300/  500000 | consumed samples:     23763200 | elapsed time per iteration (ms): 619.1 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.959650E+00 | loss scale: 1048576.0 | grad norm: 0.487 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 19:50:55] iteration   371400/  500000 | consumed samples:     23769600 | elapsed time per iteration (ms): 620.7 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.965677E+00 | loss scale: 1048576.0 | grad norm: 0.492 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 19:51:57] iteration   371500/  500000 | consumed samples:     23776000 | elapsed time per iteration (ms): 621.1 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.953932E+00 | loss scale: 1048576.0 | grad norm: 0.497 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 19:52:59] iteration   371600/  500000 | consumed samples:     23782400 | elapsed time per iteration (ms): 618.6 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.972585E+00 | loss scale: 1048576.0 | grad norm: 0.495 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 19:54:00] iteration   371700/  500000 | consumed samples:     23788800 | elapsed time per iteration (ms): 618.6 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.965786E+00 | loss scale: 1048576.0 | grad norm: 0.489 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 19:55:02] iteration   371800/  500000 | consumed samples:     23795200 | elapsed time per iteration (ms): 618.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.956616E+00 | loss scale: 1048576.0 | grad norm: 0.490 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 19:56:04] iteration   371900/  500000 | consumed samples:     23801600 | elapsed time per iteration (ms): 621.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.961323E+00 | loss scale: 1048576.0 | grad norm: 0.504 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 19:57:06] iteration   372000/  500000 | consumed samples:     23808000 | elapsed time per iteration (ms): 618.5 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.965978E+00 | loss scale: 1048576.0 | grad norm: 0.503 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2460.49, 2460.52)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 372000 | lm loss value: 3.715967E+00 | lm loss PPL: 4.109831E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-26 19:58:11] iteration   372100/  500000 | consumed samples:     23814400 | elapsed time per iteration (ms): 618.7 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.982083E+00 | loss scale: 1048576.0 | grad norm: 0.501 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 19:59:12] iteration   372200/  500000 | consumed samples:     23820800 | elapsed time per iteration (ms): 617.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.978863E+00 | loss scale: 1048576.0 | grad norm: 0.491 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-26 20:00:14] iteration   372300/  500000 | consumed samples:     23827200 | elapsed time per iteration (ms): 618.1 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.955617E+00 | loss scale: 1048576.0 | grad norm: 0.483 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 20:01:16] iteration   372400/  500000 | consumed samples:     23833600 | elapsed time per iteration (ms): 619.1 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.961167E+00 | loss scale: 1048576.0 | grad norm: 0.494 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 20:02:18] iteration   372500/  500000 | consumed samples:     23840000 | elapsed time per iteration (ms): 619.2 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.961591E+00 | loss scale: 1048576.0 | grad norm: 0.499 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 20:03:20] iteration   372600/  500000 | consumed samples:     23846400 | elapsed time per iteration (ms): 619.6 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.961517E+00 | loss scale: 1048576.0 | grad norm: 0.501 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 20:04:22] iteration   372700/  500000 | consumed samples:     23852800 | elapsed time per iteration (ms): 617.5 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.970630E+00 | loss scale: 1048576.0 | grad norm: 0.505 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 20:05:23] iteration   372800/  500000 | consumed samples:     23859200 | elapsed time per iteration (ms): 618.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.973606E+00 | loss scale: 1048576.0 | grad norm: 0.509 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 20:06:25] iteration   372900/  500000 | consumed samples:     23865600 | elapsed time per iteration (ms): 619.1 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.958499E+00 | loss scale: 1048576.0 | grad norm: 0.506 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 20:07:27] iteration   373000/  500000 | consumed samples:     23872000 | elapsed time per iteration (ms): 616.7 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.957794E+00 | loss scale: 1048576.0 | grad norm: 0.500 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2461.50, 2461.64)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 373000 | lm loss value: 3.715146E+00 | lm loss PPL: 4.106457E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-26 20:08:31] iteration   373100/  500000 | consumed samples:     23878400 | elapsed time per iteration (ms): 619.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.959474E+00 | loss scale: 1048576.0 | grad norm: 0.499 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 20:09:33] iteration   373200/  500000 | consumed samples:     23884800 | elapsed time per iteration (ms): 620.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.980845E+00 | loss scale: 2097152.0 | grad norm: 0.501 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 20:10:35] iteration   373300/  500000 | consumed samples:     23891200 | elapsed time per iteration (ms): 619.3 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.947312E+00 | loss scale: 1048576.0 | grad norm: 0.490 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-26 20:11:37] iteration   373400/  500000 | consumed samples:     23897600 | elapsed time per iteration (ms): 618.4 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.963328E+00 | loss scale: 1048576.0 | grad norm: 0.509 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 20:12:39] iteration   373500/  500000 | consumed samples:     23904000 | elapsed time per iteration (ms): 617.4 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.954453E+00 | loss scale: 1048576.0 | grad norm: 0.495 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 20:13:41] iteration   373600/  500000 | consumed samples:     23910400 | elapsed time per iteration (ms): 619.4 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.958665E+00 | loss scale: 1048576.0 | grad norm: 0.500 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 20:14:43] iteration   373700/  500000 | consumed samples:     23916800 | elapsed time per iteration (ms): 618.1 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.964042E+00 | loss scale: 1048576.0 | grad norm: 0.496 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 20:15:45] iteration   373800/  500000 | consumed samples:     23923200 | elapsed time per iteration (ms): 618.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.966622E+00 | loss scale: 1048576.0 | grad norm: 0.503 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 20:16:47] iteration   373900/  500000 | consumed samples:     23929600 | elapsed time per iteration (ms): 620.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.952048E+00 | loss scale: 1048576.0 | grad norm: 0.503 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 20:17:48] iteration   374000/  500000 | consumed samples:     23936000 | elapsed time per iteration (ms): 617.4 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.970571E+00 | loss scale: 1048576.0 | grad norm: 0.489 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2461.38, 2461.38)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 374000 | lm loss value: 3.759655E+00 | lm loss PPL: 4.293360E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-26 20:18:53] iteration   374100/  500000 | consumed samples:     23942400 | elapsed time per iteration (ms): 619.3 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.960655E+00 | loss scale: 1048576.0 | grad norm: 0.497 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 20:19:55] iteration   374200/  500000 | consumed samples:     23948800 | elapsed time per iteration (ms): 618.6 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.944210E+00 | loss scale: 1048576.0 | grad norm: 0.501 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 20:20:56] iteration   374300/  500000 | consumed samples:     23955200 | elapsed time per iteration (ms): 617.6 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.959220E+00 | loss scale: 2097152.0 | grad norm: 0.501 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 20:21:58] iteration   374400/  500000 | consumed samples:     23961600 | elapsed time per iteration (ms): 618.7 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.961070E+00 | loss scale: 2097152.0 | grad norm: 0.495 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 20:23:00] iteration   374500/  500000 | consumed samples:     23968000 | elapsed time per iteration (ms): 620.4 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.964598E+00 | loss scale: 1048576.0 | grad norm: 0.502 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-26 20:24:02] iteration   374600/  500000 | consumed samples:     23974400 | elapsed time per iteration (ms): 617.5 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.964611E+00 | loss scale: 1048576.0 | grad norm: 0.484 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 20:25:04] iteration   374700/  500000 | consumed samples:     23980800 | elapsed time per iteration (ms): 616.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.962393E+00 | loss scale: 1048576.0 | grad norm: 0.499 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 20:26:06] iteration   374800/  500000 | consumed samples:     23987200 | elapsed time per iteration (ms): 620.1 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.969494E+00 | loss scale: 1048576.0 | grad norm: 0.505 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 20:27:08] iteration   374900/  500000 | consumed samples:     23993600 | elapsed time per iteration (ms): 619.2 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.949981E+00 | loss scale: 1048576.0 | grad norm: 0.493 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 20:28:10] iteration   375000/  500000 | consumed samples:     24000000 | elapsed time per iteration (ms): 619.3 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.962985E+00 | loss scale: 1048576.0 | grad norm: 0.497 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2463.38, 2463.39)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 375000 | lm loss value: 3.723912E+00 | lm loss PPL: 4.142613E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-26 20:29:14] iteration   375100/  500000 | consumed samples:     24006400 | elapsed time per iteration (ms): 619.3 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.957008E+00 | loss scale: 1048576.0 | grad norm: 0.489 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 20:30:16] iteration   375200/  500000 | consumed samples:     24012800 | elapsed time per iteration (ms): 619.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.950782E+00 | loss scale: 1048576.0 | grad norm: 0.506 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 20:31:18] iteration   375300/  500000 | consumed samples:     24019200 | elapsed time per iteration (ms): 620.1 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.970856E+00 | loss scale: 1048576.0 | grad norm: 0.498 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 20:32:20] iteration   375400/  500000 | consumed samples:     24025600 | elapsed time per iteration (ms): 619.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.950816E+00 | loss scale: 1048576.0 | grad norm: 0.506 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 20:33:22] iteration   375500/  500000 | consumed samples:     24032000 | elapsed time per iteration (ms): 618.1 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.950247E+00 | loss scale: 2097152.0 | grad norm: 0.501 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 20:34:24] iteration   375600/  500000 | consumed samples:     24038400 | elapsed time per iteration (ms): 620.3 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.933761E+00 | loss scale: 2097152.0 | grad norm: 0.490 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-26 20:35:25] iteration   375700/  500000 | consumed samples:     24044800 | elapsed time per iteration (ms): 617.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.963203E+00 | loss scale: 1048576.0 | grad norm: 0.504 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-26 20:36:27] iteration   375800/  500000 | consumed samples:     24051200 | elapsed time per iteration (ms): 619.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.968934E+00 | loss scale: 1048576.0 | grad norm: 0.489 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 20:37:29] iteration   375900/  500000 | consumed samples:     24057600 | elapsed time per iteration (ms): 619.1 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.947311E+00 | loss scale: 524288.0 | grad norm: 0.496 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-26 20:38:31] iteration   376000/  500000 | consumed samples:     24064000 | elapsed time per iteration (ms): 616.7 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.966824E+00 | loss scale: 524288.0 | grad norm: 0.495 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2461.28, 2461.31)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 376000 | lm loss value: 3.779176E+00 | lm loss PPL: 4.377993E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-26 20:39:35] iteration   376100/  500000 | consumed samples:     24070400 | elapsed time per iteration (ms): 619.4 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.956067E+00 | loss scale: 524288.0 | grad norm: 0.486 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 20:40:37] iteration   376200/  500000 | consumed samples:     24076800 | elapsed time per iteration (ms): 619.3 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.958757E+00 | loss scale: 524288.0 | grad norm: 0.513 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 20:41:39] iteration   376300/  500000 | consumed samples:     24083200 | elapsed time per iteration (ms): 618.6 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.954457E+00 | loss scale: 524288.0 | grad norm: 0.494 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 20:42:41] iteration   376400/  500000 | consumed samples:     24089600 | elapsed time per iteration (ms): 619.7 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.938446E+00 | loss scale: 524288.0 | grad norm: 0.500 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 20:43:43] iteration   376500/  500000 | consumed samples:     24096000 | elapsed time per iteration (ms): 620.2 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.969335E+00 | loss scale: 524288.0 | grad norm: 0.495 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 20:44:45] iteration   376600/  500000 | consumed samples:     24102400 | elapsed time per iteration (ms): 618.1 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.946654E+00 | loss scale: 524288.0 | grad norm: 0.487 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 20:45:47] iteration   376700/  500000 | consumed samples:     24108800 | elapsed time per iteration (ms): 619.7 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.967132E+00 | loss scale: 524288.0 | grad norm: 0.503 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 20:46:49] iteration   376800/  500000 | consumed samples:     24115200 | elapsed time per iteration (ms): 619.1 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.966969E+00 | loss scale: 524288.0 | grad norm: 0.498 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 20:47:51] iteration   376900/  500000 | consumed samples:     24121600 | elapsed time per iteration (ms): 620.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.950681E+00 | loss scale: 1048576.0 | grad norm: 0.504 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 20:48:53] iteration   377000/  500000 | consumed samples:     24128000 | elapsed time per iteration (ms): 619.5 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.951277E+00 | loss scale: 1048576.0 | grad norm: 0.490 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2460.61, 2460.65)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 377000 | lm loss value: 3.707951E+00 | lm loss PPL: 4.077017E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-26 20:49:57] iteration   377100/  500000 | consumed samples:     24134400 | elapsed time per iteration (ms): 619.6 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.959633E+00 | loss scale: 1048576.0 | grad norm: 0.507 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 20:50:59] iteration   377200/  500000 | consumed samples:     24140800 | elapsed time per iteration (ms): 620.2 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.965485E+00 | loss scale: 1048576.0 | grad norm: 0.495 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 20:52:01] iteration   377300/  500000 | consumed samples:     24147200 | elapsed time per iteration (ms): 618.1 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.947895E+00 | loss scale: 1048576.0 | grad norm: 0.507 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 20:53:03] iteration   377400/  500000 | consumed samples:     24153600 | elapsed time per iteration (ms): 620.4 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.952229E+00 | loss scale: 1048576.0 | grad norm: 0.495 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 20:54:05] iteration   377500/  500000 | consumed samples:     24160000 | elapsed time per iteration (ms): 618.7 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.948211E+00 | loss scale: 1048576.0 | grad norm: 0.498 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 20:55:07] iteration   377600/  500000 | consumed samples:     24166400 | elapsed time per iteration (ms): 619.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.943333E+00 | loss scale: 1048576.0 | grad norm: 0.488 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 20:56:09] iteration   377700/  500000 | consumed samples:     24172800 | elapsed time per iteration (ms): 618.4 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.954041E+00 | loss scale: 1048576.0 | grad norm: 0.487 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 20:57:11] iteration   377800/  500000 | consumed samples:     24179200 | elapsed time per iteration (ms): 621.2 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.964893E+00 | loss scale: 1048576.0 | grad norm: 0.491 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 20:58:13] iteration   377900/  500000 | consumed samples:     24185600 | elapsed time per iteration (ms): 618.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.964493E+00 | loss scale: 2097152.0 | grad norm: 0.501 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-26 20:59:15] iteration   378000/  500000 | consumed samples:     24192000 | elapsed time per iteration (ms): 619.2 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.949539E+00 | loss scale: 1048576.0 | grad norm: 0.495 | number of skipped iterations:   1 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2461.31, 2461.41)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 378000 | lm loss value: 3.793797E+00 | lm loss PPL: 4.442477E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-26 21:00:19] iteration   378100/  500000 | consumed samples:     24198400 | elapsed time per iteration (ms): 619.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.958914E+00 | loss scale: 1048576.0 | grad norm: 0.490 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 21:01:21] iteration   378200/  500000 | consumed samples:     24204800 | elapsed time per iteration (ms): 620.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.959655E+00 | loss scale: 1048576.0 | grad norm: 0.494 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 21:02:23] iteration   378300/  500000 | consumed samples:     24211200 | elapsed time per iteration (ms): 618.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.957098E+00 | loss scale: 1048576.0 | grad norm: 0.495 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 21:03:25] iteration   378400/  500000 | consumed samples:     24217600 | elapsed time per iteration (ms): 620.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.948842E+00 | loss scale: 1048576.0 | grad norm: 0.511 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 21:04:27] iteration   378500/  500000 | consumed samples:     24224000 | elapsed time per iteration (ms): 618.6 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.980335E+00 | loss scale: 1048576.0 | grad norm: 0.500 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 21:05:29] iteration   378600/  500000 | consumed samples:     24230400 | elapsed time per iteration (ms): 620.3 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.964069E+00 | loss scale: 1048576.0 | grad norm: 0.512 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 21:06:31] iteration   378700/  500000 | consumed samples:     24236800 | elapsed time per iteration (ms): 619.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.962751E+00 | loss scale: 1048576.0 | grad norm: 0.502 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 21:07:33] iteration   378800/  500000 | consumed samples:     24243200 | elapsed time per iteration (ms): 619.1 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.945105E+00 | loss scale: 1048576.0 | grad norm: 0.498 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 21:08:35] iteration   378900/  500000 | consumed samples:     24249600 | elapsed time per iteration (ms): 617.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.957209E+00 | loss scale: 1048576.0 | grad norm: 0.489 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 21:09:36] iteration   379000/  500000 | consumed samples:     24256000 | elapsed time per iteration (ms): 617.3 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.958614E+00 | loss scale: 2097152.0 | grad norm: 0.502 | number of skipped iterations:   1 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2461.84, 2461.97)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 379000 | lm loss value: 3.750285E+00 | lm loss PPL: 4.253319E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-26 21:10:41] iteration   379100/  500000 | consumed samples:     24262400 | elapsed time per iteration (ms): 617.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.973716E+00 | loss scale: 1048576.0 | grad norm: 0.499 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-26 21:11:42] iteration   379200/  500000 | consumed samples:     24268800 | elapsed time per iteration (ms): 617.2 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.959120E+00 | loss scale: 1048576.0 | grad norm: 0.500 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 21:12:44] iteration   379300/  500000 | consumed samples:     24275200 | elapsed time per iteration (ms): 619.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.967332E+00 | loss scale: 1048576.0 | grad norm: 0.496 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 21:13:46] iteration   379400/  500000 | consumed samples:     24281600 | elapsed time per iteration (ms): 619.1 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.952203E+00 | loss scale: 1048576.0 | grad norm: 0.500 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 21:14:48] iteration   379500/  500000 | consumed samples:     24288000 | elapsed time per iteration (ms): 621.2 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.973004E+00 | loss scale: 1048576.0 | grad norm: 0.495 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 21:15:50] iteration   379600/  500000 | consumed samples:     24294400 | elapsed time per iteration (ms): 619.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.952296E+00 | loss scale: 1048576.0 | grad norm: 0.500 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 21:16:52] iteration   379700/  500000 | consumed samples:     24300800 | elapsed time per iteration (ms): 621.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.946102E+00 | loss scale: 1048576.0 | grad norm: 0.489 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 21:17:54] iteration   379800/  500000 | consumed samples:     24307200 | elapsed time per iteration (ms): 619.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.942247E+00 | loss scale: 1048576.0 | grad norm: 0.509 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 21:18:56] iteration   379900/  500000 | consumed samples:     24313600 | elapsed time per iteration (ms): 618.1 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.954379E+00 | loss scale: 1048576.0 | grad norm: 0.500 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 21:19:58] iteration   380000/  500000 | consumed samples:     24320000 | elapsed time per iteration (ms): 617.4 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.975087E+00 | loss scale: 1048576.0 | grad norm: 0.503 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2463.59, 2463.68)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 380000 | lm loss value: 3.736773E+00 | lm loss PPL: 4.196234E+01 | 
--------------------------------------------------------------------------------------------------
saving checkpoint at iteration  380000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-distribution in torch format
  successfully saved checkpoint at iteration  380000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-distribution
(min, max) time across ranks (ms):
    save-checkpoint ................................: (2323.62, 2323.63)
 [2024-06-26 21:21:05] iteration   380100/  500000 | consumed samples:     24326400 | elapsed time per iteration (ms): 619.5 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.960274E+00 | loss scale: 1048576.0 | grad norm: 0.493 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-26 21:22:06] iteration   380200/  500000 | consumed samples:     24332800 | elapsed time per iteration (ms): 618.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.967682E+00 | loss scale: 1048576.0 | grad norm: 0.501 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 21:23:08] iteration   380300/  500000 | consumed samples:     24339200 | elapsed time per iteration (ms): 619.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.958593E+00 | loss scale: 1048576.0 | grad norm: 0.500 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 21:24:10] iteration   380400/  500000 | consumed samples:     24345600 | elapsed time per iteration (ms): 620.3 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.963613E+00 | loss scale: 1048576.0 | grad norm: 0.489 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 21:25:12] iteration   380500/  500000 | consumed samples:     24352000 | elapsed time per iteration (ms): 618.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.943910E+00 | loss scale: 1048576.0 | grad norm: 0.493 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 21:26:14] iteration   380600/  500000 | consumed samples:     24358400 | elapsed time per iteration (ms): 619.7 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.960471E+00 | loss scale: 1048576.0 | grad norm: 0.497 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 21:27:16] iteration   380700/  500000 | consumed samples:     24364800 | elapsed time per iteration (ms): 616.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.962037E+00 | loss scale: 1048576.0 | grad norm: 0.495 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 21:28:18] iteration   380800/  500000 | consumed samples:     24371200 | elapsed time per iteration (ms): 618.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.967433E+00 | loss scale: 1048576.0 | grad norm: 0.501 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 21:29:20] iteration   380900/  500000 | consumed samples:     24377600 | elapsed time per iteration (ms): 618.3 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.948576E+00 | loss scale: 1048576.0 | grad norm: 0.490 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 21:30:21] iteration   381000/  500000 | consumed samples:     24384000 | elapsed time per iteration (ms): 618.7 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.962285E+00 | loss scale: 1048576.0 | grad norm: 0.513 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2459.89, 2459.99)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 381000 | lm loss value: 3.754154E+00 | lm loss PPL: 4.269809E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-26 21:31:26] iteration   381100/  500000 | consumed samples:     24390400 | elapsed time per iteration (ms): 619.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.967051E+00 | loss scale: 2097152.0 | grad norm: 0.507 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 21:32:28] iteration   381200/  500000 | consumed samples:     24396800 | elapsed time per iteration (ms): 620.4 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.945764E+00 | loss scale: 1048576.0 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-26 21:33:30] iteration   381300/  500000 | consumed samples:     24403200 | elapsed time per iteration (ms): 617.7 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.963411E+00 | loss scale: 1048576.0 | grad norm: 0.507 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 21:34:32] iteration   381400/  500000 | consumed samples:     24409600 | elapsed time per iteration (ms): 619.1 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.955420E+00 | loss scale: 1048576.0 | grad norm: 0.500 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 21:35:34] iteration   381500/  500000 | consumed samples:     24416000 | elapsed time per iteration (ms): 618.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.967085E+00 | loss scale: 1048576.0 | grad norm: 0.501 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 21:36:35] iteration   381600/  500000 | consumed samples:     24422400 | elapsed time per iteration (ms): 618.5 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.962770E+00 | loss scale: 1048576.0 | grad norm: 0.492 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 21:37:37] iteration   381700/  500000 | consumed samples:     24428800 | elapsed time per iteration (ms): 619.3 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.969499E+00 | loss scale: 1048576.0 | grad norm: 0.495 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 21:38:39] iteration   381800/  500000 | consumed samples:     24435200 | elapsed time per iteration (ms): 617.3 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.951496E+00 | loss scale: 1048576.0 | grad norm: 0.502 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 21:39:41] iteration   381900/  500000 | consumed samples:     24441600 | elapsed time per iteration (ms): 618.3 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.947064E+00 | loss scale: 1048576.0 | grad norm: 0.503 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 21:40:43] iteration   382000/  500000 | consumed samples:     24448000 | elapsed time per iteration (ms): 618.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.957259E+00 | loss scale: 1048576.0 | grad norm: 0.502 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2461.48, 2461.60)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 382000 | lm loss value: 3.774808E+00 | lm loss PPL: 4.358915E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-26 21:41:47] iteration   382100/  500000 | consumed samples:     24454400 | elapsed time per iteration (ms): 617.7 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.977048E+00 | loss scale: 1048576.0 | grad norm: 0.494 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 21:42:49] iteration   382200/  500000 | consumed samples:     24460800 | elapsed time per iteration (ms): 621.3 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.960573E+00 | loss scale: 2097152.0 | grad norm: 0.505 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 21:43:51] iteration   382300/  500000 | consumed samples:     24467200 | elapsed time per iteration (ms): 618.6 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.958461E+00 | loss scale: 1048576.0 | grad norm: 0.490 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-26 21:44:53] iteration   382400/  500000 | consumed samples:     24473600 | elapsed time per iteration (ms): 618.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.967533E+00 | loss scale: 1048576.0 | grad norm: 0.498 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 21:45:55] iteration   382500/  500000 | consumed samples:     24480000 | elapsed time per iteration (ms): 616.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.954697E+00 | loss scale: 1048576.0 | grad norm: 0.499 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 21:46:56] iteration   382600/  500000 | consumed samples:     24486400 | elapsed time per iteration (ms): 617.5 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.960215E+00 | loss scale: 1048576.0 | grad norm: 0.493 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 21:47:58] iteration   382700/  500000 | consumed samples:     24492800 | elapsed time per iteration (ms): 620.3 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.936663E+00 | loss scale: 1048576.0 | grad norm: 0.482 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 21:49:00] iteration   382800/  500000 | consumed samples:     24499200 | elapsed time per iteration (ms): 618.3 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.968103E+00 | loss scale: 1048576.0 | grad norm: 0.493 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 21:50:02] iteration   382900/  500000 | consumed samples:     24505600 | elapsed time per iteration (ms): 617.7 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.949910E+00 | loss scale: 1048576.0 | grad norm: 0.509 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 21:51:04] iteration   383000/  500000 | consumed samples:     24512000 | elapsed time per iteration (ms): 621.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.967917E+00 | loss scale: 1048576.0 | grad norm: 0.497 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2461.87, 2461.88)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 383000 | lm loss value: 3.764079E+00 | lm loss PPL: 4.312395E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-26 21:52:09] iteration   383100/  500000 | consumed samples:     24518400 | elapsed time per iteration (ms): 620.6 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.966320E+00 | loss scale: 1048576.0 | grad norm: 0.526 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 21:53:11] iteration   383200/  500000 | consumed samples:     24524800 | elapsed time per iteration (ms): 620.4 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.956848E+00 | loss scale: 1048576.0 | grad norm: 0.494 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 21:54:13] iteration   383300/  500000 | consumed samples:     24531200 | elapsed time per iteration (ms): 619.1 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.964432E+00 | loss scale: 2097152.0 | grad norm: 0.498 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 21:55:14] iteration   383400/  500000 | consumed samples:     24537600 | elapsed time per iteration (ms): 618.2 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.965868E+00 | loss scale: 2097152.0 | grad norm: 0.494 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-26 21:56:16] iteration   383500/  500000 | consumed samples:     24544000 | elapsed time per iteration (ms): 618.5 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.944435E+00 | loss scale: 1048576.0 | grad norm: 0.518 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-26 21:57:18] iteration   383600/  500000 | consumed samples:     24550400 | elapsed time per iteration (ms): 618.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.956812E+00 | loss scale: 1048576.0 | grad norm: 0.491 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 21:58:20] iteration   383700/  500000 | consumed samples:     24556800 | elapsed time per iteration (ms): 618.5 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.966740E+00 | loss scale: 1048576.0 | grad norm: 0.488 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 21:59:22] iteration   383800/  500000 | consumed samples:     24563200 | elapsed time per iteration (ms): 619.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.970160E+00 | loss scale: 1048576.0 | grad norm: 0.509 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 22:00:24] iteration   383900/  500000 | consumed samples:     24569600 | elapsed time per iteration (ms): 618.4 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.964167E+00 | loss scale: 1048576.0 | grad norm: 0.507 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 22:01:26] iteration   384000/  500000 | consumed samples:     24576000 | elapsed time per iteration (ms): 618.5 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.959073E+00 | loss scale: 1048576.0 | grad norm: 0.490 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2463.70, 2463.73)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 384000 | lm loss value: 3.726386E+00 | lm loss PPL: 4.152874E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-26 22:02:30] iteration   384100/  500000 | consumed samples:     24582400 | elapsed time per iteration (ms): 617.6 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.950654E+00 | loss scale: 1048576.0 | grad norm: 0.486 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 22:03:32] iteration   384200/  500000 | consumed samples:     24588800 | elapsed time per iteration (ms): 620.6 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.968291E+00 | loss scale: 1048576.0 | grad norm: 0.517 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 22:04:34] iteration   384300/  500000 | consumed samples:     24595200 | elapsed time per iteration (ms): 617.3 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.958060E+00 | loss scale: 1048576.0 | grad norm: 0.514 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 22:05:35] iteration   384400/  500000 | consumed samples:     24601600 | elapsed time per iteration (ms): 618.5 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.951393E+00 | loss scale: 1048576.0 | grad norm: 0.487 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 22:06:37] iteration   384500/  500000 | consumed samples:     24608000 | elapsed time per iteration (ms): 619.5 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.956509E+00 | loss scale: 1048576.0 | grad norm: 0.483 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-26 22:07:39] iteration   384600/  500000 | consumed samples:     24614400 | elapsed time per iteration (ms): 618.5 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.967112E+00 | loss scale: 1048576.0 | grad norm: 0.503 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 22:08:41] iteration   384700/  500000 | consumed samples:     24620800 | elapsed time per iteration (ms): 618.2 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.972589E+00 | loss scale: 1048576.0 | grad norm: 0.491 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 22:09:43] iteration   384800/  500000 | consumed samples:     24627200 | elapsed time per iteration (ms): 618.6 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.950143E+00 | loss scale: 1048576.0 | grad norm: 0.488 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 22:10:45] iteration   384900/  500000 | consumed samples:     24633600 | elapsed time per iteration (ms): 618.7 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.960734E+00 | loss scale: 1048576.0 | grad norm: 0.519 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 22:11:47] iteration   385000/  500000 | consumed samples:     24640000 | elapsed time per iteration (ms): 618.6 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.952973E+00 | loss scale: 1048576.0 | grad norm: 0.511 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2461.63, 2462.22)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 385000 | lm loss value: 3.733746E+00 | lm loss PPL: 4.183554E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-26 22:12:51] iteration   385100/  500000 | consumed samples:     24646400 | elapsed time per iteration (ms): 619.2 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.965212E+00 | loss scale: 1048576.0 | grad norm: 0.495 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 22:13:53] iteration   385200/  500000 | consumed samples:     24652800 | elapsed time per iteration (ms): 618.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.961868E+00 | loss scale: 1048576.0 | grad norm: 0.496 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 22:14:55] iteration   385300/  500000 | consumed samples:     24659200 | elapsed time per iteration (ms): 618.1 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.945444E+00 | loss scale: 1048576.0 | grad norm: 0.497 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 22:15:57] iteration   385400/  500000 | consumed samples:     24665600 | elapsed time per iteration (ms): 619.5 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.961068E+00 | loss scale: 1048576.0 | grad norm: 0.503 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 22:16:59] iteration   385500/  500000 | consumed samples:     24672000 | elapsed time per iteration (ms): 618.7 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.963201E+00 | loss scale: 1048576.0 | grad norm: 0.491 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-26 22:18:01] iteration   385600/  500000 | consumed samples:     24678400 | elapsed time per iteration (ms): 619.6 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.971552E+00 | loss scale: 1048576.0 | grad norm: 0.501 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 22:19:02] iteration   385700/  500000 | consumed samples:     24684800 | elapsed time per iteration (ms): 618.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.971733E+00 | loss scale: 1048576.0 | grad norm: 0.495 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 22:20:04] iteration   385800/  500000 | consumed samples:     24691200 | elapsed time per iteration (ms): 618.7 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.959730E+00 | loss scale: 1048576.0 | grad norm: 0.495 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 22:21:06] iteration   385900/  500000 | consumed samples:     24697600 | elapsed time per iteration (ms): 621.1 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.963099E+00 | loss scale: 1048576.0 | grad norm: 0.496 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 22:22:08] iteration   386000/  500000 | consumed samples:     24704000 | elapsed time per iteration (ms): 619.5 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.952130E+00 | loss scale: 1048576.0 | grad norm: 0.503 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2462.58, 2462.72)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 386000 | lm loss value: 3.698591E+00 | lm loss PPL: 4.039036E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-26 22:23:13] iteration   386100/  500000 | consumed samples:     24710400 | elapsed time per iteration (ms): 618.4 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.957841E+00 | loss scale: 1048576.0 | grad norm: 0.487 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 22:24:14] iteration   386200/  500000 | consumed samples:     24716800 | elapsed time per iteration (ms): 619.1 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.964620E+00 | loss scale: 1048576.0 | grad norm: 0.505 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 22:25:16] iteration   386300/  500000 | consumed samples:     24723200 | elapsed time per iteration (ms): 618.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.958268E+00 | loss scale: 1048576.0 | grad norm: 0.497 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 22:26:18] iteration   386400/  500000 | consumed samples:     24729600 | elapsed time per iteration (ms): 620.1 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.937369E+00 | loss scale: 1048576.0 | grad norm: 0.501 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 22:27:20] iteration   386500/  500000 | consumed samples:     24736000 | elapsed time per iteration (ms): 617.7 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.958522E+00 | loss scale: 2097152.0 | grad norm: 0.506 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 22:28:22] iteration   386600/  500000 | consumed samples:     24742400 | elapsed time per iteration (ms): 617.2 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.949868E+00 | loss scale: 1048576.0 | grad norm: 0.489 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-26 22:29:24] iteration   386700/  500000 | consumed samples:     24748800 | elapsed time per iteration (ms): 617.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.964865E+00 | loss scale: 1048576.0 | grad norm: 0.497 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 22:30:25] iteration   386800/  500000 | consumed samples:     24755200 | elapsed time per iteration (ms): 617.7 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.963541E+00 | loss scale: 1048576.0 | grad norm: 0.505 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 22:31:27] iteration   386900/  500000 | consumed samples:     24761600 | elapsed time per iteration (ms): 618.3 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.953130E+00 | loss scale: 1048576.0 | grad norm: 0.510 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 22:32:29] iteration   387000/  500000 | consumed samples:     24768000 | elapsed time per iteration (ms): 617.6 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.956662E+00 | loss scale: 1048576.0 | grad norm: 0.504 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2461.27, 2461.29)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 387000 | lm loss value: 3.707525E+00 | lm loss PPL: 4.075282E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-26 22:33:33] iteration   387100/  500000 | consumed samples:     24774400 | elapsed time per iteration (ms): 616.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.956536E+00 | loss scale: 1048576.0 | grad norm: 0.495 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 22:34:35] iteration   387200/  500000 | consumed samples:     24780800 | elapsed time per iteration (ms): 619.3 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.971742E+00 | loss scale: 1048576.0 | grad norm: 0.493 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 22:35:37] iteration   387300/  500000 | consumed samples:     24787200 | elapsed time per iteration (ms): 617.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.948881E+00 | loss scale: 1048576.0 | grad norm: 0.493 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 22:36:39] iteration   387400/  500000 | consumed samples:     24793600 | elapsed time per iteration (ms): 620.1 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.965799E+00 | loss scale: 1048576.0 | grad norm: 0.499 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 22:37:41] iteration   387500/  500000 | consumed samples:     24800000 | elapsed time per iteration (ms): 619.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.973706E+00 | loss scale: 1048576.0 | grad norm: 0.494 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 22:38:43] iteration   387600/  500000 | consumed samples:     24806400 | elapsed time per iteration (ms): 618.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.957876E+00 | loss scale: 2097152.0 | grad norm: 0.501 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-26 22:39:45] iteration   387700/  500000 | consumed samples:     24812800 | elapsed time per iteration (ms): 619.7 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.955420E+00 | loss scale: 2097152.0 | grad norm: 0.502 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 22:40:46] iteration   387800/  500000 | consumed samples:     24819200 | elapsed time per iteration (ms): 617.5 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.949873E+00 | loss scale: 1048576.0 | grad norm: 0.503 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-26 22:41:48] iteration   387900/  500000 | consumed samples:     24825600 | elapsed time per iteration (ms): 618.2 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.953791E+00 | loss scale: 1048576.0 | grad norm: 0.504 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 22:42:50] iteration   388000/  500000 | consumed samples:     24832000 | elapsed time per iteration (ms): 619.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.945438E+00 | loss scale: 1048576.0 | grad norm: 0.490 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2462.03, 2462.11)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 388000 | lm loss value: 3.701242E+00 | lm loss PPL: 4.049756E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-26 22:43:55] iteration   388100/  500000 | consumed samples:     24838400 | elapsed time per iteration (ms): 619.1 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.941173E+00 | loss scale: 1048576.0 | grad norm: 0.485 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 22:44:57] iteration   388200/  500000 | consumed samples:     24844800 | elapsed time per iteration (ms): 620.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.947239E+00 | loss scale: 1048576.0 | grad norm: 0.507 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 22:45:58] iteration   388300/  500000 | consumed samples:     24851200 | elapsed time per iteration (ms): 618.3 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.955657E+00 | loss scale: 1048576.0 | grad norm: 0.519 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 22:47:00] iteration   388400/  500000 | consumed samples:     24857600 | elapsed time per iteration (ms): 618.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.962928E+00 | loss scale: 1048576.0 | grad norm: 0.491 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 22:48:02] iteration   388500/  500000 | consumed samples:     24864000 | elapsed time per iteration (ms): 620.1 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.956059E+00 | loss scale: 1048576.0 | grad norm: 0.496 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 22:49:04] iteration   388600/  500000 | consumed samples:     24870400 | elapsed time per iteration (ms): 619.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.969807E+00 | loss scale: 1048576.0 | grad norm: 0.498 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 22:50:06] iteration   388700/  500000 | consumed samples:     24876800 | elapsed time per iteration (ms): 619.3 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.964781E+00 | loss scale: 1048576.0 | grad norm: 0.515 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 22:51:08] iteration   388800/  500000 | consumed samples:     24883200 | elapsed time per iteration (ms): 618.1 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.963926E+00 | loss scale: 1048576.0 | grad norm: 0.514 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-26 22:52:10] iteration   388900/  500000 | consumed samples:     24889600 | elapsed time per iteration (ms): 619.3 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.958910E+00 | loss scale: 1048576.0 | grad norm: 0.499 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 22:53:12] iteration   389000/  500000 | consumed samples:     24896000 | elapsed time per iteration (ms): 619.4 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.955120E+00 | loss scale: 1048576.0 | grad norm: 0.506 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2462.61, 2462.71)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 389000 | lm loss value: 3.756155E+00 | lm loss PPL: 4.278363E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-26 22:54:16] iteration   389100/  500000 | consumed samples:     24902400 | elapsed time per iteration (ms): 618.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.967863E+00 | loss scale: 1048576.0 | grad norm: 0.501 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 22:55:18] iteration   389200/  500000 | consumed samples:     24908800 | elapsed time per iteration (ms): 621.3 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.978998E+00 | loss scale: 1048576.0 | grad norm: 0.503 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 22:56:20] iteration   389300/  500000 | consumed samples:     24915200 | elapsed time per iteration (ms): 617.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.947300E+00 | loss scale: 1048576.0 | grad norm: 0.500 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 22:57:22] iteration   389400/  500000 | consumed samples:     24921600 | elapsed time per iteration (ms): 619.6 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.964485E+00 | loss scale: 1048576.0 | grad norm: 0.507 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 22:58:24] iteration   389500/  500000 | consumed samples:     24928000 | elapsed time per iteration (ms): 622.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.969119E+00 | loss scale: 1048576.0 | grad norm: 0.499 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 22:59:26] iteration   389600/  500000 | consumed samples:     24934400 | elapsed time per iteration (ms): 617.2 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.968884E+00 | loss scale: 1048576.0 | grad norm: 0.505 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 23:00:28] iteration   389700/  500000 | consumed samples:     24940800 | elapsed time per iteration (ms): 618.5 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.952908E+00 | loss scale: 1048576.0 | grad norm: 0.501 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 23:01:30] iteration   389800/  500000 | consumed samples:     24947200 | elapsed time per iteration (ms): 617.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.966151E+00 | loss scale: 2097152.0 | grad norm: 0.500 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 23:02:31] iteration   389900/  500000 | consumed samples:     24953600 | elapsed time per iteration (ms): 616.6 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.955186E+00 | loss scale: 1048576.0 | grad norm: 0.507 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-26 23:03:33] iteration   390000/  500000 | consumed samples:     24960000 | elapsed time per iteration (ms): 619.3 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.937841E+00 | loss scale: 1048576.0 | grad norm: 0.500 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2461.00, 2461.03)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 390000 | lm loss value: 3.743750E+00 | lm loss PPL: 4.225614E+01 | 
--------------------------------------------------------------------------------------------------
saving checkpoint at iteration  390000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-distribution in torch format
  successfully saved checkpoint at iteration  390000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-distribution
(min, max) time across ranks (ms):
    save-checkpoint ................................: (2357.21, 2357.21)
 [2024-06-26 23:04:40] iteration   390100/  500000 | consumed samples:     24966400 | elapsed time per iteration (ms): 619.2 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.966172E+00 | loss scale: 1048576.0 | grad norm: 0.499 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 23:05:42] iteration   390200/  500000 | consumed samples:     24972800 | elapsed time per iteration (ms): 619.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.951645E+00 | loss scale: 1048576.0 | grad norm: 0.495 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 23:06:44] iteration   390300/  500000 | consumed samples:     24979200 | elapsed time per iteration (ms): 618.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.967976E+00 | loss scale: 1048576.0 | grad norm: 0.505 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 23:07:46] iteration   390400/  500000 | consumed samples:     24985600 | elapsed time per iteration (ms): 618.3 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.962124E+00 | loss scale: 1048576.0 | grad norm: 0.501 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 23:08:48] iteration   390500/  500000 | consumed samples:     24992000 | elapsed time per iteration (ms): 619.7 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.953286E+00 | loss scale: 1048576.0 | grad norm: 0.497 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 23:09:49] iteration   390600/  500000 | consumed samples:     24998400 | elapsed time per iteration (ms): 618.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.965962E+00 | loss scale: 1048576.0 | grad norm: 0.516 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 23:10:51] iteration   390700/  500000 | consumed samples:     25004800 | elapsed time per iteration (ms): 618.2 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.957862E+00 | loss scale: 1048576.0 | grad norm: 0.494 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 23:11:53] iteration   390800/  500000 | consumed samples:     25011200 | elapsed time per iteration (ms): 618.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.959055E+00 | loss scale: 1048576.0 | grad norm: 0.496 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 23:12:55] iteration   390900/  500000 | consumed samples:     25017600 | elapsed time per iteration (ms): 620.2 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.969268E+00 | loss scale: 2097152.0 | grad norm: 0.488 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 23:13:57] iteration   391000/  500000 | consumed samples:     25024000 | elapsed time per iteration (ms): 618.4 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.960389E+00 | loss scale: 1048576.0 | grad norm: 0.500 | number of skipped iterations:   2 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2461.63, 2461.64)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 391000 | lm loss value: 3.680670E+00 | lm loss PPL: 3.967295E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-26 23:15:01] iteration   391100/  500000 | consumed samples:     25030400 | elapsed time per iteration (ms): 618.6 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.963693E+00 | loss scale: 1048576.0 | grad norm: 0.515 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 23:16:03] iteration   391200/  500000 | consumed samples:     25036800 | elapsed time per iteration (ms): 616.5 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.943309E+00 | loss scale: 1048576.0 | grad norm: 0.497 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 23:17:05] iteration   391300/  500000 | consumed samples:     25043200 | elapsed time per iteration (ms): 618.7 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.977731E+00 | loss scale: 1048576.0 | grad norm: 0.503 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 23:18:07] iteration   391400/  500000 | consumed samples:     25049600 | elapsed time per iteration (ms): 619.5 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.959793E+00 | loss scale: 1048576.0 | grad norm: 0.492 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 23:19:09] iteration   391500/  500000 | consumed samples:     25056000 | elapsed time per iteration (ms): 618.7 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.944127E+00 | loss scale: 1048576.0 | grad norm: 0.506 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 23:20:10] iteration   391600/  500000 | consumed samples:     25062400 | elapsed time per iteration (ms): 616.5 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.959022E+00 | loss scale: 1048576.0 | grad norm: 0.486 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 23:21:12] iteration   391700/  500000 | consumed samples:     25068800 | elapsed time per iteration (ms): 618.3 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.953803E+00 | loss scale: 1048576.0 | grad norm: 0.492 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 23:22:14] iteration   391800/  500000 | consumed samples:     25075200 | elapsed time per iteration (ms): 619.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.950166E+00 | loss scale: 1048576.0 | grad norm: 0.500 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 23:23:16] iteration   391900/  500000 | consumed samples:     25081600 | elapsed time per iteration (ms): 618.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.948359E+00 | loss scale: 1048576.0 | grad norm: 0.512 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 23:24:18] iteration   392000/  500000 | consumed samples:     25088000 | elapsed time per iteration (ms): 617.6 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.970912E+00 | loss scale: 2097152.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2466.12, 2466.21)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 392000 | lm loss value: 3.731980E+00 | lm loss PPL: 4.176172E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-26 23:25:22] iteration   392100/  500000 | consumed samples:     25094400 | elapsed time per iteration (ms): 620.3 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.963420E+00 | loss scale: 1048576.0 | grad norm: 0.505 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-26 23:26:24] iteration   392200/  500000 | consumed samples:     25100800 | elapsed time per iteration (ms): 617.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.947446E+00 | loss scale: 1048576.0 | grad norm: 0.495 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 23:27:26] iteration   392300/  500000 | consumed samples:     25107200 | elapsed time per iteration (ms): 616.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.959122E+00 | loss scale: 1048576.0 | grad norm: 0.495 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 23:28:27] iteration   392400/  500000 | consumed samples:     25113600 | elapsed time per iteration (ms): 617.6 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.962044E+00 | loss scale: 1048576.0 | grad norm: 0.486 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 23:29:29] iteration   392500/  500000 | consumed samples:     25120000 | elapsed time per iteration (ms): 618.6 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.959363E+00 | loss scale: 1048576.0 | grad norm: 0.508 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 23:30:31] iteration   392600/  500000 | consumed samples:     25126400 | elapsed time per iteration (ms): 618.5 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.957987E+00 | loss scale: 1048576.0 | grad norm: 0.499 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 23:31:33] iteration   392700/  500000 | consumed samples:     25132800 | elapsed time per iteration (ms): 620.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.957981E+00 | loss scale: 1048576.0 | grad norm: 0.500 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 23:32:35] iteration   392800/  500000 | consumed samples:     25139200 | elapsed time per iteration (ms): 620.5 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.963876E+00 | loss scale: 1048576.0 | grad norm: 0.505 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 23:33:37] iteration   392900/  500000 | consumed samples:     25145600 | elapsed time per iteration (ms): 618.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.958436E+00 | loss scale: 1048576.0 | grad norm: 0.503 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 23:34:39] iteration   393000/  500000 | consumed samples:     25152000 | elapsed time per iteration (ms): 620.4 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.956556E+00 | loss scale: 1048576.0 | grad norm: 0.486 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2463.50, 2463.55)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 393000 | lm loss value: 3.709193E+00 | lm loss PPL: 4.082084E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-26 23:35:43] iteration   393100/  500000 | consumed samples:     25158400 | elapsed time per iteration (ms): 618.7 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.942381E+00 | loss scale: 1048576.0 | grad norm: 0.492 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-26 23:36:45] iteration   393200/  500000 | consumed samples:     25164800 | elapsed time per iteration (ms): 620.2 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.951210E+00 | loss scale: 1048576.0 | grad norm: 0.496 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 23:37:47] iteration   393300/  500000 | consumed samples:     25171200 | elapsed time per iteration (ms): 619.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.944685E+00 | loss scale: 1048576.0 | grad norm: 0.497 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 23:38:49] iteration   393400/  500000 | consumed samples:     25177600 | elapsed time per iteration (ms): 618.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.969120E+00 | loss scale: 1048576.0 | grad norm: 0.499 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 23:39:51] iteration   393500/  500000 | consumed samples:     25184000 | elapsed time per iteration (ms): 618.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.952410E+00 | loss scale: 1048576.0 | grad norm: 0.500 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 23:40:53] iteration   393600/  500000 | consumed samples:     25190400 | elapsed time per iteration (ms): 619.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.961191E+00 | loss scale: 1048576.0 | grad norm: 0.509 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 23:41:55] iteration   393700/  500000 | consumed samples:     25196800 | elapsed time per iteration (ms): 618.5 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.959404E+00 | loss scale: 1048576.0 | grad norm: 0.506 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 23:42:57] iteration   393800/  500000 | consumed samples:     25203200 | elapsed time per iteration (ms): 618.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.963350E+00 | loss scale: 1048576.0 | grad norm: 0.505 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 23:43:58] iteration   393900/  500000 | consumed samples:     25209600 | elapsed time per iteration (ms): 616.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.965028E+00 | loss scale: 1048576.0 | grad norm: 0.504 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 23:45:00] iteration   394000/  500000 | consumed samples:     25216000 | elapsed time per iteration (ms): 619.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.944242E+00 | loss scale: 524288.0 | grad norm: 0.500 | number of skipped iterations:   1 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2466.69, 2466.77)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 394000 | lm loss value: 3.721070E+00 | lm loss PPL: 4.130856E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-26 23:46:05] iteration   394100/  500000 | consumed samples:     25222400 | elapsed time per iteration (ms): 619.3 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.974343E+00 | loss scale: 524288.0 | grad norm: 0.497 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 23:47:06] iteration   394200/  500000 | consumed samples:     25228800 | elapsed time per iteration (ms): 615.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.953465E+00 | loss scale: 524288.0 | grad norm: 0.495 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 23:48:08] iteration   394300/  500000 | consumed samples:     25235200 | elapsed time per iteration (ms): 616.3 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.963288E+00 | loss scale: 524288.0 | grad norm: 0.492 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 23:49:10] iteration   394400/  500000 | consumed samples:     25241600 | elapsed time per iteration (ms): 620.4 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.966881E+00 | loss scale: 524288.0 | grad norm: 0.489 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 23:50:12] iteration   394500/  500000 | consumed samples:     25248000 | elapsed time per iteration (ms): 619.1 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.963900E+00 | loss scale: 524288.0 | grad norm: 0.503 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 23:51:14] iteration   394600/  500000 | consumed samples:     25254400 | elapsed time per iteration (ms): 618.3 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.954581E+00 | loss scale: 524288.0 | grad norm: 0.491 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 23:52:16] iteration   394700/  500000 | consumed samples:     25260800 | elapsed time per iteration (ms): 619.5 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.937396E+00 | loss scale: 524288.0 | grad norm: 0.497 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 23:53:18] iteration   394800/  500000 | consumed samples:     25267200 | elapsed time per iteration (ms): 617.7 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.974742E+00 | loss scale: 524288.0 | grad norm: 0.489 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 23:54:19] iteration   394900/  500000 | consumed samples:     25273600 | elapsed time per iteration (ms): 618.3 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.967508E+00 | loss scale: 524288.0 | grad norm: 0.489 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 23:55:21] iteration   395000/  500000 | consumed samples:     25280000 | elapsed time per iteration (ms): 619.3 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.959982E+00 | loss scale: 1048576.0 | grad norm: 0.482 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2459.72, 2459.84)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 395000 | lm loss value: 3.717153E+00 | lm loss PPL: 4.114709E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-26 23:56:26] iteration   395100/  500000 | consumed samples:     25286400 | elapsed time per iteration (ms): 618.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.967527E+00 | loss scale: 1048576.0 | grad norm: 0.508 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 23:57:27] iteration   395200/  500000 | consumed samples:     25292800 | elapsed time per iteration (ms): 617.5 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.957007E+00 | loss scale: 1048576.0 | grad norm: 0.498 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 23:58:29] iteration   395300/  500000 | consumed samples:     25299200 | elapsed time per iteration (ms): 617.2 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.954731E+00 | loss scale: 1048576.0 | grad norm: 0.487 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-26 23:59:31] iteration   395400/  500000 | consumed samples:     25305600 | elapsed time per iteration (ms): 620.4 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.951998E+00 | loss scale: 1048576.0 | grad norm: 0.495 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 00:00:33] iteration   395500/  500000 | consumed samples:     25312000 | elapsed time per iteration (ms): 620.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.955927E+00 | loss scale: 1048576.0 | grad norm: 0.494 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 00:01:35] iteration   395600/  500000 | consumed samples:     25318400 | elapsed time per iteration (ms): 618.4 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.957114E+00 | loss scale: 1048576.0 | grad norm: 0.503 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 00:02:37] iteration   395700/  500000 | consumed samples:     25324800 | elapsed time per iteration (ms): 619.3 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.961127E+00 | loss scale: 1048576.0 | grad norm: 0.500 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 00:03:39] iteration   395800/  500000 | consumed samples:     25331200 | elapsed time per iteration (ms): 616.7 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.964608E+00 | loss scale: 1048576.0 | grad norm: 0.497 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 00:04:40] iteration   395900/  500000 | consumed samples:     25337600 | elapsed time per iteration (ms): 618.7 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.969784E+00 | loss scale: 1048576.0 | grad norm: 0.509 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 00:05:42] iteration   396000/  500000 | consumed samples:     25344000 | elapsed time per iteration (ms): 619.7 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.955195E+00 | loss scale: 2097152.0 | grad norm: 0.507 | number of skipped iterations:   1 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2460.17, 2460.44)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 396000 | lm loss value: 3.735239E+00 | lm loss PPL: 4.189803E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-27 00:06:47] iteration   396100/  500000 | consumed samples:     25350400 | elapsed time per iteration (ms): 618.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.954263E+00 | loss scale: 1048576.0 | grad norm: 0.503 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-27 00:07:48] iteration   396200/  500000 | consumed samples:     25356800 | elapsed time per iteration (ms): 617.3 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.945341E+00 | loss scale: 1048576.0 | grad norm: 0.494 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 00:08:50] iteration   396300/  500000 | consumed samples:     25363200 | elapsed time per iteration (ms): 620.5 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.965696E+00 | loss scale: 1048576.0 | grad norm: 0.498 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 00:09:52] iteration   396400/  500000 | consumed samples:     25369600 | elapsed time per iteration (ms): 617.4 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.943436E+00 | loss scale: 1048576.0 | grad norm: 0.511 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 00:10:54] iteration   396500/  500000 | consumed samples:     25376000 | elapsed time per iteration (ms): 618.6 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.952751E+00 | loss scale: 1048576.0 | grad norm: 0.498 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 00:11:56] iteration   396600/  500000 | consumed samples:     25382400 | elapsed time per iteration (ms): 616.2 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.957701E+00 | loss scale: 1048576.0 | grad norm: 0.493 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 00:12:58] iteration   396700/  500000 | consumed samples:     25388800 | elapsed time per iteration (ms): 619.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.967235E+00 | loss scale: 1048576.0 | grad norm: 0.510 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 00:13:59] iteration   396800/  500000 | consumed samples:     25395200 | elapsed time per iteration (ms): 618.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.948036E+00 | loss scale: 1048576.0 | grad norm: 0.508 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 00:15:01] iteration   396900/  500000 | consumed samples:     25401600 | elapsed time per iteration (ms): 617.6 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.958629E+00 | loss scale: 1048576.0 | grad norm: 0.504 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 00:16:03] iteration   397000/  500000 | consumed samples:     25408000 | elapsed time per iteration (ms): 618.2 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.964190E+00 | loss scale: 1048576.0 | grad norm: 0.503 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2462.28, 2462.29)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 397000 | lm loss value: 3.711653E+00 | lm loss PPL: 4.092141E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-27 00:17:07] iteration   397100/  500000 | consumed samples:     25414400 | elapsed time per iteration (ms): 620.1 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.959516E+00 | loss scale: 2097152.0 | grad norm: 0.505 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-27 00:18:09] iteration   397200/  500000 | consumed samples:     25420800 | elapsed time per iteration (ms): 620.2 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.950786E+00 | loss scale: 1048576.0 | grad norm: 0.504 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-27 00:19:11] iteration   397300/  500000 | consumed samples:     25427200 | elapsed time per iteration (ms): 618.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.968966E+00 | loss scale: 1048576.0 | grad norm: 0.488 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 00:20:13] iteration   397400/  500000 | consumed samples:     25433600 | elapsed time per iteration (ms): 619.5 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.965117E+00 | loss scale: 1048576.0 | grad norm: 0.498 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 00:21:15] iteration   397500/  500000 | consumed samples:     25440000 | elapsed time per iteration (ms): 618.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.941852E+00 | loss scale: 1048576.0 | grad norm: 0.503 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 00:22:17] iteration   397600/  500000 | consumed samples:     25446400 | elapsed time per iteration (ms): 618.2 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.973186E+00 | loss scale: 1048576.0 | grad norm: 0.498 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 00:23:19] iteration   397700/  500000 | consumed samples:     25452800 | elapsed time per iteration (ms): 621.1 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.972845E+00 | loss scale: 1048576.0 | grad norm: 0.512 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 00:24:21] iteration   397800/  500000 | consumed samples:     25459200 | elapsed time per iteration (ms): 619.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.963579E+00 | loss scale: 1048576.0 | grad norm: 0.500 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 00:25:23] iteration   397900/  500000 | consumed samples:     25465600 | elapsed time per iteration (ms): 618.7 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.974044E+00 | loss scale: 1048576.0 | grad norm: 0.507 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 00:26:25] iteration   398000/  500000 | consumed samples:     25472000 | elapsed time per iteration (ms): 619.4 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.954590E+00 | loss scale: 1048576.0 | grad norm: 0.509 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2461.59, 2461.74)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 398000 | lm loss value: 3.698348E+00 | lm loss PPL: 4.038053E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-27 00:27:29] iteration   398100/  500000 | consumed samples:     25478400 | elapsed time per iteration (ms): 618.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.954753E+00 | loss scale: 1048576.0 | grad norm: 0.508 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 00:28:31] iteration   398200/  500000 | consumed samples:     25484800 | elapsed time per iteration (ms): 617.7 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.968199E+00 | loss scale: 1048576.0 | grad norm: 0.505 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-27 00:29:33] iteration   398300/  500000 | consumed samples:     25491200 | elapsed time per iteration (ms): 618.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.957978E+00 | loss scale: 1048576.0 | grad norm: 0.488 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 00:30:34] iteration   398400/  500000 | consumed samples:     25497600 | elapsed time per iteration (ms): 617.1 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.962287E+00 | loss scale: 1048576.0 | grad norm: 0.512 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 00:31:36] iteration   398500/  500000 | consumed samples:     25504000 | elapsed time per iteration (ms): 616.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.970096E+00 | loss scale: 1048576.0 | grad norm: 0.490 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 00:32:38] iteration   398600/  500000 | consumed samples:     25510400 | elapsed time per iteration (ms): 618.4 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.955422E+00 | loss scale: 1048576.0 | grad norm: 0.501 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 00:33:40] iteration   398700/  500000 | consumed samples:     25516800 | elapsed time per iteration (ms): 620.7 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.956839E+00 | loss scale: 1048576.0 | grad norm: 0.499 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 00:34:42] iteration   398800/  500000 | consumed samples:     25523200 | elapsed time per iteration (ms): 618.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.956040E+00 | loss scale: 1048576.0 | grad norm: 0.491 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 00:35:44] iteration   398900/  500000 | consumed samples:     25529600 | elapsed time per iteration (ms): 618.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.950255E+00 | loss scale: 1048576.0 | grad norm: 0.496 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 00:36:46] iteration   399000/  500000 | consumed samples:     25536000 | elapsed time per iteration (ms): 618.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.957949E+00 | loss scale: 1048576.0 | grad norm: 0.497 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2460.11, 2460.15)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 399000 | lm loss value: 3.734987E+00 | lm loss PPL: 4.188746E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-27 00:37:50] iteration   399100/  500000 | consumed samples:     25542400 | elapsed time per iteration (ms): 619.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.963440E+00 | loss scale: 1048576.0 | grad norm: 0.499 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 00:38:52] iteration   399200/  500000 | consumed samples:     25548800 | elapsed time per iteration (ms): 617.5 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.960858E+00 | loss scale: 2097152.0 | grad norm: 0.495 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 00:39:54] iteration   399300/  500000 | consumed samples:     25555200 | elapsed time per iteration (ms): 620.4 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.956667E+00 | loss scale: 2097152.0 | grad norm: 0.495 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-27 00:40:56] iteration   399400/  500000 | consumed samples:     25561600 | elapsed time per iteration (ms): 617.1 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.968451E+00 | loss scale: 1048576.0 | grad norm: 0.492 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-27 00:41:57] iteration   399500/  500000 | consumed samples:     25568000 | elapsed time per iteration (ms): 618.2 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.966235E+00 | loss scale: 1048576.0 | grad norm: 0.511 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 00:42:59] iteration   399600/  500000 | consumed samples:     25574400 | elapsed time per iteration (ms): 618.5 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.955798E+00 | loss scale: 1048576.0 | grad norm: 0.508 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 00:44:01] iteration   399700/  500000 | consumed samples:     25580800 | elapsed time per iteration (ms): 618.4 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.973077E+00 | loss scale: 1048576.0 | grad norm: 0.504 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 00:45:03] iteration   399800/  500000 | consumed samples:     25587200 | elapsed time per iteration (ms): 618.5 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.962714E+00 | loss scale: 1048576.0 | grad norm: 0.500 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 00:46:05] iteration   399900/  500000 | consumed samples:     25593600 | elapsed time per iteration (ms): 619.2 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.946047E+00 | loss scale: 1048576.0 | grad norm: 0.489 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 00:47:07] iteration   400000/  500000 | consumed samples:     25600000 | elapsed time per iteration (ms): 620.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.944000E+00 | loss scale: 1048576.0 | grad norm: 0.501 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2459.81, 2459.82)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 400000 | lm loss value: 3.681253E+00 | lm loss PPL: 3.969612E+01 | 
--------------------------------------------------------------------------------------------------
saving checkpoint at iteration  400000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-distribution in torch format
  successfully saved checkpoint at iteration  400000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-distribution
(min, max) time across ranks (ms):
    save-checkpoint ................................: (2448.56, 2448.58)
 [2024-06-27 00:48:14] iteration   400100/  500000 | consumed samples:     25606400 | elapsed time per iteration (ms): 619.5 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.957083E+00 | loss scale: 1048576.0 | grad norm: 0.502 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 00:49:16] iteration   400200/  500000 | consumed samples:     25612800 | elapsed time per iteration (ms): 619.1 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.973999E+00 | loss scale: 1048576.0 | grad norm: 0.497 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 00:50:17] iteration   400300/  500000 | consumed samples:     25619200 | elapsed time per iteration (ms): 618.7 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.960070E+00 | loss scale: 1048576.0 | grad norm: 0.503 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 00:51:19] iteration   400400/  500000 | consumed samples:     25625600 | elapsed time per iteration (ms): 617.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.958328E+00 | loss scale: 2097152.0 | grad norm: 0.489 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-27 00:52:21] iteration   400500/  500000 | consumed samples:     25632000 | elapsed time per iteration (ms): 618.1 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.956559E+00 | loss scale: 1048576.0 | grad norm: 0.497 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-27 00:53:23] iteration   400600/  500000 | consumed samples:     25638400 | elapsed time per iteration (ms): 620.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.952315E+00 | loss scale: 1048576.0 | grad norm: 0.514 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 00:54:25] iteration   400700/  500000 | consumed samples:     25644800 | elapsed time per iteration (ms): 618.4 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.944149E+00 | loss scale: 1048576.0 | grad norm: 0.495 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 00:55:27] iteration   400800/  500000 | consumed samples:     25651200 | elapsed time per iteration (ms): 617.1 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.954543E+00 | loss scale: 1048576.0 | grad norm: 0.515 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 00:56:29] iteration   400900/  500000 | consumed samples:     25657600 | elapsed time per iteration (ms): 619.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.952211E+00 | loss scale: 1048576.0 | grad norm: 0.507 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 00:57:31] iteration   401000/  500000 | consumed samples:     25664000 | elapsed time per iteration (ms): 620.6 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.944967E+00 | loss scale: 1048576.0 | grad norm: 0.500 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2460.54, 2460.60)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 401000 | lm loss value: 3.704412E+00 | lm loss PPL: 4.062614E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-27 00:58:35] iteration   401100/  500000 | consumed samples:     25670400 | elapsed time per iteration (ms): 619.3 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.953572E+00 | loss scale: 1048576.0 | grad norm: 0.519 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 00:59:37] iteration   401200/  500000 | consumed samples:     25676800 | elapsed time per iteration (ms): 618.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.945487E+00 | loss scale: 1048576.0 | grad norm: 0.493 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 01:00:39] iteration   401300/  500000 | consumed samples:     25683200 | elapsed time per iteration (ms): 620.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.949208E+00 | loss scale: 1048576.0 | grad norm: 0.499 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 01:01:41] iteration   401400/  500000 | consumed samples:     25689600 | elapsed time per iteration (ms): 618.5 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.958989E+00 | loss scale: 1048576.0 | grad norm: 0.493 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 01:02:43] iteration   401500/  500000 | consumed samples:     25696000 | elapsed time per iteration (ms): 617.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.951991E+00 | loss scale: 1048576.0 | grad norm: 0.493 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-27 01:03:44] iteration   401600/  500000 | consumed samples:     25702400 | elapsed time per iteration (ms): 617.4 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.957615E+00 | loss scale: 1048576.0 | grad norm: 0.499 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 01:04:46] iteration   401700/  500000 | consumed samples:     25708800 | elapsed time per iteration (ms): 619.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.956808E+00 | loss scale: 1048576.0 | grad norm: 0.483 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 01:05:48] iteration   401800/  500000 | consumed samples:     25715200 | elapsed time per iteration (ms): 618.6 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.956275E+00 | loss scale: 1048576.0 | grad norm: 0.489 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 01:06:50] iteration   401900/  500000 | consumed samples:     25721600 | elapsed time per iteration (ms): 618.2 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.959421E+00 | loss scale: 1048576.0 | grad norm: 0.495 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 01:07:52] iteration   402000/  500000 | consumed samples:     25728000 | elapsed time per iteration (ms): 619.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.958031E+00 | loss scale: 524288.0 | grad norm: 0.507 | number of skipped iterations:   1 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2461.58, 2461.61)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 402000 | lm loss value: 3.720960E+00 | lm loss PPL: 4.130404E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-27 01:08:56] iteration   402100/  500000 | consumed samples:     25734400 | elapsed time per iteration (ms): 619.4 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.962921E+00 | loss scale: 524288.0 | grad norm: 0.509 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 01:09:58] iteration   402200/  500000 | consumed samples:     25740800 | elapsed time per iteration (ms): 618.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.964547E+00 | loss scale: 524288.0 | grad norm: 0.504 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 01:11:00] iteration   402300/  500000 | consumed samples:     25747200 | elapsed time per iteration (ms): 616.5 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.951738E+00 | loss scale: 524288.0 | grad norm: 0.518 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 01:12:02] iteration   402400/  500000 | consumed samples:     25753600 | elapsed time per iteration (ms): 617.6 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.964271E+00 | loss scale: 524288.0 | grad norm: 0.497 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 01:13:03] iteration   402500/  500000 | consumed samples:     25760000 | elapsed time per iteration (ms): 619.1 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.954964E+00 | loss scale: 524288.0 | grad norm: 0.515 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 01:14:05] iteration   402600/  500000 | consumed samples:     25766400 | elapsed time per iteration (ms): 618.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.961258E+00 | loss scale: 524288.0 | grad norm: 0.505 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 01:15:07] iteration   402700/  500000 | consumed samples:     25772800 | elapsed time per iteration (ms): 618.3 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.968049E+00 | loss scale: 524288.0 | grad norm: 0.519 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 01:16:09] iteration   402800/  500000 | consumed samples:     25779200 | elapsed time per iteration (ms): 619.6 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.956773E+00 | loss scale: 524288.0 | grad norm: 0.498 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 01:17:11] iteration   402900/  500000 | consumed samples:     25785600 | elapsed time per iteration (ms): 616.3 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.965049E+00 | loss scale: 524288.0 | grad norm: 0.497 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 01:18:13] iteration   403000/  500000 | consumed samples:     25792000 | elapsed time per iteration (ms): 619.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.962762E+00 | loss scale: 1048576.0 | grad norm: 0.507 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2462.21, 2462.35)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 403000 | lm loss value: 3.789778E+00 | lm loss PPL: 4.424660E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-27 01:19:17] iteration   403100/  500000 | consumed samples:     25798400 | elapsed time per iteration (ms): 617.2 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.970939E+00 | loss scale: 1048576.0 | grad norm: 0.497 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 01:20:19] iteration   403200/  500000 | consumed samples:     25804800 | elapsed time per iteration (ms): 617.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.964540E+00 | loss scale: 1048576.0 | grad norm: 0.494 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 01:21:21] iteration   403300/  500000 | consumed samples:     25811200 | elapsed time per iteration (ms): 620.5 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.954893E+00 | loss scale: 1048576.0 | grad norm: 0.500 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 01:22:22] iteration   403400/  500000 | consumed samples:     25817600 | elapsed time per iteration (ms): 617.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.945302E+00 | loss scale: 1048576.0 | grad norm: 0.504 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 01:23:25] iteration   403500/  500000 | consumed samples:     25824000 | elapsed time per iteration (ms): 620.7 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.958887E+00 | loss scale: 1048576.0 | grad norm: 0.505 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 01:24:27] iteration   403600/  500000 | consumed samples:     25830400 | elapsed time per iteration (ms): 620.2 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.953930E+00 | loss scale: 1048576.0 | grad norm: 0.510 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 01:25:28] iteration   403700/  500000 | consumed samples:     25836800 | elapsed time per iteration (ms): 618.3 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.961122E+00 | loss scale: 1048576.0 | grad norm: 0.486 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 01:26:30] iteration   403800/  500000 | consumed samples:     25843200 | elapsed time per iteration (ms): 619.6 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.958701E+00 | loss scale: 1048576.0 | grad norm: 0.506 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 01:27:32] iteration   403900/  500000 | consumed samples:     25849600 | elapsed time per iteration (ms): 620.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.939579E+00 | loss scale: 1048576.0 | grad norm: 0.500 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 01:28:34] iteration   404000/  500000 | consumed samples:     25856000 | elapsed time per iteration (ms): 616.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.951620E+00 | loss scale: 2097152.0 | grad norm: 0.522 | number of skipped iterations:   1 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2460.30, 2460.38)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 404000 | lm loss value: 3.729277E+00 | lm loss PPL: 4.164900E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-27 01:29:38] iteration   404100/  500000 | consumed samples:     25862400 | elapsed time per iteration (ms): 618.4 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.938785E+00 | loss scale: 1048576.0 | grad norm: 0.502 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-27 01:30:40] iteration   404200/  500000 | consumed samples:     25868800 | elapsed time per iteration (ms): 617.3 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.964312E+00 | loss scale: 1048576.0 | grad norm: 0.511 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 01:31:42] iteration   404300/  500000 | consumed samples:     25875200 | elapsed time per iteration (ms): 622.4 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.962194E+00 | loss scale: 1048576.0 | grad norm: 0.519 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 01:32:44] iteration   404400/  500000 | consumed samples:     25881600 | elapsed time per iteration (ms): 619.2 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.962979E+00 | loss scale: 1048576.0 | grad norm: 0.503 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 01:33:46] iteration   404500/  500000 | consumed samples:     25888000 | elapsed time per iteration (ms): 618.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.957083E+00 | loss scale: 1048576.0 | grad norm: 0.521 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 01:34:48] iteration   404600/  500000 | consumed samples:     25894400 | elapsed time per iteration (ms): 619.3 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.950471E+00 | loss scale: 1048576.0 | grad norm: 0.511 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 01:35:50] iteration   404700/  500000 | consumed samples:     25900800 | elapsed time per iteration (ms): 619.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.954492E+00 | loss scale: 1048576.0 | grad norm: 0.504 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 01:36:52] iteration   404800/  500000 | consumed samples:     25907200 | elapsed time per iteration (ms): 619.3 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.958636E+00 | loss scale: 1048576.0 | grad norm: 0.496 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 01:37:54] iteration   404900/  500000 | consumed samples:     25913600 | elapsed time per iteration (ms): 619.4 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.935985E+00 | loss scale: 1048576.0 | grad norm: 0.495 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 01:38:56] iteration   405000/  500000 | consumed samples:     25920000 | elapsed time per iteration (ms): 620.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.958877E+00 | loss scale: 1048576.0 | grad norm: 0.503 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2459.76, 2459.84)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 405000 | lm loss value: 3.712990E+00 | lm loss PPL: 4.097615E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-27 01:40:00] iteration   405100/  500000 | consumed samples:     25926400 | elapsed time per iteration (ms): 618.5 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.948124E+00 | loss scale: 1048576.0 | grad norm: 0.504 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-27 01:41:02] iteration   405200/  500000 | consumed samples:     25932800 | elapsed time per iteration (ms): 618.1 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.939647E+00 | loss scale: 524288.0 | grad norm: 0.512 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-27 01:42:04] iteration   405300/  500000 | consumed samples:     25939200 | elapsed time per iteration (ms): 617.4 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.961732E+00 | loss scale: 524288.0 | grad norm: 0.495 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 01:43:06] iteration   405400/  500000 | consumed samples:     25945600 | elapsed time per iteration (ms): 618.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.954874E+00 | loss scale: 524288.0 | grad norm: 0.495 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 01:44:07] iteration   405500/  500000 | consumed samples:     25952000 | elapsed time per iteration (ms): 618.1 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.951493E+00 | loss scale: 524288.0 | grad norm: 0.495 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 01:45:09] iteration   405600/  500000 | consumed samples:     25958400 | elapsed time per iteration (ms): 620.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.946932E+00 | loss scale: 524288.0 | grad norm: 0.495 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 01:46:11] iteration   405700/  500000 | consumed samples:     25964800 | elapsed time per iteration (ms): 619.7 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.948853E+00 | loss scale: 524288.0 | grad norm: 0.513 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 01:47:13] iteration   405800/  500000 | consumed samples:     25971200 | elapsed time per iteration (ms): 618.1 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.948107E+00 | loss scale: 524288.0 | grad norm: 0.504 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 01:48:15] iteration   405900/  500000 | consumed samples:     25977600 | elapsed time per iteration (ms): 618.6 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.952408E+00 | loss scale: 524288.0 | grad norm: 0.503 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 01:49:17] iteration   406000/  500000 | consumed samples:     25984000 | elapsed time per iteration (ms): 620.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.951866E+00 | loss scale: 524288.0 | grad norm: 0.507 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2460.67, 2460.69)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 406000 | lm loss value: 3.735695E+00 | lm loss PPL: 4.191714E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-27 01:50:21] iteration   406100/  500000 | consumed samples:     25990400 | elapsed time per iteration (ms): 617.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.963413E+00 | loss scale: 524288.0 | grad norm: 0.496 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 01:51:23] iteration   406200/  500000 | consumed samples:     25996800 | elapsed time per iteration (ms): 619.2 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.972019E+00 | loss scale: 1048576.0 | grad norm: 0.507 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 01:52:25] iteration   406300/  500000 | consumed samples:     26003200 | elapsed time per iteration (ms): 618.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.954332E+00 | loss scale: 1048576.0 | grad norm: 0.515 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 01:53:27] iteration   406400/  500000 | consumed samples:     26009600 | elapsed time per iteration (ms): 616.3 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.966934E+00 | loss scale: 1048576.0 | grad norm: 0.505 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 01:54:28] iteration   406500/  500000 | consumed samples:     26016000 | elapsed time per iteration (ms): 617.5 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.958146E+00 | loss scale: 1048576.0 | grad norm: 0.503 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 01:55:30] iteration   406600/  500000 | consumed samples:     26022400 | elapsed time per iteration (ms): 617.4 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.967095E+00 | loss scale: 1048576.0 | grad norm: 0.498 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 01:56:32] iteration   406700/  500000 | consumed samples:     26028800 | elapsed time per iteration (ms): 620.5 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.972171E+00 | loss scale: 1048576.0 | grad norm: 0.489 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 01:57:34] iteration   406800/  500000 | consumed samples:     26035200 | elapsed time per iteration (ms): 620.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.944444E+00 | loss scale: 1048576.0 | grad norm: 0.508 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 01:58:36] iteration   406900/  500000 | consumed samples:     26041600 | elapsed time per iteration (ms): 618.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.949114E+00 | loss scale: 1048576.0 | grad norm: 0.503 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 01:59:38] iteration   407000/  500000 | consumed samples:     26048000 | elapsed time per iteration (ms): 620.7 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.950986E+00 | loss scale: 1048576.0 | grad norm: 0.495 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2462.95, 2463.03)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 407000 | lm loss value: 3.705905E+00 | lm loss PPL: 4.068686E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-27 02:00:42] iteration   407100/  500000 | consumed samples:     26054400 | elapsed time per iteration (ms): 617.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.977037E+00 | loss scale: 1048576.0 | grad norm: 0.517 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 02:01:44] iteration   407200/  500000 | consumed samples:     26060800 | elapsed time per iteration (ms): 617.3 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.956857E+00 | loss scale: 2097152.0 | grad norm: 0.509 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-27 02:02:46] iteration   407300/  500000 | consumed samples:     26067200 | elapsed time per iteration (ms): 616.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.966491E+00 | loss scale: 1048576.0 | grad norm: 0.508 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-27 02:03:48] iteration   407400/  500000 | consumed samples:     26073600 | elapsed time per iteration (ms): 619.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.961109E+00 | loss scale: 1048576.0 | grad norm: 0.497 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 02:04:50] iteration   407500/  500000 | consumed samples:     26080000 | elapsed time per iteration (ms): 619.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.959301E+00 | loss scale: 1048576.0 | grad norm: 0.506 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 02:05:51] iteration   407600/  500000 | consumed samples:     26086400 | elapsed time per iteration (ms): 618.4 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.953340E+00 | loss scale: 1048576.0 | grad norm: 0.515 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 02:06:53] iteration   407700/  500000 | consumed samples:     26092800 | elapsed time per iteration (ms): 617.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.952184E+00 | loss scale: 1048576.0 | grad norm: 0.494 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 02:07:55] iteration   407800/  500000 | consumed samples:     26099200 | elapsed time per iteration (ms): 618.3 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.949863E+00 | loss scale: 1048576.0 | grad norm: 0.504 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 02:08:57] iteration   407900/  500000 | consumed samples:     26105600 | elapsed time per iteration (ms): 616.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.944890E+00 | loss scale: 1048576.0 | grad norm: 0.492 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 02:09:59] iteration   408000/  500000 | consumed samples:     26112000 | elapsed time per iteration (ms): 620.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.947119E+00 | loss scale: 1048576.0 | grad norm: 0.510 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2471.37, 2471.46)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 408000 | lm loss value: 3.716165E+00 | lm loss PPL: 4.110644E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-27 02:11:03] iteration   408100/  500000 | consumed samples:     26118400 | elapsed time per iteration (ms): 618.6 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.947065E+00 | loss scale: 1048576.0 | grad norm: 0.503 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 02:12:05] iteration   408200/  500000 | consumed samples:     26124800 | elapsed time per iteration (ms): 621.7 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.953449E+00 | loss scale: 1048576.0 | grad norm: 0.504 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 02:13:07] iteration   408300/  500000 | consumed samples:     26131200 | elapsed time per iteration (ms): 619.5 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.962819E+00 | loss scale: 2097152.0 | grad norm: 0.506 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 02:14:09] iteration   408400/  500000 | consumed samples:     26137600 | elapsed time per iteration (ms): 618.5 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.956068E+00 | loss scale: 1048576.0 | grad norm: 0.489 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-27 02:15:11] iteration   408500/  500000 | consumed samples:     26144000 | elapsed time per iteration (ms): 618.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.941405E+00 | loss scale: 1048576.0 | grad norm: 0.493 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 02:16:13] iteration   408600/  500000 | consumed samples:     26150400 | elapsed time per iteration (ms): 618.5 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.949421E+00 | loss scale: 1048576.0 | grad norm: 0.500 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 02:17:15] iteration   408700/  500000 | consumed samples:     26156800 | elapsed time per iteration (ms): 617.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.954981E+00 | loss scale: 1048576.0 | grad norm: 0.514 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 02:18:17] iteration   408800/  500000 | consumed samples:     26163200 | elapsed time per iteration (ms): 618.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.957008E+00 | loss scale: 1048576.0 | grad norm: 0.497 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 02:19:18] iteration   408900/  500000 | consumed samples:     26169600 | elapsed time per iteration (ms): 617.5 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.968632E+00 | loss scale: 1048576.0 | grad norm: 0.510 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 02:20:20] iteration   409000/  500000 | consumed samples:     26176000 | elapsed time per iteration (ms): 618.6 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.952353E+00 | loss scale: 1048576.0 | grad norm: 0.498 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2462.98, 2462.99)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 409000 | lm loss value: 3.709362E+00 | lm loss PPL: 4.082774E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-27 02:21:25] iteration   409100/  500000 | consumed samples:     26182400 | elapsed time per iteration (ms): 619.4 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.954496E+00 | loss scale: 1048576.0 | grad norm: 0.504 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 02:22:26] iteration   409200/  500000 | consumed samples:     26188800 | elapsed time per iteration (ms): 618.2 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.957921E+00 | loss scale: 1048576.0 | grad norm: 0.502 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 02:23:28] iteration   409300/  500000 | consumed samples:     26195200 | elapsed time per iteration (ms): 620.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.960187E+00 | loss scale: 1048576.0 | grad norm: 0.512 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 02:24:30] iteration   409400/  500000 | consumed samples:     26201600 | elapsed time per iteration (ms): 618.5 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.958772E+00 | loss scale: 1048576.0 | grad norm: 0.507 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-27 02:25:32] iteration   409500/  500000 | consumed samples:     26208000 | elapsed time per iteration (ms): 620.4 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.949793E+00 | loss scale: 1048576.0 | grad norm: 0.507 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 02:26:34] iteration   409600/  500000 | consumed samples:     26214400 | elapsed time per iteration (ms): 619.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.966085E+00 | loss scale: 1048576.0 | grad norm: 0.498 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 02:27:36] iteration   409700/  500000 | consumed samples:     26220800 | elapsed time per iteration (ms): 619.1 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.946219E+00 | loss scale: 1048576.0 | grad norm: 0.498 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 02:28:38] iteration   409800/  500000 | consumed samples:     26227200 | elapsed time per iteration (ms): 620.5 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.971975E+00 | loss scale: 1048576.0 | grad norm: 0.507 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 02:29:40] iteration   409900/  500000 | consumed samples:     26233600 | elapsed time per iteration (ms): 619.1 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.969499E+00 | loss scale: 1048576.0 | grad norm: 0.493 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 02:30:42] iteration   410000/  500000 | consumed samples:     26240000 | elapsed time per iteration (ms): 620.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.952949E+00 | loss scale: 1048576.0 | grad norm: 0.502 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2461.75, 2461.88)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 410000 | lm loss value: 3.764103E+00 | lm loss PPL: 4.312499E+01 | 
--------------------------------------------------------------------------------------------------
saving checkpoint at iteration  410000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-distribution in torch format
  successfully saved checkpoint at iteration  410000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-distribution
(min, max) time across ranks (ms):
    save-checkpoint ................................: (2292.84, 2292.85)
 [2024-06-27 02:31:49] iteration   410100/  500000 | consumed samples:     26246400 | elapsed time per iteration (ms): 619.4 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.943176E+00 | loss scale: 1048576.0 | grad norm: 0.521 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 02:32:51] iteration   410200/  500000 | consumed samples:     26252800 | elapsed time per iteration (ms): 620.5 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.952782E+00 | loss scale: 1048576.0 | grad norm: 0.503 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 02:33:53] iteration   410300/  500000 | consumed samples:     26259200 | elapsed time per iteration (ms): 617.6 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.950752E+00 | loss scale: 1048576.0 | grad norm: 0.513 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 02:34:55] iteration   410400/  500000 | consumed samples:     26265600 | elapsed time per iteration (ms): 618.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.961616E+00 | loss scale: 2097152.0 | grad norm: 0.499 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 02:35:56] iteration   410500/  500000 | consumed samples:     26272000 | elapsed time per iteration (ms): 616.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.961814E+00 | loss scale: 1048576.0 | grad norm: 0.508 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-27 02:36:58] iteration   410600/  500000 | consumed samples:     26278400 | elapsed time per iteration (ms): 617.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.949259E+00 | loss scale: 1048576.0 | grad norm: 0.496 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 02:38:00] iteration   410700/  500000 | consumed samples:     26284800 | elapsed time per iteration (ms): 619.1 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.963436E+00 | loss scale: 1048576.0 | grad norm: 0.499 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 02:39:02] iteration   410800/  500000 | consumed samples:     26291200 | elapsed time per iteration (ms): 618.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.964766E+00 | loss scale: 1048576.0 | grad norm: 0.503 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 02:40:04] iteration   410900/  500000 | consumed samples:     26297600 | elapsed time per iteration (ms): 618.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.958090E+00 | loss scale: 1048576.0 | grad norm: 0.494 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 02:41:05] iteration   411000/  500000 | consumed samples:     26304000 | elapsed time per iteration (ms): 619.1 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.973411E+00 | loss scale: 1048576.0 | grad norm: 0.508 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2460.70, 2460.80)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 411000 | lm loss value: 3.693629E+00 | lm loss PPL: 4.019043E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-27 02:42:10] iteration   411100/  500000 | consumed samples:     26310400 | elapsed time per iteration (ms): 619.3 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.960898E+00 | loss scale: 1048576.0 | grad norm: 0.508 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 02:43:12] iteration   411200/  500000 | consumed samples:     26316800 | elapsed time per iteration (ms): 620.5 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.960453E+00 | loss scale: 1048576.0 | grad norm: 0.497 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 02:44:14] iteration   411300/  500000 | consumed samples:     26323200 | elapsed time per iteration (ms): 618.3 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.946665E+00 | loss scale: 1048576.0 | grad norm: 0.517 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 02:45:16] iteration   411400/  500000 | consumed samples:     26329600 | elapsed time per iteration (ms): 618.4 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.954886E+00 | loss scale: 1048576.0 | grad norm: 0.516 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 02:46:18] iteration   411500/  500000 | consumed samples:     26336000 | elapsed time per iteration (ms): 619.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.959038E+00 | loss scale: 2097152.0 | grad norm: 0.512 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-27 02:47:19] iteration   411600/  500000 | consumed samples:     26342400 | elapsed time per iteration (ms): 618.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.964475E+00 | loss scale: 1048576.0 | grad norm: 0.503 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-27 02:48:21] iteration   411700/  500000 | consumed samples:     26348800 | elapsed time per iteration (ms): 617.5 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.952035E+00 | loss scale: 1048576.0 | grad norm: 0.508 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 02:49:23] iteration   411800/  500000 | consumed samples:     26355200 | elapsed time per iteration (ms): 619.7 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.956601E+00 | loss scale: 1048576.0 | grad norm: 0.509 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 02:50:25] iteration   411900/  500000 | consumed samples:     26361600 | elapsed time per iteration (ms): 621.7 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.952036E+00 | loss scale: 1048576.0 | grad norm: 0.523 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 02:51:27] iteration   412000/  500000 | consumed samples:     26368000 | elapsed time per iteration (ms): 618.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.957063E+00 | loss scale: 524288.0 | grad norm: 0.496 | number of skipped iterations:   1 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2461.35, 2461.38)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 412000 | lm loss value: 3.743016E+00 | lm loss PPL: 4.222514E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-27 02:52:31] iteration   412100/  500000 | consumed samples:     26374400 | elapsed time per iteration (ms): 617.1 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.950012E+00 | loss scale: 524288.0 | grad norm: 0.513 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 02:53:33] iteration   412200/  500000 | consumed samples:     26380800 | elapsed time per iteration (ms): 619.5 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.946258E+00 | loss scale: 524288.0 | grad norm: 0.505 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 02:54:35] iteration   412300/  500000 | consumed samples:     26387200 | elapsed time per iteration (ms): 618.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.942372E+00 | loss scale: 524288.0 | grad norm: 0.509 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 02:55:37] iteration   412400/  500000 | consumed samples:     26393600 | elapsed time per iteration (ms): 617.6 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.952620E+00 | loss scale: 524288.0 | grad norm: 0.503 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 02:56:39] iteration   412500/  500000 | consumed samples:     26400000 | elapsed time per iteration (ms): 618.3 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.938917E+00 | loss scale: 524288.0 | grad norm: 0.496 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 02:57:40] iteration   412600/  500000 | consumed samples:     26406400 | elapsed time per iteration (ms): 618.6 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.966328E+00 | loss scale: 524288.0 | grad norm: 0.515 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 02:58:42] iteration   412700/  500000 | consumed samples:     26412800 | elapsed time per iteration (ms): 620.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.956381E+00 | loss scale: 524288.0 | grad norm: 0.514 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 02:59:44] iteration   412800/  500000 | consumed samples:     26419200 | elapsed time per iteration (ms): 619.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.955246E+00 | loss scale: 524288.0 | grad norm: 0.510 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 03:00:46] iteration   412900/  500000 | consumed samples:     26425600 | elapsed time per iteration (ms): 618.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.952215E+00 | loss scale: 524288.0 | grad norm: 0.501 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 03:01:48] iteration   413000/  500000 | consumed samples:     26432000 | elapsed time per iteration (ms): 619.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.951135E+00 | loss scale: 1048576.0 | grad norm: 0.500 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2462.31, 2462.38)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 413000 | lm loss value: 3.728491E+00 | lm loss PPL: 4.161624E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-27 03:02:53] iteration   413100/  500000 | consumed samples:     26438400 | elapsed time per iteration (ms): 618.1 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.953176E+00 | loss scale: 1048576.0 | grad norm: 0.504 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 03:03:54] iteration   413200/  500000 | consumed samples:     26444800 | elapsed time per iteration (ms): 617.7 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.958491E+00 | loss scale: 1048576.0 | grad norm: 0.505 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 03:04:56] iteration   413300/  500000 | consumed samples:     26451200 | elapsed time per iteration (ms): 620.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.962403E+00 | loss scale: 1048576.0 | grad norm: 0.508 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 03:05:58] iteration   413400/  500000 | consumed samples:     26457600 | elapsed time per iteration (ms): 618.7 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.954821E+00 | loss scale: 1048576.0 | grad norm: 0.493 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 03:07:00] iteration   413500/  500000 | consumed samples:     26464000 | elapsed time per iteration (ms): 620.7 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.960295E+00 | loss scale: 1048576.0 | grad norm: 0.519 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 03:08:02] iteration   413600/  500000 | consumed samples:     26470400 | elapsed time per iteration (ms): 617.3 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.960155E+00 | loss scale: 1048576.0 | grad norm: 0.503 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 03:09:04] iteration   413700/  500000 | consumed samples:     26476800 | elapsed time per iteration (ms): 620.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.964529E+00 | loss scale: 1048576.0 | grad norm: 0.518 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 03:10:06] iteration   413800/  500000 | consumed samples:     26483200 | elapsed time per iteration (ms): 618.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.971364E+00 | loss scale: 1048576.0 | grad norm: 0.518 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 03:11:08] iteration   413900/  500000 | consumed samples:     26489600 | elapsed time per iteration (ms): 618.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.953160E+00 | loss scale: 1048576.0 | grad norm: 0.512 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 03:12:10] iteration   414000/  500000 | consumed samples:     26496000 | elapsed time per iteration (ms): 621.1 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.963392E+00 | loss scale: 2097152.0 | grad norm: 0.509 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2464.84, 2464.84)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 414000 | lm loss value: 3.726098E+00 | lm loss PPL: 4.151681E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-27 03:13:14] iteration   414100/  500000 | consumed samples:     26502400 | elapsed time per iteration (ms): 617.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.943718E+00 | loss scale: 1048576.0 | grad norm: 0.490 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-27 03:14:16] iteration   414200/  500000 | consumed samples:     26508800 | elapsed time per iteration (ms): 618.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.967384E+00 | loss scale: 1048576.0 | grad norm: 0.507 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 03:15:18] iteration   414300/  500000 | consumed samples:     26515200 | elapsed time per iteration (ms): 621.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.952690E+00 | loss scale: 1048576.0 | grad norm: 0.497 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 03:16:20] iteration   414400/  500000 | consumed samples:     26521600 | elapsed time per iteration (ms): 618.5 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.960089E+00 | loss scale: 1048576.0 | grad norm: 0.507 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 03:17:22] iteration   414500/  500000 | consumed samples:     26528000 | elapsed time per iteration (ms): 617.5 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.941690E+00 | loss scale: 524288.0 | grad norm: 0.494 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-27 03:18:24] iteration   414600/  500000 | consumed samples:     26534400 | elapsed time per iteration (ms): 618.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.972027E+00 | loss scale: 524288.0 | grad norm: 0.518 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 03:19:25] iteration   414700/  500000 | consumed samples:     26540800 | elapsed time per iteration (ms): 617.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.963602E+00 | loss scale: 524288.0 | grad norm: 0.504 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 03:20:27] iteration   414800/  500000 | consumed samples:     26547200 | elapsed time per iteration (ms): 619.1 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.959377E+00 | loss scale: 524288.0 | grad norm: 0.502 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 03:21:29] iteration   414900/  500000 | consumed samples:     26553600 | elapsed time per iteration (ms): 617.3 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.958857E+00 | loss scale: 524288.0 | grad norm: 0.510 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 03:22:31] iteration   415000/  500000 | consumed samples:     26560000 | elapsed time per iteration (ms): 619.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.953987E+00 | loss scale: 524288.0 | grad norm: 0.491 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2465.63, 2465.77)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 415000 | lm loss value: 3.722964E+00 | lm loss PPL: 4.138688E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-27 03:23:35] iteration   415100/  500000 | consumed samples:     26566400 | elapsed time per iteration (ms): 621.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.945572E+00 | loss scale: 524288.0 | grad norm: 0.499 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 03:24:37] iteration   415200/  500000 | consumed samples:     26572800 | elapsed time per iteration (ms): 618.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.949061E+00 | loss scale: 524288.0 | grad norm: 0.495 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 03:25:39] iteration   415300/  500000 | consumed samples:     26579200 | elapsed time per iteration (ms): 617.7 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.949200E+00 | loss scale: 524288.0 | grad norm: 0.501 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 03:26:41] iteration   415400/  500000 | consumed samples:     26585600 | elapsed time per iteration (ms): 616.4 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.961462E+00 | loss scale: 524288.0 | grad norm: 0.493 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 03:27:43] iteration   415500/  500000 | consumed samples:     26592000 | elapsed time per iteration (ms): 617.6 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.959231E+00 | loss scale: 1048576.0 | grad norm: 0.509 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 03:28:44] iteration   415600/  500000 | consumed samples:     26598400 | elapsed time per iteration (ms): 618.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.956144E+00 | loss scale: 1048576.0 | grad norm: 0.511 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 03:29:46] iteration   415700/  500000 | consumed samples:     26604800 | elapsed time per iteration (ms): 617.3 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.955198E+00 | loss scale: 1048576.0 | grad norm: 0.501 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 03:30:48] iteration   415800/  500000 | consumed samples:     26611200 | elapsed time per iteration (ms): 619.1 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.942228E+00 | loss scale: 1048576.0 | grad norm: 0.509 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 03:31:50] iteration   415900/  500000 | consumed samples:     26617600 | elapsed time per iteration (ms): 618.1 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.976440E+00 | loss scale: 1048576.0 | grad norm: 0.494 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 03:32:52] iteration   416000/  500000 | consumed samples:     26624000 | elapsed time per iteration (ms): 619.7 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.940677E+00 | loss scale: 1048576.0 | grad norm: 0.488 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2463.13, 2463.15)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 416000 | lm loss value: 3.742965E+00 | lm loss PPL: 4.222302E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-27 03:33:56] iteration   416100/  500000 | consumed samples:     26630400 | elapsed time per iteration (ms): 618.5 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.954790E+00 | loss scale: 1048576.0 | grad norm: 0.506 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 03:34:58] iteration   416200/  500000 | consumed samples:     26636800 | elapsed time per iteration (ms): 617.5 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.954455E+00 | loss scale: 1048576.0 | grad norm: 0.500 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 03:36:00] iteration   416300/  500000 | consumed samples:     26643200 | elapsed time per iteration (ms): 619.3 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.953388E+00 | loss scale: 1048576.0 | grad norm: 0.516 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 03:37:02] iteration   416400/  500000 | consumed samples:     26649600 | elapsed time per iteration (ms): 616.6 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.961743E+00 | loss scale: 1048576.0 | grad norm: 0.511 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 03:38:03] iteration   416500/  500000 | consumed samples:     26656000 | elapsed time per iteration (ms): 617.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.966429E+00 | loss scale: 1048576.0 | grad norm: 0.515 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-27 03:39:05] iteration   416600/  500000 | consumed samples:     26662400 | elapsed time per iteration (ms): 619.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.950999E+00 | loss scale: 1048576.0 | grad norm: 0.488 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 03:40:07] iteration   416700/  500000 | consumed samples:     26668800 | elapsed time per iteration (ms): 621.2 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.955578E+00 | loss scale: 1048576.0 | grad norm: 0.521 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 03:41:09] iteration   416800/  500000 | consumed samples:     26675200 | elapsed time per iteration (ms): 619.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.967627E+00 | loss scale: 1048576.0 | grad norm: 0.502 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 03:42:11] iteration   416900/  500000 | consumed samples:     26681600 | elapsed time per iteration (ms): 619.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.949168E+00 | loss scale: 1048576.0 | grad norm: 0.500 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 03:43:13] iteration   417000/  500000 | consumed samples:     26688000 | elapsed time per iteration (ms): 619.2 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.950472E+00 | loss scale: 1048576.0 | grad norm: 0.501 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2462.91, 2462.92)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 417000 | lm loss value: 3.739797E+00 | lm loss PPL: 4.208944E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-27 03:44:18] iteration   417100/  500000 | consumed samples:     26694400 | elapsed time per iteration (ms): 619.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.950709E+00 | loss scale: 1048576.0 | grad norm: 0.507 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 03:45:20] iteration   417200/  500000 | consumed samples:     26700800 | elapsed time per iteration (ms): 619.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.950504E+00 | loss scale: 1048576.0 | grad norm: 0.498 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 03:46:22] iteration   417300/  500000 | consumed samples:     26707200 | elapsed time per iteration (ms): 620.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.963148E+00 | loss scale: 1048576.0 | grad norm: 0.507 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 03:47:23] iteration   417400/  500000 | consumed samples:     26713600 | elapsed time per iteration (ms): 618.6 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.959152E+00 | loss scale: 1048576.0 | grad norm: 0.513 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 03:48:26] iteration   417500/  500000 | consumed samples:     26720000 | elapsed time per iteration (ms): 620.7 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.963870E+00 | loss scale: 2097152.0 | grad norm: 0.508 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 03:49:28] iteration   417600/  500000 | consumed samples:     26726400 | elapsed time per iteration (ms): 620.1 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.952549E+00 | loss scale: 1048576.0 | grad norm: 0.516 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-27 03:50:29] iteration   417700/  500000 | consumed samples:     26732800 | elapsed time per iteration (ms): 617.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.954998E+00 | loss scale: 1048576.0 | grad norm: 0.518 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 03:51:31] iteration   417800/  500000 | consumed samples:     26739200 | elapsed time per iteration (ms): 618.2 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.944690E+00 | loss scale: 1048576.0 | grad norm: 0.503 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 03:52:33] iteration   417900/  500000 | consumed samples:     26745600 | elapsed time per iteration (ms): 617.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.954449E+00 | loss scale: 1048576.0 | grad norm: 0.505 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 03:53:35] iteration   418000/  500000 | consumed samples:     26752000 | elapsed time per iteration (ms): 620.5 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.960388E+00 | loss scale: 1048576.0 | grad norm: 0.504 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2460.40, 2460.51)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 418000 | lm loss value: 3.723636E+00 | lm loss PPL: 4.141470E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-27 03:54:39] iteration   418100/  500000 | consumed samples:     26758400 | elapsed time per iteration (ms): 619.5 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.962114E+00 | loss scale: 1048576.0 | grad norm: 0.506 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 03:55:41] iteration   418200/  500000 | consumed samples:     26764800 | elapsed time per iteration (ms): 618.2 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.960077E+00 | loss scale: 1048576.0 | grad norm: 0.517 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 03:56:43] iteration   418300/  500000 | consumed samples:     26771200 | elapsed time per iteration (ms): 616.7 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.960569E+00 | loss scale: 1048576.0 | grad norm: 0.530 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 03:57:45] iteration   418400/  500000 | consumed samples:     26777600 | elapsed time per iteration (ms): 617.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.949740E+00 | loss scale: 1048576.0 | grad norm: 0.496 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 03:58:47] iteration   418500/  500000 | consumed samples:     26784000 | elapsed time per iteration (ms): 619.4 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.943018E+00 | loss scale: 1048576.0 | grad norm: 0.508 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 03:59:48] iteration   418600/  500000 | consumed samples:     26790400 | elapsed time per iteration (ms): 618.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.938720E+00 | loss scale: 2097152.0 | grad norm: 0.503 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 04:00:50] iteration   418700/  500000 | consumed samples:     26796800 | elapsed time per iteration (ms): 618.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.972504E+00 | loss scale: 1048576.0 | grad norm: 0.521 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-27 04:01:52] iteration   418800/  500000 | consumed samples:     26803200 | elapsed time per iteration (ms): 618.6 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.954117E+00 | loss scale: 1048576.0 | grad norm: 0.509 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 04:02:54] iteration   418900/  500000 | consumed samples:     26809600 | elapsed time per iteration (ms): 619.1 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.956458E+00 | loss scale: 1048576.0 | grad norm: 0.513 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 04:03:56] iteration   419000/  500000 | consumed samples:     26816000 | elapsed time per iteration (ms): 620.3 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.937269E+00 | loss scale: 1048576.0 | grad norm: 0.503 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2460.60, 2460.64)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 419000 | lm loss value: 3.749442E+00 | lm loss PPL: 4.249738E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-27 04:05:00] iteration   419100/  500000 | consumed samples:     26822400 | elapsed time per iteration (ms): 619.5 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.942153E+00 | loss scale: 1048576.0 | grad norm: 0.507 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 04:06:02] iteration   419200/  500000 | consumed samples:     26828800 | elapsed time per iteration (ms): 618.3 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.954393E+00 | loss scale: 1048576.0 | grad norm: 0.493 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 04:07:04] iteration   419300/  500000 | consumed samples:     26835200 | elapsed time per iteration (ms): 619.3 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.947322E+00 | loss scale: 1048576.0 | grad norm: 0.515 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 04:08:06] iteration   419400/  500000 | consumed samples:     26841600 | elapsed time per iteration (ms): 620.5 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.955582E+00 | loss scale: 1048576.0 | grad norm: 0.502 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 04:09:08] iteration   419500/  500000 | consumed samples:     26848000 | elapsed time per iteration (ms): 618.7 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.944110E+00 | loss scale: 1048576.0 | grad norm: 0.501 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 04:10:10] iteration   419600/  500000 | consumed samples:     26854400 | elapsed time per iteration (ms): 620.6 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.952880E+00 | loss scale: 1048576.0 | grad norm: 0.508 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 04:11:12] iteration   419700/  500000 | consumed samples:     26860800 | elapsed time per iteration (ms): 620.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.956670E+00 | loss scale: 2097152.0 | grad norm: 0.504 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-27 04:12:14] iteration   419800/  500000 | consumed samples:     26867200 | elapsed time per iteration (ms): 620.5 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.956082E+00 | loss scale: 1048576.0 | grad norm: 0.500 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-27 04:13:16] iteration   419900/  500000 | consumed samples:     26873600 | elapsed time per iteration (ms): 618.6 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.952229E+00 | loss scale: 1048576.0 | grad norm: 0.495 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 04:14:18] iteration   420000/  500000 | consumed samples:     26880000 | elapsed time per iteration (ms): 618.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.954224E+00 | loss scale: 1048576.0 | grad norm: 0.508 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2461.72, 2461.72)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 420000 | lm loss value: 3.751639E+00 | lm loss PPL: 4.259083E+01 | 
--------------------------------------------------------------------------------------------------
saving checkpoint at iteration  420000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-distribution in torch format
  successfully saved checkpoint at iteration  420000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-distribution
(min, max) time across ranks (ms):
    save-checkpoint ................................: (2316.29, 2316.30)
 [2024-06-27 04:15:25] iteration   420100/  500000 | consumed samples:     26886400 | elapsed time per iteration (ms): 617.3 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.946074E+00 | loss scale: 1048576.0 | grad norm: 0.491 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 04:16:27] iteration   420200/  500000 | consumed samples:     26892800 | elapsed time per iteration (ms): 620.7 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.946699E+00 | loss scale: 1048576.0 | grad norm: 0.496 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 04:17:28] iteration   420300/  500000 | consumed samples:     26899200 | elapsed time per iteration (ms): 618.6 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.955526E+00 | loss scale: 1048576.0 | grad norm: 0.498 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 04:18:30] iteration   420400/  500000 | consumed samples:     26905600 | elapsed time per iteration (ms): 619.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.953602E+00 | loss scale: 1048576.0 | grad norm: 0.502 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 04:19:32] iteration   420500/  500000 | consumed samples:     26912000 | elapsed time per iteration (ms): 619.5 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.948738E+00 | loss scale: 1048576.0 | grad norm: 0.519 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 04:20:34] iteration   420600/  500000 | consumed samples:     26918400 | elapsed time per iteration (ms): 617.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.964297E+00 | loss scale: 1048576.0 | grad norm: 0.514 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 04:21:36] iteration   420700/  500000 | consumed samples:     26924800 | elapsed time per iteration (ms): 617.4 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.969109E+00 | loss scale: 1048576.0 | grad norm: 0.511 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 04:22:38] iteration   420800/  500000 | consumed samples:     26931200 | elapsed time per iteration (ms): 620.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.953429E+00 | loss scale: 2097152.0 | grad norm: 0.515 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 04:23:40] iteration   420900/  500000 | consumed samples:     26937600 | elapsed time per iteration (ms): 620.1 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.955973E+00 | loss scale: 2097152.0 | grad norm: 0.493 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 04:24:42] iteration   421000/  500000 | consumed samples:     26944000 | elapsed time per iteration (ms): 619.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.955951E+00 | loss scale: 2097152.0 | grad norm: 0.528 | number of skipped iterations:   1 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2461.43, 2461.52)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 421000 | lm loss value: 3.752706E+00 | lm loss PPL: 4.263629E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-27 04:25:46] iteration   421100/  500000 | consumed samples:     26950400 | elapsed time per iteration (ms): 619.2 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.962586E+00 | loss scale: 1048576.0 | grad norm: 0.503 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-27 04:26:48] iteration   421200/  500000 | consumed samples:     26956800 | elapsed time per iteration (ms): 619.6 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.965105E+00 | loss scale: 1048576.0 | grad norm: 0.507 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 04:27:50] iteration   421300/  500000 | consumed samples:     26963200 | elapsed time per iteration (ms): 618.2 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.954762E+00 | loss scale: 1048576.0 | grad norm: 0.522 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 04:28:52] iteration   421400/  500000 | consumed samples:     26969600 | elapsed time per iteration (ms): 619.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.953182E+00 | loss scale: 1048576.0 | grad norm: 0.504 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 04:29:54] iteration   421500/  500000 | consumed samples:     26976000 | elapsed time per iteration (ms): 618.6 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.945069E+00 | loss scale: 1048576.0 | grad norm: 0.512 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 04:30:56] iteration   421600/  500000 | consumed samples:     26982400 | elapsed time per iteration (ms): 618.6 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.954607E+00 | loss scale: 1048576.0 | grad norm: 0.496 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 04:31:58] iteration   421700/  500000 | consumed samples:     26988800 | elapsed time per iteration (ms): 619.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.944231E+00 | loss scale: 1048576.0 | grad norm: 0.518 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 04:33:00] iteration   421800/  500000 | consumed samples:     26995200 | elapsed time per iteration (ms): 618.7 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.958667E+00 | loss scale: 1048576.0 | grad norm: 0.510 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 04:34:02] iteration   421900/  500000 | consumed samples:     27001600 | elapsed time per iteration (ms): 619.7 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.942039E+00 | loss scale: 1048576.0 | grad norm: 0.506 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 04:35:03] iteration   422000/  500000 | consumed samples:     27008000 | elapsed time per iteration (ms): 618.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.968503E+00 | loss scale: 1048576.0 | grad norm: 0.495 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2464.62, 2464.66)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 422000 | lm loss value: 3.707993E+00 | lm loss PPL: 4.077190E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-27 04:36:08] iteration   422100/  500000 | consumed samples:     27014400 | elapsed time per iteration (ms): 620.3 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.945122E+00 | loss scale: 1048576.0 | grad norm: 0.499 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-27 04:37:10] iteration   422200/  500000 | consumed samples:     27020800 | elapsed time per iteration (ms): 617.6 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.960798E+00 | loss scale: 1048576.0 | grad norm: 0.507 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 04:38:12] iteration   422300/  500000 | consumed samples:     27027200 | elapsed time per iteration (ms): 618.4 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.971981E+00 | loss scale: 1048576.0 | grad norm: 0.505 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 04:39:13] iteration   422400/  500000 | consumed samples:     27033600 | elapsed time per iteration (ms): 618.7 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.957511E+00 | loss scale: 1048576.0 | grad norm: 0.501 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 04:40:15] iteration   422500/  500000 | consumed samples:     27040000 | elapsed time per iteration (ms): 619.4 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.948368E+00 | loss scale: 1048576.0 | grad norm: 0.485 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 04:41:17] iteration   422600/  500000 | consumed samples:     27046400 | elapsed time per iteration (ms): 620.1 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.970480E+00 | loss scale: 1048576.0 | grad norm: 0.502 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 04:42:19] iteration   422700/  500000 | consumed samples:     27052800 | elapsed time per iteration (ms): 617.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.961864E+00 | loss scale: 1048576.0 | grad norm: 0.500 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 04:43:21] iteration   422800/  500000 | consumed samples:     27059200 | elapsed time per iteration (ms): 618.4 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.947910E+00 | loss scale: 1048576.0 | grad norm: 0.500 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 04:44:23] iteration   422900/  500000 | consumed samples:     27065600 | elapsed time per iteration (ms): 616.3 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.959409E+00 | loss scale: 1048576.0 | grad norm: 0.515 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 04:45:24] iteration   423000/  500000 | consumed samples:     27072000 | elapsed time per iteration (ms): 617.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.958386E+00 | loss scale: 1048576.0 | grad norm: 0.508 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2461.17, 2461.38)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 423000 | lm loss value: 3.740277E+00 | lm loss PPL: 4.210966E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-27 04:46:29] iteration   423100/  500000 | consumed samples:     27078400 | elapsed time per iteration (ms): 619.6 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.956616E+00 | loss scale: 1048576.0 | grad norm: 0.507 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-27 04:47:31] iteration   423200/  500000 | consumed samples:     27084800 | elapsed time per iteration (ms): 618.1 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.946154E+00 | loss scale: 1048576.0 | grad norm: 0.513 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 04:48:33] iteration   423300/  500000 | consumed samples:     27091200 | elapsed time per iteration (ms): 619.4 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.956717E+00 | loss scale: 1048576.0 | grad norm: 0.506 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 04:49:35] iteration   423400/  500000 | consumed samples:     27097600 | elapsed time per iteration (ms): 619.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.972731E+00 | loss scale: 1048576.0 | grad norm: 0.505 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 04:50:36] iteration   423500/  500000 | consumed samples:     27104000 | elapsed time per iteration (ms): 619.1 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.953169E+00 | loss scale: 1048576.0 | grad norm: 0.499 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 04:51:39] iteration   423600/  500000 | consumed samples:     27110400 | elapsed time per iteration (ms): 620.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.957577E+00 | loss scale: 1048576.0 | grad norm: 0.506 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 04:52:40] iteration   423700/  500000 | consumed samples:     27116800 | elapsed time per iteration (ms): 618.6 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.950952E+00 | loss scale: 1048576.0 | grad norm: 0.517 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 04:53:42] iteration   423800/  500000 | consumed samples:     27123200 | elapsed time per iteration (ms): 620.2 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.956169E+00 | loss scale: 1048576.0 | grad norm: 0.497 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 04:54:44] iteration   423900/  500000 | consumed samples:     27129600 | elapsed time per iteration (ms): 620.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.964460E+00 | loss scale: 1048576.0 | grad norm: 0.534 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 04:55:46] iteration   424000/  500000 | consumed samples:     27136000 | elapsed time per iteration (ms): 618.7 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.954575E+00 | loss scale: 1048576.0 | grad norm: 0.509 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2465.51, 2465.63)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 424000 | lm loss value: 3.742356E+00 | lm loss PPL: 4.219729E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-27 04:56:51] iteration   424100/  500000 | consumed samples:     27142400 | elapsed time per iteration (ms): 620.7 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.953809E+00 | loss scale: 2097152.0 | grad norm: 0.497 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 04:57:53] iteration   424200/  500000 | consumed samples:     27148800 | elapsed time per iteration (ms): 616.7 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.952916E+00 | loss scale: 1048576.0 | grad norm: 0.511 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-27 04:58:54] iteration   424300/  500000 | consumed samples:     27155200 | elapsed time per iteration (ms): 619.1 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.956465E+00 | loss scale: 1048576.0 | grad norm: 0.509 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 04:59:57] iteration   424400/  500000 | consumed samples:     27161600 | elapsed time per iteration (ms): 621.2 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.955543E+00 | loss scale: 1048576.0 | grad norm: 0.505 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 05:00:58] iteration   424500/  500000 | consumed samples:     27168000 | elapsed time per iteration (ms): 618.5 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.961417E+00 | loss scale: 1048576.0 | grad norm: 0.502 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 05:02:00] iteration   424600/  500000 | consumed samples:     27174400 | elapsed time per iteration (ms): 620.5 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.950905E+00 | loss scale: 1048576.0 | grad norm: 0.500 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 05:03:02] iteration   424700/  500000 | consumed samples:     27180800 | elapsed time per iteration (ms): 619.6 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.962446E+00 | loss scale: 1048576.0 | grad norm: 0.503 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 05:04:05] iteration   424800/  500000 | consumed samples:     27187200 | elapsed time per iteration (ms): 621.5 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.964096E+00 | loss scale: 524288.0 | grad norm: 0.505 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-27 05:05:06] iteration   424900/  500000 | consumed samples:     27193600 | elapsed time per iteration (ms): 619.1 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.966546E+00 | loss scale: 524288.0 | grad norm: 0.498 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 05:06:09] iteration   425000/  500000 | consumed samples:     27200000 | elapsed time per iteration (ms): 621.5 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.961501E+00 | loss scale: 524288.0 | grad norm: 0.509 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2461.89, 2461.91)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 425000 | lm loss value: 3.733940E+00 | lm loss PPL: 4.184365E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-27 05:07:13] iteration   425100/  500000 | consumed samples:     27206400 | elapsed time per iteration (ms): 621.4 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.961818E+00 | loss scale: 524288.0 | grad norm: 0.506 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 05:08:15] iteration   425200/  500000 | consumed samples:     27212800 | elapsed time per iteration (ms): 619.6 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.962309E+00 | loss scale: 524288.0 | grad norm: 0.512 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 05:09:17] iteration   425300/  500000 | consumed samples:     27219200 | elapsed time per iteration (ms): 618.1 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.949814E+00 | loss scale: 524288.0 | grad norm: 0.518 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 05:10:19] iteration   425400/  500000 | consumed samples:     27225600 | elapsed time per iteration (ms): 619.4 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.958437E+00 | loss scale: 524288.0 | grad norm: 0.498 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 05:11:21] iteration   425500/  500000 | consumed samples:     27232000 | elapsed time per iteration (ms): 618.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.958476E+00 | loss scale: 524288.0 | grad norm: 0.505 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 05:12:23] iteration   425600/  500000 | consumed samples:     27238400 | elapsed time per iteration (ms): 619.6 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.961885E+00 | loss scale: 524288.0 | grad norm: 0.519 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 05:13:25] iteration   425700/  500000 | consumed samples:     27244800 | elapsed time per iteration (ms): 619.3 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.945582E+00 | loss scale: 524288.0 | grad norm: 0.518 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 05:14:27] iteration   425800/  500000 | consumed samples:     27251200 | elapsed time per iteration (ms): 619.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.963192E+00 | loss scale: 1048576.0 | grad norm: 0.498 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 05:15:29] iteration   425900/  500000 | consumed samples:     27257600 | elapsed time per iteration (ms): 619.6 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.955353E+00 | loss scale: 1048576.0 | grad norm: 0.507 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 05:16:31] iteration   426000/  500000 | consumed samples:     27264000 | elapsed time per iteration (ms): 618.6 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.962199E+00 | loss scale: 1048576.0 | grad norm: 0.496 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2460.93, 2460.96)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 426000 | lm loss value: 3.733569E+00 | lm loss PPL: 4.182812E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-27 05:17:35] iteration   426100/  500000 | consumed samples:     27270400 | elapsed time per iteration (ms): 618.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.963297E+00 | loss scale: 1048576.0 | grad norm: 0.506 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 05:18:37] iteration   426200/  500000 | consumed samples:     27276800 | elapsed time per iteration (ms): 619.2 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.949588E+00 | loss scale: 1048576.0 | grad norm: 0.516 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 05:19:39] iteration   426300/  500000 | consumed samples:     27283200 | elapsed time per iteration (ms): 620.1 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.965647E+00 | loss scale: 1048576.0 | grad norm: 0.500 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 05:20:41] iteration   426400/  500000 | consumed samples:     27289600 | elapsed time per iteration (ms): 618.1 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.968385E+00 | loss scale: 1048576.0 | grad norm: 0.500 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 05:21:42] iteration   426500/  500000 | consumed samples:     27296000 | elapsed time per iteration (ms): 617.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.972421E+00 | loss scale: 1048576.0 | grad norm: 0.507 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 05:22:44] iteration   426600/  500000 | consumed samples:     27302400 | elapsed time per iteration (ms): 617.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.960651E+00 | loss scale: 1048576.0 | grad norm: 0.519 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 05:23:46] iteration   426700/  500000 | consumed samples:     27308800 | elapsed time per iteration (ms): 619.6 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.941674E+00 | loss scale: 1048576.0 | grad norm: 0.515 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 05:24:48] iteration   426800/  500000 | consumed samples:     27315200 | elapsed time per iteration (ms): 619.1 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.961148E+00 | loss scale: 2097152.0 | grad norm: 0.491 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-27 05:25:50] iteration   426900/  500000 | consumed samples:     27321600 | elapsed time per iteration (ms): 619.2 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.955688E+00 | loss scale: 1048576.0 | grad norm: 0.494 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-27 05:26:52] iteration   427000/  500000 | consumed samples:     27328000 | elapsed time per iteration (ms): 618.7 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.950045E+00 | loss scale: 1048576.0 | grad norm: 0.510 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2462.10, 2462.16)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 427000 | lm loss value: 3.782753E+00 | lm loss PPL: 4.393685E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-27 05:27:56] iteration   427100/  500000 | consumed samples:     27334400 | elapsed time per iteration (ms): 619.7 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.954796E+00 | loss scale: 1048576.0 | grad norm: 0.504 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 05:28:58] iteration   427200/  500000 | consumed samples:     27340800 | elapsed time per iteration (ms): 617.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.957611E+00 | loss scale: 1048576.0 | grad norm: 0.512 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 05:30:00] iteration   427300/  500000 | consumed samples:     27347200 | elapsed time per iteration (ms): 619.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.960615E+00 | loss scale: 1048576.0 | grad norm: 0.503 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 05:31:02] iteration   427400/  500000 | consumed samples:     27353600 | elapsed time per iteration (ms): 619.1 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.961042E+00 | loss scale: 1048576.0 | grad norm: 0.501 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 05:32:04] iteration   427500/  500000 | consumed samples:     27360000 | elapsed time per iteration (ms): 618.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.956672E+00 | loss scale: 1048576.0 | grad norm: 0.500 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 05:33:06] iteration   427600/  500000 | consumed samples:     27366400 | elapsed time per iteration (ms): 618.6 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.946320E+00 | loss scale: 1048576.0 | grad norm: 0.511 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 05:34:07] iteration   427700/  500000 | consumed samples:     27372800 | elapsed time per iteration (ms): 618.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.956856E+00 | loss scale: 1048576.0 | grad norm: 0.500 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 05:35:10] iteration   427800/  500000 | consumed samples:     27379200 | elapsed time per iteration (ms): 620.2 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.952342E+00 | loss scale: 1048576.0 | grad norm: 0.520 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 05:36:11] iteration   427900/  500000 | consumed samples:     27385600 | elapsed time per iteration (ms): 618.4 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.958941E+00 | loss scale: 1048576.0 | grad norm: 0.534 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-27 05:37:13] iteration   428000/  500000 | consumed samples:     27392000 | elapsed time per iteration (ms): 621.2 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.962968E+00 | loss scale: 1048576.0 | grad norm: 0.503 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2463.46, 2463.50)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 428000 | lm loss value: 3.716396E+00 | lm loss PPL: 4.111593E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-27 05:38:18] iteration   428100/  500000 | consumed samples:     27398400 | elapsed time per iteration (ms): 619.5 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.955333E+00 | loss scale: 1048576.0 | grad norm: 0.504 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 05:39:20] iteration   428200/  500000 | consumed samples:     27404800 | elapsed time per iteration (ms): 620.6 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.957127E+00 | loss scale: 1048576.0 | grad norm: 0.505 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 05:40:22] iteration   428300/  500000 | consumed samples:     27411200 | elapsed time per iteration (ms): 620.7 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.949131E+00 | loss scale: 1048576.0 | grad norm: 0.515 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 05:41:24] iteration   428400/  500000 | consumed samples:     27417600 | elapsed time per iteration (ms): 617.7 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.948322E+00 | loss scale: 1048576.0 | grad norm: 0.490 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 05:42:26] iteration   428500/  500000 | consumed samples:     27424000 | elapsed time per iteration (ms): 618.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.952908E+00 | loss scale: 1048576.0 | grad norm: 0.501 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 05:43:27] iteration   428600/  500000 | consumed samples:     27430400 | elapsed time per iteration (ms): 618.2 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.955342E+00 | loss scale: 524288.0 | grad norm: 0.506 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-27 05:44:29] iteration   428700/  500000 | consumed samples:     27436800 | elapsed time per iteration (ms): 619.3 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.947171E+00 | loss scale: 524288.0 | grad norm: 0.500 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 05:45:31] iteration   428800/  500000 | consumed samples:     27443200 | elapsed time per iteration (ms): 618.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.954937E+00 | loss scale: 524288.0 | grad norm: 0.495 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 05:46:33] iteration   428900/  500000 | consumed samples:     27449600 | elapsed time per iteration (ms): 619.4 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.957790E+00 | loss scale: 524288.0 | grad norm: 0.499 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 05:47:35] iteration   429000/  500000 | consumed samples:     27456000 | elapsed time per iteration (ms): 618.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.959166E+00 | loss scale: 524288.0 | grad norm: 0.503 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2459.62, 2459.69)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 429000 | lm loss value: 3.731251E+00 | lm loss PPL: 4.173129E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-27 05:48:40] iteration   429100/  500000 | consumed samples:     27462400 | elapsed time per iteration (ms): 620.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.950589E+00 | loss scale: 524288.0 | grad norm: 0.498 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 05:49:41] iteration   429200/  500000 | consumed samples:     27468800 | elapsed time per iteration (ms): 618.3 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.951984E+00 | loss scale: 524288.0 | grad norm: 0.502 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 05:50:44] iteration   429300/  500000 | consumed samples:     27475200 | elapsed time per iteration (ms): 620.1 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.958784E+00 | loss scale: 524288.0 | grad norm: 0.508 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 05:51:46] iteration   429400/  500000 | consumed samples:     27481600 | elapsed time per iteration (ms): 620.2 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.942431E+00 | loss scale: 524288.0 | grad norm: 0.507 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 05:52:47] iteration   429500/  500000 | consumed samples:     27488000 | elapsed time per iteration (ms): 619.2 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.954816E+00 | loss scale: 524288.0 | grad norm: 0.501 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 05:53:49] iteration   429600/  500000 | consumed samples:     27494400 | elapsed time per iteration (ms): 618.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.957656E+00 | loss scale: 1048576.0 | grad norm: 0.517 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 05:54:51] iteration   429700/  500000 | consumed samples:     27500800 | elapsed time per iteration (ms): 620.3 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.958713E+00 | loss scale: 1048576.0 | grad norm: 0.519 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 05:55:53] iteration   429800/  500000 | consumed samples:     27507200 | elapsed time per iteration (ms): 619.3 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.965936E+00 | loss scale: 1048576.0 | grad norm: 0.510 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 05:56:55] iteration   429900/  500000 | consumed samples:     27513600 | elapsed time per iteration (ms): 618.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.954511E+00 | loss scale: 1048576.0 | grad norm: 0.512 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 05:57:57] iteration   430000/  500000 | consumed samples:     27520000 | elapsed time per iteration (ms): 617.1 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.958188E+00 | loss scale: 1048576.0 | grad norm: 0.511 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2460.89, 2460.98)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 430000 | lm loss value: 3.714035E+00 | lm loss PPL: 4.101898E+01 | 
--------------------------------------------------------------------------------------------------
saving checkpoint at iteration  430000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-distribution in torch format
  successfully saved checkpoint at iteration  430000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-distribution
(min, max) time across ranks (ms):
    save-checkpoint ................................: (2380.65, 2380.66)
 [2024-06-27 05:59:04] iteration   430100/  500000 | consumed samples:     27526400 | elapsed time per iteration (ms): 618.3 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.959189E+00 | loss scale: 1048576.0 | grad norm: 0.504 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 06:00:05] iteration   430200/  500000 | consumed samples:     27532800 | elapsed time per iteration (ms): 618.5 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.955553E+00 | loss scale: 1048576.0 | grad norm: 0.506 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 06:01:07] iteration   430300/  500000 | consumed samples:     27539200 | elapsed time per iteration (ms): 619.4 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.956291E+00 | loss scale: 1048576.0 | grad norm: 0.499 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 06:02:09] iteration   430400/  500000 | consumed samples:     27545600 | elapsed time per iteration (ms): 619.6 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.941429E+00 | loss scale: 1048576.0 | grad norm: 0.507 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 06:03:11] iteration   430500/  500000 | consumed samples:     27552000 | elapsed time per iteration (ms): 619.7 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.953272E+00 | loss scale: 1048576.0 | grad norm: 0.510 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 06:04:13] iteration   430600/  500000 | consumed samples:     27558400 | elapsed time per iteration (ms): 618.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.961545E+00 | loss scale: 1048576.0 | grad norm: 0.504 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-27 06:05:15] iteration   430700/  500000 | consumed samples:     27564800 | elapsed time per iteration (ms): 619.5 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.953488E+00 | loss scale: 1048576.0 | grad norm: 0.506 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 06:06:17] iteration   430800/  500000 | consumed samples:     27571200 | elapsed time per iteration (ms): 617.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.947865E+00 | loss scale: 1048576.0 | grad norm: 0.503 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 06:07:19] iteration   430900/  500000 | consumed samples:     27577600 | elapsed time per iteration (ms): 619.4 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.951721E+00 | loss scale: 1048576.0 | grad norm: 0.494 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 06:08:21] iteration   431000/  500000 | consumed samples:     27584000 | elapsed time per iteration (ms): 618.7 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.954266E+00 | loss scale: 1048576.0 | grad norm: 0.504 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2461.89, 2461.90)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 431000 | lm loss value: 3.741286E+00 | lm loss PPL: 4.215216E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-27 06:09:25] iteration   431100/  500000 | consumed samples:     27590400 | elapsed time per iteration (ms): 616.7 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.951354E+00 | loss scale: 1048576.0 | grad norm: 0.510 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 06:10:27] iteration   431200/  500000 | consumed samples:     27596800 | elapsed time per iteration (ms): 618.7 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.973575E+00 | loss scale: 1048576.0 | grad norm: 0.500 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 06:11:29] iteration   431300/  500000 | consumed samples:     27603200 | elapsed time per iteration (ms): 620.6 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.954555E+00 | loss scale: 1048576.0 | grad norm: 0.513 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 06:12:31] iteration   431400/  500000 | consumed samples:     27609600 | elapsed time per iteration (ms): 618.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.939480E+00 | loss scale: 1048576.0 | grad norm: 0.517 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 06:13:33] iteration   431500/  500000 | consumed samples:     27616000 | elapsed time per iteration (ms): 621.5 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.943891E+00 | loss scale: 1048576.0 | grad norm: 0.523 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 06:14:35] iteration   431600/  500000 | consumed samples:     27622400 | elapsed time per iteration (ms): 620.5 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.955119E+00 | loss scale: 2097152.0 | grad norm: 0.514 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-27 06:15:37] iteration   431700/  500000 | consumed samples:     27628800 | elapsed time per iteration (ms): 618.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.967531E+00 | loss scale: 1048576.0 | grad norm: 0.506 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-27 06:16:39] iteration   431800/  500000 | consumed samples:     27635200 | elapsed time per iteration (ms): 619.7 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.961619E+00 | loss scale: 1048576.0 | grad norm: 0.510 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 06:17:40] iteration   431900/  500000 | consumed samples:     27641600 | elapsed time per iteration (ms): 618.3 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.956602E+00 | loss scale: 1048576.0 | grad norm: 0.499 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 06:18:42] iteration   432000/  500000 | consumed samples:     27648000 | elapsed time per iteration (ms): 619.5 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.938661E+00 | loss scale: 1048576.0 | grad norm: 0.503 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2463.53, 2463.55)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 432000 | lm loss value: 3.739936E+00 | lm loss PPL: 4.209528E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-27 06:19:47] iteration   432100/  500000 | consumed samples:     27654400 | elapsed time per iteration (ms): 620.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.950568E+00 | loss scale: 1048576.0 | grad norm: 0.509 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 06:20:49] iteration   432200/  500000 | consumed samples:     27660800 | elapsed time per iteration (ms): 620.1 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.953456E+00 | loss scale: 1048576.0 | grad norm: 0.509 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 06:21:51] iteration   432300/  500000 | consumed samples:     27667200 | elapsed time per iteration (ms): 618.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.949584E+00 | loss scale: 1048576.0 | grad norm: 0.507 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 06:22:53] iteration   432400/  500000 | consumed samples:     27673600 | elapsed time per iteration (ms): 617.5 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.960267E+00 | loss scale: 1048576.0 | grad norm: 0.504 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 06:23:54] iteration   432500/  500000 | consumed samples:     27680000 | elapsed time per iteration (ms): 618.3 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.951487E+00 | loss scale: 1048576.0 | grad norm: 0.512 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 06:24:56] iteration   432600/  500000 | consumed samples:     27686400 | elapsed time per iteration (ms): 619.4 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.966650E+00 | loss scale: 1048576.0 | grad norm: 0.510 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 06:25:58] iteration   432700/  500000 | consumed samples:     27692800 | elapsed time per iteration (ms): 619.1 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.950199E+00 | loss scale: 1048576.0 | grad norm: 0.510 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-27 06:27:00] iteration   432800/  500000 | consumed samples:     27699200 | elapsed time per iteration (ms): 619.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.962725E+00 | loss scale: 1048576.0 | grad norm: 0.506 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 06:28:02] iteration   432900/  500000 | consumed samples:     27705600 | elapsed time per iteration (ms): 620.7 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.946918E+00 | loss scale: 1048576.0 | grad norm: 0.511 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 06:29:04] iteration   433000/  500000 | consumed samples:     27712000 | elapsed time per iteration (ms): 618.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.967111E+00 | loss scale: 1048576.0 | grad norm: 0.500 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2463.73, 2463.79)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 433000 | lm loss value: 3.719905E+00 | lm loss PPL: 4.126046E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-27 06:30:09] iteration   433100/  500000 | consumed samples:     27718400 | elapsed time per iteration (ms): 619.1 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.967197E+00 | loss scale: 1048576.0 | grad norm: 0.497 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 06:31:10] iteration   433200/  500000 | consumed samples:     27724800 | elapsed time per iteration (ms): 619.3 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.968404E+00 | loss scale: 1048576.0 | grad norm: 0.504 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 06:32:13] iteration   433300/  500000 | consumed samples:     27731200 | elapsed time per iteration (ms): 620.7 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.946055E+00 | loss scale: 1048576.0 | grad norm: 0.503 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 06:33:14] iteration   433400/  500000 | consumed samples:     27737600 | elapsed time per iteration (ms): 619.3 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.951543E+00 | loss scale: 1048576.0 | grad norm: 0.508 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 06:34:16] iteration   433500/  500000 | consumed samples:     27744000 | elapsed time per iteration (ms): 619.5 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.933178E+00 | loss scale: 1048576.0 | grad norm: 0.508 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 06:35:18] iteration   433600/  500000 | consumed samples:     27750400 | elapsed time per iteration (ms): 618.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.959685E+00 | loss scale: 1048576.0 | grad norm: 0.496 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 06:36:20] iteration   433700/  500000 | consumed samples:     27756800 | elapsed time per iteration (ms): 618.4 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.950812E+00 | loss scale: 2097152.0 | grad norm: 0.494 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 06:37:22] iteration   433800/  500000 | consumed samples:     27763200 | elapsed time per iteration (ms): 618.2 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.960341E+00 | loss scale: 2097152.0 | grad norm: 0.508 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 06:38:24] iteration   433900/  500000 | consumed samples:     27769600 | elapsed time per iteration (ms): 619.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.949772E+00 | loss scale: 1048576.0 | grad norm: 0.521 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-27 06:39:26] iteration   434000/  500000 | consumed samples:     27776000 | elapsed time per iteration (ms): 619.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.955400E+00 | loss scale: 1048576.0 | grad norm: 0.504 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2462.51, 2462.54)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 434000 | lm loss value: 3.761888E+00 | lm loss PPL: 4.302960E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-27 06:40:30] iteration   434100/  500000 | consumed samples:     27782400 | elapsed time per iteration (ms): 618.3 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.950027E+00 | loss scale: 1048576.0 | grad norm: 0.508 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 06:41:32] iteration   434200/  500000 | consumed samples:     27788800 | elapsed time per iteration (ms): 618.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.948439E+00 | loss scale: 1048576.0 | grad norm: 0.507 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 06:42:34] iteration   434300/  500000 | consumed samples:     27795200 | elapsed time per iteration (ms): 618.1 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.956621E+00 | loss scale: 1048576.0 | grad norm: 0.519 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 06:43:36] iteration   434400/  500000 | consumed samples:     27801600 | elapsed time per iteration (ms): 622.1 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.950253E+00 | loss scale: 1048576.0 | grad norm: 0.511 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 06:44:38] iteration   434500/  500000 | consumed samples:     27808000 | elapsed time per iteration (ms): 618.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.951471E+00 | loss scale: 1048576.0 | grad norm: 0.505 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 06:45:40] iteration   434600/  500000 | consumed samples:     27814400 | elapsed time per iteration (ms): 618.6 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.956776E+00 | loss scale: 1048576.0 | grad norm: 0.512 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 06:46:42] iteration   434700/  500000 | consumed samples:     27820800 | elapsed time per iteration (ms): 618.1 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.975018E+00 | loss scale: 1048576.0 | grad norm: 0.513 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 06:47:44] iteration   434800/  500000 | consumed samples:     27827200 | elapsed time per iteration (ms): 619.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.941953E+00 | loss scale: 1048576.0 | grad norm: 0.495 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 06:48:46] iteration   434900/  500000 | consumed samples:     27833600 | elapsed time per iteration (ms): 619.6 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.938094E+00 | loss scale: 2097152.0 | grad norm: 0.510 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 06:49:48] iteration   435000/  500000 | consumed samples:     27840000 | elapsed time per iteration (ms): 619.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.971703E+00 | loss scale: 1048576.0 | grad norm: 0.505 | number of skipped iterations:   2 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2462.13, 2462.21)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 435000 | lm loss value: 3.708983E+00 | lm loss PPL: 4.081229E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-27 06:50:52] iteration   435100/  500000 | consumed samples:     27846400 | elapsed time per iteration (ms): 618.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.956499E+00 | loss scale: 1048576.0 | grad norm: 0.504 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 06:51:54] iteration   435200/  500000 | consumed samples:     27852800 | elapsed time per iteration (ms): 619.7 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.942299E+00 | loss scale: 1048576.0 | grad norm: 0.502 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 06:52:56] iteration   435300/  500000 | consumed samples:     27859200 | elapsed time per iteration (ms): 620.3 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.960010E+00 | loss scale: 1048576.0 | grad norm: 0.508 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 06:53:58] iteration   435400/  500000 | consumed samples:     27865600 | elapsed time per iteration (ms): 620.3 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.945538E+00 | loss scale: 1048576.0 | grad norm: 0.499 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 06:55:00] iteration   435500/  500000 | consumed samples:     27872000 | elapsed time per iteration (ms): 619.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.945613E+00 | loss scale: 1048576.0 | grad norm: 0.505 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 06:56:02] iteration   435600/  500000 | consumed samples:     27878400 | elapsed time per iteration (ms): 620.1 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.964935E+00 | loss scale: 1048576.0 | grad norm: 0.521 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 06:57:04] iteration   435700/  500000 | consumed samples:     27884800 | elapsed time per iteration (ms): 618.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.957982E+00 | loss scale: 1048576.0 | grad norm: 0.497 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 06:58:06] iteration   435800/  500000 | consumed samples:     27891200 | elapsed time per iteration (ms): 620.4 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.950545E+00 | loss scale: 1048576.0 | grad norm: 0.506 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 06:59:08] iteration   435900/  500000 | consumed samples:     27897600 | elapsed time per iteration (ms): 621.2 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.967546E+00 | loss scale: 1048576.0 | grad norm: 0.511 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 07:00:10] iteration   436000/  500000 | consumed samples:     27904000 | elapsed time per iteration (ms): 619.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.932406E+00 | loss scale: 1048576.0 | grad norm: 0.515 | number of skipped iterations:   2 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2466.05, 2466.10)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 436000 | lm loss value: 3.731564E+00 | lm loss PPL: 4.174435E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-27 07:01:14] iteration   436100/  500000 | consumed samples:     27910400 | elapsed time per iteration (ms): 620.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.956349E+00 | loss scale: 1048576.0 | grad norm: 0.506 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 07:02:16] iteration   436200/  500000 | consumed samples:     27916800 | elapsed time per iteration (ms): 618.7 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.954684E+00 | loss scale: 1048576.0 | grad norm: 0.501 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 07:03:18] iteration   436300/  500000 | consumed samples:     27923200 | elapsed time per iteration (ms): 620.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.954687E+00 | loss scale: 1048576.0 | grad norm: 0.498 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 07:04:20] iteration   436400/  500000 | consumed samples:     27929600 | elapsed time per iteration (ms): 619.7 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.958942E+00 | loss scale: 1048576.0 | grad norm: 0.500 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 07:05:22] iteration   436500/  500000 | consumed samples:     27936000 | elapsed time per iteration (ms): 619.5 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.938394E+00 | loss scale: 1048576.0 | grad norm: 0.501 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 07:06:24] iteration   436600/  500000 | consumed samples:     27942400 | elapsed time per iteration (ms): 619.1 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.954454E+00 | loss scale: 1048576.0 | grad norm: 0.497 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 07:07:26] iteration   436700/  500000 | consumed samples:     27948800 | elapsed time per iteration (ms): 619.2 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.953772E+00 | loss scale: 1048576.0 | grad norm: 0.500 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 07:08:28] iteration   436800/  500000 | consumed samples:     27955200 | elapsed time per iteration (ms): 619.4 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.955371E+00 | loss scale: 1048576.0 | grad norm: 0.503 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 07:09:30] iteration   436900/  500000 | consumed samples:     27961600 | elapsed time per iteration (ms): 617.2 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.962919E+00 | loss scale: 1048576.0 | grad norm: 0.520 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 07:10:31] iteration   437000/  500000 | consumed samples:     27968000 | elapsed time per iteration (ms): 618.4 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.959925E+00 | loss scale: 2097152.0 | grad norm: 0.502 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2461.53, 2461.65)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 437000 | lm loss value: 3.727260E+00 | lm loss PPL: 4.156506E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-27 07:11:36] iteration   437100/  500000 | consumed samples:     27974400 | elapsed time per iteration (ms): 618.3 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.944353E+00 | loss scale: 1048576.0 | grad norm: 0.505 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-27 07:12:38] iteration   437200/  500000 | consumed samples:     27980800 | elapsed time per iteration (ms): 618.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.940921E+00 | loss scale: 1048576.0 | grad norm: 0.522 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 07:13:40] iteration   437300/  500000 | consumed samples:     27987200 | elapsed time per iteration (ms): 618.5 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.959590E+00 | loss scale: 1048576.0 | grad norm: 0.500 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 07:14:42] iteration   437400/  500000 | consumed samples:     27993600 | elapsed time per iteration (ms): 620.5 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.950751E+00 | loss scale: 1048576.0 | grad norm: 0.505 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 07:15:44] iteration   437500/  500000 | consumed samples:     28000000 | elapsed time per iteration (ms): 620.6 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.961766E+00 | loss scale: 1048576.0 | grad norm: 0.518 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 07:16:46] iteration   437600/  500000 | consumed samples:     28006400 | elapsed time per iteration (ms): 620.3 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.960348E+00 | loss scale: 1048576.0 | grad norm: 0.504 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 07:17:48] iteration   437700/  500000 | consumed samples:     28012800 | elapsed time per iteration (ms): 619.2 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.955450E+00 | loss scale: 1048576.0 | grad norm: 0.521 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 07:18:50] iteration   437800/  500000 | consumed samples:     28019200 | elapsed time per iteration (ms): 619.6 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.954353E+00 | loss scale: 1048576.0 | grad norm: 0.505 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 07:19:51] iteration   437900/  500000 | consumed samples:     28025600 | elapsed time per iteration (ms): 619.3 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.962785E+00 | loss scale: 1048576.0 | grad norm: 0.508 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 07:20:53] iteration   438000/  500000 | consumed samples:     28032000 | elapsed time per iteration (ms): 618.7 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.969234E+00 | loss scale: 1048576.0 | grad norm: 0.502 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2462.13, 2462.15)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 438000 | lm loss value: 3.756268E+00 | lm loss PPL: 4.278842E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-27 07:21:58] iteration   438100/  500000 | consumed samples:     28038400 | elapsed time per iteration (ms): 618.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.957201E+00 | loss scale: 2097152.0 | grad norm: 0.520 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-27 07:23:00] iteration   438200/  500000 | consumed samples:     28044800 | elapsed time per iteration (ms): 620.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.954820E+00 | loss scale: 1048576.0 | grad norm: 0.519 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-27 07:24:02] iteration   438300/  500000 | consumed samples:     28051200 | elapsed time per iteration (ms): 620.5 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.966625E+00 | loss scale: 1048576.0 | grad norm: 0.515 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 07:25:04] iteration   438400/  500000 | consumed samples:     28057600 | elapsed time per iteration (ms): 618.5 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.954943E+00 | loss scale: 1048576.0 | grad norm: 0.511 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 07:26:05] iteration   438500/  500000 | consumed samples:     28064000 | elapsed time per iteration (ms): 619.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.956132E+00 | loss scale: 1048576.0 | grad norm: 0.501 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 07:27:07] iteration   438600/  500000 | consumed samples:     28070400 | elapsed time per iteration (ms): 619.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.964451E+00 | loss scale: 1048576.0 | grad norm: 0.523 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 07:28:10] iteration   438700/  500000 | consumed samples:     28076800 | elapsed time per iteration (ms): 622.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.966210E+00 | loss scale: 1048576.0 | grad norm: 0.504 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 07:29:11] iteration   438800/  500000 | consumed samples:     28083200 | elapsed time per iteration (ms): 617.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.952552E+00 | loss scale: 1048576.0 | grad norm: 0.501 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 07:30:13] iteration   438900/  500000 | consumed samples:     28089600 | elapsed time per iteration (ms): 620.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.954236E+00 | loss scale: 1048576.0 | grad norm: 0.505 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 07:31:15] iteration   439000/  500000 | consumed samples:     28096000 | elapsed time per iteration (ms): 618.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.953012E+00 | loss scale: 524288.0 | grad norm: 0.510 | number of skipped iterations:   1 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2462.72, 2462.72)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 439000 | lm loss value: 3.733819E+00 | lm loss PPL: 4.183860E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-27 07:32:20] iteration   439100/  500000 | consumed samples:     28102400 | elapsed time per iteration (ms): 620.3 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.960444E+00 | loss scale: 524288.0 | grad norm: 0.511 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 07:33:22] iteration   439200/  500000 | consumed samples:     28108800 | elapsed time per iteration (ms): 617.4 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.947394E+00 | loss scale: 524288.0 | grad norm: 0.516 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 07:34:24] iteration   439300/  500000 | consumed samples:     28115200 | elapsed time per iteration (ms): 620.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.961778E+00 | loss scale: 524288.0 | grad norm: 0.510 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 07:35:25] iteration   439400/  500000 | consumed samples:     28121600 | elapsed time per iteration (ms): 617.7 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.958597E+00 | loss scale: 524288.0 | grad norm: 0.514 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 07:36:27] iteration   439500/  500000 | consumed samples:     28128000 | elapsed time per iteration (ms): 619.3 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.936375E+00 | loss scale: 524288.0 | grad norm: 0.511 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 07:37:29] iteration   439600/  500000 | consumed samples:     28134400 | elapsed time per iteration (ms): 618.2 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.952558E+00 | loss scale: 524288.0 | grad norm: 0.508 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 07:38:31] iteration   439700/  500000 | consumed samples:     28140800 | elapsed time per iteration (ms): 620.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.945817E+00 | loss scale: 524288.0 | grad norm: 0.500 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 07:39:33] iteration   439800/  500000 | consumed samples:     28147200 | elapsed time per iteration (ms): 619.7 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.952943E+00 | loss scale: 524288.0 | grad norm: 0.510 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 07:40:35] iteration   439900/  500000 | consumed samples:     28153600 | elapsed time per iteration (ms): 619.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.951574E+00 | loss scale: 524288.0 | grad norm: 0.516 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 07:41:37] iteration   440000/  500000 | consumed samples:     28160000 | elapsed time per iteration (ms): 619.6 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.947786E+00 | loss scale: 1048576.0 | grad norm: 0.493 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2463.11, 2463.13)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 440000 | lm loss value: 3.749753E+00 | lm loss PPL: 4.251056E+01 | 
--------------------------------------------------------------------------------------------------
saving checkpoint at iteration  440000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-distribution in torch format
  successfully saved checkpoint at iteration  440000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-distribution
(min, max) time across ranks (ms):
    save-checkpoint ................................: (2328.90, 2328.93)
 [2024-06-27 07:42:44] iteration   440100/  500000 | consumed samples:     28166400 | elapsed time per iteration (ms): 620.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.961428E+00 | loss scale: 1048576.0 | grad norm: 0.502 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 07:43:46] iteration   440200/  500000 | consumed samples:     28172800 | elapsed time per iteration (ms): 618.1 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.960496E+00 | loss scale: 1048576.0 | grad norm: 0.501 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 07:44:48] iteration   440300/  500000 | consumed samples:     28179200 | elapsed time per iteration (ms): 618.3 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.963790E+00 | loss scale: 1048576.0 | grad norm: 0.513 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 07:45:50] iteration   440400/  500000 | consumed samples:     28185600 | elapsed time per iteration (ms): 619.1 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.952071E+00 | loss scale: 1048576.0 | grad norm: 0.506 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 07:46:51] iteration   440500/  500000 | consumed samples:     28192000 | elapsed time per iteration (ms): 617.3 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.950140E+00 | loss scale: 1048576.0 | grad norm: 0.516 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 07:47:53] iteration   440600/  500000 | consumed samples:     28198400 | elapsed time per iteration (ms): 619.7 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.957243E+00 | loss scale: 1048576.0 | grad norm: 0.503 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 07:48:55] iteration   440700/  500000 | consumed samples:     28204800 | elapsed time per iteration (ms): 621.5 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.957342E+00 | loss scale: 1048576.0 | grad norm: 0.515 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 07:49:57] iteration   440800/  500000 | consumed samples:     28211200 | elapsed time per iteration (ms): 620.4 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.955051E+00 | loss scale: 1048576.0 | grad norm: 0.508 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 07:50:59] iteration   440900/  500000 | consumed samples:     28217600 | elapsed time per iteration (ms): 619.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.959490E+00 | loss scale: 1048576.0 | grad norm: 0.509 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 07:52:01] iteration   441000/  500000 | consumed samples:     28224000 | elapsed time per iteration (ms): 620.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.957082E+00 | loss scale: 2097152.0 | grad norm: 0.506 | number of skipped iterations:   1 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2464.24, 2464.50)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 441000 | lm loss value: 3.732625E+00 | lm loss PPL: 4.178867E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-27 07:53:06] iteration   441100/  500000 | consumed samples:     28230400 | elapsed time per iteration (ms): 624.1 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.950068E+00 | loss scale: 1048576.0 | grad norm: 0.501 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-27 07:54:08] iteration   441200/  500000 | consumed samples:     28236800 | elapsed time per iteration (ms): 618.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.965168E+00 | loss scale: 1048576.0 | grad norm: 0.518 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 07:55:10] iteration   441300/  500000 | consumed samples:     28243200 | elapsed time per iteration (ms): 619.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.944051E+00 | loss scale: 1048576.0 | grad norm: 0.503 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 07:56:12] iteration   441400/  500000 | consumed samples:     28249600 | elapsed time per iteration (ms): 619.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.961640E+00 | loss scale: 1048576.0 | grad norm: 0.507 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 07:57:14] iteration   441500/  500000 | consumed samples:     28256000 | elapsed time per iteration (ms): 619.3 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.950534E+00 | loss scale: 1048576.0 | grad norm: 0.518 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 07:58:16] iteration   441600/  500000 | consumed samples:     28262400 | elapsed time per iteration (ms): 619.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.964818E+00 | loss scale: 1048576.0 | grad norm: 0.509 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 07:59:18] iteration   441700/  500000 | consumed samples:     28268800 | elapsed time per iteration (ms): 619.7 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.950840E+00 | loss scale: 1048576.0 | grad norm: 0.520 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 08:00:20] iteration   441800/  500000 | consumed samples:     28275200 | elapsed time per iteration (ms): 618.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.953215E+00 | loss scale: 1048576.0 | grad norm: 0.515 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 08:01:22] iteration   441900/  500000 | consumed samples:     28281600 | elapsed time per iteration (ms): 619.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.951628E+00 | loss scale: 1048576.0 | grad norm: 0.505 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 08:02:24] iteration   442000/  500000 | consumed samples:     28288000 | elapsed time per iteration (ms): 619.6 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.958578E+00 | loss scale: 1048576.0 | grad norm: 0.510 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2461.87, 2461.88)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 442000 | lm loss value: 3.755764E+00 | lm loss PPL: 4.276688E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-27 08:03:28] iteration   442100/  500000 | consumed samples:     28294400 | elapsed time per iteration (ms): 617.4 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.951923E+00 | loss scale: 2097152.0 | grad norm: 0.516 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-27 08:04:30] iteration   442200/  500000 | consumed samples:     28300800 | elapsed time per iteration (ms): 621.5 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.966017E+00 | loss scale: 1048576.0 | grad norm: 0.513 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-27 08:05:32] iteration   442300/  500000 | consumed samples:     28307200 | elapsed time per iteration (ms): 617.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.960654E+00 | loss scale: 1048576.0 | grad norm: 0.509 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 08:06:34] iteration   442400/  500000 | consumed samples:     28313600 | elapsed time per iteration (ms): 619.3 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.960607E+00 | loss scale: 1048576.0 | grad norm: 0.509 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 08:07:36] iteration   442500/  500000 | consumed samples:     28320000 | elapsed time per iteration (ms): 618.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.958506E+00 | loss scale: 1048576.0 | grad norm: 0.515 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 08:08:38] iteration   442600/  500000 | consumed samples:     28326400 | elapsed time per iteration (ms): 619.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.956953E+00 | loss scale: 1048576.0 | grad norm: 0.507 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 08:09:39] iteration   442700/  500000 | consumed samples:     28332800 | elapsed time per iteration (ms): 619.1 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.948307E+00 | loss scale: 1048576.0 | grad norm: 0.513 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 08:10:41] iteration   442800/  500000 | consumed samples:     28339200 | elapsed time per iteration (ms): 618.4 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.934516E+00 | loss scale: 1048576.0 | grad norm: 0.509 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 08:11:43] iteration   442900/  500000 | consumed samples:     28345600 | elapsed time per iteration (ms): 621.5 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.962128E+00 | loss scale: 1048576.0 | grad norm: 0.505 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 08:12:46] iteration   443000/  500000 | consumed samples:     28352000 | elapsed time per iteration (ms): 621.4 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.937504E+00 | loss scale: 1048576.0 | grad norm: 0.489 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2462.33, 2462.34)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 443000 | lm loss value: 3.762496E+00 | lm loss PPL: 4.305575E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-27 08:13:50] iteration   443100/  500000 | consumed samples:     28358400 | elapsed time per iteration (ms): 619.4 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.952776E+00 | loss scale: 1048576.0 | grad norm: 0.528 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 08:14:52] iteration   443200/  500000 | consumed samples:     28364800 | elapsed time per iteration (ms): 620.7 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.960623E+00 | loss scale: 1048576.0 | grad norm: 0.511 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-27 08:15:54] iteration   443300/  500000 | consumed samples:     28371200 | elapsed time per iteration (ms): 617.4 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.945988E+00 | loss scale: 1048576.0 | grad norm: 0.518 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 08:16:56] iteration   443400/  500000 | consumed samples:     28377600 | elapsed time per iteration (ms): 619.2 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.939263E+00 | loss scale: 1048576.0 | grad norm: 0.521 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 08:17:57] iteration   443500/  500000 | consumed samples:     28384000 | elapsed time per iteration (ms): 617.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.949552E+00 | loss scale: 1048576.0 | grad norm: 0.515 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 08:18:59] iteration   443600/  500000 | consumed samples:     28390400 | elapsed time per iteration (ms): 619.4 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.949137E+00 | loss scale: 1048576.0 | grad norm: 0.512 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 08:20:01] iteration   443700/  500000 | consumed samples:     28396800 | elapsed time per iteration (ms): 616.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.968581E+00 | loss scale: 1048576.0 | grad norm: 0.505 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 08:21:03] iteration   443800/  500000 | consumed samples:     28403200 | elapsed time per iteration (ms): 619.3 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.956106E+00 | loss scale: 1048576.0 | grad norm: 0.496 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 08:22:05] iteration   443900/  500000 | consumed samples:     28409600 | elapsed time per iteration (ms): 618.1 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.951568E+00 | loss scale: 1048576.0 | grad norm: 0.511 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 08:23:07] iteration   444000/  500000 | consumed samples:     28416000 | elapsed time per iteration (ms): 618.7 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.955245E+00 | loss scale: 1048576.0 | grad norm: 0.503 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2461.44, 2461.54)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 444000 | lm loss value: 3.761491E+00 | lm loss PPL: 4.301249E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-27 08:24:11] iteration   444100/  500000 | consumed samples:     28422400 | elapsed time per iteration (ms): 617.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.959469E+00 | loss scale: 1048576.0 | grad norm: 0.507 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 08:25:13] iteration   444200/  500000 | consumed samples:     28428800 | elapsed time per iteration (ms): 619.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.947664E+00 | loss scale: 2097152.0 | grad norm: 0.517 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 08:26:15] iteration   444300/  500000 | consumed samples:     28435200 | elapsed time per iteration (ms): 619.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.942484E+00 | loss scale: 1048576.0 | grad norm: 0.509 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-27 08:27:17] iteration   444400/  500000 | consumed samples:     28441600 | elapsed time per iteration (ms): 620.3 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.957331E+00 | loss scale: 1048576.0 | grad norm: 0.510 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 08:28:19] iteration   444500/  500000 | consumed samples:     28448000 | elapsed time per iteration (ms): 618.7 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.948862E+00 | loss scale: 1048576.0 | grad norm: 0.500 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 08:29:21] iteration   444600/  500000 | consumed samples:     28454400 | elapsed time per iteration (ms): 619.2 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.946857E+00 | loss scale: 1048576.0 | grad norm: 0.509 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 08:30:23] iteration   444700/  500000 | consumed samples:     28460800 | elapsed time per iteration (ms): 620.4 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.954160E+00 | loss scale: 1048576.0 | grad norm: 0.527 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 08:31:25] iteration   444800/  500000 | consumed samples:     28467200 | elapsed time per iteration (ms): 618.3 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.938472E+00 | loss scale: 1048576.0 | grad norm: 0.501 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 08:32:26] iteration   444900/  500000 | consumed samples:     28473600 | elapsed time per iteration (ms): 617.5 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.950055E+00 | loss scale: 1048576.0 | grad norm: 0.509 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 08:33:28] iteration   445000/  500000 | consumed samples:     28480000 | elapsed time per iteration (ms): 620.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.962281E+00 | loss scale: 1048576.0 | grad norm: 0.519 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2463.58, 2464.81)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 445000 | lm loss value: 3.722973E+00 | lm loss PPL: 4.138725E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-27 08:34:33] iteration   445100/  500000 | consumed samples:     28486400 | elapsed time per iteration (ms): 618.5 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.953583E+00 | loss scale: 1048576.0 | grad norm: 0.507 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 08:35:35] iteration   445200/  500000 | consumed samples:     28492800 | elapsed time per iteration (ms): 619.5 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.972596E+00 | loss scale: 1048576.0 | grad norm: 0.517 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 08:36:36] iteration   445300/  500000 | consumed samples:     28499200 | elapsed time per iteration (ms): 617.5 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.955002E+00 | loss scale: 1048576.0 | grad norm: 0.513 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-27 08:37:38] iteration   445400/  500000 | consumed samples:     28505600 | elapsed time per iteration (ms): 619.1 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.950414E+00 | loss scale: 1048576.0 | grad norm: 0.513 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 08:38:40] iteration   445500/  500000 | consumed samples:     28512000 | elapsed time per iteration (ms): 618.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.943725E+00 | loss scale: 1048576.0 | grad norm: 0.515 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 08:39:42] iteration   445600/  500000 | consumed samples:     28518400 | elapsed time per iteration (ms): 620.2 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.970431E+00 | loss scale: 1048576.0 | grad norm: 0.507 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 08:40:44] iteration   445700/  500000 | consumed samples:     28524800 | elapsed time per iteration (ms): 618.7 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.963194E+00 | loss scale: 1048576.0 | grad norm: 0.495 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 08:41:46] iteration   445800/  500000 | consumed samples:     28531200 | elapsed time per iteration (ms): 618.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.953494E+00 | loss scale: 1048576.0 | grad norm: 0.503 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 08:42:48] iteration   445900/  500000 | consumed samples:     28537600 | elapsed time per iteration (ms): 620.3 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.957628E+00 | loss scale: 1048576.0 | grad norm: 0.498 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 08:43:50] iteration   446000/  500000 | consumed samples:     28544000 | elapsed time per iteration (ms): 618.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.954422E+00 | loss scale: 1048576.0 | grad norm: 0.495 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2466.82, 2466.85)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 446000 | lm loss value: 3.769124E+00 | lm loss PPL: 4.334209E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-27 08:44:54] iteration   446100/  500000 | consumed samples:     28550400 | elapsed time per iteration (ms): 618.1 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.956124E+00 | loss scale: 524288.0 | grad norm: 0.521 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-27 08:45:56] iteration   446200/  500000 | consumed samples:     28556800 | elapsed time per iteration (ms): 617.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.942471E+00 | loss scale: 524288.0 | grad norm: 0.514 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 08:46:58] iteration   446300/  500000 | consumed samples:     28563200 | elapsed time per iteration (ms): 620.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.956087E+00 | loss scale: 524288.0 | grad norm: 0.515 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 08:48:00] iteration   446400/  500000 | consumed samples:     28569600 | elapsed time per iteration (ms): 619.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.953622E+00 | loss scale: 524288.0 | grad norm: 0.508 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 08:49:02] iteration   446500/  500000 | consumed samples:     28576000 | elapsed time per iteration (ms): 618.4 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.935020E+00 | loss scale: 524288.0 | grad norm: 0.490 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 08:50:04] iteration   446600/  500000 | consumed samples:     28582400 | elapsed time per iteration (ms): 618.7 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.954297E+00 | loss scale: 524288.0 | grad norm: 0.517 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 08:51:05] iteration   446700/  500000 | consumed samples:     28588800 | elapsed time per iteration (ms): 619.1 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.961033E+00 | loss scale: 524288.0 | grad norm: 0.497 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 08:52:07] iteration   446800/  500000 | consumed samples:     28595200 | elapsed time per iteration (ms): 617.1 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.947578E+00 | loss scale: 524288.0 | grad norm: 0.522 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 08:53:09] iteration   446900/  500000 | consumed samples:     28601600 | elapsed time per iteration (ms): 620.3 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.955795E+00 | loss scale: 524288.0 | grad norm: 0.515 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 08:54:11] iteration   447000/  500000 | consumed samples:     28608000 | elapsed time per iteration (ms): 616.3 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.950522E+00 | loss scale: 524288.0 | grad norm: 0.500 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2460.49, 2460.60)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 447000 | lm loss value: 3.737556E+00 | lm loss PPL: 4.199522E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-27 08:55:15] iteration   447100/  500000 | consumed samples:     28614400 | elapsed time per iteration (ms): 617.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.958855E+00 | loss scale: 1048576.0 | grad norm: 0.516 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 08:56:17] iteration   447200/  500000 | consumed samples:     28620800 | elapsed time per iteration (ms): 618.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.939892E+00 | loss scale: 1048576.0 | grad norm: 0.499 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 08:57:19] iteration   447300/  500000 | consumed samples:     28627200 | elapsed time per iteration (ms): 620.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.958127E+00 | loss scale: 1048576.0 | grad norm: 0.514 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 08:58:21] iteration   447400/  500000 | consumed samples:     28633600 | elapsed time per iteration (ms): 619.3 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.955385E+00 | loss scale: 1048576.0 | grad norm: 0.520 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 08:59:23] iteration   447500/  500000 | consumed samples:     28640000 | elapsed time per iteration (ms): 619.5 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.975387E+00 | loss scale: 1048576.0 | grad norm: 0.518 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 09:00:25] iteration   447600/  500000 | consumed samples:     28646400 | elapsed time per iteration (ms): 619.2 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.951185E+00 | loss scale: 1048576.0 | grad norm: 0.501 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 09:01:27] iteration   447700/  500000 | consumed samples:     28652800 | elapsed time per iteration (ms): 618.2 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.937252E+00 | loss scale: 1048576.0 | grad norm: 0.507 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 09:02:28] iteration   447800/  500000 | consumed samples:     28659200 | elapsed time per iteration (ms): 617.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.951992E+00 | loss scale: 1048576.0 | grad norm: 0.507 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 09:03:30] iteration   447900/  500000 | consumed samples:     28665600 | elapsed time per iteration (ms): 619.7 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.954926E+00 | loss scale: 1048576.0 | grad norm: 0.518 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 09:04:32] iteration   448000/  500000 | consumed samples:     28672000 | elapsed time per iteration (ms): 618.7 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.966151E+00 | loss scale: 1048576.0 | grad norm: 0.513 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2463.44, 2463.66)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 448000 | lm loss value: 3.718695E+00 | lm loss PPL: 4.121059E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-27 09:05:37] iteration   448100/  500000 | consumed samples:     28678400 | elapsed time per iteration (ms): 618.6 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.954988E+00 | loss scale: 2097152.0 | grad norm: 0.498 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 09:06:39] iteration   448200/  500000 | consumed samples:     28684800 | elapsed time per iteration (ms): 620.6 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.963135E+00 | loss scale: 1048576.0 | grad norm: 0.512 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-27 09:07:41] iteration   448300/  500000 | consumed samples:     28691200 | elapsed time per iteration (ms): 618.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.960441E+00 | loss scale: 1048576.0 | grad norm: 0.516 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 09:08:42] iteration   448400/  500000 | consumed samples:     28697600 | elapsed time per iteration (ms): 619.2 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.951364E+00 | loss scale: 1048576.0 | grad norm: 0.516 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 09:09:44] iteration   448500/  500000 | consumed samples:     28704000 | elapsed time per iteration (ms): 620.7 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.939449E+00 | loss scale: 1048576.0 | grad norm: 0.507 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 09:10:46] iteration   448600/  500000 | consumed samples:     28710400 | elapsed time per iteration (ms): 618.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.945201E+00 | loss scale: 1048576.0 | grad norm: 0.508 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 09:11:48] iteration   448700/  500000 | consumed samples:     28716800 | elapsed time per iteration (ms): 619.4 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.952796E+00 | loss scale: 1048576.0 | grad norm: 0.526 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 09:12:50] iteration   448800/  500000 | consumed samples:     28723200 | elapsed time per iteration (ms): 617.4 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.952416E+00 | loss scale: 1048576.0 | grad norm: 0.509 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 09:13:52] iteration   448900/  500000 | consumed samples:     28729600 | elapsed time per iteration (ms): 617.4 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.964391E+00 | loss scale: 1048576.0 | grad norm: 0.537 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 09:14:54] iteration   449000/  500000 | consumed samples:     28736000 | elapsed time per iteration (ms): 620.5 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.943528E+00 | loss scale: 1048576.0 | grad norm: 0.517 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2462.15, 2462.23)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 449000 | lm loss value: 3.762231E+00 | lm loss PPL: 4.304434E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-27 09:15:58] iteration   449100/  500000 | consumed samples:     28742400 | elapsed time per iteration (ms): 620.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.952194E+00 | loss scale: 1048576.0 | grad norm: 0.501 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 09:17:00] iteration   449200/  500000 | consumed samples:     28748800 | elapsed time per iteration (ms): 618.5 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.967729E+00 | loss scale: 1048576.0 | grad norm: 0.503 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-27 09:18:02] iteration   449300/  500000 | consumed samples:     28755200 | elapsed time per iteration (ms): 618.7 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.956344E+00 | loss scale: 1048576.0 | grad norm: 0.494 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 09:19:04] iteration   449400/  500000 | consumed samples:     28761600 | elapsed time per iteration (ms): 618.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.957882E+00 | loss scale: 1048576.0 | grad norm: 0.508 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 09:20:06] iteration   449500/  500000 | consumed samples:     28768000 | elapsed time per iteration (ms): 618.1 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.962229E+00 | loss scale: 1048576.0 | grad norm: 0.503 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 09:21:08] iteration   449600/  500000 | consumed samples:     28774400 | elapsed time per iteration (ms): 620.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.955349E+00 | loss scale: 1048576.0 | grad norm: 0.502 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 09:22:10] iteration   449700/  500000 | consumed samples:     28780800 | elapsed time per iteration (ms): 620.2 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.951161E+00 | loss scale: 1048576.0 | grad norm: 0.505 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 09:23:12] iteration   449800/  500000 | consumed samples:     28787200 | elapsed time per iteration (ms): 618.2 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.957645E+00 | loss scale: 1048576.0 | grad norm: 0.513 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 09:24:14] iteration   449900/  500000 | consumed samples:     28793600 | elapsed time per iteration (ms): 619.2 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.946522E+00 | loss scale: 1048576.0 | grad norm: 0.512 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 09:25:16] iteration   450000/  500000 | consumed samples:     28800000 | elapsed time per iteration (ms): 620.3 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.957147E+00 | loss scale: 1048576.0 | grad norm: 0.498 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2462.93, 2462.96)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 450000 | lm loss value: 3.716425E+00 | lm loss PPL: 4.111715E+01 | 
--------------------------------------------------------------------------------------------------
saving checkpoint at iteration  450000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-distribution in torch format
  successfully saved checkpoint at iteration  450000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-distribution
(min, max) time across ranks (ms):
    save-checkpoint ................................: (2381.80, 2381.82)
 [2024-06-27 09:26:22] iteration   450100/  500000 | consumed samples:     28806400 | elapsed time per iteration (ms): 617.3 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.956125E+00 | loss scale: 1048576.0 | grad norm: 0.510 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 09:27:24] iteration   450200/  500000 | consumed samples:     28812800 | elapsed time per iteration (ms): 618.5 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.955067E+00 | loss scale: 2097152.0 | grad norm: 0.499 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-27 09:28:26] iteration   450300/  500000 | consumed samples:     28819200 | elapsed time per iteration (ms): 617.5 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.953125E+00 | loss scale: 1048576.0 | grad norm: 0.506 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-27 09:29:28] iteration   450400/  500000 | consumed samples:     28825600 | elapsed time per iteration (ms): 618.6 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.937957E+00 | loss scale: 1048576.0 | grad norm: 0.520 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 09:30:30] iteration   450500/  500000 | consumed samples:     28832000 | elapsed time per iteration (ms): 618.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.959557E+00 | loss scale: 1048576.0 | grad norm: 0.522 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 09:31:31] iteration   450600/  500000 | consumed samples:     28838400 | elapsed time per iteration (ms): 619.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.948779E+00 | loss scale: 1048576.0 | grad norm: 0.510 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 09:32:33] iteration   450700/  500000 | consumed samples:     28844800 | elapsed time per iteration (ms): 619.6 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.972063E+00 | loss scale: 1048576.0 | grad norm: 0.509 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 09:33:35] iteration   450800/  500000 | consumed samples:     28851200 | elapsed time per iteration (ms): 618.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.939862E+00 | loss scale: 1048576.0 | grad norm: 0.519 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 09:34:37] iteration   450900/  500000 | consumed samples:     28857600 | elapsed time per iteration (ms): 616.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.946611E+00 | loss scale: 1048576.0 | grad norm: 0.510 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 09:35:39] iteration   451000/  500000 | consumed samples:     28864000 | elapsed time per iteration (ms): 619.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.953023E+00 | loss scale: 1048576.0 | grad norm: 0.516 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2463.76, 2463.80)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 451000 | lm loss value: 3.763249E+00 | lm loss PPL: 4.308819E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-27 09:36:43] iteration   451100/  500000 | consumed samples:     28870400 | elapsed time per iteration (ms): 618.3 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.944000E+00 | loss scale: 1048576.0 | grad norm: 0.512 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 09:37:45] iteration   451200/  500000 | consumed samples:     28876800 | elapsed time per iteration (ms): 621.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.947609E+00 | loss scale: 1048576.0 | grad norm: 0.503 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 09:38:47] iteration   451300/  500000 | consumed samples:     28883200 | elapsed time per iteration (ms): 617.7 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.957588E+00 | loss scale: 2097152.0 | grad norm: 0.512 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 09:39:49] iteration   451400/  500000 | consumed samples:     28889600 | elapsed time per iteration (ms): 619.4 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.958569E+00 | loss scale: 2097152.0 | grad norm: 0.503 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-27 09:40:51] iteration   451500/  500000 | consumed samples:     28896000 | elapsed time per iteration (ms): 617.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.962775E+00 | loss scale: 1048576.0 | grad norm: 0.513 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-27 09:41:53] iteration   451600/  500000 | consumed samples:     28902400 | elapsed time per iteration (ms): 620.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.957799E+00 | loss scale: 1048576.0 | grad norm: 0.503 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 09:42:55] iteration   451700/  500000 | consumed samples:     28908800 | elapsed time per iteration (ms): 617.7 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.962442E+00 | loss scale: 1048576.0 | grad norm: 0.507 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 09:43:57] iteration   451800/  500000 | consumed samples:     28915200 | elapsed time per iteration (ms): 619.6 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.954499E+00 | loss scale: 1048576.0 | grad norm: 0.508 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 09:44:59] iteration   451900/  500000 | consumed samples:     28921600 | elapsed time per iteration (ms): 618.3 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.945146E+00 | loss scale: 1048576.0 | grad norm: 0.505 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 09:46:00] iteration   452000/  500000 | consumed samples:     28928000 | elapsed time per iteration (ms): 618.2 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.949936E+00 | loss scale: 1048576.0 | grad norm: 0.502 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2464.57, 2464.82)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 452000 | lm loss value: 3.724957E+00 | lm loss PPL: 4.146946E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-27 09:47:05] iteration   452100/  500000 | consumed samples:     28934400 | elapsed time per iteration (ms): 617.1 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.951690E+00 | loss scale: 1048576.0 | grad norm: 0.507 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 09:48:07] iteration   452200/  500000 | consumed samples:     28940800 | elapsed time per iteration (ms): 619.7 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.952785E+00 | loss scale: 1048576.0 | grad norm: 0.513 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 09:49:08] iteration   452300/  500000 | consumed samples:     28947200 | elapsed time per iteration (ms): 619.5 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.955454E+00 | loss scale: 1048576.0 | grad norm: 0.522 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 09:50:10] iteration   452400/  500000 | consumed samples:     28953600 | elapsed time per iteration (ms): 618.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.941924E+00 | loss scale: 1048576.0 | grad norm: 0.521 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 09:51:12] iteration   452500/  500000 | consumed samples:     28960000 | elapsed time per iteration (ms): 618.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.956674E+00 | loss scale: 1048576.0 | grad norm: 0.506 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-27 09:52:14] iteration   452600/  500000 | consumed samples:     28966400 | elapsed time per iteration (ms): 619.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.955537E+00 | loss scale: 1048576.0 | grad norm: 0.518 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 09:53:16] iteration   452700/  500000 | consumed samples:     28972800 | elapsed time per iteration (ms): 618.3 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.942775E+00 | loss scale: 1048576.0 | grad norm: 0.499 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 09:54:18] iteration   452800/  500000 | consumed samples:     28979200 | elapsed time per iteration (ms): 619.3 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.958068E+00 | loss scale: 1048576.0 | grad norm: 0.504 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 09:55:20] iteration   452900/  500000 | consumed samples:     28985600 | elapsed time per iteration (ms): 618.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.957158E+00 | loss scale: 1048576.0 | grad norm: 0.502 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 09:56:22] iteration   453000/  500000 | consumed samples:     28992000 | elapsed time per iteration (ms): 619.2 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.946004E+00 | loss scale: 1048576.0 | grad norm: 0.509 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2463.14, 2463.18)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 453000 | lm loss value: 3.697906E+00 | lm loss PPL: 4.036271E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-27 09:57:26] iteration   453100/  500000 | consumed samples:     28998400 | elapsed time per iteration (ms): 618.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.955932E+00 | loss scale: 1048576.0 | grad norm: 0.516 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 09:58:28] iteration   453200/  500000 | consumed samples:     29004800 | elapsed time per iteration (ms): 618.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.951494E+00 | loss scale: 1048576.0 | grad norm: 0.507 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 09:59:30] iteration   453300/  500000 | consumed samples:     29011200 | elapsed time per iteration (ms): 618.4 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.954888E+00 | loss scale: 1048576.0 | grad norm: 0.510 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 10:00:32] iteration   453400/  500000 | consumed samples:     29017600 | elapsed time per iteration (ms): 617.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.951331E+00 | loss scale: 1048576.0 | grad norm: 0.507 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 10:01:34] iteration   453500/  500000 | consumed samples:     29024000 | elapsed time per iteration (ms): 619.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.954578E+00 | loss scale: 1048576.0 | grad norm: 0.512 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-27 10:02:35] iteration   453600/  500000 | consumed samples:     29030400 | elapsed time per iteration (ms): 619.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.941544E+00 | loss scale: 1048576.0 | grad norm: 0.508 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 10:03:37] iteration   453700/  500000 | consumed samples:     29036800 | elapsed time per iteration (ms): 619.4 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.949213E+00 | loss scale: 1048576.0 | grad norm: 0.520 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 10:04:39] iteration   453800/  500000 | consumed samples:     29043200 | elapsed time per iteration (ms): 619.4 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.957044E+00 | loss scale: 1048576.0 | grad norm: 0.521 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 10:05:41] iteration   453900/  500000 | consumed samples:     29049600 | elapsed time per iteration (ms): 618.6 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.959824E+00 | loss scale: 1048576.0 | grad norm: 0.504 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 10:06:43] iteration   454000/  500000 | consumed samples:     29056000 | elapsed time per iteration (ms): 619.1 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.942889E+00 | loss scale: 1048576.0 | grad norm: 0.506 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2461.15, 2461.27)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 454000 | lm loss value: 3.743976E+00 | lm loss PPL: 4.226570E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-27 10:07:47] iteration   454100/  500000 | consumed samples:     29062400 | elapsed time per iteration (ms): 617.4 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.963931E+00 | loss scale: 1048576.0 | grad norm: 0.506 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 10:08:49] iteration   454200/  500000 | consumed samples:     29068800 | elapsed time per iteration (ms): 619.7 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.956550E+00 | loss scale: 1048576.0 | grad norm: 0.512 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 10:09:51] iteration   454300/  500000 | consumed samples:     29075200 | elapsed time per iteration (ms): 617.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.960634E+00 | loss scale: 1048576.0 | grad norm: 0.510 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 10:10:53] iteration   454400/  500000 | consumed samples:     29081600 | elapsed time per iteration (ms): 618.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.959903E+00 | loss scale: 1048576.0 | grad norm: 0.510 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 10:11:55] iteration   454500/  500000 | consumed samples:     29088000 | elapsed time per iteration (ms): 617.4 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.946623E+00 | loss scale: 2097152.0 | grad norm: 0.523 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 10:12:57] iteration   454600/  500000 | consumed samples:     29094400 | elapsed time per iteration (ms): 621.1 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.948937E+00 | loss scale: 1048576.0 | grad norm: 0.513 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-27 10:13:59] iteration   454700/  500000 | consumed samples:     29100800 | elapsed time per iteration (ms): 619.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.955728E+00 | loss scale: 1048576.0 | grad norm: 0.505 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 10:15:01] iteration   454800/  500000 | consumed samples:     29107200 | elapsed time per iteration (ms): 620.1 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.954858E+00 | loss scale: 1048576.0 | grad norm: 0.521 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 10:16:02] iteration   454900/  500000 | consumed samples:     29113600 | elapsed time per iteration (ms): 618.2 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.948616E+00 | loss scale: 1048576.0 | grad norm: 0.509 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 10:17:04] iteration   455000/  500000 | consumed samples:     29120000 | elapsed time per iteration (ms): 619.5 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.941905E+00 | loss scale: 1048576.0 | grad norm: 0.507 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2463.34, 2463.35)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 455000 | lm loss value: 3.734986E+00 | lm loss PPL: 4.188743E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-27 10:18:09] iteration   455100/  500000 | consumed samples:     29126400 | elapsed time per iteration (ms): 620.6 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.959931E+00 | loss scale: 1048576.0 | grad norm: 0.525 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 10:19:11] iteration   455200/  500000 | consumed samples:     29132800 | elapsed time per iteration (ms): 621.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.953986E+00 | loss scale: 1048576.0 | grad norm: 0.507 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 10:20:13] iteration   455300/  500000 | consumed samples:     29139200 | elapsed time per iteration (ms): 619.1 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.973419E+00 | loss scale: 1048576.0 | grad norm: 0.502 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 10:21:15] iteration   455400/  500000 | consumed samples:     29145600 | elapsed time per iteration (ms): 620.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.940654E+00 | loss scale: 1048576.0 | grad norm: 0.502 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 10:22:17] iteration   455500/  500000 | consumed samples:     29152000 | elapsed time per iteration (ms): 620.1 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.954374E+00 | loss scale: 1048576.0 | grad norm: 0.517 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 10:23:19] iteration   455600/  500000 | consumed samples:     29158400 | elapsed time per iteration (ms): 621.5 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.960266E+00 | loss scale: 1048576.0 | grad norm: 0.498 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-27 10:24:21] iteration   455700/  500000 | consumed samples:     29164800 | elapsed time per iteration (ms): 618.7 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.954344E+00 | loss scale: 1048576.0 | grad norm: 0.523 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 10:25:23] iteration   455800/  500000 | consumed samples:     29171200 | elapsed time per iteration (ms): 618.4 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.948078E+00 | loss scale: 1048576.0 | grad norm: 0.518 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 10:26:25] iteration   455900/  500000 | consumed samples:     29177600 | elapsed time per iteration (ms): 618.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.951003E+00 | loss scale: 1048576.0 | grad norm: 0.505 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 10:27:27] iteration   456000/  500000 | consumed samples:     29184000 | elapsed time per iteration (ms): 620.3 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.944107E+00 | loss scale: 1048576.0 | grad norm: 0.505 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2463.15, 2463.17)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 456000 | lm loss value: 3.760501E+00 | lm loss PPL: 4.296995E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-27 10:28:31] iteration   456100/  500000 | consumed samples:     29190400 | elapsed time per iteration (ms): 619.4 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.957140E+00 | loss scale: 1048576.0 | grad norm: 0.506 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 10:29:33] iteration   456200/  500000 | consumed samples:     29196800 | elapsed time per iteration (ms): 618.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.951899E+00 | loss scale: 1048576.0 | grad norm: 0.516 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 10:30:35] iteration   456300/  500000 | consumed samples:     29203200 | elapsed time per iteration (ms): 618.7 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.955534E+00 | loss scale: 1048576.0 | grad norm: 0.496 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 10:31:37] iteration   456400/  500000 | consumed samples:     29209600 | elapsed time per iteration (ms): 617.4 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.958544E+00 | loss scale: 1048576.0 | grad norm: 0.505 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 10:32:39] iteration   456500/  500000 | consumed samples:     29216000 | elapsed time per iteration (ms): 619.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.944651E+00 | loss scale: 1048576.0 | grad norm: 0.501 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 10:33:41] iteration   456600/  500000 | consumed samples:     29222400 | elapsed time per iteration (ms): 620.1 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.955120E+00 | loss scale: 2097152.0 | grad norm: 0.513 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 10:34:42] iteration   456700/  500000 | consumed samples:     29228800 | elapsed time per iteration (ms): 618.7 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.956772E+00 | loss scale: 1048576.0 | grad norm: 0.504 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-27 10:35:45] iteration   456800/  500000 | consumed samples:     29235200 | elapsed time per iteration (ms): 620.7 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.941266E+00 | loss scale: 1048576.0 | grad norm: 0.514 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 10:36:46] iteration   456900/  500000 | consumed samples:     29241600 | elapsed time per iteration (ms): 618.2 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.957096E+00 | loss scale: 1048576.0 | grad norm: 0.508 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 10:37:48] iteration   457000/  500000 | consumed samples:     29248000 | elapsed time per iteration (ms): 617.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.947012E+00 | loss scale: 1048576.0 | grad norm: 0.509 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2463.40, 2463.45)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 457000 | lm loss value: 3.723581E+00 | lm loss PPL: 4.141241E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-27 10:38:53] iteration   457100/  500000 | consumed samples:     29254400 | elapsed time per iteration (ms): 619.4 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.950078E+00 | loss scale: 1048576.0 | grad norm: 0.525 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 10:39:54] iteration   457200/  500000 | consumed samples:     29260800 | elapsed time per iteration (ms): 617.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.959786E+00 | loss scale: 1048576.0 | grad norm: 0.500 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 10:40:56] iteration   457300/  500000 | consumed samples:     29267200 | elapsed time per iteration (ms): 618.7 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.961272E+00 | loss scale: 1048576.0 | grad norm: 0.522 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 10:41:58] iteration   457400/  500000 | consumed samples:     29273600 | elapsed time per iteration (ms): 618.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.940667E+00 | loss scale: 1048576.0 | grad norm: 0.532 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 10:43:00] iteration   457500/  500000 | consumed samples:     29280000 | elapsed time per iteration (ms): 620.4 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.958721E+00 | loss scale: 1048576.0 | grad norm: 0.516 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 10:44:02] iteration   457600/  500000 | consumed samples:     29286400 | elapsed time per iteration (ms): 619.7 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.961789E+00 | loss scale: 1048576.0 | grad norm: 0.510 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 10:45:04] iteration   457700/  500000 | consumed samples:     29292800 | elapsed time per iteration (ms): 617.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.948881E+00 | loss scale: 1048576.0 | grad norm: 0.517 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-27 10:46:06] iteration   457800/  500000 | consumed samples:     29299200 | elapsed time per iteration (ms): 619.2 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.943552E+00 | loss scale: 1048576.0 | grad norm: 0.507 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 10:47:07] iteration   457900/  500000 | consumed samples:     29305600 | elapsed time per iteration (ms): 616.6 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.955339E+00 | loss scale: 1048576.0 | grad norm: 0.512 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 10:48:09] iteration   458000/  500000 | consumed samples:     29312000 | elapsed time per iteration (ms): 619.6 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.958683E+00 | loss scale: 1048576.0 | grad norm: 0.516 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2464.84, 2464.90)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 458000 | lm loss value: 3.717465E+00 | lm loss PPL: 4.115993E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-27 10:49:14] iteration   458100/  500000 | consumed samples:     29318400 | elapsed time per iteration (ms): 618.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.965822E+00 | loss scale: 1048576.0 | grad norm: 0.516 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 10:50:16] iteration   458200/  500000 | consumed samples:     29324800 | elapsed time per iteration (ms): 618.6 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.958246E+00 | loss scale: 1048576.0 | grad norm: 0.522 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 10:51:18] iteration   458300/  500000 | consumed samples:     29331200 | elapsed time per iteration (ms): 619.6 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.936005E+00 | loss scale: 1048576.0 | grad norm: 0.509 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 10:52:19] iteration   458400/  500000 | consumed samples:     29337600 | elapsed time per iteration (ms): 619.2 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.952697E+00 | loss scale: 1048576.0 | grad norm: 0.501 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 10:53:21] iteration   458500/  500000 | consumed samples:     29344000 | elapsed time per iteration (ms): 620.1 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.935998E+00 | loss scale: 1048576.0 | grad norm: 0.526 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 10:54:23] iteration   458600/  500000 | consumed samples:     29350400 | elapsed time per iteration (ms): 619.6 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.944559E+00 | loss scale: 1048576.0 | grad norm: 0.504 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 10:55:25] iteration   458700/  500000 | consumed samples:     29356800 | elapsed time per iteration (ms): 617.4 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.961834E+00 | loss scale: 2097152.0 | grad norm: 0.500 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-27 10:56:27] iteration   458800/  500000 | consumed samples:     29363200 | elapsed time per iteration (ms): 620.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.958753E+00 | loss scale: 1048576.0 | grad norm: 0.503 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-27 10:57:29] iteration   458900/  500000 | consumed samples:     29369600 | elapsed time per iteration (ms): 619.5 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.940912E+00 | loss scale: 1048576.0 | grad norm: 0.534 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 10:58:31] iteration   459000/  500000 | consumed samples:     29376000 | elapsed time per iteration (ms): 620.6 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.947161E+00 | loss scale: 1048576.0 | grad norm: 0.506 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2461.62, 2461.64)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 459000 | lm loss value: 3.742941E+00 | lm loss PPL: 4.222197E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-27 10:59:36] iteration   459100/  500000 | consumed samples:     29382400 | elapsed time per iteration (ms): 619.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.955456E+00 | loss scale: 1048576.0 | grad norm: 0.512 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 11:00:38] iteration   459200/  500000 | consumed samples:     29388800 | elapsed time per iteration (ms): 620.7 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.951846E+00 | loss scale: 1048576.0 | grad norm: 0.522 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 11:01:40] iteration   459300/  500000 | consumed samples:     29395200 | elapsed time per iteration (ms): 620.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.932136E+00 | loss scale: 1048576.0 | grad norm: 0.505 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 11:02:42] iteration   459400/  500000 | consumed samples:     29401600 | elapsed time per iteration (ms): 618.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.954555E+00 | loss scale: 1048576.0 | grad norm: 0.504 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 11:03:44] iteration   459500/  500000 | consumed samples:     29408000 | elapsed time per iteration (ms): 619.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.965186E+00 | loss scale: 1048576.0 | grad norm: 0.511 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 11:04:46] iteration   459600/  500000 | consumed samples:     29414400 | elapsed time per iteration (ms): 619.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.935854E+00 | loss scale: 1048576.0 | grad norm: 0.519 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 11:05:47] iteration   459700/  500000 | consumed samples:     29420800 | elapsed time per iteration (ms): 618.3 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.955720E+00 | loss scale: 1048576.0 | grad norm: 0.515 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 11:06:49] iteration   459800/  500000 | consumed samples:     29427200 | elapsed time per iteration (ms): 618.2 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.950999E+00 | loss scale: 2097152.0 | grad norm: 0.517 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-27 11:07:51] iteration   459900/  500000 | consumed samples:     29433600 | elapsed time per iteration (ms): 619.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.949161E+00 | loss scale: 1048576.0 | grad norm: 0.524 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-27 11:08:53] iteration   460000/  500000 | consumed samples:     29440000 | elapsed time per iteration (ms): 619.2 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.960860E+00 | loss scale: 1048576.0 | grad norm: 0.517 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2462.67, 2462.76)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 460000 | lm loss value: 3.788908E+00 | lm loss PPL: 4.420810E+01 | 
--------------------------------------------------------------------------------------------------
saving checkpoint at iteration  460000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-distribution in torch format
  successfully saved checkpoint at iteration  460000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-distribution
(min, max) time across ranks (ms):
    save-checkpoint ................................: (2321.90, 2321.92)
 [2024-06-27 11:10:00] iteration   460100/  500000 | consumed samples:     29446400 | elapsed time per iteration (ms): 619.7 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.952369E+00 | loss scale: 1048576.0 | grad norm: 0.526 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 11:11:02] iteration   460200/  500000 | consumed samples:     29452800 | elapsed time per iteration (ms): 620.4 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.951473E+00 | loss scale: 1048576.0 | grad norm: 0.507 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 11:12:04] iteration   460300/  500000 | consumed samples:     29459200 | elapsed time per iteration (ms): 618.5 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.965164E+00 | loss scale: 1048576.0 | grad norm: 0.520 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 11:13:06] iteration   460400/  500000 | consumed samples:     29465600 | elapsed time per iteration (ms): 619.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.944052E+00 | loss scale: 1048576.0 | grad norm: 0.518 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 11:14:08] iteration   460500/  500000 | consumed samples:     29472000 | elapsed time per iteration (ms): 620.3 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.956727E+00 | loss scale: 1048576.0 | grad norm: 0.519 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 11:15:10] iteration   460600/  500000 | consumed samples:     29478400 | elapsed time per iteration (ms): 620.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.939749E+00 | loss scale: 1048576.0 | grad norm: 0.518 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 11:16:12] iteration   460700/  500000 | consumed samples:     29484800 | elapsed time per iteration (ms): 618.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.952768E+00 | loss scale: 1048576.0 | grad norm: 0.520 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 11:17:14] iteration   460800/  500000 | consumed samples:     29491200 | elapsed time per iteration (ms): 618.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.963508E+00 | loss scale: 1048576.0 | grad norm: 0.533 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 11:18:16] iteration   460900/  500000 | consumed samples:     29497600 | elapsed time per iteration (ms): 620.1 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.960597E+00 | loss scale: 1048576.0 | grad norm: 0.514 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-27 11:19:17] iteration   461000/  500000 | consumed samples:     29504000 | elapsed time per iteration (ms): 619.3 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.949222E+00 | loss scale: 1048576.0 | grad norm: 0.514 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2462.51, 2462.55)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 461000 | lm loss value: 3.743029E+00 | lm loss PPL: 4.222568E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-27 11:20:22] iteration   461100/  500000 | consumed samples:     29510400 | elapsed time per iteration (ms): 618.4 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.943627E+00 | loss scale: 1048576.0 | grad norm: 0.512 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 11:21:24] iteration   461200/  500000 | consumed samples:     29516800 | elapsed time per iteration (ms): 619.7 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.957861E+00 | loss scale: 1048576.0 | grad norm: 0.511 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 11:22:26] iteration   461300/  500000 | consumed samples:     29523200 | elapsed time per iteration (ms): 619.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.950221E+00 | loss scale: 1048576.0 | grad norm: 0.519 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 11:23:28] iteration   461400/  500000 | consumed samples:     29529600 | elapsed time per iteration (ms): 619.7 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.951735E+00 | loss scale: 1048576.0 | grad norm: 0.517 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 11:24:29] iteration   461500/  500000 | consumed samples:     29536000 | elapsed time per iteration (ms): 618.6 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.953970E+00 | loss scale: 1048576.0 | grad norm: 0.505 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 11:25:31] iteration   461600/  500000 | consumed samples:     29542400 | elapsed time per iteration (ms): 618.6 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.960739E+00 | loss scale: 1048576.0 | grad norm: 0.504 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 11:26:33] iteration   461700/  500000 | consumed samples:     29548800 | elapsed time per iteration (ms): 619.1 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.950851E+00 | loss scale: 1048576.0 | grad norm: 0.514 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 11:27:35] iteration   461800/  500000 | consumed samples:     29555200 | elapsed time per iteration (ms): 619.5 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.940265E+00 | loss scale: 1048576.0 | grad norm: 0.502 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 11:28:37] iteration   461900/  500000 | consumed samples:     29561600 | elapsed time per iteration (ms): 620.2 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.955754E+00 | loss scale: 1048576.0 | grad norm: 0.520 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-27 11:29:39] iteration   462000/  500000 | consumed samples:     29568000 | elapsed time per iteration (ms): 620.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.960778E+00 | loss scale: 1048576.0 | grad norm: 0.521 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2463.49, 2463.57)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 462000 | lm loss value: 3.757311E+00 | lm loss PPL: 4.283311E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-27 11:30:44] iteration   462100/  500000 | consumed samples:     29574400 | elapsed time per iteration (ms): 618.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.956943E+00 | loss scale: 1048576.0 | grad norm: 0.496 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 11:31:46] iteration   462200/  500000 | consumed samples:     29580800 | elapsed time per iteration (ms): 619.3 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.942705E+00 | loss scale: 524288.0 | grad norm: 0.532 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-27 11:32:47] iteration   462300/  500000 | consumed samples:     29587200 | elapsed time per iteration (ms): 619.6 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.946963E+00 | loss scale: 524288.0 | grad norm: 0.513 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 11:33:49] iteration   462400/  500000 | consumed samples:     29593600 | elapsed time per iteration (ms): 619.6 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.959671E+00 | loss scale: 524288.0 | grad norm: 0.532 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 11:34:51] iteration   462500/  500000 | consumed samples:     29600000 | elapsed time per iteration (ms): 618.4 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.945059E+00 | loss scale: 524288.0 | grad norm: 0.509 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 11:35:53] iteration   462600/  500000 | consumed samples:     29606400 | elapsed time per iteration (ms): 618.6 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.954703E+00 | loss scale: 524288.0 | grad norm: 0.519 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 11:36:55] iteration   462700/  500000 | consumed samples:     29612800 | elapsed time per iteration (ms): 617.7 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.955770E+00 | loss scale: 524288.0 | grad norm: 0.531 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 11:37:57] iteration   462800/  500000 | consumed samples:     29619200 | elapsed time per iteration (ms): 617.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.944775E+00 | loss scale: 524288.0 | grad norm: 0.513 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 11:38:58] iteration   462900/  500000 | consumed samples:     29625600 | elapsed time per iteration (ms): 617.5 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.949669E+00 | loss scale: 524288.0 | grad norm: 0.509 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 11:40:00] iteration   463000/  500000 | consumed samples:     29632000 | elapsed time per iteration (ms): 618.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.943737E+00 | loss scale: 524288.0 | grad norm: 0.520 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2465.85, 2466.07)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 463000 | lm loss value: 3.757563E+00 | lm loss PPL: 4.284389E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-27 11:41:05] iteration   463100/  500000 | consumed samples:     29638400 | elapsed time per iteration (ms): 619.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.958882E+00 | loss scale: 524288.0 | grad norm: 0.525 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 11:42:07] iteration   463200/  500000 | consumed samples:     29644800 | elapsed time per iteration (ms): 617.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.948589E+00 | loss scale: 1048576.0 | grad norm: 0.525 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 11:43:09] iteration   463300/  500000 | consumed samples:     29651200 | elapsed time per iteration (ms): 620.6 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.946080E+00 | loss scale: 1048576.0 | grad norm: 0.517 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 11:44:10] iteration   463400/  500000 | consumed samples:     29657600 | elapsed time per iteration (ms): 618.6 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.954268E+00 | loss scale: 1048576.0 | grad norm: 0.499 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 11:45:12] iteration   463500/  500000 | consumed samples:     29664000 | elapsed time per iteration (ms): 620.1 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.946713E+00 | loss scale: 1048576.0 | grad norm: 0.529 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 11:46:14] iteration   463600/  500000 | consumed samples:     29670400 | elapsed time per iteration (ms): 618.3 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.948850E+00 | loss scale: 1048576.0 | grad norm: 0.519 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 11:47:17] iteration   463700/  500000 | consumed samples:     29676800 | elapsed time per iteration (ms): 621.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.942122E+00 | loss scale: 1048576.0 | grad norm: 0.509 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 11:48:19] iteration   463800/  500000 | consumed samples:     29683200 | elapsed time per iteration (ms): 622.1 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.944724E+00 | loss scale: 1048576.0 | grad norm: 0.522 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 11:49:21] iteration   463900/  500000 | consumed samples:     29689600 | elapsed time per iteration (ms): 619.3 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.951682E+00 | loss scale: 1048576.0 | grad norm: 0.525 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 11:50:22] iteration   464000/  500000 | consumed samples:     29696000 | elapsed time per iteration (ms): 617.5 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.966604E+00 | loss scale: 1048576.0 | grad norm: 0.503 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2462.67, 2462.73)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 464000 | lm loss value: 3.724993E+00 | lm loss PPL: 4.147095E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-27 11:51:27] iteration   464100/  500000 | consumed samples:     29702400 | elapsed time per iteration (ms): 617.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.939420E+00 | loss scale: 1048576.0 | grad norm: 0.514 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 11:52:28] iteration   464200/  500000 | consumed samples:     29708800 | elapsed time per iteration (ms): 618.3 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.953697E+00 | loss scale: 2097152.0 | grad norm: 0.517 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-27 11:53:30] iteration   464300/  500000 | consumed samples:     29715200 | elapsed time per iteration (ms): 617.4 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.956038E+00 | loss scale: 1048576.0 | grad norm: 0.496 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-27 11:54:32] iteration   464400/  500000 | consumed samples:     29721600 | elapsed time per iteration (ms): 618.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.946483E+00 | loss scale: 1048576.0 | grad norm: 0.515 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 11:55:34] iteration   464500/  500000 | consumed samples:     29728000 | elapsed time per iteration (ms): 619.6 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.956642E+00 | loss scale: 1048576.0 | grad norm: 0.511 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 11:56:36] iteration   464600/  500000 | consumed samples:     29734400 | elapsed time per iteration (ms): 619.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.940886E+00 | loss scale: 1048576.0 | grad norm: 0.524 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 11:57:38] iteration   464700/  500000 | consumed samples:     29740800 | elapsed time per iteration (ms): 618.5 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.964890E+00 | loss scale: 1048576.0 | grad norm: 0.514 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 11:58:40] iteration   464800/  500000 | consumed samples:     29747200 | elapsed time per iteration (ms): 621.1 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.969227E+00 | loss scale: 1048576.0 | grad norm: 0.507 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 11:59:42] iteration   464900/  500000 | consumed samples:     29753600 | elapsed time per iteration (ms): 619.4 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.958249E+00 | loss scale: 1048576.0 | grad norm: 0.501 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 12:00:44] iteration   465000/  500000 | consumed samples:     29760000 | elapsed time per iteration (ms): 621.2 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.952166E+00 | loss scale: 1048576.0 | grad norm: 0.519 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2462.38, 2462.44)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 465000 | lm loss value: 3.725954E+00 | lm loss PPL: 4.151082E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-27 12:01:48] iteration   465100/  500000 | consumed samples:     29766400 | elapsed time per iteration (ms): 618.1 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.941179E+00 | loss scale: 1048576.0 | grad norm: 0.515 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 12:02:50] iteration   465200/  500000 | consumed samples:     29772800 | elapsed time per iteration (ms): 619.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.962184E+00 | loss scale: 1048576.0 | grad norm: 0.510 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 12:03:52] iteration   465300/  500000 | consumed samples:     29779200 | elapsed time per iteration (ms): 620.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.943315E+00 | loss scale: 1048576.0 | grad norm: 0.494 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-27 12:04:54] iteration   465400/  500000 | consumed samples:     29785600 | elapsed time per iteration (ms): 619.3 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.943561E+00 | loss scale: 1048576.0 | grad norm: 0.509 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 12:05:56] iteration   465500/  500000 | consumed samples:     29792000 | elapsed time per iteration (ms): 619.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.958349E+00 | loss scale: 1048576.0 | grad norm: 0.512 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 12:06:58] iteration   465600/  500000 | consumed samples:     29798400 | elapsed time per iteration (ms): 617.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.944538E+00 | loss scale: 1048576.0 | grad norm: 0.512 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 12:08:00] iteration   465700/  500000 | consumed samples:     29804800 | elapsed time per iteration (ms): 617.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.936699E+00 | loss scale: 1048576.0 | grad norm: 0.508 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 12:09:01] iteration   465800/  500000 | consumed samples:     29811200 | elapsed time per iteration (ms): 617.1 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.960166E+00 | loss scale: 524288.0 | grad norm: 0.521 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-27 12:10:03] iteration   465900/  500000 | consumed samples:     29817600 | elapsed time per iteration (ms): 620.6 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.936794E+00 | loss scale: 524288.0 | grad norm: 0.517 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 12:11:05] iteration   466000/  500000 | consumed samples:     29824000 | elapsed time per iteration (ms): 619.3 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.972433E+00 | loss scale: 524288.0 | grad norm: 0.501 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2462.07, 2462.21)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 466000 | lm loss value: 3.728623E+00 | lm loss PPL: 4.162175E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-27 12:12:10] iteration   466100/  500000 | consumed samples:     29830400 | elapsed time per iteration (ms): 619.4 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.966773E+00 | loss scale: 524288.0 | grad norm: 0.496 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 12:13:12] iteration   466200/  500000 | consumed samples:     29836800 | elapsed time per iteration (ms): 619.5 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.956136E+00 | loss scale: 524288.0 | grad norm: 0.496 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 12:14:14] iteration   466300/  500000 | consumed samples:     29843200 | elapsed time per iteration (ms): 620.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.955269E+00 | loss scale: 524288.0 | grad norm: 0.513 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 12:15:16] iteration   466400/  500000 | consumed samples:     29849600 | elapsed time per iteration (ms): 618.2 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.966555E+00 | loss scale: 524288.0 | grad norm: 0.507 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 12:16:17] iteration   466500/  500000 | consumed samples:     29856000 | elapsed time per iteration (ms): 618.3 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.957920E+00 | loss scale: 524288.0 | grad norm: 0.514 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 12:17:19] iteration   466600/  500000 | consumed samples:     29862400 | elapsed time per iteration (ms): 620.1 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.934527E+00 | loss scale: 524288.0 | grad norm: 0.513 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 12:18:21] iteration   466700/  500000 | consumed samples:     29868800 | elapsed time per iteration (ms): 620.2 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.965750E+00 | loss scale: 524288.0 | grad norm: 0.516 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 12:19:23] iteration   466800/  500000 | consumed samples:     29875200 | elapsed time per iteration (ms): 620.1 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.931956E+00 | loss scale: 1048576.0 | grad norm: 0.516 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 12:20:25] iteration   466900/  500000 | consumed samples:     29881600 | elapsed time per iteration (ms): 617.4 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.937727E+00 | loss scale: 1048576.0 | grad norm: 0.515 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 12:21:27] iteration   467000/  500000 | consumed samples:     29888000 | elapsed time per iteration (ms): 619.7 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.967164E+00 | loss scale: 1048576.0 | grad norm: 0.510 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2463.57, 2463.65)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 467000 | lm loss value: 3.710608E+00 | lm loss PPL: 4.087863E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-27 12:22:31] iteration   467100/  500000 | consumed samples:     29894400 | elapsed time per iteration (ms): 616.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.950917E+00 | loss scale: 1048576.0 | grad norm: 0.530 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 12:23:33] iteration   467200/  500000 | consumed samples:     29900800 | elapsed time per iteration (ms): 618.3 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.945923E+00 | loss scale: 1048576.0 | grad norm: 0.521 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 12:24:35] iteration   467300/  500000 | consumed samples:     29907200 | elapsed time per iteration (ms): 618.7 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.954402E+00 | loss scale: 1048576.0 | grad norm: 0.511 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 12:25:37] iteration   467400/  500000 | consumed samples:     29913600 | elapsed time per iteration (ms): 620.5 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.956544E+00 | loss scale: 1048576.0 | grad norm: 0.508 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 12:26:39] iteration   467500/  500000 | consumed samples:     29920000 | elapsed time per iteration (ms): 619.3 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.939624E+00 | loss scale: 1048576.0 | grad norm: 0.508 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 12:27:41] iteration   467600/  500000 | consumed samples:     29926400 | elapsed time per iteration (ms): 618.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.952367E+00 | loss scale: 1048576.0 | grad norm: 0.529 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 12:28:42] iteration   467700/  500000 | consumed samples:     29932800 | elapsed time per iteration (ms): 616.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.952096E+00 | loss scale: 1048576.0 | grad norm: 0.514 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 12:29:44] iteration   467800/  500000 | consumed samples:     29939200 | elapsed time per iteration (ms): 619.3 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.945792E+00 | loss scale: 2097152.0 | grad norm: 0.514 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-27 12:30:46] iteration   467900/  500000 | consumed samples:     29945600 | elapsed time per iteration (ms): 616.3 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.946322E+00 | loss scale: 1048576.0 | grad norm: 0.519 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-27 12:31:48] iteration   468000/  500000 | consumed samples:     29952000 | elapsed time per iteration (ms): 619.1 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.945801E+00 | loss scale: 1048576.0 | grad norm: 0.527 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2463.17, 2463.24)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 468000 | lm loss value: 3.713030E+00 | lm loss PPL: 4.097777E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-27 12:32:52] iteration   468100/  500000 | consumed samples:     29958400 | elapsed time per iteration (ms): 618.1 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.937906E+00 | loss scale: 1048576.0 | grad norm: 0.500 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 12:33:54] iteration   468200/  500000 | consumed samples:     29964800 | elapsed time per iteration (ms): 620.1 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.968381E+00 | loss scale: 1048576.0 | grad norm: 0.505 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 12:34:56] iteration   468300/  500000 | consumed samples:     29971200 | elapsed time per iteration (ms): 619.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.955625E+00 | loss scale: 1048576.0 | grad norm: 0.519 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 12:35:58] iteration   468400/  500000 | consumed samples:     29977600 | elapsed time per iteration (ms): 619.6 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.948709E+00 | loss scale: 1048576.0 | grad norm: 0.505 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 12:37:00] iteration   468500/  500000 | consumed samples:     29984000 | elapsed time per iteration (ms): 620.2 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.935247E+00 | loss scale: 1048576.0 | grad norm: 0.504 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 12:38:02] iteration   468600/  500000 | consumed samples:     29990400 | elapsed time per iteration (ms): 620.5 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.948475E+00 | loss scale: 1048576.0 | grad norm: 0.521 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 12:39:04] iteration   468700/  500000 | consumed samples:     29996800 | elapsed time per iteration (ms): 617.2 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.953727E+00 | loss scale: 1048576.0 | grad norm: 0.515 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 12:40:06] iteration   468800/  500000 | consumed samples:     30003200 | elapsed time per iteration (ms): 618.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.950924E+00 | loss scale: 1048576.0 | grad norm: 0.510 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 12:41:08] iteration   468900/  500000 | consumed samples:     30009600 | elapsed time per iteration (ms): 619.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.950950E+00 | loss scale: 1048576.0 | grad norm: 0.511 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-27 12:42:10] iteration   469000/  500000 | consumed samples:     30016000 | elapsed time per iteration (ms): 619.1 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.951702E+00 | loss scale: 1048576.0 | grad norm: 0.517 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2461.85, 2461.93)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 469000 | lm loss value: 3.737222E+00 | lm loss PPL: 4.198122E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-27 12:43:14] iteration   469100/  500000 | consumed samples:     30022400 | elapsed time per iteration (ms): 620.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.954682E+00 | loss scale: 1048576.0 | grad norm: 0.514 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 12:44:16] iteration   469200/  500000 | consumed samples:     30028800 | elapsed time per iteration (ms): 618.1 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.960064E+00 | loss scale: 1048576.0 | grad norm: 0.515 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 12:45:18] iteration   469300/  500000 | consumed samples:     30035200 | elapsed time per iteration (ms): 620.1 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.962688E+00 | loss scale: 1048576.0 | grad norm: 0.508 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 12:46:20] iteration   469400/  500000 | consumed samples:     30041600 | elapsed time per iteration (ms): 617.4 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.934908E+00 | loss scale: 1048576.0 | grad norm: 0.512 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 12:47:21] iteration   469500/  500000 | consumed samples:     30048000 | elapsed time per iteration (ms): 617.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.954201E+00 | loss scale: 1048576.0 | grad norm: 0.492 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 12:48:23] iteration   469600/  500000 | consumed samples:     30054400 | elapsed time per iteration (ms): 620.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.960195E+00 | loss scale: 1048576.0 | grad norm: 0.513 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 12:49:25] iteration   469700/  500000 | consumed samples:     30060800 | elapsed time per iteration (ms): 619.4 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.958350E+00 | loss scale: 1048576.0 | grad norm: 0.516 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 12:50:27] iteration   469800/  500000 | consumed samples:     30067200 | elapsed time per iteration (ms): 619.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.948345E+00 | loss scale: 1048576.0 | grad norm: 0.504 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 12:51:29] iteration   469900/  500000 | consumed samples:     30073600 | elapsed time per iteration (ms): 619.7 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.960819E+00 | loss scale: 2097152.0 | grad norm: 0.518 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 12:52:31] iteration   470000/  500000 | consumed samples:     30080000 | elapsed time per iteration (ms): 619.5 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.949714E+00 | loss scale: 2097152.0 | grad norm: 0.514 | number of skipped iterations:   1 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2461.28, 2461.29)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 470000 | lm loss value: 3.741797E+00 | lm loss PPL: 4.217372E+01 | 
--------------------------------------------------------------------------------------------------
saving checkpoint at iteration  470000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-distribution in torch format
  successfully saved checkpoint at iteration  470000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-distribution
(min, max) time across ranks (ms):
    save-checkpoint ................................: (2282.24, 2282.26)
 [2024-06-27 12:53:38] iteration   470100/  500000 | consumed samples:     30086400 | elapsed time per iteration (ms): 620.7 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.945489E+00 | loss scale: 1048576.0 | grad norm: 0.500 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-27 12:54:40] iteration   470200/  500000 | consumed samples:     30092800 | elapsed time per iteration (ms): 618.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.963242E+00 | loss scale: 1048576.0 | grad norm: 0.508 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 12:55:42] iteration   470300/  500000 | consumed samples:     30099200 | elapsed time per iteration (ms): 619.4 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.954745E+00 | loss scale: 1048576.0 | grad norm: 0.501 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 12:56:44] iteration   470400/  500000 | consumed samples:     30105600 | elapsed time per iteration (ms): 619.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.947516E+00 | loss scale: 1048576.0 | grad norm: 0.504 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 12:57:46] iteration   470500/  500000 | consumed samples:     30112000 | elapsed time per iteration (ms): 618.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.944416E+00 | loss scale: 1048576.0 | grad norm: 0.518 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 12:58:47] iteration   470600/  500000 | consumed samples:     30118400 | elapsed time per iteration (ms): 618.1 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.940281E+00 | loss scale: 1048576.0 | grad norm: 0.518 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 12:59:49] iteration   470700/  500000 | consumed samples:     30124800 | elapsed time per iteration (ms): 618.4 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.948207E+00 | loss scale: 1048576.0 | grad norm: 0.520 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 13:00:51] iteration   470800/  500000 | consumed samples:     30131200 | elapsed time per iteration (ms): 618.4 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.954293E+00 | loss scale: 1048576.0 | grad norm: 0.504 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 13:01:53] iteration   470900/  500000 | consumed samples:     30137600 | elapsed time per iteration (ms): 620.4 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.950500E+00 | loss scale: 1048576.0 | grad norm: 0.518 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 13:02:55] iteration   471000/  500000 | consumed samples:     30144000 | elapsed time per iteration (ms): 619.6 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.960654E+00 | loss scale: 1048576.0 | grad norm: 0.531 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2460.16, 2460.28)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 471000 | lm loss value: 3.711499E+00 | lm loss PPL: 4.091511E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-27 13:04:00] iteration   471100/  500000 | consumed samples:     30150400 | elapsed time per iteration (ms): 620.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.945337E+00 | loss scale: 2097152.0 | grad norm: 0.514 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-27 13:05:02] iteration   471200/  500000 | consumed samples:     30156800 | elapsed time per iteration (ms): 620.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.939313E+00 | loss scale: 1048576.0 | grad norm: 0.510 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-27 13:06:04] iteration   471300/  500000 | consumed samples:     30163200 | elapsed time per iteration (ms): 620.6 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.960582E+00 | loss scale: 1048576.0 | grad norm: 0.514 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 13:07:06] iteration   471400/  500000 | consumed samples:     30169600 | elapsed time per iteration (ms): 618.6 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.943356E+00 | loss scale: 1048576.0 | grad norm: 0.522 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 13:08:08] iteration   471500/  500000 | consumed samples:     30176000 | elapsed time per iteration (ms): 619.6 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.953713E+00 | loss scale: 1048576.0 | grad norm: 0.513 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 13:09:10] iteration   471600/  500000 | consumed samples:     30182400 | elapsed time per iteration (ms): 621.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.953708E+00 | loss scale: 1048576.0 | grad norm: 0.497 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 13:10:12] iteration   471700/  500000 | consumed samples:     30188800 | elapsed time per iteration (ms): 620.1 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.936497E+00 | loss scale: 1048576.0 | grad norm: 0.516 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 13:11:14] iteration   471800/  500000 | consumed samples:     30195200 | elapsed time per iteration (ms): 617.4 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.945651E+00 | loss scale: 524288.0 | grad norm: 0.513 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-27 13:12:15] iteration   471900/  500000 | consumed samples:     30201600 | elapsed time per iteration (ms): 618.2 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.962205E+00 | loss scale: 524288.0 | grad norm: 0.520 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 13:13:17] iteration   472000/  500000 | consumed samples:     30208000 | elapsed time per iteration (ms): 618.7 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.948755E+00 | loss scale: 524288.0 | grad norm: 0.514 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2461.96, 2462.38)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 472000 | lm loss value: 3.786525E+00 | lm loss PPL: 4.410290E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-27 13:14:21] iteration   472100/  500000 | consumed samples:     30214400 | elapsed time per iteration (ms): 617.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.948731E+00 | loss scale: 524288.0 | grad norm: 0.521 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 13:15:23] iteration   472200/  500000 | consumed samples:     30220800 | elapsed time per iteration (ms): 617.4 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.960198E+00 | loss scale: 524288.0 | grad norm: 0.528 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 13:16:25] iteration   472300/  500000 | consumed samples:     30227200 | elapsed time per iteration (ms): 618.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.950172E+00 | loss scale: 524288.0 | grad norm: 0.504 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 13:17:27] iteration   472400/  500000 | consumed samples:     30233600 | elapsed time per iteration (ms): 618.2 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.951877E+00 | loss scale: 524288.0 | grad norm: 0.515 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 13:18:29] iteration   472500/  500000 | consumed samples:     30240000 | elapsed time per iteration (ms): 617.7 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.952122E+00 | loss scale: 524288.0 | grad norm: 0.514 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 13:19:30] iteration   472600/  500000 | consumed samples:     30246400 | elapsed time per iteration (ms): 619.5 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.963484E+00 | loss scale: 524288.0 | grad norm: 0.499 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 13:20:32] iteration   472700/  500000 | consumed samples:     30252800 | elapsed time per iteration (ms): 617.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.956343E+00 | loss scale: 524288.0 | grad norm: 0.509 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 13:21:34] iteration   472800/  500000 | consumed samples:     30259200 | elapsed time per iteration (ms): 617.4 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.946522E+00 | loss scale: 1048576.0 | grad norm: 0.500 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 13:22:36] iteration   472900/  500000 | consumed samples:     30265600 | elapsed time per iteration (ms): 620.3 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.957097E+00 | loss scale: 1048576.0 | grad norm: 0.519 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 13:23:38] iteration   473000/  500000 | consumed samples:     30272000 | elapsed time per iteration (ms): 619.1 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.949367E+00 | loss scale: 1048576.0 | grad norm: 0.512 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2462.74, 2462.85)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 473000 | lm loss value: 3.739365E+00 | lm loss PPL: 4.207127E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-27 13:24:42] iteration   473100/  500000 | consumed samples:     30278400 | elapsed time per iteration (ms): 619.2 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.974501E+00 | loss scale: 1048576.0 | grad norm: 0.502 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 13:25:44] iteration   473200/  500000 | consumed samples:     30284800 | elapsed time per iteration (ms): 618.5 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.952817E+00 | loss scale: 1048576.0 | grad norm: 0.514 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 13:26:46] iteration   473300/  500000 | consumed samples:     30291200 | elapsed time per iteration (ms): 621.4 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.964601E+00 | loss scale: 1048576.0 | grad norm: 0.515 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 13:27:48] iteration   473400/  500000 | consumed samples:     30297600 | elapsed time per iteration (ms): 617.3 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.959220E+00 | loss scale: 1048576.0 | grad norm: 0.506 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 13:28:50] iteration   473500/  500000 | consumed samples:     30304000 | elapsed time per iteration (ms): 619.4 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.955214E+00 | loss scale: 1048576.0 | grad norm: 0.520 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 13:29:52] iteration   473600/  500000 | consumed samples:     30310400 | elapsed time per iteration (ms): 619.6 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.951975E+00 | loss scale: 1048576.0 | grad norm: 0.516 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 13:30:54] iteration   473700/  500000 | consumed samples:     30316800 | elapsed time per iteration (ms): 619.3 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.946369E+00 | loss scale: 1048576.0 | grad norm: 0.513 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 13:31:56] iteration   473800/  500000 | consumed samples:     30323200 | elapsed time per iteration (ms): 619.3 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.947227E+00 | loss scale: 1048576.0 | grad norm: 0.521 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-27 13:32:58] iteration   473900/  500000 | consumed samples:     30329600 | elapsed time per iteration (ms): 621.1 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.965567E+00 | loss scale: 1048576.0 | grad norm: 0.505 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 13:34:00] iteration   474000/  500000 | consumed samples:     30336000 | elapsed time per iteration (ms): 619.6 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.945370E+00 | loss scale: 1048576.0 | grad norm: 0.518 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2462.90, 2462.96)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 474000 | lm loss value: 3.723465E+00 | lm loss PPL: 4.140761E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-27 13:35:04] iteration   474100/  500000 | consumed samples:     30342400 | elapsed time per iteration (ms): 619.5 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.949696E+00 | loss scale: 1048576.0 | grad norm: 0.524 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 13:36:06] iteration   474200/  500000 | consumed samples:     30348800 | elapsed time per iteration (ms): 619.5 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.942134E+00 | loss scale: 1048576.0 | grad norm: 0.509 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 13:37:08] iteration   474300/  500000 | consumed samples:     30355200 | elapsed time per iteration (ms): 619.5 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.953491E+00 | loss scale: 1048576.0 | grad norm: 0.506 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 13:38:10] iteration   474400/  500000 | consumed samples:     30361600 | elapsed time per iteration (ms): 619.1 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.944640E+00 | loss scale: 1048576.0 | grad norm: 0.499 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 13:39:12] iteration   474500/  500000 | consumed samples:     30368000 | elapsed time per iteration (ms): 620.6 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.952416E+00 | loss scale: 1048576.0 | grad norm: 0.500 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 13:40:14] iteration   474600/  500000 | consumed samples:     30374400 | elapsed time per iteration (ms): 618.7 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.935598E+00 | loss scale: 1048576.0 | grad norm: 0.510 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 13:41:16] iteration   474700/  500000 | consumed samples:     30380800 | elapsed time per iteration (ms): 619.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.950968E+00 | loss scale: 1048576.0 | grad norm: 0.517 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 13:42:18] iteration   474800/  500000 | consumed samples:     30387200 | elapsed time per iteration (ms): 617.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.953365E+00 | loss scale: 2097152.0 | grad norm: 0.534 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 13:43:20] iteration   474900/  500000 | consumed samples:     30393600 | elapsed time per iteration (ms): 618.1 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.947979E+00 | loss scale: 2097152.0 | grad norm: 0.525 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-27 13:44:21] iteration   475000/  500000 | consumed samples:     30400000 | elapsed time per iteration (ms): 617.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.957092E+00 | loss scale: 1048576.0 | grad norm: 0.516 | number of skipped iterations:   1 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2461.12, 2461.28)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 475000 | lm loss value: 3.759976E+00 | lm loss PPL: 4.294740E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-27 13:45:26] iteration   475100/  500000 | consumed samples:     30406400 | elapsed time per iteration (ms): 618.6 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.949325E+00 | loss scale: 1048576.0 | grad norm: 0.515 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 13:46:28] iteration   475200/  500000 | consumed samples:     30412800 | elapsed time per iteration (ms): 620.5 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.941524E+00 | loss scale: 1048576.0 | grad norm: 0.512 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 13:47:29] iteration   475300/  500000 | consumed samples:     30419200 | elapsed time per iteration (ms): 618.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.951104E+00 | loss scale: 1048576.0 | grad norm: 0.503 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 13:48:31] iteration   475400/  500000 | consumed samples:     30425600 | elapsed time per iteration (ms): 617.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.936305E+00 | loss scale: 1048576.0 | grad norm: 0.517 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 13:49:33] iteration   475500/  500000 | consumed samples:     30432000 | elapsed time per iteration (ms): 618.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.962416E+00 | loss scale: 1048576.0 | grad norm: 0.504 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 13:50:35] iteration   475600/  500000 | consumed samples:     30438400 | elapsed time per iteration (ms): 619.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.954641E+00 | loss scale: 1048576.0 | grad norm: 0.518 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 13:51:37] iteration   475700/  500000 | consumed samples:     30444800 | elapsed time per iteration (ms): 619.3 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.962820E+00 | loss scale: 1048576.0 | grad norm: 0.516 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 13:52:39] iteration   475800/  500000 | consumed samples:     30451200 | elapsed time per iteration (ms): 619.7 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.949150E+00 | loss scale: 1048576.0 | grad norm: 0.515 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 13:53:41] iteration   475900/  500000 | consumed samples:     30457600 | elapsed time per iteration (ms): 618.2 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.958635E+00 | loss scale: 1048576.0 | grad norm: 0.514 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 13:54:43] iteration   476000/  500000 | consumed samples:     30464000 | elapsed time per iteration (ms): 618.4 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.955500E+00 | loss scale: 1048576.0 | grad norm: 0.512 | number of skipped iterations:   2 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2463.70, 2463.88)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 476000 | lm loss value: 3.753221E+00 | lm loss PPL: 4.265825E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-27 13:55:47] iteration   476100/  500000 | consumed samples:     30470400 | elapsed time per iteration (ms): 618.5 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.931683E+00 | loss scale: 1048576.0 | grad norm: 0.516 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 13:56:49] iteration   476200/  500000 | consumed samples:     30476800 | elapsed time per iteration (ms): 619.2 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.946678E+00 | loss scale: 1048576.0 | grad norm: 0.518 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 13:57:51] iteration   476300/  500000 | consumed samples:     30483200 | elapsed time per iteration (ms): 619.3 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.967239E+00 | loss scale: 1048576.0 | grad norm: 0.531 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 13:58:53] iteration   476400/  500000 | consumed samples:     30489600 | elapsed time per iteration (ms): 620.4 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.948651E+00 | loss scale: 1048576.0 | grad norm: 0.519 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 13:59:55] iteration   476500/  500000 | consumed samples:     30496000 | elapsed time per iteration (ms): 618.7 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.959631E+00 | loss scale: 1048576.0 | grad norm: 0.516 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 14:00:57] iteration   476600/  500000 | consumed samples:     30502400 | elapsed time per iteration (ms): 621.4 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.963654E+00 | loss scale: 1048576.0 | grad norm: 0.519 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 14:01:59] iteration   476700/  500000 | consumed samples:     30508800 | elapsed time per iteration (ms): 620.3 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.949153E+00 | loss scale: 1048576.0 | grad norm: 0.530 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 14:03:01] iteration   476800/  500000 | consumed samples:     30515200 | elapsed time per iteration (ms): 618.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.944837E+00 | loss scale: 1048576.0 | grad norm: 0.515 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 14:04:03] iteration   476900/  500000 | consumed samples:     30521600 | elapsed time per iteration (ms): 618.7 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.942841E+00 | loss scale: 1048576.0 | grad norm: 0.531 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 14:05:04] iteration   477000/  500000 | consumed samples:     30528000 | elapsed time per iteration (ms): 618.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.966438E+00 | loss scale: 1048576.0 | grad norm: 0.504 | number of skipped iterations:   2 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2461.70, 2461.75)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 477000 | lm loss value: 3.746073E+00 | lm loss PPL: 4.235441E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-27 14:06:09] iteration   477100/  500000 | consumed samples:     30534400 | elapsed time per iteration (ms): 616.7 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.943672E+00 | loss scale: 1048576.0 | grad norm: 0.511 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 14:07:10] iteration   477200/  500000 | consumed samples:     30540800 | elapsed time per iteration (ms): 619.3 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.936234E+00 | loss scale: 1048576.0 | grad norm: 0.519 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 14:08:12] iteration   477300/  500000 | consumed samples:     30547200 | elapsed time per iteration (ms): 619.2 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.950222E+00 | loss scale: 524288.0 | grad norm: 0.510 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-27 14:09:14] iteration   477400/  500000 | consumed samples:     30553600 | elapsed time per iteration (ms): 619.3 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.962027E+00 | loss scale: 524288.0 | grad norm: 0.514 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 14:10:16] iteration   477500/  500000 | consumed samples:     30560000 | elapsed time per iteration (ms): 620.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.940722E+00 | loss scale: 524288.0 | grad norm: 0.520 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 14:11:18] iteration   477600/  500000 | consumed samples:     30566400 | elapsed time per iteration (ms): 621.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.950190E+00 | loss scale: 524288.0 | grad norm: 0.515 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 14:12:20] iteration   477700/  500000 | consumed samples:     30572800 | elapsed time per iteration (ms): 618.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.949173E+00 | loss scale: 524288.0 | grad norm: 0.508 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 14:13:22] iteration   477800/  500000 | consumed samples:     30579200 | elapsed time per iteration (ms): 619.7 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.951082E+00 | loss scale: 524288.0 | grad norm: 0.523 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 14:14:24] iteration   477900/  500000 | consumed samples:     30585600 | elapsed time per iteration (ms): 618.5 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.947137E+00 | loss scale: 524288.0 | grad norm: 0.520 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 14:15:26] iteration   478000/  500000 | consumed samples:     30592000 | elapsed time per iteration (ms): 619.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.942072E+00 | loss scale: 524288.0 | grad norm: 0.516 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2462.73, 2462.83)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 478000 | lm loss value: 3.753768E+00 | lm loss PPL: 4.268161E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-27 14:16:30] iteration   478100/  500000 | consumed samples:     30598400 | elapsed time per iteration (ms): 619.5 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.964984E+00 | loss scale: 524288.0 | grad norm: 0.517 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 14:17:32] iteration   478200/  500000 | consumed samples:     30604800 | elapsed time per iteration (ms): 619.7 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.956734E+00 | loss scale: 524288.0 | grad norm: 0.513 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 14:18:34] iteration   478300/  500000 | consumed samples:     30611200 | elapsed time per iteration (ms): 620.1 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.963440E+00 | loss scale: 1048576.0 | grad norm: 0.515 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 14:19:36] iteration   478400/  500000 | consumed samples:     30617600 | elapsed time per iteration (ms): 617.6 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.955403E+00 | loss scale: 1048576.0 | grad norm: 0.508 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 14:20:38] iteration   478500/  500000 | consumed samples:     30624000 | elapsed time per iteration (ms): 619.4 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.951070E+00 | loss scale: 1048576.0 | grad norm: 0.515 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 14:21:40] iteration   478600/  500000 | consumed samples:     30630400 | elapsed time per iteration (ms): 616.6 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.958559E+00 | loss scale: 1048576.0 | grad norm: 0.518 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 14:22:41] iteration   478700/  500000 | consumed samples:     30636800 | elapsed time per iteration (ms): 615.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.957345E+00 | loss scale: 1048576.0 | grad norm: 0.513 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 14:23:43] iteration   478800/  500000 | consumed samples:     30643200 | elapsed time per iteration (ms): 616.6 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.953743E+00 | loss scale: 1048576.0 | grad norm: 0.521 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 14:24:45] iteration   478900/  500000 | consumed samples:     30649600 | elapsed time per iteration (ms): 619.6 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.934807E+00 | loss scale: 1048576.0 | grad norm: 0.512 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-27 14:25:47] iteration   479000/  500000 | consumed samples:     30656000 | elapsed time per iteration (ms): 619.6 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.953174E+00 | loss scale: 1048576.0 | grad norm: 0.521 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2460.84, 2460.93)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 479000 | lm loss value: 3.716047E+00 | lm loss PPL: 4.110160E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-27 14:26:51] iteration   479100/  500000 | consumed samples:     30662400 | elapsed time per iteration (ms): 616.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.955959E+00 | loss scale: 1048576.0 | grad norm: 0.503 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 14:27:53] iteration   479200/  500000 | consumed samples:     30668800 | elapsed time per iteration (ms): 618.5 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.977646E+00 | loss scale: 524288.0 | grad norm: 0.507 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-27 14:28:55] iteration   479300/  500000 | consumed samples:     30675200 | elapsed time per iteration (ms): 617.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.952895E+00 | loss scale: 524288.0 | grad norm: 0.527 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 14:29:56] iteration   479400/  500000 | consumed samples:     30681600 | elapsed time per iteration (ms): 618.1 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.954886E+00 | loss scale: 524288.0 | grad norm: 0.511 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 14:30:58] iteration   479500/  500000 | consumed samples:     30688000 | elapsed time per iteration (ms): 618.5 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.940883E+00 | loss scale: 524288.0 | grad norm: 0.500 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 14:32:00] iteration   479600/  500000 | consumed samples:     30694400 | elapsed time per iteration (ms): 619.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.939472E+00 | loss scale: 524288.0 | grad norm: 0.510 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 14:33:02] iteration   479700/  500000 | consumed samples:     30700800 | elapsed time per iteration (ms): 618.3 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.959267E+00 | loss scale: 524288.0 | grad norm: 0.526 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 14:34:04] iteration   479800/  500000 | consumed samples:     30707200 | elapsed time per iteration (ms): 617.4 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.944453E+00 | loss scale: 524288.0 | grad norm: 0.524 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 14:35:06] iteration   479900/  500000 | consumed samples:     30713600 | elapsed time per iteration (ms): 621.4 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.964283E+00 | loss scale: 524288.0 | grad norm: 0.538 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 14:36:08] iteration   480000/  500000 | consumed samples:     30720000 | elapsed time per iteration (ms): 617.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.941437E+00 | loss scale: 524288.0 | grad norm: 0.534 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2461.42, 2461.45)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 480000 | lm loss value: 3.728772E+00 | lm loss PPL: 4.162795E+01 | 
--------------------------------------------------------------------------------------------------
saving checkpoint at iteration  480000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-distribution in torch format
  successfully saved checkpoint at iteration  480000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-distribution
(min, max) time across ranks (ms):
    save-checkpoint ................................: (2346.93, 2346.94)
 [2024-06-27 14:37:14] iteration   480100/  500000 | consumed samples:     30726400 | elapsed time per iteration (ms): 618.1 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.947554E+00 | loss scale: 524288.0 | grad norm: 0.550 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 14:38:16] iteration   480200/  500000 | consumed samples:     30732800 | elapsed time per iteration (ms): 617.2 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.953915E+00 | loss scale: 1048576.0 | grad norm: 0.520 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 14:39:18] iteration   480300/  500000 | consumed samples:     30739200 | elapsed time per iteration (ms): 620.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.939200E+00 | loss scale: 1048576.0 | grad norm: 0.513 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 14:40:20] iteration   480400/  500000 | consumed samples:     30745600 | elapsed time per iteration (ms): 620.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.941300E+00 | loss scale: 1048576.0 | grad norm: 0.516 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 14:41:22] iteration   480500/  500000 | consumed samples:     30752000 | elapsed time per iteration (ms): 622.6 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.968437E+00 | loss scale: 1048576.0 | grad norm: 0.529 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 14:42:24] iteration   480600/  500000 | consumed samples:     30758400 | elapsed time per iteration (ms): 619.6 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.947432E+00 | loss scale: 1048576.0 | grad norm: 0.500 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 14:43:26] iteration   480700/  500000 | consumed samples:     30764800 | elapsed time per iteration (ms): 618.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.959243E+00 | loss scale: 1048576.0 | grad norm: 0.521 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 14:44:28] iteration   480800/  500000 | consumed samples:     30771200 | elapsed time per iteration (ms): 619.5 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.951991E+00 | loss scale: 1048576.0 | grad norm: 0.508 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 14:45:30] iteration   480900/  500000 | consumed samples:     30777600 | elapsed time per iteration (ms): 618.6 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.945741E+00 | loss scale: 1048576.0 | grad norm: 0.519 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 14:46:32] iteration   481000/  500000 | consumed samples:     30784000 | elapsed time per iteration (ms): 618.5 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.948875E+00 | loss scale: 1048576.0 | grad norm: 0.524 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2460.93, 2460.94)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 481000 | lm loss value: 3.722977E+00 | lm loss PPL: 4.138741E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-27 14:47:36] iteration   481100/  500000 | consumed samples:     30790400 | elapsed time per iteration (ms): 619.1 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.951172E+00 | loss scale: 1048576.0 | grad norm: 0.518 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 14:48:38] iteration   481200/  500000 | consumed samples:     30796800 | elapsed time per iteration (ms): 618.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.961066E+00 | loss scale: 2097152.0 | grad norm: 0.507 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 14:49:40] iteration   481300/  500000 | consumed samples:     30803200 | elapsed time per iteration (ms): 618.5 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.949293E+00 | loss scale: 1048576.0 | grad norm: 0.519 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-27 14:50:42] iteration   481400/  500000 | consumed samples:     30809600 | elapsed time per iteration (ms): 619.7 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.960893E+00 | loss scale: 1048576.0 | grad norm: 0.516 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 14:51:44] iteration   481500/  500000 | consumed samples:     30816000 | elapsed time per iteration (ms): 620.7 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.962367E+00 | loss scale: 1048576.0 | grad norm: 0.501 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 14:52:46] iteration   481600/  500000 | consumed samples:     30822400 | elapsed time per iteration (ms): 620.6 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.942795E+00 | loss scale: 1048576.0 | grad norm: 0.517 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 14:53:48] iteration   481700/  500000 | consumed samples:     30828800 | elapsed time per iteration (ms): 618.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.954397E+00 | loss scale: 1048576.0 | grad norm: 0.521 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 14:54:50] iteration   481800/  500000 | consumed samples:     30835200 | elapsed time per iteration (ms): 619.6 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.951672E+00 | loss scale: 1048576.0 | grad norm: 0.515 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 14:55:52] iteration   481900/  500000 | consumed samples:     30841600 | elapsed time per iteration (ms): 618.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.955797E+00 | loss scale: 1048576.0 | grad norm: 0.515 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 14:56:53] iteration   482000/  500000 | consumed samples:     30848000 | elapsed time per iteration (ms): 617.4 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.953481E+00 | loss scale: 1048576.0 | grad norm: 0.512 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2463.58, 2463.72)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 482000 | lm loss value: 3.729693E+00 | lm loss PPL: 4.166631E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-27 14:57:58] iteration   482100/  500000 | consumed samples:     30854400 | elapsed time per iteration (ms): 620.1 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.949823E+00 | loss scale: 1048576.0 | grad norm: 0.523 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 14:59:00] iteration   482200/  500000 | consumed samples:     30860800 | elapsed time per iteration (ms): 617.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.946261E+00 | loss scale: 1048576.0 | grad norm: 0.513 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 15:00:02] iteration   482300/  500000 | consumed samples:     30867200 | elapsed time per iteration (ms): 620.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.954785E+00 | loss scale: 1048576.0 | grad norm: 0.498 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-27 15:01:04] iteration   482400/  500000 | consumed samples:     30873600 | elapsed time per iteration (ms): 618.7 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.952911E+00 | loss scale: 1048576.0 | grad norm: 0.515 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 15:02:06] iteration   482500/  500000 | consumed samples:     30880000 | elapsed time per iteration (ms): 619.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.938658E+00 | loss scale: 1048576.0 | grad norm: 0.506 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 15:03:08] iteration   482600/  500000 | consumed samples:     30886400 | elapsed time per iteration (ms): 620.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.958749E+00 | loss scale: 1048576.0 | grad norm: 0.537 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 15:04:09] iteration   482700/  500000 | consumed samples:     30892800 | elapsed time per iteration (ms): 619.1 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.947998E+00 | loss scale: 1048576.0 | grad norm: 0.511 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 15:05:11] iteration   482800/  500000 | consumed samples:     30899200 | elapsed time per iteration (ms): 620.1 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.949619E+00 | loss scale: 1048576.0 | grad norm: 0.513 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 15:06:13] iteration   482900/  500000 | consumed samples:     30905600 | elapsed time per iteration (ms): 619.6 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.948625E+00 | loss scale: 1048576.0 | grad norm: 0.508 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 15:07:15] iteration   483000/  500000 | consumed samples:     30912000 | elapsed time per iteration (ms): 618.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.938271E+00 | loss scale: 1048576.0 | grad norm: 0.523 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2460.88, 2460.97)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 483000 | lm loss value: 3.748421E+00 | lm loss PPL: 4.245400E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-27 15:08:20] iteration   483100/  500000 | consumed samples:     30918400 | elapsed time per iteration (ms): 619.4 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.939778E+00 | loss scale: 1048576.0 | grad norm: 0.510 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 15:09:22] iteration   483200/  500000 | consumed samples:     30924800 | elapsed time per iteration (ms): 621.1 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.965671E+00 | loss scale: 1048576.0 | grad norm: 0.512 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 15:10:24] iteration   483300/  500000 | consumed samples:     30931200 | elapsed time per iteration (ms): 619.1 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.939555E+00 | loss scale: 1048576.0 | grad norm: 0.508 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-27 15:11:26] iteration   483400/  500000 | consumed samples:     30937600 | elapsed time per iteration (ms): 620.1 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.937321E+00 | loss scale: 1048576.0 | grad norm: 0.522 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 15:12:28] iteration   483500/  500000 | consumed samples:     30944000 | elapsed time per iteration (ms): 621.2 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.953574E+00 | loss scale: 1048576.0 | grad norm: 0.521 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 15:13:30] iteration   483600/  500000 | consumed samples:     30950400 | elapsed time per iteration (ms): 619.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.942614E+00 | loss scale: 1048576.0 | grad norm: 0.537 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 15:14:31] iteration   483700/  500000 | consumed samples:     30956800 | elapsed time per iteration (ms): 616.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.945444E+00 | loss scale: 1048576.0 | grad norm: 0.512 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 15:15:33] iteration   483800/  500000 | consumed samples:     30963200 | elapsed time per iteration (ms): 619.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.952408E+00 | loss scale: 1048576.0 | grad norm: 0.518 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 15:16:35] iteration   483900/  500000 | consumed samples:     30969600 | elapsed time per iteration (ms): 620.4 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.957419E+00 | loss scale: 1048576.0 | grad norm: 0.525 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 15:17:37] iteration   484000/  500000 | consumed samples:     30976000 | elapsed time per iteration (ms): 620.7 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.939003E+00 | loss scale: 1048576.0 | grad norm: 0.522 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2462.41, 2462.54)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 484000 | lm loss value: 3.780524E+00 | lm loss PPL: 4.383903E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-27 15:18:42] iteration   484100/  500000 | consumed samples:     30982400 | elapsed time per iteration (ms): 618.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.955565E+00 | loss scale: 1048576.0 | grad norm: 0.515 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 15:19:44] iteration   484200/  500000 | consumed samples:     30988800 | elapsed time per iteration (ms): 621.1 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.941502E+00 | loss scale: 1048576.0 | grad norm: 0.510 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 15:20:46] iteration   484300/  500000 | consumed samples:     30995200 | elapsed time per iteration (ms): 617.6 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.956060E+00 | loss scale: 2097152.0 | grad norm: 0.506 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 15:21:48] iteration   484400/  500000 | consumed samples:     31001600 | elapsed time per iteration (ms): 618.6 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.948253E+00 | loss scale: 2097152.0 | grad norm: 0.504 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-27 15:22:50] iteration   484500/  500000 | consumed samples:     31008000 | elapsed time per iteration (ms): 619.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.972025E+00 | loss scale: 1048576.0 | grad norm: 0.530 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-27 15:23:52] iteration   484600/  500000 | consumed samples:     31014400 | elapsed time per iteration (ms): 620.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.952540E+00 | loss scale: 1048576.0 | grad norm: 0.502 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 15:24:53] iteration   484700/  500000 | consumed samples:     31020800 | elapsed time per iteration (ms): 618.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.950734E+00 | loss scale: 1048576.0 | grad norm: 0.506 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 15:25:55] iteration   484800/  500000 | consumed samples:     31027200 | elapsed time per iteration (ms): 618.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.950130E+00 | loss scale: 1048576.0 | grad norm: 0.530 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 15:26:57] iteration   484900/  500000 | consumed samples:     31033600 | elapsed time per iteration (ms): 618.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.948930E+00 | loss scale: 1048576.0 | grad norm: 0.524 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 15:27:59] iteration   485000/  500000 | consumed samples:     31040000 | elapsed time per iteration (ms): 619.4 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.955221E+00 | loss scale: 1048576.0 | grad norm: 0.513 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2463.31, 2463.40)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 485000 | lm loss value: 3.742367E+00 | lm loss PPL: 4.219774E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-27 15:29:03] iteration   485100/  500000 | consumed samples:     31046400 | elapsed time per iteration (ms): 617.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.964339E+00 | loss scale: 1048576.0 | grad norm: 0.510 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 15:30:05] iteration   485200/  500000 | consumed samples:     31052800 | elapsed time per iteration (ms): 618.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.957304E+00 | loss scale: 1048576.0 | grad norm: 0.526 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 15:31:07] iteration   485300/  500000 | consumed samples:     31059200 | elapsed time per iteration (ms): 620.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.945046E+00 | loss scale: 1048576.0 | grad norm: 0.543 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 15:32:09] iteration   485400/  500000 | consumed samples:     31065600 | elapsed time per iteration (ms): 617.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.949247E+00 | loss scale: 1048576.0 | grad norm: 0.521 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 15:33:11] iteration   485500/  500000 | consumed samples:     31072000 | elapsed time per iteration (ms): 618.5 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.952347E+00 | loss scale: 1048576.0 | grad norm: 0.526 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-27 15:34:13] iteration   485600/  500000 | consumed samples:     31078400 | elapsed time per iteration (ms): 618.1 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.955640E+00 | loss scale: 1048576.0 | grad norm: 0.515 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 15:35:15] iteration   485700/  500000 | consumed samples:     31084800 | elapsed time per iteration (ms): 619.1 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.942357E+00 | loss scale: 1048576.0 | grad norm: 0.508 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 15:36:17] iteration   485800/  500000 | consumed samples:     31091200 | elapsed time per iteration (ms): 620.1 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.955333E+00 | loss scale: 1048576.0 | grad norm: 0.505 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 15:37:19] iteration   485900/  500000 | consumed samples:     31097600 | elapsed time per iteration (ms): 619.3 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.969025E+00 | loss scale: 1048576.0 | grad norm: 0.514 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 15:38:20] iteration   486000/  500000 | consumed samples:     31104000 | elapsed time per iteration (ms): 617.5 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.952586E+00 | loss scale: 1048576.0 | grad norm: 0.521 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2460.97, 2461.04)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 486000 | lm loss value: 3.732630E+00 | lm loss PPL: 4.178888E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-27 15:39:25] iteration   486100/  500000 | consumed samples:     31110400 | elapsed time per iteration (ms): 618.3 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.947331E+00 | loss scale: 1048576.0 | grad norm: 0.511 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 15:40:27] iteration   486200/  500000 | consumed samples:     31116800 | elapsed time per iteration (ms): 619.5 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.952600E+00 | loss scale: 1048576.0 | grad norm: 0.516 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 15:41:28] iteration   486300/  500000 | consumed samples:     31123200 | elapsed time per iteration (ms): 619.2 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.948094E+00 | loss scale: 1048576.0 | grad norm: 0.526 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 15:42:30] iteration   486400/  500000 | consumed samples:     31129600 | elapsed time per iteration (ms): 618.3 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.960820E+00 | loss scale: 1048576.0 | grad norm: 0.523 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 15:43:32] iteration   486500/  500000 | consumed samples:     31136000 | elapsed time per iteration (ms): 616.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.941536E+00 | loss scale: 2097152.0 | grad norm: 0.509 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-27 15:44:34] iteration   486600/  500000 | consumed samples:     31142400 | elapsed time per iteration (ms): 619.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.932342E+00 | loss scale: 1048576.0 | grad norm: 0.507 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-27 15:45:36] iteration   486700/  500000 | consumed samples:     31148800 | elapsed time per iteration (ms): 617.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.945103E+00 | loss scale: 1048576.0 | grad norm: 0.506 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 15:46:38] iteration   486800/  500000 | consumed samples:     31155200 | elapsed time per iteration (ms): 619.4 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.953432E+00 | loss scale: 1048576.0 | grad norm: 0.512 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 15:47:39] iteration   486900/  500000 | consumed samples:     31161600 | elapsed time per iteration (ms): 618.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.938971E+00 | loss scale: 1048576.0 | grad norm: 0.531 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 15:48:41] iteration   487000/  500000 | consumed samples:     31168000 | elapsed time per iteration (ms): 617.5 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.946813E+00 | loss scale: 1048576.0 | grad norm: 0.527 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2461.19, 2461.22)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 487000 | lm loss value: 3.766289E+00 | lm loss PPL: 4.321940E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-27 15:49:46] iteration   487100/  500000 | consumed samples:     31174400 | elapsed time per iteration (ms): 618.6 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.945435E+00 | loss scale: 1048576.0 | grad norm: 0.507 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 15:50:48] iteration   487200/  500000 | consumed samples:     31180800 | elapsed time per iteration (ms): 620.7 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.955699E+00 | loss scale: 1048576.0 | grad norm: 0.513 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 15:51:49] iteration   487300/  500000 | consumed samples:     31187200 | elapsed time per iteration (ms): 618.6 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.952915E+00 | loss scale: 1048576.0 | grad norm: 0.527 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 15:52:51] iteration   487400/  500000 | consumed samples:     31193600 | elapsed time per iteration (ms): 618.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.949359E+00 | loss scale: 1048576.0 | grad norm: 0.506 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 15:53:53] iteration   487500/  500000 | consumed samples:     31200000 | elapsed time per iteration (ms): 617.2 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.955757E+00 | loss scale: 1048576.0 | grad norm: 0.510 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 15:54:55] iteration   487600/  500000 | consumed samples:     31206400 | elapsed time per iteration (ms): 617.5 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.970696E+00 | loss scale: 2097152.0 | grad norm: 0.530 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-27 15:55:57] iteration   487700/  500000 | consumed samples:     31212800 | elapsed time per iteration (ms): 618.1 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.939774E+00 | loss scale: 1048576.0 | grad norm: 0.520 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-27 15:56:58] iteration   487800/  500000 | consumed samples:     31219200 | elapsed time per iteration (ms): 617.6 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.954203E+00 | loss scale: 1048576.0 | grad norm: 0.503 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 15:58:00] iteration   487900/  500000 | consumed samples:     31225600 | elapsed time per iteration (ms): 617.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.953734E+00 | loss scale: 1048576.0 | grad norm: 0.504 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 15:59:02] iteration   488000/  500000 | consumed samples:     31232000 | elapsed time per iteration (ms): 618.6 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.931910E+00 | loss scale: 1048576.0 | grad norm: 0.507 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2464.36, 2464.38)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 488000 | lm loss value: 3.781113E+00 | lm loss PPL: 4.386482E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-27 16:00:06] iteration   488100/  500000 | consumed samples:     31238400 | elapsed time per iteration (ms): 618.3 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.957013E+00 | loss scale: 1048576.0 | grad norm: 0.528 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 16:01:08] iteration   488200/  500000 | consumed samples:     31244800 | elapsed time per iteration (ms): 618.1 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.947920E+00 | loss scale: 1048576.0 | grad norm: 0.523 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 16:02:10] iteration   488300/  500000 | consumed samples:     31251200 | elapsed time per iteration (ms): 618.3 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.946709E+00 | loss scale: 1048576.0 | grad norm: 0.528 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 16:03:12] iteration   488400/  500000 | consumed samples:     31257600 | elapsed time per iteration (ms): 619.6 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.965143E+00 | loss scale: 1048576.0 | grad norm: 0.526 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 16:04:14] iteration   488500/  500000 | consumed samples:     31264000 | elapsed time per iteration (ms): 619.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.946625E+00 | loss scale: 1048576.0 | grad norm: 0.511 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 16:05:16] iteration   488600/  500000 | consumed samples:     31270400 | elapsed time per iteration (ms): 621.6 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.952162E+00 | loss scale: 1048576.0 | grad norm: 0.508 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 16:06:18] iteration   488700/  500000 | consumed samples:     31276800 | elapsed time per iteration (ms): 618.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.959339E+00 | loss scale: 1048576.0 | grad norm: 0.515 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-27 16:07:20] iteration   488800/  500000 | consumed samples:     31283200 | elapsed time per iteration (ms): 618.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.952964E+00 | loss scale: 1048576.0 | grad norm: 0.524 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 16:08:22] iteration   488900/  500000 | consumed samples:     31289600 | elapsed time per iteration (ms): 618.4 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.951405E+00 | loss scale: 1048576.0 | grad norm: 0.532 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 16:09:24] iteration   489000/  500000 | consumed samples:     31296000 | elapsed time per iteration (ms): 619.2 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.953794E+00 | loss scale: 1048576.0 | grad norm: 0.521 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2462.68, 2462.68)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 489000 | lm loss value: 3.771978E+00 | lm loss PPL: 4.346597E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-27 16:10:28] iteration   489100/  500000 | consumed samples:     31302400 | elapsed time per iteration (ms): 617.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.958970E+00 | loss scale: 1048576.0 | grad norm: 0.510 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 16:11:30] iteration   489200/  500000 | consumed samples:     31308800 | elapsed time per iteration (ms): 618.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.943637E+00 | loss scale: 1048576.0 | grad norm: 0.508 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 16:12:32] iteration   489300/  500000 | consumed samples:     31315200 | elapsed time per iteration (ms): 620.6 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.959619E+00 | loss scale: 1048576.0 | grad norm: 0.524 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 16:13:34] iteration   489400/  500000 | consumed samples:     31321600 | elapsed time per iteration (ms): 619.4 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.947888E+00 | loss scale: 1048576.0 | grad norm: 0.506 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 16:14:36] iteration   489500/  500000 | consumed samples:     31328000 | elapsed time per iteration (ms): 618.6 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.944229E+00 | loss scale: 1048576.0 | grad norm: 0.528 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 16:15:38] iteration   489600/  500000 | consumed samples:     31334400 | elapsed time per iteration (ms): 619.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.940163E+00 | loss scale: 1048576.0 | grad norm: 0.526 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 16:16:39] iteration   489700/  500000 | consumed samples:     31340800 | elapsed time per iteration (ms): 617.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.952492E+00 | loss scale: 1048576.0 | grad norm: 0.518 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-27 16:17:41] iteration   489800/  500000 | consumed samples:     31347200 | elapsed time per iteration (ms): 619.7 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.943795E+00 | loss scale: 1048576.0 | grad norm: 0.525 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 16:18:43] iteration   489900/  500000 | consumed samples:     31353600 | elapsed time per iteration (ms): 621.3 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.950496E+00 | loss scale: 1048576.0 | grad norm: 0.508 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 16:19:45] iteration   490000/  500000 | consumed samples:     31360000 | elapsed time per iteration (ms): 620.7 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.950613E+00 | loss scale: 1048576.0 | grad norm: 0.508 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2461.32, 2461.38)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 490000 | lm loss value: 3.754118E+00 | lm loss PPL: 4.269653E+01 | 
--------------------------------------------------------------------------------------------------
saving checkpoint at iteration  490000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-distribution in torch format
  successfully saved checkpoint at iteration  490000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-distribution
(min, max) time across ranks (ms):
    save-checkpoint ................................: (2298.35, 2298.37)
 [2024-06-27 16:20:52] iteration   490100/  500000 | consumed samples:     31366400 | elapsed time per iteration (ms): 619.1 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.959953E+00 | loss scale: 1048576.0 | grad norm: 0.511 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 16:21:54] iteration   490200/  500000 | consumed samples:     31372800 | elapsed time per iteration (ms): 617.7 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.951375E+00 | loss scale: 1048576.0 | grad norm: 0.515 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 16:22:56] iteration   490300/  500000 | consumed samples:     31379200 | elapsed time per iteration (ms): 619.5 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.952496E+00 | loss scale: 1048576.0 | grad norm: 0.500 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 16:23:58] iteration   490400/  500000 | consumed samples:     31385600 | elapsed time per iteration (ms): 617.1 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.939700E+00 | loss scale: 1048576.0 | grad norm: 0.507 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 16:24:59] iteration   490500/  500000 | consumed samples:     31392000 | elapsed time per iteration (ms): 617.5 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.936869E+00 | loss scale: 1048576.0 | grad norm: 0.507 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 16:26:01] iteration   490600/  500000 | consumed samples:     31398400 | elapsed time per iteration (ms): 618.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.946005E+00 | loss scale: 1048576.0 | grad norm: 0.529 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 16:27:03] iteration   490700/  500000 | consumed samples:     31404800 | elapsed time per iteration (ms): 618.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.966804E+00 | loss scale: 2097152.0 | grad norm: 0.505 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-27 16:28:05] iteration   490800/  500000 | consumed samples:     31411200 | elapsed time per iteration (ms): 618.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.956313E+00 | loss scale: 1048576.0 | grad norm: 0.498 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-27 16:29:07] iteration   490900/  500000 | consumed samples:     31417600 | elapsed time per iteration (ms): 620.3 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.959237E+00 | loss scale: 1048576.0 | grad norm: 0.516 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 16:30:09] iteration   491000/  500000 | consumed samples:     31424000 | elapsed time per iteration (ms): 621.2 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.936368E+00 | loss scale: 1048576.0 | grad norm: 0.522 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2463.43, 2463.45)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 491000 | lm loss value: 3.727035E+00 | lm loss PPL: 4.155572E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-27 16:31:14] iteration   491100/  500000 | consumed samples:     31430400 | elapsed time per iteration (ms): 619.6 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.961155E+00 | loss scale: 1048576.0 | grad norm: 0.507 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 16:32:16] iteration   491200/  500000 | consumed samples:     31436800 | elapsed time per iteration (ms): 621.2 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.949110E+00 | loss scale: 1048576.0 | grad norm: 0.509 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 16:33:18] iteration   491300/  500000 | consumed samples:     31443200 | elapsed time per iteration (ms): 619.4 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.947894E+00 | loss scale: 1048576.0 | grad norm: 0.522 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 16:34:20] iteration   491400/  500000 | consumed samples:     31449600 | elapsed time per iteration (ms): 619.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.949637E+00 | loss scale: 1048576.0 | grad norm: 0.512 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 16:35:21] iteration   491500/  500000 | consumed samples:     31456000 | elapsed time per iteration (ms): 618.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.954032E+00 | loss scale: 1048576.0 | grad norm: 0.519 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 16:36:23] iteration   491600/  500000 | consumed samples:     31462400 | elapsed time per iteration (ms): 619.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.953709E+00 | loss scale: 1048576.0 | grad norm: 0.513 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 16:37:25] iteration   491700/  500000 | consumed samples:     31468800 | elapsed time per iteration (ms): 621.7 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.949138E+00 | loss scale: 1048576.0 | grad norm: 0.518 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 16:38:27] iteration   491800/  500000 | consumed samples:     31475200 | elapsed time per iteration (ms): 619.3 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.952336E+00 | loss scale: 1048576.0 | grad norm: 0.511 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-27 16:39:29] iteration   491900/  500000 | consumed samples:     31481600 | elapsed time per iteration (ms): 619.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.953911E+00 | loss scale: 1048576.0 | grad norm: 0.535 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 16:40:31] iteration   492000/  500000 | consumed samples:     31488000 | elapsed time per iteration (ms): 618.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.939534E+00 | loss scale: 1048576.0 | grad norm: 0.518 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2463.64, 2463.77)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 492000 | lm loss value: 3.722270E+00 | lm loss PPL: 4.135816E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-27 16:41:36] iteration   492100/  500000 | consumed samples:     31494400 | elapsed time per iteration (ms): 621.1 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.961606E+00 | loss scale: 1048576.0 | grad norm: 0.515 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 16:42:38] iteration   492200/  500000 | consumed samples:     31500800 | elapsed time per iteration (ms): 619.5 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.946489E+00 | loss scale: 1048576.0 | grad norm: 0.515 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 16:43:40] iteration   492300/  500000 | consumed samples:     31507200 | elapsed time per iteration (ms): 620.1 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.947234E+00 | loss scale: 1048576.0 | grad norm: 0.517 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 16:44:42] iteration   492400/  500000 | consumed samples:     31513600 | elapsed time per iteration (ms): 620.4 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.942737E+00 | loss scale: 1048576.0 | grad norm: 0.508 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 16:45:44] iteration   492500/  500000 | consumed samples:     31520000 | elapsed time per iteration (ms): 619.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.950366E+00 | loss scale: 1048576.0 | grad norm: 0.516 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 16:46:46] iteration   492600/  500000 | consumed samples:     31526400 | elapsed time per iteration (ms): 620.6 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.942030E+00 | loss scale: 1048576.0 | grad norm: 0.509 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 16:47:48] iteration   492700/  500000 | consumed samples:     31532800 | elapsed time per iteration (ms): 617.6 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.951669E+00 | loss scale: 1048576.0 | grad norm: 0.534 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 16:48:49] iteration   492800/  500000 | consumed samples:     31539200 | elapsed time per iteration (ms): 618.6 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.938142E+00 | loss scale: 2097152.0 | grad norm: 0.523 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-27 16:49:51] iteration   492900/  500000 | consumed samples:     31545600 | elapsed time per iteration (ms): 619.5 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.952474E+00 | loss scale: 1048576.0 | grad norm: 0.529 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-27 16:50:53] iteration   493000/  500000 | consumed samples:     31552000 | elapsed time per iteration (ms): 617.4 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.940134E+00 | loss scale: 1048576.0 | grad norm: 0.514 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2462.19, 2462.27)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 493000 | lm loss value: 3.702979E+00 | lm loss PPL: 4.056796E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-27 16:51:58] iteration   493100/  500000 | consumed samples:     31558400 | elapsed time per iteration (ms): 619.2 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.950249E+00 | loss scale: 1048576.0 | grad norm: 0.501 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 16:53:00] iteration   493200/  500000 | consumed samples:     31564800 | elapsed time per iteration (ms): 620.2 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.952855E+00 | loss scale: 1048576.0 | grad norm: 0.504 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 16:54:01] iteration   493300/  500000 | consumed samples:     31571200 | elapsed time per iteration (ms): 617.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.953665E+00 | loss scale: 1048576.0 | grad norm: 0.511 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 16:55:03] iteration   493400/  500000 | consumed samples:     31577600 | elapsed time per iteration (ms): 619.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.935575E+00 | loss scale: 1048576.0 | grad norm: 0.536 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 16:56:05] iteration   493500/  500000 | consumed samples:     31584000 | elapsed time per iteration (ms): 619.1 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.951301E+00 | loss scale: 1048576.0 | grad norm: 0.519 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 16:57:07] iteration   493600/  500000 | consumed samples:     31590400 | elapsed time per iteration (ms): 617.3 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.955418E+00 | loss scale: 1048576.0 | grad norm: 0.512 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 16:58:09] iteration   493700/  500000 | consumed samples:     31596800 | elapsed time per iteration (ms): 619.1 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.937388E+00 | loss scale: 1048576.0 | grad norm: 0.516 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 16:59:11] iteration   493800/  500000 | consumed samples:     31603200 | elapsed time per iteration (ms): 619.3 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.950916E+00 | loss scale: 1048576.0 | grad norm: 0.506 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 17:00:13] iteration   493900/  500000 | consumed samples:     31609600 | elapsed time per iteration (ms): 618.7 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.944645E+00 | loss scale: 1048576.0 | grad norm: 0.522 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-27 17:01:14] iteration   494000/  500000 | consumed samples:     31616000 | elapsed time per iteration (ms): 618.2 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.955829E+00 | loss scale: 1048576.0 | grad norm: 0.518 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2465.40, 2465.40)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 494000 | lm loss value: 3.780058E+00 | lm loss PPL: 4.381860E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-27 17:02:19] iteration   494100/  500000 | consumed samples:     31622400 | elapsed time per iteration (ms): 620.5 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.969204E+00 | loss scale: 1048576.0 | grad norm: 0.514 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 17:03:21] iteration   494200/  500000 | consumed samples:     31628800 | elapsed time per iteration (ms): 617.5 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.942946E+00 | loss scale: 1048576.0 | grad norm: 0.521 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 17:04:23] iteration   494300/  500000 | consumed samples:     31635200 | elapsed time per iteration (ms): 618.6 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.949088E+00 | loss scale: 1048576.0 | grad norm: 0.523 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 17:05:24] iteration   494400/  500000 | consumed samples:     31641600 | elapsed time per iteration (ms): 619.4 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.953240E+00 | loss scale: 1048576.0 | grad norm: 0.510 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 17:06:26] iteration   494500/  500000 | consumed samples:     31648000 | elapsed time per iteration (ms): 618.4 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.955374E+00 | loss scale: 1048576.0 | grad norm: 0.523 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 17:07:28] iteration   494600/  500000 | consumed samples:     31654400 | elapsed time per iteration (ms): 618.7 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.961112E+00 | loss scale: 1048576.0 | grad norm: 0.512 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 17:08:30] iteration   494700/  500000 | consumed samples:     31660800 | elapsed time per iteration (ms): 620.7 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.949378E+00 | loss scale: 1048576.0 | grad norm: 0.519 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 17:09:32] iteration   494800/  500000 | consumed samples:     31667200 | elapsed time per iteration (ms): 618.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.959364E+00 | loss scale: 1048576.0 | grad norm: 0.512 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 17:10:34] iteration   494900/  500000 | consumed samples:     31673600 | elapsed time per iteration (ms): 619.7 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.968228E+00 | loss scale: 2097152.0 | grad norm: 0.516 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-27 17:11:36] iteration   495000/  500000 | consumed samples:     31680000 | elapsed time per iteration (ms): 618.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.953873E+00 | loss scale: 1048576.0 | grad norm: 0.513 | number of skipped iterations:   1 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2461.29, 2461.32)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 495000 | lm loss value: 3.736512E+00 | lm loss PPL: 4.195143E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-27 17:12:40] iteration   495100/  500000 | consumed samples:     31686400 | elapsed time per iteration (ms): 618.7 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.949081E+00 | loss scale: 1048576.0 | grad norm: 0.518 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 17:13:42] iteration   495200/  500000 | consumed samples:     31692800 | elapsed time per iteration (ms): 619.4 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.947564E+00 | loss scale: 1048576.0 | grad norm: 0.512 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 17:14:44] iteration   495300/  500000 | consumed samples:     31699200 | elapsed time per iteration (ms): 619.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.958491E+00 | loss scale: 1048576.0 | grad norm: 0.515 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 17:15:46] iteration   495400/  500000 | consumed samples:     31705600 | elapsed time per iteration (ms): 620.1 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.948777E+00 | loss scale: 1048576.0 | grad norm: 0.521 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 17:16:48] iteration   495500/  500000 | consumed samples:     31712000 | elapsed time per iteration (ms): 621.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.945236E+00 | loss scale: 1048576.0 | grad norm: 0.505 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 17:17:50] iteration   495600/  500000 | consumed samples:     31718400 | elapsed time per iteration (ms): 618.1 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.944164E+00 | loss scale: 1048576.0 | grad norm: 0.521 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 17:18:52] iteration   495700/  500000 | consumed samples:     31724800 | elapsed time per iteration (ms): 618.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.940384E+00 | loss scale: 1048576.0 | grad norm: 0.528 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 17:19:54] iteration   495800/  500000 | consumed samples:     31731200 | elapsed time per iteration (ms): 621.1 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.953701E+00 | loss scale: 1048576.0 | grad norm: 0.502 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 17:20:56] iteration   495900/  500000 | consumed samples:     31737600 | elapsed time per iteration (ms): 620.4 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.951537E+00 | loss scale: 1048576.0 | grad norm: 0.521 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 17:21:58] iteration   496000/  500000 | consumed samples:     31744000 | elapsed time per iteration (ms): 619.4 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.956292E+00 | loss scale: 1048576.0 | grad norm: 0.504 | number of skipped iterations:   2 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2463.12, 2463.26)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 496000 | lm loss value: 3.739608E+00 | lm loss PPL: 4.208147E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-27 17:23:03] iteration   496100/  500000 | consumed samples:     31750400 | elapsed time per iteration (ms): 621.4 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.948131E+00 | loss scale: 1048576.0 | grad norm: 0.510 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 17:24:05] iteration   496200/  500000 | consumed samples:     31756800 | elapsed time per iteration (ms): 619.6 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.947031E+00 | loss scale: 1048576.0 | grad norm: 0.516 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 17:25:06] iteration   496300/  500000 | consumed samples:     31763200 | elapsed time per iteration (ms): 616.4 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.944926E+00 | loss scale: 1048576.0 | grad norm: 0.528 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 17:26:08] iteration   496400/  500000 | consumed samples:     31769600 | elapsed time per iteration (ms): 620.5 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.955416E+00 | loss scale: 1048576.0 | grad norm: 0.514 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 17:27:10] iteration   496500/  500000 | consumed samples:     31776000 | elapsed time per iteration (ms): 618.6 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.965599E+00 | loss scale: 1048576.0 | grad norm: 0.524 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 17:28:12] iteration   496600/  500000 | consumed samples:     31782400 | elapsed time per iteration (ms): 618.5 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.927785E+00 | loss scale: 1048576.0 | grad norm: 0.516 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 17:29:14] iteration   496700/  500000 | consumed samples:     31788800 | elapsed time per iteration (ms): 618.6 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.934440E+00 | loss scale: 1048576.0 | grad norm: 0.505 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 17:30:16] iteration   496800/  500000 | consumed samples:     31795200 | elapsed time per iteration (ms): 619.1 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.939225E+00 | loss scale: 1048576.0 | grad norm: 0.510 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 17:31:18] iteration   496900/  500000 | consumed samples:     31801600 | elapsed time per iteration (ms): 618.2 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.946446E+00 | loss scale: 1048576.0 | grad norm: 0.506 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 17:32:20] iteration   497000/  500000 | consumed samples:     31808000 | elapsed time per iteration (ms): 619.7 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.957528E+00 | loss scale: 1048576.0 | grad norm: 0.509 | number of skipped iterations:   2 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2462.15, 2462.25)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 497000 | lm loss value: 3.740684E+00 | lm loss PPL: 4.212681E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-27 17:33:24] iteration   497100/  500000 | consumed samples:     31814400 | elapsed time per iteration (ms): 618.6 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.942980E+00 | loss scale: 1048576.0 | grad norm: 0.518 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 17:34:26] iteration   497200/  500000 | consumed samples:     31820800 | elapsed time per iteration (ms): 618.7 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.933506E+00 | loss scale: 1048576.0 | grad norm: 0.515 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 17:35:28] iteration   497300/  500000 | consumed samples:     31827200 | elapsed time per iteration (ms): 618.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.955264E+00 | loss scale: 1048576.0 | grad norm: 0.509 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 17:36:30] iteration   497400/  500000 | consumed samples:     31833600 | elapsed time per iteration (ms): 618.7 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.957192E+00 | loss scale: 1048576.0 | grad norm: 0.516 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 17:37:32] iteration   497500/  500000 | consumed samples:     31840000 | elapsed time per iteration (ms): 620.4 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.945059E+00 | loss scale: 1048576.0 | grad norm: 0.503 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 17:38:34] iteration   497600/  500000 | consumed samples:     31846400 | elapsed time per iteration (ms): 620.7 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.960102E+00 | loss scale: 1048576.0 | grad norm: 0.515 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 17:39:36] iteration   497700/  500000 | consumed samples:     31852800 | elapsed time per iteration (ms): 619.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.954880E+00 | loss scale: 1048576.0 | grad norm: 0.513 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 17:40:38] iteration   497800/  500000 | consumed samples:     31859200 | elapsed time per iteration (ms): 620.4 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.957545E+00 | loss scale: 1048576.0 | grad norm: 0.521 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 17:41:40] iteration   497900/  500000 | consumed samples:     31865600 | elapsed time per iteration (ms): 619.2 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.954897E+00 | loss scale: 1048576.0 | grad norm: 0.508 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 17:42:42] iteration   498000/  500000 | consumed samples:     31872000 | elapsed time per iteration (ms): 619.3 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.946624E+00 | loss scale: 1048576.0 | grad norm: 0.516 | number of skipped iterations:   2 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2461.53, 2461.57)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 498000 | lm loss value: 3.761600E+00 | lm loss PPL: 4.301722E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-27 17:43:46] iteration   498100/  500000 | consumed samples:     31878400 | elapsed time per iteration (ms): 622.1 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.972736E+00 | loss scale: 1048576.0 | grad norm: 0.523 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 17:44:48] iteration   498200/  500000 | consumed samples:     31884800 | elapsed time per iteration (ms): 620.2 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.958022E+00 | loss scale: 1048576.0 | grad norm: 0.513 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 17:45:50] iteration   498300/  500000 | consumed samples:     31891200 | elapsed time per iteration (ms): 620.7 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.961361E+00 | loss scale: 1048576.0 | grad norm: 0.518 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 17:46:52] iteration   498400/  500000 | consumed samples:     31897600 | elapsed time per iteration (ms): 618.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.930204E+00 | loss scale: 1048576.0 | grad norm: 0.517 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 17:47:54] iteration   498500/  500000 | consumed samples:     31904000 | elapsed time per iteration (ms): 619.9 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.953356E+00 | loss scale: 1048576.0 | grad norm: 0.531 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 17:48:56] iteration   498600/  500000 | consumed samples:     31910400 | elapsed time per iteration (ms): 618.7 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.946684E+00 | loss scale: 1048576.0 | grad norm: 0.522 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 17:49:58] iteration   498700/  500000 | consumed samples:     31916800 | elapsed time per iteration (ms): 620.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.942278E+00 | loss scale: 1048576.0 | grad norm: 0.510 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 17:51:00] iteration   498800/  500000 | consumed samples:     31923200 | elapsed time per iteration (ms): 619.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.960975E+00 | loss scale: 1048576.0 | grad norm: 0.522 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 17:52:02] iteration   498900/  500000 | consumed samples:     31929600 | elapsed time per iteration (ms): 620.1 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.938592E+00 | loss scale: 1048576.0 | grad norm: 0.544 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 17:53:04] iteration   499000/  500000 | consumed samples:     31936000 | elapsed time per iteration (ms): 618.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.940150E+00 | loss scale: 1048576.0 | grad norm: 0.525 | number of skipped iterations:   2 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2465.76, 2465.81)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 499000 | lm loss value: 3.755250E+00 | lm loss PPL: 4.274489E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-27 17:54:08] iteration   499100/  500000 | consumed samples:     31942400 | elapsed time per iteration (ms): 618.4 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.954404E+00 | loss scale: 1048576.0 | grad norm: 0.538 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 17:55:10] iteration   499200/  500000 | consumed samples:     31948800 | elapsed time per iteration (ms): 618.6 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.953617E+00 | loss scale: 1048576.0 | grad norm: 0.527 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 17:56:12] iteration   499300/  500000 | consumed samples:     31955200 | elapsed time per iteration (ms): 619.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.949847E+00 | loss scale: 1048576.0 | grad norm: 0.531 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 17:57:14] iteration   499400/  500000 | consumed samples:     31961600 | elapsed time per iteration (ms): 618.5 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.955748E+00 | loss scale: 1048576.0 | grad norm: 0.511 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 17:58:16] iteration   499500/  500000 | consumed samples:     31968000 | elapsed time per iteration (ms): 618.2 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.950108E+00 | loss scale: 1048576.0 | grad norm: 0.524 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 17:59:18] iteration   499600/  500000 | consumed samples:     31974400 | elapsed time per iteration (ms): 618.2 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.962224E+00 | loss scale: 1048576.0 | grad norm: 0.520 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 18:00:20] iteration   499700/  500000 | consumed samples:     31980800 | elapsed time per iteration (ms): 619.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.946138E+00 | loss scale: 1048576.0 | grad norm: 0.511 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 18:01:21] iteration   499800/  500000 | consumed samples:     31987200 | elapsed time per iteration (ms): 617.8 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.949977E+00 | loss scale: 1048576.0 | grad norm: 0.514 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 18:02:23] iteration   499900/  500000 | consumed samples:     31993600 | elapsed time per iteration (ms): 621.0 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.962924E+00 | loss scale: 1048576.0 | grad norm: 0.523 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-27 18:03:25] iteration   500000/  500000 | consumed samples:     32000000 | elapsed time per iteration (ms): 619.4 | learning rate: 1.000000E-05 | global batch size:    64 | lm loss: 2.958226E+00 | loss scale: 2097152.0 | grad norm: 0.509 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (2462.50, 2462.54)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 500000 | lm loss value: 3.724654E+00 | lm loss PPL: 4.145688E+01 | 
--------------------------------------------------------------------------------------------------
saving checkpoint at iteration  500000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-distribution in torch format
  successfully saved checkpoint at iteration  500000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-distribution
(min, max) time across ranks (ms):
    save-checkpoint ................................: (2297.02, 2297.03)
[after training is done] datetime: 2024-06-27 18:03:30 
Evaluating on 640 samples
Evaluating iter 1/10
Evaluating iter 2/10
Evaluating iter 3/10
Evaluating iter 4/10
Evaluating iter 5/10
Evaluating iter 6/10
Evaluating iter 7/10
Evaluating iter 8/10
Evaluating iter 9/10
Evaluating iter 10/10
(min, max) time across ranks (ms):
    evaluate .......................................: (2465.90, 2466.08)
--------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 500000 on validation set | lm loss value: 3.728523E+00 | lm loss PPL: 4.161759E+01 | 
--------------------------------------------------------------------------------------------------------------------
Evaluating on 640 samples
Evaluating iter 1/10
Evaluating iter 2/10
Evaluating iter 3/10
Evaluating iter 4/10
Evaluating iter 5/10
Evaluating iter 6/10
Evaluating iter 7/10
Evaluating iter 8/10
Evaluating iter 9/10
Evaluating iter 10/10
(min, max) time across ranks (ms):
    evaluate .......................................: (2461.72, 2461.90)
--------------------------------------------------------------------------------------------------------------
 validation loss at iteration 500000 on test set | lm loss value: 3.646783E+00 | lm loss PPL: 3.835108E+01 | 
--------------------------------------------------------------------------------------------------------------
