nohup: ignoring input
using world size: 1, data-parallel size: 1, context-parallel size: 1 tensor-model-parallel size: 1, pipeline-model-parallel size: 1 
WARNING: Setting args.overlap_p2p_comm to False since non-interleaved schedule does not support overlapping p2p communication
WARNING: Setting args.check_for_nan_in_loss_and_grad to False since dynamic loss scaling is being used
using torch.float16 for parameters ...
------------------------print arguments ------------------------
  accumulate_allreduce_grads_in_fp32 .............. False
  adam_beta1 ...................................... 0.9
  adam_beta2 ...................................... 0.999
  adam_eps ........................................ 1e-08
  add_bias_linear ................................. True
  add_position_embedding .......................... True
  add_qkv_bias .................................... False
  adlr_autoresume ................................. False
  adlr_autoresume_interval ........................ 1000
  apply_layernorm_1p .............................. False
  apply_query_key_layer_scaling ................... False
  apply_residual_connection_post_layernorm ........ False
  apply_rope_fusion ............................... True
  async_tensor_model_parallel_allreduce ........... True
  attention_dropout ............................... 0.1
  attention_softmax_in_fp32 ....................... False
  auto_detect_ckpt_format ......................... False
  barrier_with_L1_time ............................ True
  bert_binary_head ................................ True
  bert_embedder_type .............................. megatron
  bert_load ....................................... None
  bf16 ............................................ False
  bias_dropout_fusion ............................. True
  bias_gelu_fusion ................................ True
  bias_swiglu_fusion .............................. True
  biencoder_projection_dim ........................ 0
  biencoder_shared_query_context_model ............ False
  block_data_path ................................. None
  check_for_nan_in_loss_and_grad .................. False
  ckpt_fully_parallel_save ........................ False
  ckpt_step ....................................... None
  classes_fraction ................................ 1.0
  clip_grad ....................................... 1.0
  clone_scatter_output_in_embedding ............... True
  consumed_train_samples .......................... 0
  consumed_valid_samples .......................... 0
  context_parallel_size ........................... 1
  create_attention_mask_in_dataloader ............. True
  data_cache_path ................................. None
  data_parallel_random_init ....................... False
  data_parallel_size .............................. 1
  data_path ....................................... ['/Zhushitong/workspace/Models/gpt-2/data/meg-gpt2_text_document']
  data_per_class_fraction ......................... 1.0
  data_sharding ................................... True
  dataloader_type ................................. single
  ddp_bucket_size ................................. None
  decoder_num_layers .............................. None
  decoder_seq_length .............................. None
  decoupled_lr .................................... None
  decoupled_min_lr ................................ None
  delay_grad_reduce ............................... True
  delay_param_gather .............................. False
  dino_bottleneck_size ............................ 256
  dino_freeze_last_layer .......................... 1
  dino_head_hidden_size ........................... 2048
  dino_local_crops_number ......................... 10
  dino_local_img_size ............................. 96
  dino_norm_last_layer ............................ False
  dino_teacher_temp ............................... 0.07
  dino_warmup_teacher_temp ........................ 0.04
  dino_warmup_teacher_temp_epochs ................. 30
  disable_straggler_on_startup .................... False
  dist_ckpt_format ................................ torch_dist
  distribute_saved_activations .................... False
  distributed_backend ............................. nccl
  distributed_timeout_minutes ..................... 10
  embedding_path .................................. None
  empty_unused_memory_level ....................... 0
  enable_one_logger ............................... False
  encoder_num_layers .............................. 24
  encoder_seq_length .............................. 1024
  end_weight_decay ................................ 0.01
  eod_mask_loss ................................... False
  eval_interval ................................... 1000
  eval_iters ...................................... 10
  evidence_data_path .............................. None
  exit_duration_in_mins ........................... None
  exit_interval ................................... None
  exit_on_missing_checkpoint ...................... False
  exit_signal_handler ............................. False
  expert_model_parallel_size ...................... 1
  ffn_hidden_size ................................. 5120
  finetune ........................................ False
  fp16 ............................................ True
  fp16_lm_cross_entropy ........................... False
  fp32_residual_connection ........................ False
  fp8 ............................................. None
  fp8_amax_compute_algo ........................... most_recent
  fp8_amax_history_len ............................ 1
  fp8_interval .................................... 1
  fp8_margin ...................................... 0
  fp8_wgrad ....................................... True
  global_batch_size ............................... 8
  gradient_accumulation_fusion .................... True
  group_query_attention ........................... False
  head_lr_mult .................................... 1.0
  hidden_dropout .................................. 0.1
  hidden_size ..................................... 1280
  hysteresis ...................................... 2
  ict_head_size ................................... None
  ict_load ........................................ None
  img_h ........................................... 224
  img_w ........................................... 224
  indexer_batch_size .............................. 128
  indexer_log_interval ............................ 1000
  inference_batch_times_seqlen_threshold .......... 512
  init_method_std ................................. 0.02
  init_method_xavier_uniform ...................... False
  initial_loss_scale .............................. 4294967296
  iter_per_epoch .................................. 1250
  kv_channels ..................................... 64
  lazy_mpu_init ................................... None
  load ............................................ /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-max
  local_rank ...................................... None
  log_batch_size_to_tensorboard ................... False
  log_interval .................................... 100
  log_learning_rate_to_tensorboard ................ True
  log_loss_scale_to_tensorboard ................... True
  log_memory_to_tensorboard ....................... False
  log_num_zeros_in_grad ........................... False
  log_params_norm ................................. False
  log_progress .................................... False
  log_straggler ................................... False
  log_throughput .................................. False
  log_timers_to_tensorboard ....................... False
  log_validation_ppl_to_tensorboard ............... False
  log_world_size_to_tensorboard ................... False
  loss_scale ...................................... None
  loss_scale_window ............................... 1000
  lr .............................................. 0.00015
  lr_decay_iters .................................. 320000
  lr_decay_samples ................................ None
  lr_decay_style .................................. cosine
  lr_warmup_fraction .............................. 0.01
  lr_warmup_init .................................. 0.0
  lr_warmup_iters ................................. 0
  lr_warmup_samples ............................... 0
  make_vocab_size_divisible_by .................... 128
  manual_gc ....................................... False
  manual_gc_eval .................................. True
  manual_gc_interval .............................. 0
  mask_factor ..................................... 1.0
  mask_prob ....................................... 0.15
  mask_type ....................................... random
  masked_softmax_fusion ........................... True
  max_position_embeddings ......................... 1024
  max_tokens_to_oom ............................... 12000
  merge_file ...................................... /Zhushitong/workspace/Models/gpt-2/data/gpt2-merges.txt
  micro_batch_size ................................ 4
  min_loss_scale .................................. 1.0
  min_lr .......................................... 1e-05
  mmap_bin_files .................................. True
  mock_data ....................................... False
  moe_aux_loss_coeff .............................. 0.0
  moe_grouped_gemm ................................ False
  moe_input_jitter_eps ............................ None
  moe_per_layer_logging ........................... False
  moe_router_load_balancing_type .................. aux_loss
  moe_router_topk ................................. 2
  moe_token_dispatcher_type ....................... allgather
  moe_token_dropping .............................. False
  moe_z_loss_coeff ................................ None
  nccl_communicator_config_path ................... None
  no_load_optim ................................... None
  no_load_rng ..................................... None
  no_persist_layer_norm ........................... False
  no_save_optim ................................... None
  no_save_rng ..................................... None
  norm_epsilon .................................... 1e-05
  normalization ................................... LayerNorm
  num_attention_heads ............................. 20
  num_channels .................................... 3
  num_classes ..................................... 1000
  num_experts ..................................... None
  num_layers ...................................... 24
  num_layers_per_virtual_pipeline_stage ........... None
  num_query_groups ................................ 1
  num_workers ..................................... 2
  one_logger_entity ............................... hwinf_dcm
  one_logger_project .............................. e2e-tracking
  one_logger_run_name ............................. None
  onnx_safe ....................................... None
  openai_gelu ..................................... False
  optimizer ....................................... adam
  output_bert_embeddings .......................... False
  overlap_grad_reduce ............................. False
  overlap_p2p_comm ................................ False
  overlap_param_gather ............................ False
  override_opt_param_scheduler .................... False
  params_dtype .................................... torch.float16
  patch_dim ....................................... 16
  perform_initialization .......................... True
  pipeline_model_parallel_size .................... 1
  pipeline_model_parallel_split_rank .............. None
  position_embedding_type ......................... learned_absolute
  pretrained_checkpoint ........................... None
  profile ......................................... False
  profile_ranks ................................... [0]
  profile_step_end ................................ 12
  profile_step_start .............................. 10
  qk_layernorm .................................... False
  query_in_block_prob ............................. 0.1
  rampup_batch_size ............................... None
  rank ............................................ 0
  recompute_granularity ........................... None
  recompute_method ................................ None
  recompute_num_layers ............................ None
  reset_attention_mask ............................ False
  reset_position_ids .............................. False
  retriever_report_topk_accuracies ................ []
  retriever_score_scaling ......................... False
  retriever_seq_length ............................ 256
  retro_add_retriever ............................. False
  retro_attention_gate ............................ 1
  retro_cyclic_train_iters ........................ None
  retro_encoder_attention_dropout ................. 0.1
  retro_encoder_hidden_dropout .................... 0.1
  retro_encoder_layers ............................ 2
  retro_num_neighbors ............................. 2
  retro_num_retrieved_chunks ...................... 2
  retro_project_dir ............................... None
  retro_verify_neighbor_count ..................... True
  rotary_interleaved .............................. False
  rotary_percent .................................. 1.0
  rotary_seq_len_interpolation_factor ............. None
  sample_rate ..................................... 1.0
  save ............................................ /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-max
  save_interval ................................... 10000
  scatter_gather_tensors_in_pipeline .............. True
  seed ............................................ 1234
  seq_length ...................................... 1024
  sequence_parallel ............................... False
  sgd_momentum .................................... 0.9
  short_seq_prob .................................. 0.1
  skip_train ...................................... False
  spec ............................................ None
  split ........................................... 949,50,1
  squared_relu .................................... False
  standalone_embedding_stage ...................... False
  start_weight_decay .............................. 0.01
  straggler_ctrlr_port ............................ 65535
  straggler_minmax_count .......................... 1
  swiglu .......................................... False
  swin_backbone_type .............................. tiny
  tensor_model_parallel_size ...................... 1
  tensorboard_dir ................................. None
  tensorboard_log_interval ........................ 1
  tensorboard_queue_size .......................... 1000
  test_data_path .................................. None
  test_mode ....................................... False
  timing_log_level ................................ 0
  timing_log_option ............................... minmax
  titles_data_path ................................ None
  tokenizer_model ................................. None
  tokenizer_type .................................. GPT2BPETokenizer
  tp_comm_bulk_dgrad .............................. True
  tp_comm_bulk_wgrad .............................. True
  tp_comm_overlap ................................. False
  tp_comm_overlap_ag .............................. True
  tp_comm_overlap_cfg ............................. None
  tp_comm_overlap_rs .............................. True
  tp_comm_overlap_rs_dgrad ........................ False
  tp_comm_split_ag ................................ True
  tp_comm_split_rs ................................ True
  train_data_path ................................. None
  train_iters ..................................... 500000
  train_samples ................................... None
  transformer_impl ................................ transformer_engine
  transformer_pipeline_model_parallel_size ........ 1
  untie_embeddings_and_output_weights ............. False
  use_checkpoint_args ............................. False
  use_checkpoint_opt_param_scheduler .............. False
  use_cpu_initialization .......................... None
  use_dist_ckpt ................................... False
  use_distributed_optimizer ....................... False
  use_flash_attn .................................. False
  use_mcore_models ................................ False
  use_one_sent_docs ............................... False
  use_ring_exchange_p2p ........................... False
  use_rotary_position_embeddings .................. False
  use_tp_pp_dp_mapping ............................ False
  valid_data_path ................................. None
  variable_seq_lengths ............................ False
  virtual_pipeline_model_parallel_size ............ None
  vision_backbone_type ............................ vit
  vision_pretraining .............................. False
  vision_pretraining_type ......................... classify
  vocab_extra_ids ................................. 0
  vocab_file ...................................... /Zhushitong/workspace/Models/gpt-2/data/gpt2-vocab.json
  vocab_size ...................................... None
  wandb_exp_name .................................. 
  wandb_project ................................... 
  wandb_save_dir .................................. 
  weight_decay .................................... 0.01
  weight_decay_incr_style ......................... constant
  world_size ...................................... 1
  yaml_cfg ........................................ None
-------------------- end of arguments ---------------------
setting number of micro-batches to constant 2
> building GPT2BPETokenizer tokenizer ...
 > padded vocab (size: 50257) with 47 dummy tokens (new size: 50304)
> initializing torch distributed ...
> initialized tensor model parallel with size 1
> initialized pipeline model parallel with size 1
> setting random seeds to 1234 ...
> compiling dataset index builder ...
make: Entering directory '/Zhushitong/workspace/Git/Megatron-LM/megatron/core/datasets'
make: Nothing to be done for 'default'.
make: Leaving directory '/Zhushitong/workspace/Git/Megatron-LM/megatron/core/datasets'
>>> done with dataset index builder. Compilation time: 0.076 seconds
> compiling and loading fused kernels ...
>>> done with compiling and loading fused kernels. Compilation time: 0.688 seconds
time to initialize megatron (seconds): 1.814
[after megatron is initialized] datetime: 2024-06-21 06:47:21 
building GPT model ...
/usr/local/lib/python3.8/dist-packages/transformer_engine/pytorch/transformer.py:967: DeprecationWarning: Arguments `attention_softmax_in_fp32` and `apply_query_key_layer_scaling`are deprecated and will be fully removed in future releases.
  warnings.warn(
 > number of parameters on (tensor, pipeline) model parallel rank (0, 0): 537960960
INFO:megatron.core.distributed.distributed_data_parallel:Setting up DistributedDataParallel with DistributedDataParallelConfig: DistributedDataParallelConfig(grad_reduce_in_fp32=False, overlap_grad_reduce=False, use_distributed_optimizer=False, check_for_nan_in_grad=False, bucket_size=None)
INFO:megatron.core.distributed.param_and_grad_buffer:Number of buckets for gradient all-reduce / reduce-scatter: 1
INFO:megatron.core.distributed.param_and_grad_buffer:Params for bucket 1 (537960960 elements):
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.20.layernorm_mlp.fc2_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.15.self_attention.layernorm_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.11.self_attention.layernorm_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.5.self_attention.proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.1.layernorm_mlp.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.19.layernorm_mlp.fc1_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.17.self_attention.proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.11.layernorm_mlp.fc1_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.9.layernorm_mlp.fc2_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.8.self_attention.layernorm_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.21.layernorm_mlp.fc2_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.16.self_attention.layernorm_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.12.self_attention.layernorm_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.6.self_attention.proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.0.layernorm_mlp.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.2.layernorm_mlp.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.18.self_attention.proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.14.layernorm_mlp.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.12.layernorm_mlp.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.10.layernorm_mlp.fc1_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.8.layernorm_mlp.fc2_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.3.self_attention.layernorm_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.22.layernorm_mlp.fc2_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.21.self_attention.layernorm_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.13.self_attention.layernorm_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.7.layernorm_mlp.fc1_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.5.self_attention.proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.19.self_attention.proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.15.layernorm_mlp.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.13.layernorm_mlp.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.9.layernorm_mlp.fc2_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.4.self_attention.layernorm_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.0.layernorm_mlp.fc1_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.23.layernorm_mlp.fc2_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.22.self_attention.layernorm_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.14.self_attention.layernorm_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.8.layernorm_mlp.fc1_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.6.self_attention.proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.20.layernorm_mlp.fc1_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.18.self_attention.proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.12.layernorm_mlp.fc1_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.10.layernorm_mlp.fc2_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.8.layernorm_mlp.fc2_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.5.self_attention.layernorm_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.1.self_attention.layernorm_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.22.layernorm_mlp.fc2_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.17.self_attention.layernorm_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.13.self_attention.layernorm_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.7.self_attention.proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.3.layernorm_mlp.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.1.layernorm_mlp.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.21.layernorm_mlp.fc1_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.19.self_attention.proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.13.layernorm_mlp.fc1_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.11.layernorm_mlp.fc2_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.10.self_attention.layernorm_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.2.self_attention.layernorm_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.4.layernorm_mlp.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.2.layernorm_mlp.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.18.self_attention.layernorm_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.23.layernorm_mlp.fc2_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.14.self_attention.layernorm_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.8.self_attention.proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.1.self_attention.layernorm_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.20.self_attention.proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.16.layernorm_mlp.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.14.layernorm_mlp.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.12.layernorm_mlp.fc1_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.10.layernorm_mlp.fc2_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.5.self_attention.layernorm_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.23.self_attention.layernorm_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.15.self_attention.layernorm_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.9.layernorm_mlp.fc1_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.7.self_attention.proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.1.layernorm_mlp.fc1_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.21.self_attention.proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.17.layernorm_mlp.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.15.layernorm_mlp.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.11.layernorm_mlp.fc2_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.6.self_attention.layernorm_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.2.self_attention.layernorm_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.0.self_attention.layernorm_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.16.self_attention.layernorm_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.8.self_attention.proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.2.layernorm_mlp.fc1_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.0.layernorm_mlp.fc2_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.22.layernorm_mlp.fc1_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.20.self_attention.proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.14.layernorm_mlp.fc1_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.12.layernorm_mlp.fc2_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.11.self_attention.layernorm_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.7.self_attention.layernorm_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.3.self_attention.layernorm_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.19.self_attention.layernorm_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.15.self_attention.layernorm_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.9.self_attention.proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.5.layernorm_mlp.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.3.layernorm_mlp.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.23.layernorm_mlp.fc1_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.21.self_attention.proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.15.layernorm_mlp.fc1_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.13.layernorm_mlp.fc2_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.12.self_attention.layernorm_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.4.self_attention.layernorm_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.0.layernorm_mlp.fc2_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.20.self_attention.layernorm_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.16.self_attention.layernorm_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.10.self_attention.proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.6.layernorm_mlp.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.4.layernorm_mlp.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.22.self_attention.proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.18.layernorm_mlp.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.16.layernorm_mlp.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.14.layernorm_mlp.fc1_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.12.layernorm_mlp.fc2_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.7.self_attention.layernorm_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.3.self_attention.layernorm_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.17.self_attention.layernorm_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.11.layernorm_mlp.fc1_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.9.self_attention.proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.3.layernorm_mlp.fc1_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.1.layernorm_mlp.fc2_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.embedding.word_embeddings.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.23.self_attention.proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.19.layernorm_mlp.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.17.layernorm_mlp.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.13.layernorm_mlp.fc2_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.8.self_attention.layernorm_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.4.self_attention.layernorm_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.1.self_attention.layernorm_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.2.layernorm_mlp.fc2_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.18.self_attention.layernorm_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.10.self_attention.proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.4.layernorm_mlp.fc1_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.5.self_attention.layernorm_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.22.self_attention.proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.16.layernorm_mlp.fc1_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.14.layernorm_mlp.fc2_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.13.self_attention.layernorm_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.9.self_attention.layernorm_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.21.self_attention.layernorm_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.17.self_attention.layernorm_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.11.self_attention.proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.7.layernorm_mlp.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.5.layernorm_mlp.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.1.layernorm_mlp.fc2_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.23.self_attention.proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.17.layernorm_mlp.fc1_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.15.layernorm_mlp.fc2_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.14.self_attention.layernorm_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.6.self_attention.layernorm_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.final_norm.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.22.self_attention.layernorm_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.18.self_attention.layernorm_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.12.self_attention.proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.8.layernorm_mlp.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.6.layernorm_mlp.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.2.layernorm_mlp.fc2_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.embedding.position_embeddings.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.20.layernorm_mlp.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.18.layernorm_mlp.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.16.layernorm_mlp.fc1_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.14.layernorm_mlp.fc2_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.9.self_attention.layernorm_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.5.self_attention.layernorm_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.19.self_attention.layernorm_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.13.layernorm_mlp.fc1_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.11.self_attention.proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.5.layernorm_mlp.fc1_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.3.layernorm_mlp.fc2_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.2.self_attention.layernorm_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.21.layernorm_mlp.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.19.layernorm_mlp.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.15.layernorm_mlp.fc2_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.10.self_attention.layernorm_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.6.self_attention.layernorm_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.0.layernorm_mlp.fc1_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.20.self_attention.layernorm_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.12.self_attention.proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.6.layernorm_mlp.fc1_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.4.layernorm_mlp.fc2_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.0.self_attention.layernorm_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.1.layernorm_mlp.fc1_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.18.layernorm_mlp.fc1_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.16.layernorm_mlp.fc2_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.15.self_attention.layernorm_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.7.self_attention.layernorm_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.23.self_attention.layernorm_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.19.self_attention.layernorm_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.13.self_attention.proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.9.layernorm_mlp.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.7.layernorm_mlp.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.3.layernorm_mlp.fc2_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.19.layernorm_mlp.fc1_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.17.layernorm_mlp.fc2_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.16.self_attention.layernorm_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.8.self_attention.layernorm_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.0.self_attention.proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.2.layernorm_mlp.fc1_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.20.self_attention.layernorm_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.14.self_attention.proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.10.layernorm_mlp.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.8.layernorm_mlp.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.4.layernorm_mlp.fc2_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.22.layernorm_mlp.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.20.layernorm_mlp.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.18.layernorm_mlp.fc1_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.16.layernorm_mlp.fc2_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.11.self_attention.layernorm_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.7.self_attention.layernorm_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.0.self_attention.layernorm_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.1.self_attention.proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.21.self_attention.layernorm_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.15.layernorm_mlp.fc1_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.13.self_attention.proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.7.layernorm_mlp.fc1_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.5.layernorm_mlp.fc2_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.4.self_attention.layernorm_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.0.self_attention.proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.2.self_attention.proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.23.layernorm_mlp.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.21.layernorm_mlp.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.17.layernorm_mlp.fc2_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.12.self_attention.layernorm_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.8.self_attention.layernorm_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.22.self_attention.layernorm_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.14.self_attention.proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.8.layernorm_mlp.fc1_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.6.layernorm_mlp.fc2_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.20.layernorm_mlp.fc1_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.18.layernorm_mlp.fc2_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.17.self_attention.layernorm_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.9.self_attention.layernorm_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.3.layernorm_mlp.fc1_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.1.self_attention.proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.21.self_attention.layernorm_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.15.self_attention.proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.11.layernorm_mlp.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.9.layernorm_mlp.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.5.layernorm_mlp.fc2_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.4.layernorm_mlp.fc1_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.2.self_attention.proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.21.layernorm_mlp.fc1_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.19.layernorm_mlp.fc2_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.18.self_attention.layernorm_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.10.self_attention.layernorm_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.0.layernorm_mlp.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.1.self_attention.layernorm_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.3.self_attention.layernorm_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.22.self_attention.layernorm_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.16.self_attention.proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.12.layernorm_mlp.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.10.layernorm_mlp.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.6.layernorm_mlp.fc2_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.22.layernorm_mlp.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.18.layernorm_mlp.fc2_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.13.self_attention.layernorm_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.9.self_attention.layernorm_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.3.self_attention.proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.23.self_attention.layernorm_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.17.layernorm_mlp.fc1_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.15.self_attention.proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.9.layernorm_mlp.fc1_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.7.layernorm_mlp.fc2_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.6.self_attention.layernorm_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.23.layernorm_mlp.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.19.layernorm_mlp.fc2_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.14.self_attention.layernorm_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.10.self_attention.layernorm_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.4.self_attention.proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.16.self_attention.proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.10.layernorm_mlp.fc1_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.0.self_attention.layernorm_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.19.self_attention.layernorm_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.final_norm.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.22.layernorm_mlp.fc1_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.20.layernorm_mlp.fc2_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.11.self_attention.layernorm_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.5.layernorm_mlp.fc1_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.3.self_attention.proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.23.self_attention.layernorm_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.17.self_attention.proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.13.layernorm_mlp.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.11.layernorm_mlp.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.7.layernorm_mlp.fc2_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.2.self_attention.layernorm_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.4.self_attention.proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.23.layernorm_mlp.fc1_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.21.layernorm_mlp.fc2_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.20.self_attention.layernorm_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.12.self_attention.layernorm_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    module.language_model.encoder.layers.6.layernorm_mlp.fc1_bias
INFO:megatron.core.optimizer:Setting up optimizer with OptimizerConfig: OptimizerConfig(optimizer='adam', lr=0.00015, min_lr=1e-05, decoupled_lr=None, decoupled_min_lr=None, weight_decay=0.01, fp16=True, bf16=False, params_dtype=torch.float16, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, adam_beta1=0.9, adam_beta2=0.999, adam_eps=1e-08, sgd_momentum=0.9, use_distributed_optimizer=False, overlap_grad_reduce=False, overlap_param_gather=False, clip_grad=1.0, log_num_zeros_in_grad=False, barrier_with_L1_time=True, timers=<megatron.core.timers.Timers object at 0x7ff942ed7970>)
> learning rate decay style: cosine
WARNING: could not find the metadata file /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-max/latest_checkpointed_iteration.txt 
    will not load any checkpoints and will start from random
/usr/local/lib/python3.8/dist-packages/torch/distributed/distributed_c10d.py:2603: UserWarning: torch.distributed._all_gather_base is a private function and will be deprecated. Please use torch.distributed.all_gather_into_tensor instead.
  warnings.warn(
(min, max) time across ranks (ms):
    load-checkpoint ................................: (0.16, 0.16)
[after model, optimizer, and learning rate scheduler are built] datetime: 2024-06-21 06:47:24 
> building train, validation, and test datasets ...
 > datasets target sizes (minimum size):
    train:      4000000
    validation: 40080
    test:       80
INFO:megatron.core.datasets.blended_megatron_dataset_config:mock = False
INFO:megatron.core.datasets.blended_megatron_dataset_config:Let split_matrix = [(0, 0.949), (0.949, 0.999), (0.999, 1.0)]
> building train, validation, and test datasets for GPT ...
WARNING:megatron.core.datasets.blended_megatron_dataset_builder:Building dataset splits with cls=GPTDataset, sizes=(4000000, 40080, 80), and config=GPTDatasetConfig(random_seed=1234, sequence_length=1024, blend=(['/Zhushitong/workspace/Models/gpt-2/data/meg-gpt2_text_document'], None), blend_per_split=[None, None, None], split='949,50,1', split_matrix=[(0, 0.949), (0.949, 0.999), (0.999, 1.0)], path_to_cache=None, mmap_bin_files=True, mock=False, tokenizer=<megatron.training.tokenizer.tokenizer._GPT2BPETokenizer object at 0x7ff8824459a0>, reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, create_attention_mask=True)
INFO:megatron.core.datasets.indexed_dataset:Load the _IndexReader from /Zhushitong/workspace/Models/gpt-2/data/meg-gpt2_text_document.idx
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence lengths
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence pointers
INFO:megatron.core.datasets.indexed_dataset:	Extract the document indices
INFO:megatron.core.datasets.indexed_dataset:> total number of sequences: 79000
INFO:megatron.core.datasets.indexed_dataset:> total number of documents: 79000
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset train indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 0831db64118c86978054233f84164e99-GPTDataset-train-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 0831db64118c86978054233f84164e99-GPTDataset-train-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 0831db64118c86978054233f84164e99-GPTDataset-train-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 4121016
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset valid indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 9642c90b06873d6042237fae50b6da64-GPTDataset-valid-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 9642c90b06873d6042237fae50b6da64-GPTDataset-valid-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 9642c90b06873d6042237fae50b6da64-GPTDataset-valid-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 46332
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset test indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from ed6aefe87045eebcfd4ef4be903cf4c7-GPTDataset-test-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from ed6aefe87045eebcfd4ef4be903cf4c7-GPTDataset-test-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from ed6aefe87045eebcfd4ef4be903cf4c7-GPTDataset-test-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 368
> finished creating GPT datasets ...
[after dataloaders are built] datetime: 2024-06-21 06:47:24 
done with setup ...
(min, max) time across ranks (ms):
    model-and-optimizer-setup ......................: (3080.20, 3080.20)
    train/valid/test-data-iterators-setup ..........: (564.86, 564.86)
training ...
[before the start of training step] datetime: 2024-06-21 06:47:24 
 [2024-06-21 06:47:58] iteration      100/  500000 | consumed samples:          800 | elapsed time per iteration (ms): 339.8 | learning rate: 3.937500E-06 | global batch size:     8 | lm loss: 9.628196E+00 | loss scale: 131072.0 | grad norm: 3.318 | number of skipped iterations:  16 | number of nan iterations:   0 |
Number of parameters in transformer layers in billions:  0.47
Number of parameters in embedding layers in billions: 0.06
Total number of parameters in billions: 0.54
Number of parameters in most loaded shard in billions: 0.5364
Theoretical memory footprints: weight and optimizer=9207.47 MB
[Rank 0] (after 100 iterations) memory (MB) | allocated: 10328.42138671875 | max allocated: 21321.59130859375 | reserved: 22960.0 | max reserved: 22960.0
 [2024-06-21 06:48:31] iteration      200/  500000 | consumed samples:         1600 | elapsed time per iteration (ms): 327.9 | learning rate: 8.578125E-06 | global batch size:     8 | lm loss: 8.518981E+00 | loss scale: 65536.0 | grad norm: 4.583 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-21 06:49:04] iteration      300/  500000 | consumed samples:         2400 | elapsed time per iteration (ms): 326.3 | learning rate: 1.326562E-05 | global batch size:     8 | lm loss: 7.751246E+00 | loss scale: 65536.0 | grad norm: 2.615 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 06:49:36] iteration      400/  500000 | consumed samples:         3200 | elapsed time per iteration (ms): 324.3 | learning rate: 1.795312E-05 | global batch size:     8 | lm loss: 7.312198E+00 | loss scale: 65536.0 | grad norm: 1.895 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 06:50:08] iteration      500/  500000 | consumed samples:         4000 | elapsed time per iteration (ms): 323.1 | learning rate: 2.264062E-05 | global batch size:     8 | lm loss: 7.110884E+00 | loss scale: 65536.0 | grad norm: 1.825 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 06:50:41] iteration      600/  500000 | consumed samples:         4800 | elapsed time per iteration (ms): 324.4 | learning rate: 2.732812E-05 | global batch size:     8 | lm loss: 6.951069E+00 | loss scale: 65536.0 | grad norm: 1.730 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 06:51:13] iteration      700/  500000 | consumed samples:         5600 | elapsed time per iteration (ms): 324.8 | learning rate: 3.201562E-05 | global batch size:     8 | lm loss: 6.867491E+00 | loss scale: 65536.0 | grad norm: 1.768 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 06:51:46] iteration      800/  500000 | consumed samples:         6400 | elapsed time per iteration (ms): 325.5 | learning rate: 3.670312E-05 | global batch size:     8 | lm loss: 6.736702E+00 | loss scale: 65536.0 | grad norm: 1.421 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 06:52:18] iteration      900/  500000 | consumed samples:         7200 | elapsed time per iteration (ms): 325.1 | learning rate: 4.139062E-05 | global batch size:     8 | lm loss: 6.659988E+00 | loss scale: 65536.0 | grad norm: 1.779 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 06:52:51] iteration     1000/  500000 | consumed samples:         8000 | elapsed time per iteration (ms): 326.3 | learning rate: 4.607812E-05 | global batch size:     8 | lm loss: 6.594288E+00 | loss scale: 65536.0 | grad norm: 1.424 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1248.18, 1248.18)
------------------------------------------------------------------------------------------------
 validation loss at iteration 1000 | lm loss value: 6.708843E+00 | lm loss PPL: 8.196216E+02 | 
------------------------------------------------------------------------------------------------
 [2024-06-21 06:53:25] iteration     1100/  500000 | consumed samples:         8800 | elapsed time per iteration (ms): 324.8 | learning rate: 5.076562E-05 | global batch size:     8 | lm loss: 6.564820E+00 | loss scale: 65536.0 | grad norm: 1.318 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 06:53:57] iteration     1200/  500000 | consumed samples:         9600 | elapsed time per iteration (ms): 325.6 | learning rate: 5.545313E-05 | global batch size:     8 | lm loss: 6.551660E+00 | loss scale: 131072.0 | grad norm: 1.283 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 06:54:30] iteration     1300/  500000 | consumed samples:        10400 | elapsed time per iteration (ms): 325.1 | learning rate: 6.014062E-05 | global batch size:     8 | lm loss: 6.486216E+00 | loss scale: 131072.0 | grad norm: 3.451 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 06:55:02] iteration     1400/  500000 | consumed samples:        11200 | elapsed time per iteration (ms): 324.0 | learning rate: 6.482812E-05 | global batch size:     8 | lm loss: 6.443566E+00 | loss scale: 131072.0 | grad norm: 1.066 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 06:55:35] iteration     1500/  500000 | consumed samples:        12000 | elapsed time per iteration (ms): 323.1 | learning rate: 6.946875E-05 | global batch size:     8 | lm loss: 6.396492E+00 | loss scale: 131072.0 | grad norm: 1.131 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-21 06:56:07] iteration     1600/  500000 | consumed samples:        12800 | elapsed time per iteration (ms): 324.5 | learning rate: 7.415625E-05 | global batch size:     8 | lm loss: 6.360401E+00 | loss scale: 131072.0 | grad norm: 1.134 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 06:56:39] iteration     1700/  500000 | consumed samples:        13600 | elapsed time per iteration (ms): 324.9 | learning rate: 7.884375E-05 | global batch size:     8 | lm loss: 6.284518E+00 | loss scale: 131072.0 | grad norm: 1.045 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 06:57:12] iteration     1800/  500000 | consumed samples:        14400 | elapsed time per iteration (ms): 325.1 | learning rate: 8.353125E-05 | global batch size:     8 | lm loss: 6.199023E+00 | loss scale: 131072.0 | grad norm: 1.005 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 06:57:44] iteration     1900/  500000 | consumed samples:        15200 | elapsed time per iteration (ms): 324.5 | learning rate: 8.821875E-05 | global batch size:     8 | lm loss: 6.185013E+00 | loss scale: 131072.0 | grad norm: 1.052 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 06:58:17] iteration     2000/  500000 | consumed samples:        16000 | elapsed time per iteration (ms): 325.0 | learning rate: 9.290625E-05 | global batch size:     8 | lm loss: 6.099934E+00 | loss scale: 131072.0 | grad norm: 1.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1063.97, 1063.97)
------------------------------------------------------------------------------------------------
 validation loss at iteration 2000 | lm loss value: 6.205446E+00 | lm loss PPL: 4.954398E+02 | 
------------------------------------------------------------------------------------------------
 [2024-06-21 06:58:50] iteration     2100/  500000 | consumed samples:        16800 | elapsed time per iteration (ms): 323.4 | learning rate: 9.759375E-05 | global batch size:     8 | lm loss: 6.097639E+00 | loss scale: 131072.0 | grad norm: 1.006 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 06:59:23] iteration     2200/  500000 | consumed samples:        17600 | elapsed time per iteration (ms): 323.9 | learning rate: 1.022812E-04 | global batch size:     8 | lm loss: 6.064526E+00 | loss scale: 131072.0 | grad norm: 0.874 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 06:59:55] iteration     2300/  500000 | consumed samples:        18400 | elapsed time per iteration (ms): 322.4 | learning rate: 1.069687E-04 | global batch size:     8 | lm loss: 5.992750E+00 | loss scale: 131072.0 | grad norm: 0.929 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 07:00:27] iteration     2400/  500000 | consumed samples:        19200 | elapsed time per iteration (ms): 321.2 | learning rate: 1.116562E-04 | global batch size:     8 | lm loss: 5.994790E+00 | loss scale: 131072.0 | grad norm: 1.109 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 07:00:59] iteration     2500/  500000 | consumed samples:        20000 | elapsed time per iteration (ms): 322.8 | learning rate: 1.163437E-04 | global batch size:     8 | lm loss: 5.927001E+00 | loss scale: 262144.0 | grad norm: 0.939 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 07:01:32] iteration     2600/  500000 | consumed samples:        20800 | elapsed time per iteration (ms): 323.9 | learning rate: 1.209375E-04 | global batch size:     8 | lm loss: 5.925262E+00 | loss scale: 131072.0 | grad norm: 0.875 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-21 07:02:04] iteration     2700/  500000 | consumed samples:        21600 | elapsed time per iteration (ms): 322.0 | learning rate: 1.256250E-04 | global batch size:     8 | lm loss: 5.925284E+00 | loss scale: 131072.0 | grad norm: 0.939 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 07:02:36] iteration     2800/  500000 | consumed samples:        22400 | elapsed time per iteration (ms): 323.3 | learning rate: 1.303125E-04 | global batch size:     8 | lm loss: 5.845781E+00 | loss scale: 131072.0 | grad norm: 0.996 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 07:03:08] iteration     2900/  500000 | consumed samples:        23200 | elapsed time per iteration (ms): 321.7 | learning rate: 1.350000E-04 | global batch size:     8 | lm loss: 5.794272E+00 | loss scale: 131072.0 | grad norm: 0.905 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 07:03:40] iteration     3000/  500000 | consumed samples:        24000 | elapsed time per iteration (ms): 320.2 | learning rate: 1.396875E-04 | global batch size:     8 | lm loss: 5.799637E+00 | loss scale: 131072.0 | grad norm: 1.024 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1064.20, 1064.20)
------------------------------------------------------------------------------------------------
 validation loss at iteration 3000 | lm loss value: 5.657132E+00 | lm loss PPL: 2.863263E+02 | 
------------------------------------------------------------------------------------------------
 [2024-06-21 07:04:14] iteration     3100/  500000 | consumed samples:        24800 | elapsed time per iteration (ms): 321.8 | learning rate: 1.443750E-04 | global batch size:     8 | lm loss: 5.740626E+00 | loss scale: 131072.0 | grad norm: 0.951 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 07:04:46] iteration     3200/  500000 | consumed samples:        25600 | elapsed time per iteration (ms): 322.9 | learning rate: 1.490625E-04 | global batch size:     8 | lm loss: 5.713570E+00 | loss scale: 131072.0 | grad norm: 0.857 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 07:05:18] iteration     3300/  500000 | consumed samples:        26400 | elapsed time per iteration (ms): 321.6 | learning rate: 1.500000E-04 | global batch size:     8 | lm loss: 5.689236E+00 | loss scale: 131072.0 | grad norm: 0.872 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 07:05:51] iteration     3400/  500000 | consumed samples:        27200 | elapsed time per iteration (ms): 325.7 | learning rate: 1.499999E-04 | global batch size:     8 | lm loss: 5.653978E+00 | loss scale: 131072.0 | grad norm: 1.119 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 07:06:23] iteration     3500/  500000 | consumed samples:        28000 | elapsed time per iteration (ms): 321.1 | learning rate: 1.499997E-04 | global batch size:     8 | lm loss: 5.632106E+00 | loss scale: 131072.0 | grad norm: 0.933 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 07:06:55] iteration     3600/  500000 | consumed samples:        28800 | elapsed time per iteration (ms): 321.7 | learning rate: 1.499995E-04 | global batch size:     8 | lm loss: 5.583675E+00 | loss scale: 262144.0 | grad norm: 0.822 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 07:07:27] iteration     3700/  500000 | consumed samples:        29600 | elapsed time per iteration (ms): 321.1 | learning rate: 1.499992E-04 | global batch size:     8 | lm loss: 5.548552E+00 | loss scale: 262144.0 | grad norm: 0.916 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 07:07:59] iteration     3800/  500000 | consumed samples:        30400 | elapsed time per iteration (ms): 322.9 | learning rate: 1.499988E-04 | global batch size:     8 | lm loss: 5.528223E+00 | loss scale: 262144.0 | grad norm: 1.193 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 07:08:32] iteration     3900/  500000 | consumed samples:        31200 | elapsed time per iteration (ms): 323.3 | learning rate: 1.499984E-04 | global batch size:     8 | lm loss: 5.478697E+00 | loss scale: 262144.0 | grad norm: 0.806 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 07:09:04] iteration     4000/  500000 | consumed samples:        32000 | elapsed time per iteration (ms): 323.6 | learning rate: 1.499979E-04 | global batch size:     8 | lm loss: 5.464162E+00 | loss scale: 262144.0 | grad norm: 0.797 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1064.80, 1064.80)
------------------------------------------------------------------------------------------------
 validation loss at iteration 4000 | lm loss value: 5.529079E+00 | lm loss PPL: 2.519118E+02 | 
------------------------------------------------------------------------------------------------
 [2024-06-21 07:09:37] iteration     4100/  500000 | consumed samples:        32800 | elapsed time per iteration (ms): 321.4 | learning rate: 1.499973E-04 | global batch size:     8 | lm loss: 5.434599E+00 | loss scale: 262144.0 | grad norm: 0.811 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 07:10:10] iteration     4200/  500000 | consumed samples:        33600 | elapsed time per iteration (ms): 323.2 | learning rate: 1.499967E-04 | global batch size:     8 | lm loss: 5.405760E+00 | loss scale: 262144.0 | grad norm: 0.777 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-21 07:10:42] iteration     4300/  500000 | consumed samples:        34400 | elapsed time per iteration (ms): 323.3 | learning rate: 1.499960E-04 | global batch size:     8 | lm loss: 5.375546E+00 | loss scale: 262144.0 | grad norm: 0.914 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 07:11:14] iteration     4400/  500000 | consumed samples:        35200 | elapsed time per iteration (ms): 322.8 | learning rate: 1.499952E-04 | global batch size:     8 | lm loss: 5.370890E+00 | loss scale: 262144.0 | grad norm: 0.861 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 07:11:47] iteration     4500/  500000 | consumed samples:        36000 | elapsed time per iteration (ms): 322.7 | learning rate: 1.499944E-04 | global batch size:     8 | lm loss: 5.336227E+00 | loss scale: 262144.0 | grad norm: 0.790 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 07:12:19] iteration     4600/  500000 | consumed samples:        36800 | elapsed time per iteration (ms): 321.7 | learning rate: 1.499935E-04 | global batch size:     8 | lm loss: 5.277076E+00 | loss scale: 262144.0 | grad norm: 0.903 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 07:12:51] iteration     4700/  500000 | consumed samples:        37600 | elapsed time per iteration (ms): 322.7 | learning rate: 1.499925E-04 | global batch size:     8 | lm loss: 5.269637E+00 | loss scale: 131072.0 | grad norm: 0.883 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-21 07:13:23] iteration     4800/  500000 | consumed samples:        38400 | elapsed time per iteration (ms): 322.9 | learning rate: 1.499914E-04 | global batch size:     8 | lm loss: 5.241168E+00 | loss scale: 131072.0 | grad norm: 0.976 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 07:13:55] iteration     4900/  500000 | consumed samples:        39200 | elapsed time per iteration (ms): 321.5 | learning rate: 1.499903E-04 | global batch size:     8 | lm loss: 5.284930E+00 | loss scale: 131072.0 | grad norm: 0.845 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 07:14:28] iteration     5000/  500000 | consumed samples:        40000 | elapsed time per iteration (ms): 321.4 | learning rate: 1.499891E-04 | global batch size:     8 | lm loss: 5.208956E+00 | loss scale: 131072.0 | grad norm: 1.458 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1063.27, 1063.27)
------------------------------------------------------------------------------------------------
 validation loss at iteration 5000 | lm loss value: 5.237237E+00 | lm loss PPL: 1.881495E+02 | 
------------------------------------------------------------------------------------------------
 [2024-06-21 07:15:01] iteration     5100/  500000 | consumed samples:        40800 | elapsed time per iteration (ms): 321.7 | learning rate: 1.499879E-04 | global batch size:     8 | lm loss: 5.199708E+00 | loss scale: 131072.0 | grad norm: 3.333 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 07:15:33] iteration     5200/  500000 | consumed samples:        41600 | elapsed time per iteration (ms): 321.9 | learning rate: 1.499865E-04 | global batch size:     8 | lm loss: 5.165211E+00 | loss scale: 131072.0 | grad norm: 0.792 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 07:16:05] iteration     5300/  500000 | consumed samples:        42400 | elapsed time per iteration (ms): 321.0 | learning rate: 1.499851E-04 | global batch size:     8 | lm loss: 5.137601E+00 | loss scale: 131072.0 | grad norm: 1.094 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 07:16:37] iteration     5400/  500000 | consumed samples:        43200 | elapsed time per iteration (ms): 321.7 | learning rate: 1.499837E-04 | global batch size:     8 | lm loss: 5.082924E+00 | loss scale: 131072.0 | grad norm: 0.762 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 07:17:10] iteration     5500/  500000 | consumed samples:        44000 | elapsed time per iteration (ms): 322.9 | learning rate: 1.499821E-04 | global batch size:     8 | lm loss: 5.086007E+00 | loss scale: 131072.0 | grad norm: 0.832 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 07:17:42] iteration     5600/  500000 | consumed samples:        44800 | elapsed time per iteration (ms): 322.7 | learning rate: 1.499805E-04 | global batch size:     8 | lm loss: 5.034132E+00 | loss scale: 131072.0 | grad norm: 0.821 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 07:18:14] iteration     5700/  500000 | consumed samples:        45600 | elapsed time per iteration (ms): 322.3 | learning rate: 1.499789E-04 | global batch size:     8 | lm loss: 4.994547E+00 | loss scale: 262144.0 | grad norm: 0.919 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 07:18:46] iteration     5800/  500000 | consumed samples:        46400 | elapsed time per iteration (ms): 324.7 | learning rate: 1.499771E-04 | global batch size:     8 | lm loss: 5.026805E+00 | loss scale: 262144.0 | grad norm: 1.268 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 07:19:19] iteration     5900/  500000 | consumed samples:        47200 | elapsed time per iteration (ms): 322.9 | learning rate: 1.499753E-04 | global batch size:     8 | lm loss: 4.994871E+00 | loss scale: 262144.0 | grad norm: 0.804 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 07:19:51] iteration     6000/  500000 | consumed samples:        48000 | elapsed time per iteration (ms): 323.9 | learning rate: 1.499734E-04 | global batch size:     8 | lm loss: 4.988492E+00 | loss scale: 262144.0 | grad norm: 0.984 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1064.06, 1064.06)
------------------------------------------------------------------------------------------------
 validation loss at iteration 6000 | lm loss value: 4.993351E+00 | lm loss PPL: 1.474296E+02 | 
------------------------------------------------------------------------------------------------
 [2024-06-21 07:20:25] iteration     6100/  500000 | consumed samples:        48800 | elapsed time per iteration (ms): 323.6 | learning rate: 1.499715E-04 | global batch size:     8 | lm loss: 4.995372E+00 | loss scale: 262144.0 | grad norm: 0.826 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 07:20:57] iteration     6200/  500000 | consumed samples:        49600 | elapsed time per iteration (ms): 323.6 | learning rate: 1.499695E-04 | global batch size:     8 | lm loss: 4.932497E+00 | loss scale: 262144.0 | grad norm: 0.786 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 07:21:29] iteration     6300/  500000 | consumed samples:        50400 | elapsed time per iteration (ms): 323.7 | learning rate: 1.499674E-04 | global batch size:     8 | lm loss: 4.886818E+00 | loss scale: 262144.0 | grad norm: 0.753 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 07:22:02] iteration     6400/  500000 | consumed samples:        51200 | elapsed time per iteration (ms): 322.7 | learning rate: 1.499652E-04 | global batch size:     8 | lm loss: 4.866572E+00 | loss scale: 262144.0 | grad norm: 0.807 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 07:22:34] iteration     6500/  500000 | consumed samples:        52000 | elapsed time per iteration (ms): 323.0 | learning rate: 1.499630E-04 | global batch size:     8 | lm loss: 4.907317E+00 | loss scale: 262144.0 | grad norm: 0.949 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 07:23:06] iteration     6600/  500000 | consumed samples:        52800 | elapsed time per iteration (ms): 322.8 | learning rate: 1.499607E-04 | global batch size:     8 | lm loss: 4.864505E+00 | loss scale: 262144.0 | grad norm: 0.870 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 07:23:38] iteration     6700/  500000 | consumed samples:        53600 | elapsed time per iteration (ms): 322.0 | learning rate: 1.499584E-04 | global batch size:     8 | lm loss: 4.846080E+00 | loss scale: 524288.0 | grad norm: 1.096 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-21 07:24:11] iteration     6800/  500000 | consumed samples:        54400 | elapsed time per iteration (ms): 322.1 | learning rate: 1.499560E-04 | global batch size:     8 | lm loss: 4.827372E+00 | loss scale: 131072.0 | grad norm: 0.803 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-21 07:24:43] iteration     6900/  500000 | consumed samples:        55200 | elapsed time per iteration (ms): 323.0 | learning rate: 1.499535E-04 | global batch size:     8 | lm loss: 4.827448E+00 | loss scale: 131072.0 | grad norm: 0.818 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 07:25:15] iteration     7000/  500000 | consumed samples:        56000 | elapsed time per iteration (ms): 320.9 | learning rate: 1.499510E-04 | global batch size:     8 | lm loss: 4.770512E+00 | loss scale: 131072.0 | grad norm: 0.917 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1063.57, 1063.57)
------------------------------------------------------------------------------------------------
 validation loss at iteration 7000 | lm loss value: 4.710091E+00 | lm loss PPL: 1.110623E+02 | 
------------------------------------------------------------------------------------------------
 [2024-06-21 07:25:48] iteration     7100/  500000 | consumed samples:        56800 | elapsed time per iteration (ms): 321.1 | learning rate: 1.499483E-04 | global batch size:     8 | lm loss: 4.793965E+00 | loss scale: 131072.0 | grad norm: 0.865 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 07:26:20] iteration     7200/  500000 | consumed samples:        57600 | elapsed time per iteration (ms): 322.7 | learning rate: 1.499456E-04 | global batch size:     8 | lm loss: 4.782191E+00 | loss scale: 131072.0 | grad norm: 0.756 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 07:26:53] iteration     7300/  500000 | consumed samples:        58400 | elapsed time per iteration (ms): 321.0 | learning rate: 1.499429E-04 | global batch size:     8 | lm loss: 4.779688E+00 | loss scale: 131072.0 | grad norm: 0.961 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 07:27:25] iteration     7400/  500000 | consumed samples:        59200 | elapsed time per iteration (ms): 321.2 | learning rate: 1.499400E-04 | global batch size:     8 | lm loss: 4.777802E+00 | loss scale: 65536.0 | grad norm: 0.864 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-21 07:27:57] iteration     7500/  500000 | consumed samples:        60000 | elapsed time per iteration (ms): 321.5 | learning rate: 1.499371E-04 | global batch size:     8 | lm loss: 4.724415E+00 | loss scale: 65536.0 | grad norm: 0.769 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 07:28:29] iteration     7600/  500000 | consumed samples:        60800 | elapsed time per iteration (ms): 323.0 | learning rate: 1.499342E-04 | global batch size:     8 | lm loss: 4.717384E+00 | loss scale: 65536.0 | grad norm: 0.912 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 07:29:01] iteration     7700/  500000 | consumed samples:        61600 | elapsed time per iteration (ms): 321.5 | learning rate: 1.499311E-04 | global batch size:     8 | lm loss: 4.719268E+00 | loss scale: 65536.0 | grad norm: 0.780 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 07:29:33] iteration     7800/  500000 | consumed samples:        62400 | elapsed time per iteration (ms): 321.9 | learning rate: 1.499280E-04 | global batch size:     8 | lm loss: 4.721491E+00 | loss scale: 65536.0 | grad norm: 0.826 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 07:30:06] iteration     7900/  500000 | consumed samples:        63200 | elapsed time per iteration (ms): 324.1 | learning rate: 1.499248E-04 | global batch size:     8 | lm loss: 4.683647E+00 | loss scale: 65536.0 | grad norm: 0.752 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 07:30:38] iteration     8000/  500000 | consumed samples:        64000 | elapsed time per iteration (ms): 322.2 | learning rate: 1.499216E-04 | global batch size:     8 | lm loss: 4.691547E+00 | loss scale: 65536.0 | grad norm: 0.778 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1067.26, 1067.26)
------------------------------------------------------------------------------------------------
 validation loss at iteration 8000 | lm loss value: 4.629719E+00 | lm loss PPL: 1.024852E+02 | 
------------------------------------------------------------------------------------------------
 [2024-06-21 07:31:11] iteration     8100/  500000 | consumed samples:        64800 | elapsed time per iteration (ms): 321.7 | learning rate: 1.499183E-04 | global batch size:     8 | lm loss: 4.660337E+00 | loss scale: 65536.0 | grad norm: 1.121 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 07:31:44] iteration     8200/  500000 | consumed samples:        65600 | elapsed time per iteration (ms): 322.4 | learning rate: 1.499149E-04 | global batch size:     8 | lm loss: 4.676445E+00 | loss scale: 65536.0 | grad norm: 0.762 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 07:32:16] iteration     8300/  500000 | consumed samples:        66400 | elapsed time per iteration (ms): 322.1 | learning rate: 1.499114E-04 | global batch size:     8 | lm loss: 4.674102E+00 | loss scale: 65536.0 | grad norm: 0.889 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 07:32:48] iteration     8400/  500000 | consumed samples:        67200 | elapsed time per iteration (ms): 322.9 | learning rate: 1.499079E-04 | global batch size:     8 | lm loss: 4.676335E+00 | loss scale: 131072.0 | grad norm: 0.738 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 07:33:20] iteration     8500/  500000 | consumed samples:        68000 | elapsed time per iteration (ms): 320.4 | learning rate: 1.499043E-04 | global batch size:     8 | lm loss: 4.662207E+00 | loss scale: 131072.0 | grad norm: 0.761 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 07:33:52] iteration     8600/  500000 | consumed samples:        68800 | elapsed time per iteration (ms): 320.0 | learning rate: 1.499006E-04 | global batch size:     8 | lm loss: 4.630305E+00 | loss scale: 131072.0 | grad norm: 0.821 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 07:34:24] iteration     8700/  500000 | consumed samples:        69600 | elapsed time per iteration (ms): 324.0 | learning rate: 1.498969E-04 | global batch size:     8 | lm loss: 4.615967E+00 | loss scale: 131072.0 | grad norm: 0.796 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 07:34:57] iteration     8800/  500000 | consumed samples:        70400 | elapsed time per iteration (ms): 324.2 | learning rate: 1.498931E-04 | global batch size:     8 | lm loss: 4.602652E+00 | loss scale: 131072.0 | grad norm: 0.754 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 07:35:29] iteration     8900/  500000 | consumed samples:        71200 | elapsed time per iteration (ms): 323.7 | learning rate: 1.498892E-04 | global batch size:     8 | lm loss: 4.583784E+00 | loss scale: 131072.0 | grad norm: 0.725 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 07:36:02] iteration     9000/  500000 | consumed samples:        72000 | elapsed time per iteration (ms): 323.6 | learning rate: 1.498853E-04 | global batch size:     8 | lm loss: 4.598717E+00 | loss scale: 131072.0 | grad norm: 0.747 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1065.51, 1065.51)
------------------------------------------------------------------------------------------------
 validation loss at iteration 9000 | lm loss value: 4.593406E+00 | lm loss PPL: 9.883049E+01 | 
------------------------------------------------------------------------------------------------
 [2024-06-21 07:36:35] iteration     9100/  500000 | consumed samples:        72800 | elapsed time per iteration (ms): 323.2 | learning rate: 1.498813E-04 | global batch size:     8 | lm loss: 4.577106E+00 | loss scale: 131072.0 | grad norm: 0.711 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 07:37:07] iteration     9200/  500000 | consumed samples:        73600 | elapsed time per iteration (ms): 322.9 | learning rate: 1.498772E-04 | global batch size:     8 | lm loss: 4.584185E+00 | loss scale: 131072.0 | grad norm: 0.745 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 07:37:40] iteration     9300/  500000 | consumed samples:        74400 | elapsed time per iteration (ms): 323.3 | learning rate: 1.498731E-04 | global batch size:     8 | lm loss: 4.572428E+00 | loss scale: 131072.0 | grad norm: 0.710 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 07:38:12] iteration     9400/  500000 | consumed samples:        75200 | elapsed time per iteration (ms): 321.3 | learning rate: 1.498688E-04 | global batch size:     8 | lm loss: 4.567594E+00 | loss scale: 262144.0 | grad norm: 0.778 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 07:38:44] iteration     9500/  500000 | consumed samples:        76000 | elapsed time per iteration (ms): 321.9 | learning rate: 1.498646E-04 | global batch size:     8 | lm loss: 4.578477E+00 | loss scale: 262144.0 | grad norm: 0.807 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 07:39:16] iteration     9600/  500000 | consumed samples:        76800 | elapsed time per iteration (ms): 321.7 | learning rate: 1.498602E-04 | global batch size:     8 | lm loss: 4.529072E+00 | loss scale: 262144.0 | grad norm: 0.737 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 07:39:48] iteration     9700/  500000 | consumed samples:        77600 | elapsed time per iteration (ms): 320.1 | learning rate: 1.498558E-04 | global batch size:     8 | lm loss: 4.544579E+00 | loss scale: 262144.0 | grad norm: 0.842 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 07:40:20] iteration     9800/  500000 | consumed samples:        78400 | elapsed time per iteration (ms): 319.6 | learning rate: 1.498513E-04 | global batch size:     8 | lm loss: 4.514339E+00 | loss scale: 262144.0 | grad norm: 0.982 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 07:40:52] iteration     9900/  500000 | consumed samples:        79200 | elapsed time per iteration (ms): 323.1 | learning rate: 1.498467E-04 | global batch size:     8 | lm loss: 4.559193E+00 | loss scale: 262144.0 | grad norm: 0.786 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 07:41:25] iteration    10000/  500000 | consumed samples:        80000 | elapsed time per iteration (ms): 321.9 | learning rate: 1.498421E-04 | global batch size:     8 | lm loss: 4.506695E+00 | loss scale: 262144.0 | grad norm: 0.699 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1063.20, 1063.20)
-------------------------------------------------------------------------------------------------
 validation loss at iteration 10000 | lm loss value: 4.548869E+00 | lm loss PPL: 9.452541E+01 | 
-------------------------------------------------------------------------------------------------
saving checkpoint at iteration   10000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-max in torch format
  successfully saved checkpoint at iteration   10000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-max
(min, max) time across ranks (ms):
    save-checkpoint ................................: (5777.43, 5777.43)
 [2024-06-21 07:42:04] iteration    10100/  500000 | consumed samples:        80800 | elapsed time per iteration (ms): 323.2 | learning rate: 1.498374E-04 | global batch size:     8 | lm loss: 4.522247E+00 | loss scale: 262144.0 | grad norm: 0.762 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 07:42:36] iteration    10200/  500000 | consumed samples:        81600 | elapsed time per iteration (ms): 321.5 | learning rate: 1.498327E-04 | global batch size:     8 | lm loss: 4.594060E+00 | loss scale: 262144.0 | grad norm: 0.759 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 07:43:08] iteration    10300/  500000 | consumed samples:        82400 | elapsed time per iteration (ms): 321.5 | learning rate: 1.498279E-04 | global batch size:     8 | lm loss: 4.521455E+00 | loss scale: 262144.0 | grad norm: 0.706 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-21 07:43:40] iteration    10400/  500000 | consumed samples:        83200 | elapsed time per iteration (ms): 321.3 | learning rate: 1.498230E-04 | global batch size:     8 | lm loss: 4.473603E+00 | loss scale: 131072.0 | grad norm: 0.963 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-21 07:44:13] iteration    10500/  500000 | consumed samples:        84000 | elapsed time per iteration (ms): 323.1 | learning rate: 1.498181E-04 | global batch size:     8 | lm loss: 4.478460E+00 | loss scale: 65536.0 | grad norm: 0.935 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-21 07:44:45] iteration    10600/  500000 | consumed samples:        84800 | elapsed time per iteration (ms): 321.8 | learning rate: 1.498131E-04 | global batch size:     8 | lm loss: 4.504015E+00 | loss scale: 65536.0 | grad norm: 0.718 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 07:45:17] iteration    10700/  500000 | consumed samples:        85600 | elapsed time per iteration (ms): 322.9 | learning rate: 1.498080E-04 | global batch size:     8 | lm loss: 4.504978E+00 | loss scale: 65536.0 | grad norm: 0.766 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 07:45:49] iteration    10800/  500000 | consumed samples:        86400 | elapsed time per iteration (ms): 324.6 | learning rate: 1.498028E-04 | global batch size:     8 | lm loss: 4.481190E+00 | loss scale: 65536.0 | grad norm: 1.333 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 07:46:21] iteration    10900/  500000 | consumed samples:        87200 | elapsed time per iteration (ms): 320.3 | learning rate: 1.497976E-04 | global batch size:     8 | lm loss: 4.459887E+00 | loss scale: 65536.0 | grad norm: 0.797 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 07:46:54] iteration    11000/  500000 | consumed samples:        88000 | elapsed time per iteration (ms): 320.3 | learning rate: 1.497923E-04 | global batch size:     8 | lm loss: 4.461056E+00 | loss scale: 32768.0 | grad norm: 0.703 | number of skipped iterations:   1 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1063.61, 1063.61)
-------------------------------------------------------------------------------------------------
 validation loss at iteration 11000 | lm loss value: 4.407737E+00 | lm loss PPL: 8.208352E+01 | 
-------------------------------------------------------------------------------------------------
 [2024-06-21 07:47:27] iteration    11100/  500000 | consumed samples:        88800 | elapsed time per iteration (ms): 321.2 | learning rate: 1.497869E-04 | global batch size:     8 | lm loss: 4.450923E+00 | loss scale: 32768.0 | grad norm: 0.707 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 07:47:59] iteration    11200/  500000 | consumed samples:        89600 | elapsed time per iteration (ms): 323.2 | learning rate: 1.497815E-04 | global batch size:     8 | lm loss: 4.469844E+00 | loss scale: 32768.0 | grad norm: 0.734 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 07:48:31] iteration    11300/  500000 | consumed samples:        90400 | elapsed time per iteration (ms): 320.8 | learning rate: 1.497760E-04 | global batch size:     8 | lm loss: 4.422798E+00 | loss scale: 32768.0 | grad norm: 0.848 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 07:49:03] iteration    11400/  500000 | consumed samples:        91200 | elapsed time per iteration (ms): 321.2 | learning rate: 1.497704E-04 | global batch size:     8 | lm loss: 4.446373E+00 | loss scale: 32768.0 | grad norm: 0.823 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 07:49:35] iteration    11500/  500000 | consumed samples:        92000 | elapsed time per iteration (ms): 321.4 | learning rate: 1.497647E-04 | global batch size:     8 | lm loss: 4.465115E+00 | loss scale: 32768.0 | grad norm: 0.704 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 07:50:07] iteration    11600/  500000 | consumed samples:        92800 | elapsed time per iteration (ms): 321.1 | learning rate: 1.497590E-04 | global batch size:     8 | lm loss: 4.422662E+00 | loss scale: 32768.0 | grad norm: 0.734 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 07:50:39] iteration    11700/  500000 | consumed samples:        93600 | elapsed time per iteration (ms): 320.0 | learning rate: 1.497532E-04 | global batch size:     8 | lm loss: 4.451390E+00 | loss scale: 32768.0 | grad norm: 0.719 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 07:51:12] iteration    11800/  500000 | consumed samples:        94400 | elapsed time per iteration (ms): 321.4 | learning rate: 1.497474E-04 | global batch size:     8 | lm loss: 4.415098E+00 | loss scale: 32768.0 | grad norm: 0.755 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 07:51:44] iteration    11900/  500000 | consumed samples:        95200 | elapsed time per iteration (ms): 322.3 | learning rate: 1.497414E-04 | global batch size:     8 | lm loss: 4.440289E+00 | loss scale: 32768.0 | grad norm: 0.702 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 07:52:16] iteration    12000/  500000 | consumed samples:        96000 | elapsed time per iteration (ms): 322.8 | learning rate: 1.497354E-04 | global batch size:     8 | lm loss: 4.395846E+00 | loss scale: 65536.0 | grad norm: 0.727 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1063.86, 1063.86)
-------------------------------------------------------------------------------------------------
 validation loss at iteration 12000 | lm loss value: 4.329156E+00 | lm loss PPL: 7.588021E+01 | 
-------------------------------------------------------------------------------------------------
 [2024-06-21 07:52:49] iteration    12100/  500000 | consumed samples:        96800 | elapsed time per iteration (ms): 322.3 | learning rate: 1.497294E-04 | global batch size:     8 | lm loss: 4.433280E+00 | loss scale: 65536.0 | grad norm: 0.749 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 07:53:22] iteration    12200/  500000 | consumed samples:        97600 | elapsed time per iteration (ms): 323.3 | learning rate: 1.497232E-04 | global batch size:     8 | lm loss: 4.383402E+00 | loss scale: 65536.0 | grad norm: 0.680 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 07:53:54] iteration    12300/  500000 | consumed samples:        98400 | elapsed time per iteration (ms): 324.7 | learning rate: 1.497170E-04 | global batch size:     8 | lm loss: 4.429848E+00 | loss scale: 65536.0 | grad norm: 0.774 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 07:54:26] iteration    12400/  500000 | consumed samples:        99200 | elapsed time per iteration (ms): 322.6 | learning rate: 1.497108E-04 | global batch size:     8 | lm loss: 4.382687E+00 | loss scale: 65536.0 | grad norm: 0.710 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 07:54:59] iteration    12500/  500000 | consumed samples:       100000 | elapsed time per iteration (ms): 322.1 | learning rate: 1.497044E-04 | global batch size:     8 | lm loss: 4.394322E+00 | loss scale: 65536.0 | grad norm: 0.717 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 07:55:31] iteration    12600/  500000 | consumed samples:       100800 | elapsed time per iteration (ms): 322.2 | learning rate: 1.496980E-04 | global batch size:     8 | lm loss: 4.345831E+00 | loss scale: 65536.0 | grad norm: 0.747 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 07:56:03] iteration    12700/  500000 | consumed samples:       101600 | elapsed time per iteration (ms): 321.0 | learning rate: 1.496916E-04 | global batch size:     8 | lm loss: 4.424470E+00 | loss scale: 65536.0 | grad norm: 0.789 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 07:56:35] iteration    12800/  500000 | consumed samples:       102400 | elapsed time per iteration (ms): 322.6 | learning rate: 1.496850E-04 | global batch size:     8 | lm loss: 4.391853E+00 | loss scale: 65536.0 | grad norm: 0.735 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 07:57:08] iteration    12900/  500000 | consumed samples:       103200 | elapsed time per iteration (ms): 322.7 | learning rate: 1.496784E-04 | global batch size:     8 | lm loss: 4.368968E+00 | loss scale: 65536.0 | grad norm: 0.711 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 07:57:40] iteration    13000/  500000 | consumed samples:       104000 | elapsed time per iteration (ms): 324.6 | learning rate: 1.496717E-04 | global batch size:     8 | lm loss: 4.335243E+00 | loss scale: 131072.0 | grad norm: 0.768 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1064.03, 1064.03)
-------------------------------------------------------------------------------------------------
 validation loss at iteration 13000 | lm loss value: 4.401270E+00 | lm loss PPL: 8.155437E+01 | 
-------------------------------------------------------------------------------------------------
 [2024-06-21 07:58:14] iteration    13100/  500000 | consumed samples:       104800 | elapsed time per iteration (ms): 324.7 | learning rate: 1.496650E-04 | global batch size:     8 | lm loss: 4.335031E+00 | loss scale: 131072.0 | grad norm: 0.739 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 07:58:46] iteration    13200/  500000 | consumed samples:       105600 | elapsed time per iteration (ms): 324.8 | learning rate: 1.496582E-04 | global batch size:     8 | lm loss: 4.377138E+00 | loss scale: 131072.0 | grad norm: 0.723 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 07:59:18] iteration    13300/  500000 | consumed samples:       106400 | elapsed time per iteration (ms): 323.2 | learning rate: 1.496513E-04 | global batch size:     8 | lm loss: 4.323987E+00 | loss scale: 131072.0 | grad norm: 0.776 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 07:59:51] iteration    13400/  500000 | consumed samples:       107200 | elapsed time per iteration (ms): 324.4 | learning rate: 1.496443E-04 | global batch size:     8 | lm loss: 4.355246E+00 | loss scale: 131072.0 | grad norm: 0.963 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 08:00:23] iteration    13500/  500000 | consumed samples:       108000 | elapsed time per iteration (ms): 321.4 | learning rate: 1.496373E-04 | global batch size:     8 | lm loss: 4.345407E+00 | loss scale: 131072.0 | grad norm: 0.694 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 08:00:55] iteration    13600/  500000 | consumed samples:       108800 | elapsed time per iteration (ms): 321.1 | learning rate: 1.496302E-04 | global batch size:     8 | lm loss: 4.367559E+00 | loss scale: 131072.0 | grad norm: 0.705 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 08:01:27] iteration    13700/  500000 | consumed samples:       109600 | elapsed time per iteration (ms): 321.4 | learning rate: 1.496230E-04 | global batch size:     8 | lm loss: 4.353635E+00 | loss scale: 131072.0 | grad norm: 0.702 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 08:01:59] iteration    13800/  500000 | consumed samples:       110400 | elapsed time per iteration (ms): 321.2 | learning rate: 1.496158E-04 | global batch size:     8 | lm loss: 4.325171E+00 | loss scale: 131072.0 | grad norm: 0.738 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 08:02:31] iteration    13900/  500000 | consumed samples:       111200 | elapsed time per iteration (ms): 321.8 | learning rate: 1.496085E-04 | global batch size:     8 | lm loss: 4.312605E+00 | loss scale: 131072.0 | grad norm: 0.683 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 08:03:04] iteration    14000/  500000 | consumed samples:       112000 | elapsed time per iteration (ms): 323.4 | learning rate: 1.496011E-04 | global batch size:     8 | lm loss: 4.335760E+00 | loss scale: 262144.0 | grad norm: 0.657 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1063.41, 1063.41)
-------------------------------------------------------------------------------------------------
 validation loss at iteration 14000 | lm loss value: 4.290030E+00 | lm loss PPL: 7.296869E+01 | 
-------------------------------------------------------------------------------------------------
 [2024-06-21 08:03:37] iteration    14100/  500000 | consumed samples:       112800 | elapsed time per iteration (ms): 323.6 | learning rate: 1.495937E-04 | global batch size:     8 | lm loss: 4.348954E+00 | loss scale: 262144.0 | grad norm: 0.675 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 08:04:09] iteration    14200/  500000 | consumed samples:       113600 | elapsed time per iteration (ms): 321.2 | learning rate: 1.495862E-04 | global batch size:     8 | lm loss: 4.305666E+00 | loss scale: 262144.0 | grad norm: 0.707 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 08:04:41] iteration    14300/  500000 | consumed samples:       114400 | elapsed time per iteration (ms): 319.6 | learning rate: 1.495787E-04 | global batch size:     8 | lm loss: 4.315166E+00 | loss scale: 262144.0 | grad norm: 0.657 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-21 08:05:14] iteration    14400/  500000 | consumed samples:       115200 | elapsed time per iteration (ms): 323.3 | learning rate: 1.495711E-04 | global batch size:     8 | lm loss: 4.330689E+00 | loss scale: 262144.0 | grad norm: 0.713 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 08:05:46] iteration    14500/  500000 | consumed samples:       116000 | elapsed time per iteration (ms): 322.6 | learning rate: 1.495634E-04 | global batch size:     8 | lm loss: 4.321805E+00 | loss scale: 262144.0 | grad norm: 0.748 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 08:06:18] iteration    14600/  500000 | consumed samples:       116800 | elapsed time per iteration (ms): 320.8 | learning rate: 1.495557E-04 | global batch size:     8 | lm loss: 4.342363E+00 | loss scale: 131072.0 | grad norm: 3.920 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-21 08:06:50] iteration    14700/  500000 | consumed samples:       117600 | elapsed time per iteration (ms): 321.0 | learning rate: 1.495478E-04 | global batch size:     8 | lm loss: 4.338402E+00 | loss scale: 131072.0 | grad norm: 0.716 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 08:07:22] iteration    14800/  500000 | consumed samples:       118400 | elapsed time per iteration (ms): 321.9 | learning rate: 1.495399E-04 | global batch size:     8 | lm loss: 4.285276E+00 | loss scale: 131072.0 | grad norm: 0.789 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 08:07:55] iteration    14900/  500000 | consumed samples:       119200 | elapsed time per iteration (ms): 323.4 | learning rate: 1.495320E-04 | global batch size:     8 | lm loss: 4.333201E+00 | loss scale: 65536.0 | grad norm: 0.692 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-21 08:08:27] iteration    15000/  500000 | consumed samples:       120000 | elapsed time per iteration (ms): 320.6 | learning rate: 1.495240E-04 | global batch size:     8 | lm loss: 4.265814E+00 | loss scale: 65536.0 | grad norm: 0.681 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1062.84, 1062.84)
-------------------------------------------------------------------------------------------------
 validation loss at iteration 15000 | lm loss value: 4.407818E+00 | lm loss PPL: 8.209017E+01 | 
-------------------------------------------------------------------------------------------------
 [2024-06-21 08:09:00] iteration    15100/  500000 | consumed samples:       120800 | elapsed time per iteration (ms): 321.2 | learning rate: 1.495159E-04 | global batch size:     8 | lm loss: 4.294487E+00 | loss scale: 65536.0 | grad norm: 0.707 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 08:09:32] iteration    15200/  500000 | consumed samples:       121600 | elapsed time per iteration (ms): 322.1 | learning rate: 1.495077E-04 | global batch size:     8 | lm loss: 4.289866E+00 | loss scale: 65536.0 | grad norm: 0.681 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 08:10:04] iteration    15300/  500000 | consumed samples:       122400 | elapsed time per iteration (ms): 320.2 | learning rate: 1.494994E-04 | global batch size:     8 | lm loss: 4.270438E+00 | loss scale: 65536.0 | grad norm: 0.714 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 08:10:36] iteration    15400/  500000 | consumed samples:       123200 | elapsed time per iteration (ms): 322.3 | learning rate: 1.494911E-04 | global batch size:     8 | lm loss: 4.275388E+00 | loss scale: 65536.0 | grad norm: 0.783 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 08:11:08] iteration    15500/  500000 | consumed samples:       124000 | elapsed time per iteration (ms): 321.7 | learning rate: 1.494827E-04 | global batch size:     8 | lm loss: 4.288937E+00 | loss scale: 65536.0 | grad norm: 0.642 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 08:11:41] iteration    15600/  500000 | consumed samples:       124800 | elapsed time per iteration (ms): 322.0 | learning rate: 1.494742E-04 | global batch size:     8 | lm loss: 4.256791E+00 | loss scale: 65536.0 | grad norm: 0.665 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 08:12:13] iteration    15700/  500000 | consumed samples:       125600 | elapsed time per iteration (ms): 321.3 | learning rate: 1.494657E-04 | global batch size:     8 | lm loss: 4.302364E+00 | loss scale: 65536.0 | grad norm: 0.707 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 08:12:45] iteration    15800/  500000 | consumed samples:       126400 | elapsed time per iteration (ms): 320.6 | learning rate: 1.494571E-04 | global batch size:     8 | lm loss: 4.278472E+00 | loss scale: 65536.0 | grad norm: 0.651 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 08:13:17] iteration    15900/  500000 | consumed samples:       127200 | elapsed time per iteration (ms): 320.8 | learning rate: 1.494485E-04 | global batch size:     8 | lm loss: 4.268053E+00 | loss scale: 131072.0 | grad norm: 0.686 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 08:13:49] iteration    16000/  500000 | consumed samples:       128000 | elapsed time per iteration (ms): 321.4 | learning rate: 1.494397E-04 | global batch size:     8 | lm loss: 4.275836E+00 | loss scale: 131072.0 | grad norm: 0.671 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1064.61, 1064.61)
-------------------------------------------------------------------------------------------------
 validation loss at iteration 16000 | lm loss value: 4.260414E+00 | lm loss PPL: 7.083928E+01 | 
-------------------------------------------------------------------------------------------------
 [2024-06-21 08:14:22] iteration    16100/  500000 | consumed samples:       128800 | elapsed time per iteration (ms): 321.9 | learning rate: 1.494311E-04 | global batch size:     8 | lm loss: 4.270626E+00 | loss scale: 65536.0 | grad norm: 0.736 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-21 08:14:55] iteration    16200/  500000 | consumed samples:       129600 | elapsed time per iteration (ms): 322.4 | learning rate: 1.494222E-04 | global batch size:     8 | lm loss: 4.234111E+00 | loss scale: 65536.0 | grad norm: 2.714 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 08:15:27] iteration    16300/  500000 | consumed samples:       130400 | elapsed time per iteration (ms): 320.0 | learning rate: 1.494133E-04 | global batch size:     8 | lm loss: 4.279736E+00 | loss scale: 65536.0 | grad norm: 0.706 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 08:15:59] iteration    16400/  500000 | consumed samples:       131200 | elapsed time per iteration (ms): 320.8 | learning rate: 1.494043E-04 | global batch size:     8 | lm loss: 4.255096E+00 | loss scale: 65536.0 | grad norm: 0.676 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 08:16:31] iteration    16500/  500000 | consumed samples:       132000 | elapsed time per iteration (ms): 322.8 | learning rate: 1.493952E-04 | global batch size:     8 | lm loss: 4.261606E+00 | loss scale: 65536.0 | grad norm: 0.757 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 08:17:03] iteration    16600/  500000 | consumed samples:       132800 | elapsed time per iteration (ms): 322.7 | learning rate: 1.493861E-04 | global batch size:     8 | lm loss: 4.217724E+00 | loss scale: 65536.0 | grad norm: 0.677 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 08:17:35] iteration    16700/  500000 | consumed samples:       133600 | elapsed time per iteration (ms): 320.4 | learning rate: 1.493769E-04 | global batch size:     8 | lm loss: 4.261521E+00 | loss scale: 65536.0 | grad norm: 11.934 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 08:18:08] iteration    16800/  500000 | consumed samples:       134400 | elapsed time per iteration (ms): 324.3 | learning rate: 1.493676E-04 | global batch size:     8 | lm loss: 4.231875E+00 | loss scale: 65536.0 | grad norm: 0.672 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 08:18:40] iteration    16900/  500000 | consumed samples:       135200 | elapsed time per iteration (ms): 321.7 | learning rate: 1.493583E-04 | global batch size:     8 | lm loss: 4.248279E+00 | loss scale: 65536.0 | grad norm: 0.655 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 08:19:12] iteration    17000/  500000 | consumed samples:       136000 | elapsed time per iteration (ms): 320.8 | learning rate: 1.493489E-04 | global batch size:     8 | lm loss: 4.222460E+00 | loss scale: 65536.0 | grad norm: 0.711 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1066.40, 1066.40)
-------------------------------------------------------------------------------------------------
 validation loss at iteration 17000 | lm loss value: 4.337047E+00 | lm loss PPL: 7.648136E+01 | 
-------------------------------------------------------------------------------------------------
 [2024-06-21 08:19:45] iteration    17100/  500000 | consumed samples:       136800 | elapsed time per iteration (ms): 321.7 | learning rate: 1.493394E-04 | global batch size:     8 | lm loss: 4.234426E+00 | loss scale: 131072.0 | grad norm: 0.687 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 08:20:17] iteration    17200/  500000 | consumed samples:       137600 | elapsed time per iteration (ms): 322.5 | learning rate: 1.493298E-04 | global batch size:     8 | lm loss: 4.208314E+00 | loss scale: 131072.0 | grad norm: 0.651 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 08:20:50] iteration    17300/  500000 | consumed samples:       138400 | elapsed time per iteration (ms): 324.2 | learning rate: 1.493202E-04 | global batch size:     8 | lm loss: 4.217886E+00 | loss scale: 131072.0 | grad norm: 0.687 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 08:21:22] iteration    17400/  500000 | consumed samples:       139200 | elapsed time per iteration (ms): 320.3 | learning rate: 1.493106E-04 | global batch size:     8 | lm loss: 4.213104E+00 | loss scale: 131072.0 | grad norm: 0.684 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-21 08:21:54] iteration    17500/  500000 | consumed samples:       140000 | elapsed time per iteration (ms): 322.3 | learning rate: 1.493009E-04 | global batch size:     8 | lm loss: 4.242779E+00 | loss scale: 131072.0 | grad norm: 0.632 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 08:22:26] iteration    17600/  500000 | consumed samples:       140800 | elapsed time per iteration (ms): 322.8 | learning rate: 1.492911E-04 | global batch size:     8 | lm loss: 4.216852E+00 | loss scale: 131072.0 | grad norm: 2.199 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 08:22:59] iteration    17700/  500000 | consumed samples:       141600 | elapsed time per iteration (ms): 323.5 | learning rate: 1.492812E-04 | global batch size:     8 | lm loss: 4.190327E+00 | loss scale: 131072.0 | grad norm: 0.669 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 08:23:31] iteration    17800/  500000 | consumed samples:       142400 | elapsed time per iteration (ms): 322.6 | learning rate: 1.492712E-04 | global batch size:     8 | lm loss: 4.195511E+00 | loss scale: 131072.0 | grad norm: 0.701 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 08:24:03] iteration    17900/  500000 | consumed samples:       143200 | elapsed time per iteration (ms): 323.1 | learning rate: 1.492612E-04 | global batch size:     8 | lm loss: 4.188412E+00 | loss scale: 131072.0 | grad norm: 0.833 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 08:24:36] iteration    18000/  500000 | consumed samples:       144000 | elapsed time per iteration (ms): 322.6 | learning rate: 1.492511E-04 | global batch size:     8 | lm loss: 4.184476E+00 | loss scale: 131072.0 | grad norm: 0.700 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1063.82, 1063.82)
-------------------------------------------------------------------------------------------------
 validation loss at iteration 18000 | lm loss value: 4.203533E+00 | lm loss PPL: 6.692236E+01 | 
-------------------------------------------------------------------------------------------------
 [2024-06-21 08:25:09] iteration    18100/  500000 | consumed samples:       144800 | elapsed time per iteration (ms): 322.2 | learning rate: 1.492409E-04 | global batch size:     8 | lm loss: 4.200034E+00 | loss scale: 131072.0 | grad norm: 0.741 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 08:25:41] iteration    18200/  500000 | consumed samples:       145600 | elapsed time per iteration (ms): 321.5 | learning rate: 1.492307E-04 | global batch size:     8 | lm loss: 4.190217E+00 | loss scale: 131072.0 | grad norm: 0.750 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 08:26:13] iteration    18300/  500000 | consumed samples:       146400 | elapsed time per iteration (ms): 321.6 | learning rate: 1.492204E-04 | global batch size:     8 | lm loss: 4.205833E+00 | loss scale: 131072.0 | grad norm: 0.666 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 08:26:45] iteration    18400/  500000 | consumed samples:       147200 | elapsed time per iteration (ms): 322.1 | learning rate: 1.492100E-04 | global batch size:     8 | lm loss: 4.172365E+00 | loss scale: 262144.0 | grad norm: 0.632 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 08:27:17] iteration    18500/  500000 | consumed samples:       148000 | elapsed time per iteration (ms): 321.0 | learning rate: 1.491997E-04 | global batch size:     8 | lm loss: 4.177634E+00 | loss scale: 262144.0 | grad norm: 0.722 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-21 08:27:50] iteration    18600/  500000 | consumed samples:       148800 | elapsed time per iteration (ms): 322.8 | learning rate: 1.491893E-04 | global batch size:     8 | lm loss: 4.195931E+00 | loss scale: 131072.0 | grad norm: 0.685 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-21 08:28:22] iteration    18700/  500000 | consumed samples:       149600 | elapsed time per iteration (ms): 320.5 | learning rate: 1.491787E-04 | global batch size:     8 | lm loss: 4.188414E+00 | loss scale: 131072.0 | grad norm: 0.705 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 08:28:54] iteration    18800/  500000 | consumed samples:       150400 | elapsed time per iteration (ms): 321.7 | learning rate: 1.491681E-04 | global batch size:     8 | lm loss: 4.217861E+00 | loss scale: 131072.0 | grad norm: 0.685 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 08:29:26] iteration    18900/  500000 | consumed samples:       151200 | elapsed time per iteration (ms): 321.5 | learning rate: 1.491574E-04 | global batch size:     8 | lm loss: 4.212344E+00 | loss scale: 131072.0 | grad norm: 0.683 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 08:29:58] iteration    19000/  500000 | consumed samples:       152000 | elapsed time per iteration (ms): 321.7 | learning rate: 1.491466E-04 | global batch size:     8 | lm loss: 4.208262E+00 | loss scale: 131072.0 | grad norm: 0.780 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1064.51, 1064.51)
-------------------------------------------------------------------------------------------------
 validation loss at iteration 19000 | lm loss value: 4.160477E+00 | lm loss PPL: 6.410207E+01 | 
-------------------------------------------------------------------------------------------------
 [2024-06-21 08:30:31] iteration    19100/  500000 | consumed samples:       152800 | elapsed time per iteration (ms): 321.6 | learning rate: 1.491358E-04 | global batch size:     8 | lm loss: 4.177873E+00 | loss scale: 131072.0 | grad norm: 0.760 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 08:31:04] iteration    19200/  500000 | consumed samples:       153600 | elapsed time per iteration (ms): 320.9 | learning rate: 1.491249E-04 | global batch size:     8 | lm loss: 4.156003E+00 | loss scale: 131072.0 | grad norm: 0.729 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 08:31:36] iteration    19300/  500000 | consumed samples:       154400 | elapsed time per iteration (ms): 321.8 | learning rate: 1.491139E-04 | global batch size:     8 | lm loss: 4.113760E+00 | loss scale: 131072.0 | grad norm: 0.686 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 08:32:08] iteration    19400/  500000 | consumed samples:       155200 | elapsed time per iteration (ms): 320.4 | learning rate: 1.491029E-04 | global batch size:     8 | lm loss: 4.181488E+00 | loss scale: 131072.0 | grad norm: 0.646 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 08:32:40] iteration    19500/  500000 | consumed samples:       156000 | elapsed time per iteration (ms): 321.2 | learning rate: 1.490918E-04 | global batch size:     8 | lm loss: 4.163024E+00 | loss scale: 131072.0 | grad norm: 0.695 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 08:33:12] iteration    19600/  500000 | consumed samples:       156800 | elapsed time per iteration (ms): 322.1 | learning rate: 1.490806E-04 | global batch size:     8 | lm loss: 4.133088E+00 | loss scale: 262144.0 | grad norm: 0.701 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 08:33:44] iteration    19700/  500000 | consumed samples:       157600 | elapsed time per iteration (ms): 323.1 | learning rate: 1.490693E-04 | global batch size:     8 | lm loss: 4.177972E+00 | loss scale: 262144.0 | grad norm: 0.692 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 08:34:17] iteration    19800/  500000 | consumed samples:       158400 | elapsed time per iteration (ms): 322.3 | learning rate: 1.490580E-04 | global batch size:     8 | lm loss: 4.147320E+00 | loss scale: 262144.0 | grad norm: 0.671 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 08:34:49] iteration    19900/  500000 | consumed samples:       159200 | elapsed time per iteration (ms): 324.7 | learning rate: 1.490466E-04 | global batch size:     8 | lm loss: 4.165466E+00 | loss scale: 262144.0 | grad norm: 0.733 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 08:35:21] iteration    20000/  500000 | consumed samples:       160000 | elapsed time per iteration (ms): 320.7 | learning rate: 1.490352E-04 | global batch size:     8 | lm loss: 4.140732E+00 | loss scale: 262144.0 | grad norm: 0.649 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1063.45, 1063.45)
-------------------------------------------------------------------------------------------------
 validation loss at iteration 20000 | lm loss value: 4.276013E+00 | lm loss PPL: 7.195298E+01 | 
-------------------------------------------------------------------------------------------------
saving checkpoint at iteration   20000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-max in torch format
  successfully saved checkpoint at iteration   20000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-max
(min, max) time across ranks (ms):
    save-checkpoint ................................: (5676.03, 5676.03)
 [2024-06-21 08:36:00] iteration    20100/  500000 | consumed samples:       160800 | elapsed time per iteration (ms): 321.5 | learning rate: 1.490238E-04 | global batch size:     8 | lm loss: 4.170645E+00 | loss scale: 262144.0 | grad norm: 0.728 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-21 08:36:32] iteration    20200/  500000 | consumed samples:       161600 | elapsed time per iteration (ms): 322.3 | learning rate: 1.490122E-04 | global batch size:     8 | lm loss: 4.079478E+00 | loss scale: 262144.0 | grad norm: 0.639 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 08:37:04] iteration    20300/  500000 | consumed samples:       162400 | elapsed time per iteration (ms): 320.8 | learning rate: 1.490005E-04 | global batch size:     8 | lm loss: 4.172128E+00 | loss scale: 262144.0 | grad norm: 0.680 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 08:37:37] iteration    20400/  500000 | consumed samples:       163200 | elapsed time per iteration (ms): 322.3 | learning rate: 1.489888E-04 | global batch size:     8 | lm loss: 4.124893E+00 | loss scale: 262144.0 | grad norm: 0.736 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 08:38:09] iteration    20500/  500000 | consumed samples:       164000 | elapsed time per iteration (ms): 320.3 | learning rate: 1.489771E-04 | global batch size:     8 | lm loss: 4.174362E+00 | loss scale: 131072.0 | grad norm: 0.834 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-21 08:38:41] iteration    20600/  500000 | consumed samples:       164800 | elapsed time per iteration (ms): 322.4 | learning rate: 1.489653E-04 | global batch size:     8 | lm loss: 4.127561E+00 | loss scale: 131072.0 | grad norm: 0.635 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 08:39:13] iteration    20700/  500000 | consumed samples:       165600 | elapsed time per iteration (ms): 322.9 | learning rate: 1.489534E-04 | global batch size:     8 | lm loss: 4.097148E+00 | loss scale: 131072.0 | grad norm: 0.673 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 08:39:45] iteration    20800/  500000 | consumed samples:       166400 | elapsed time per iteration (ms): 319.8 | learning rate: 1.489414E-04 | global batch size:     8 | lm loss: 4.098697E+00 | loss scale: 131072.0 | grad norm: 0.830 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 08:40:17] iteration    20900/  500000 | consumed samples:       167200 | elapsed time per iteration (ms): 320.3 | learning rate: 1.489293E-04 | global batch size:     8 | lm loss: 4.114032E+00 | loss scale: 131072.0 | grad norm: 0.658 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 08:40:49] iteration    21000/  500000 | consumed samples:       168000 | elapsed time per iteration (ms): 322.4 | learning rate: 1.489172E-04 | global batch size:     8 | lm loss: 4.115847E+00 | loss scale: 131072.0 | grad norm: 0.703 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1064.61, 1064.61)
-------------------------------------------------------------------------------------------------
 validation loss at iteration 21000 | lm loss value: 4.131836E+00 | lm loss PPL: 6.229218E+01 | 
-------------------------------------------------------------------------------------------------
 [2024-06-21 08:41:23] iteration    21100/  500000 | consumed samples:       168800 | elapsed time per iteration (ms): 321.8 | learning rate: 1.489050E-04 | global batch size:     8 | lm loss: 4.118742E+00 | loss scale: 131072.0 | grad norm: 0.729 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 08:41:55] iteration    21200/  500000 | consumed samples:       169600 | elapsed time per iteration (ms): 321.3 | learning rate: 1.488927E-04 | global batch size:     8 | lm loss: 4.142379E+00 | loss scale: 131072.0 | grad norm: 0.693 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 08:42:27] iteration    21300/  500000 | consumed samples:       170400 | elapsed time per iteration (ms): 322.6 | learning rate: 1.488804E-04 | global batch size:     8 | lm loss: 4.115890E+00 | loss scale: 131072.0 | grad norm: 0.686 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 08:42:59] iteration    21400/  500000 | consumed samples:       171200 | elapsed time per iteration (ms): 323.1 | learning rate: 1.488680E-04 | global batch size:     8 | lm loss: 4.114395E+00 | loss scale: 131072.0 | grad norm: 0.630 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 08:43:31] iteration    21500/  500000 | consumed samples:       172000 | elapsed time per iteration (ms): 320.1 | learning rate: 1.488556E-04 | global batch size:     8 | lm loss: 4.131288E+00 | loss scale: 262144.0 | grad norm: 0.639 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-21 08:44:04] iteration    21600/  500000 | consumed samples:       172800 | elapsed time per iteration (ms): 321.2 | learning rate: 1.488431E-04 | global batch size:     8 | lm loss: 4.112875E+00 | loss scale: 262144.0 | grad norm: 0.682 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 08:44:35] iteration    21700/  500000 | consumed samples:       173600 | elapsed time per iteration (ms): 319.6 | learning rate: 1.488306E-04 | global batch size:     8 | lm loss: 4.108280E+00 | loss scale: 131072.0 | grad norm: 0.686 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-21 08:45:08] iteration    21800/  500000 | consumed samples:       174400 | elapsed time per iteration (ms): 320.7 | learning rate: 1.488180E-04 | global batch size:     8 | lm loss: 4.078402E+00 | loss scale: 131072.0 | grad norm: 0.804 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 08:45:40] iteration    21900/  500000 | consumed samples:       175200 | elapsed time per iteration (ms): 320.6 | learning rate: 1.488052E-04 | global batch size:     8 | lm loss: 4.116187E+00 | loss scale: 131072.0 | grad norm: 0.726 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 08:46:12] iteration    22000/  500000 | consumed samples:       176000 | elapsed time per iteration (ms): 322.4 | learning rate: 1.487925E-04 | global batch size:     8 | lm loss: 4.132981E+00 | loss scale: 65536.0 | grad norm: 0.700 | number of skipped iterations:   1 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1065.69, 1065.69)
-------------------------------------------------------------------------------------------------
 validation loss at iteration 22000 | lm loss value: 4.188906E+00 | lm loss PPL: 6.595061E+01 | 
-------------------------------------------------------------------------------------------------
 [2024-06-21 08:46:45] iteration    22100/  500000 | consumed samples:       176800 | elapsed time per iteration (ms): 322.3 | learning rate: 1.487797E-04 | global batch size:     8 | lm loss: 4.095055E+00 | loss scale: 65536.0 | grad norm: 0.647 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 08:47:17] iteration    22200/  500000 | consumed samples:       177600 | elapsed time per iteration (ms): 321.9 | learning rate: 1.487667E-04 | global batch size:     8 | lm loss: 4.122747E+00 | loss scale: 65536.0 | grad norm: 0.677 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 08:47:49] iteration    22300/  500000 | consumed samples:       178400 | elapsed time per iteration (ms): 321.0 | learning rate: 1.487537E-04 | global batch size:     8 | lm loss: 4.127892E+00 | loss scale: 65536.0 | grad norm: 0.650 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 08:48:22] iteration    22400/  500000 | consumed samples:       179200 | elapsed time per iteration (ms): 321.7 | learning rate: 1.487408E-04 | global batch size:     8 | lm loss: 4.068775E+00 | loss scale: 32768.0 | grad norm: 0.883 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-21 08:48:54] iteration    22500/  500000 | consumed samples:       180000 | elapsed time per iteration (ms): 324.6 | learning rate: 1.487276E-04 | global batch size:     8 | lm loss: 4.153367E+00 | loss scale: 32768.0 | grad norm: 0.701 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 08:49:26] iteration    22600/  500000 | consumed samples:       180800 | elapsed time per iteration (ms): 320.9 | learning rate: 1.487144E-04 | global batch size:     8 | lm loss: 4.085558E+00 | loss scale: 32768.0 | grad norm: 0.651 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 08:49:58] iteration    22700/  500000 | consumed samples:       181600 | elapsed time per iteration (ms): 322.4 | learning rate: 1.487012E-04 | global batch size:     8 | lm loss: 4.064018E+00 | loss scale: 32768.0 | grad norm: 0.710 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 08:50:31] iteration    22800/  500000 | consumed samples:       182400 | elapsed time per iteration (ms): 322.3 | learning rate: 1.486878E-04 | global batch size:     8 | lm loss: 4.078785E+00 | loss scale: 32768.0 | grad norm: 0.675 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 08:51:03] iteration    22900/  500000 | consumed samples:       183200 | elapsed time per iteration (ms): 320.5 | learning rate: 1.486744E-04 | global batch size:     8 | lm loss: 4.057924E+00 | loss scale: 32768.0 | grad norm: 0.625 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 08:51:35] iteration    23000/  500000 | consumed samples:       184000 | elapsed time per iteration (ms): 321.2 | learning rate: 1.486609E-04 | global batch size:     8 | lm loss: 4.073616E+00 | loss scale: 32768.0 | grad norm: 0.679 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1065.18, 1065.18)
-------------------------------------------------------------------------------------------------
 validation loss at iteration 23000 | lm loss value: 4.361361E+00 | lm loss PPL: 7.836372E+01 | 
-------------------------------------------------------------------------------------------------
 [2024-06-21 08:52:08] iteration    23100/  500000 | consumed samples:       184800 | elapsed time per iteration (ms): 323.7 | learning rate: 1.486474E-04 | global batch size:     8 | lm loss: 4.038915E+00 | loss scale: 32768.0 | grad norm: 0.665 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 08:52:40] iteration    23200/  500000 | consumed samples:       185600 | elapsed time per iteration (ms): 321.6 | learning rate: 1.486338E-04 | global batch size:     8 | lm loss: 4.066849E+00 | loss scale: 32768.0 | grad norm: 0.740 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 08:53:13] iteration    23300/  500000 | consumed samples:       186400 | elapsed time per iteration (ms): 322.0 | learning rate: 1.486201E-04 | global batch size:     8 | lm loss: 4.066978E+00 | loss scale: 32768.0 | grad norm: 0.629 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 08:53:45] iteration    23400/  500000 | consumed samples:       187200 | elapsed time per iteration (ms): 323.3 | learning rate: 1.486063E-04 | global batch size:     8 | lm loss: 4.077363E+00 | loss scale: 65536.0 | grad norm: 0.708 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 08:54:17] iteration    23500/  500000 | consumed samples:       188000 | elapsed time per iteration (ms): 321.8 | learning rate: 1.485925E-04 | global batch size:     8 | lm loss: 4.057253E+00 | loss scale: 65536.0 | grad norm: 0.649 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 08:54:49] iteration    23600/  500000 | consumed samples:       188800 | elapsed time per iteration (ms): 323.0 | learning rate: 1.485786E-04 | global batch size:     8 | lm loss: 4.088292E+00 | loss scale: 65536.0 | grad norm: 0.624 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 08:55:21] iteration    23700/  500000 | consumed samples:       189600 | elapsed time per iteration (ms): 320.5 | learning rate: 1.485647E-04 | global batch size:     8 | lm loss: 4.078662E+00 | loss scale: 65536.0 | grad norm: 0.710 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 08:55:54] iteration    23800/  500000 | consumed samples:       190400 | elapsed time per iteration (ms): 325.5 | learning rate: 1.485507E-04 | global batch size:     8 | lm loss: 4.050259E+00 | loss scale: 65536.0 | grad norm: 0.666 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 08:56:26] iteration    23900/  500000 | consumed samples:       191200 | elapsed time per iteration (ms): 320.8 | learning rate: 1.485366E-04 | global batch size:     8 | lm loss: 4.084261E+00 | loss scale: 65536.0 | grad norm: 0.634 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 08:56:58] iteration    24000/  500000 | consumed samples:       192000 | elapsed time per iteration (ms): 321.3 | learning rate: 1.485224E-04 | global batch size:     8 | lm loss: 4.036809E+00 | loss scale: 65536.0 | grad norm: 0.635 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1063.57, 1063.57)
-------------------------------------------------------------------------------------------------
 validation loss at iteration 24000 | lm loss value: 4.058635E+00 | lm loss PPL: 5.789522E+01 | 
-------------------------------------------------------------------------------------------------
 [2024-06-21 08:57:32] iteration    24100/  500000 | consumed samples:       192800 | elapsed time per iteration (ms): 323.0 | learning rate: 1.485082E-04 | global batch size:     8 | lm loss: 4.066604E+00 | loss scale: 65536.0 | grad norm: 0.745 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 08:58:04] iteration    24200/  500000 | consumed samples:       193600 | elapsed time per iteration (ms): 322.1 | learning rate: 1.484939E-04 | global batch size:     8 | lm loss: 4.038499E+00 | loss scale: 65536.0 | grad norm: 0.635 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 08:58:36] iteration    24300/  500000 | consumed samples:       194400 | elapsed time per iteration (ms): 320.6 | learning rate: 1.484796E-04 | global batch size:     8 | lm loss: 4.050267E+00 | loss scale: 65536.0 | grad norm: 0.707 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 08:59:08] iteration    24400/  500000 | consumed samples:       195200 | elapsed time per iteration (ms): 322.5 | learning rate: 1.484653E-04 | global batch size:     8 | lm loss: 4.062411E+00 | loss scale: 131072.0 | grad norm: 0.974 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-21 08:59:40] iteration    24500/  500000 | consumed samples:       196000 | elapsed time per iteration (ms): 320.1 | learning rate: 1.484508E-04 | global batch size:     8 | lm loss: 4.059577E+00 | loss scale: 131072.0 | grad norm: 0.686 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 09:00:12] iteration    24600/  500000 | consumed samples:       196800 | elapsed time per iteration (ms): 323.7 | learning rate: 1.484362E-04 | global batch size:     8 | lm loss: 4.023415E+00 | loss scale: 131072.0 | grad norm: 0.719 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 09:00:45] iteration    24700/  500000 | consumed samples:       197600 | elapsed time per iteration (ms): 321.6 | learning rate: 1.484218E-04 | global batch size:     8 | lm loss: 4.013738E+00 | loss scale: 65536.0 | grad norm: 0.652 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-21 09:01:17] iteration    24800/  500000 | consumed samples:       198400 | elapsed time per iteration (ms): 320.2 | learning rate: 1.484072E-04 | global batch size:     8 | lm loss: 4.052868E+00 | loss scale: 32768.0 | grad norm: 0.702 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-21 09:01:49] iteration    24900/  500000 | consumed samples:       199200 | elapsed time per iteration (ms): 323.8 | learning rate: 1.483925E-04 | global batch size:     8 | lm loss: 4.043513E+00 | loss scale: 32768.0 | grad norm: 0.708 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 09:02:21] iteration    25000/  500000 | consumed samples:       200000 | elapsed time per iteration (ms): 319.9 | learning rate: 1.483776E-04 | global batch size:     8 | lm loss: 4.058373E+00 | loss scale: 32768.0 | grad norm: 0.726 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1064.36, 1064.36)
-------------------------------------------------------------------------------------------------
 validation loss at iteration 25000 | lm loss value: 4.082000E+00 | lm loss PPL: 5.926389E+01 | 
-------------------------------------------------------------------------------------------------
 [2024-06-21 09:02:54] iteration    25100/  500000 | consumed samples:       200800 | elapsed time per iteration (ms): 320.7 | learning rate: 1.483627E-04 | global batch size:     8 | lm loss: 4.080937E+00 | loss scale: 32768.0 | grad norm: 0.635 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 09:03:27] iteration    25200/  500000 | consumed samples:       201600 | elapsed time per iteration (ms): 324.4 | learning rate: 1.483478E-04 | global batch size:     8 | lm loss: 4.024524E+00 | loss scale: 32768.0 | grad norm: 0.666 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 09:03:59] iteration    25300/  500000 | consumed samples:       202400 | elapsed time per iteration (ms): 322.1 | learning rate: 1.483329E-04 | global batch size:     8 | lm loss: 4.038641E+00 | loss scale: 16384.0 | grad norm: 0.648 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-21 09:04:31] iteration    25400/  500000 | consumed samples:       203200 | elapsed time per iteration (ms): 321.7 | learning rate: 1.483178E-04 | global batch size:     8 | lm loss: 3.996996E+00 | loss scale: 16384.0 | grad norm: 0.676 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 09:05:03] iteration    25500/  500000 | consumed samples:       204000 | elapsed time per iteration (ms): 322.8 | learning rate: 1.483026E-04 | global batch size:     8 | lm loss: 4.025697E+00 | loss scale: 16384.0 | grad norm: 0.634 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 09:05:35] iteration    25600/  500000 | consumed samples:       204800 | elapsed time per iteration (ms): 320.9 | learning rate: 1.482874E-04 | global batch size:     8 | lm loss: 4.045286E+00 | loss scale: 16384.0 | grad norm: 0.640 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 09:06:08] iteration    25700/  500000 | consumed samples:       205600 | elapsed time per iteration (ms): 323.1 | learning rate: 1.482721E-04 | global batch size:     8 | lm loss: 4.025429E+00 | loss scale: 16384.0 | grad norm: 0.649 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 09:06:40] iteration    25800/  500000 | consumed samples:       206400 | elapsed time per iteration (ms): 321.8 | learning rate: 1.482568E-04 | global batch size:     8 | lm loss: 4.054372E+00 | loss scale: 16384.0 | grad norm: 0.647 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 09:07:12] iteration    25900/  500000 | consumed samples:       207200 | elapsed time per iteration (ms): 320.4 | learning rate: 1.482413E-04 | global batch size:     8 | lm loss: 4.020554E+00 | loss scale: 16384.0 | grad norm: 0.645 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 09:07:44] iteration    26000/  500000 | consumed samples:       208000 | elapsed time per iteration (ms): 323.3 | learning rate: 1.482258E-04 | global batch size:     8 | lm loss: 4.020079E+00 | loss scale: 16384.0 | grad norm: 0.676 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1066.65, 1066.65)
-------------------------------------------------------------------------------------------------
 validation loss at iteration 26000 | lm loss value: 4.045036E+00 | lm loss PPL: 5.711323E+01 | 
-------------------------------------------------------------------------------------------------
 [2024-06-21 09:08:18] iteration    26100/  500000 | consumed samples:       208800 | elapsed time per iteration (ms): 322.6 | learning rate: 1.482103E-04 | global batch size:     8 | lm loss: 3.988219E+00 | loss scale: 16384.0 | grad norm: 0.631 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 09:08:50] iteration    26200/  500000 | consumed samples:       209600 | elapsed time per iteration (ms): 323.7 | learning rate: 1.481946E-04 | global batch size:     8 | lm loss: 3.998963E+00 | loss scale: 16384.0 | grad norm: 0.638 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 09:09:22] iteration    26300/  500000 | consumed samples:       210400 | elapsed time per iteration (ms): 321.1 | learning rate: 1.481789E-04 | global batch size:     8 | lm loss: 4.037845E+00 | loss scale: 32768.0 | grad norm: 0.623 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 09:09:54] iteration    26400/  500000 | consumed samples:       211200 | elapsed time per iteration (ms): 321.3 | learning rate: 1.481632E-04 | global batch size:     8 | lm loss: 4.016299E+00 | loss scale: 32768.0 | grad norm: 0.691 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 09:10:27] iteration    26500/  500000 | consumed samples:       212000 | elapsed time per iteration (ms): 324.1 | learning rate: 1.481474E-04 | global batch size:     8 | lm loss: 4.061528E+00 | loss scale: 32768.0 | grad norm: 0.670 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 09:10:59] iteration    26600/  500000 | consumed samples:       212800 | elapsed time per iteration (ms): 323.1 | learning rate: 1.481315E-04 | global batch size:     8 | lm loss: 4.019209E+00 | loss scale: 32768.0 | grad norm: 0.621 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 09:11:31] iteration    26700/  500000 | consumed samples:       213600 | elapsed time per iteration (ms): 322.8 | learning rate: 1.481155E-04 | global batch size:     8 | lm loss: 4.029167E+00 | loss scale: 32768.0 | grad norm: 0.633 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 09:12:03] iteration    26800/  500000 | consumed samples:       214400 | elapsed time per iteration (ms): 322.0 | learning rate: 1.480995E-04 | global batch size:     8 | lm loss: 4.010609E+00 | loss scale: 32768.0 | grad norm: 0.718 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 09:12:36] iteration    26900/  500000 | consumed samples:       215200 | elapsed time per iteration (ms): 323.0 | learning rate: 1.480834E-04 | global batch size:     8 | lm loss: 4.034555E+00 | loss scale: 32768.0 | grad norm: 0.635 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 09:13:08] iteration    27000/  500000 | consumed samples:       216000 | elapsed time per iteration (ms): 322.4 | learning rate: 1.480672E-04 | global batch size:     8 | lm loss: 4.027688E+00 | loss scale: 32768.0 | grad norm: 0.621 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1062.34, 1062.34)
-------------------------------------------------------------------------------------------------
 validation loss at iteration 27000 | lm loss value: 3.994823E+00 | lm loss PPL: 5.431624E+01 | 
-------------------------------------------------------------------------------------------------
 [2024-06-21 09:13:41] iteration    27100/  500000 | consumed samples:       216800 | elapsed time per iteration (ms): 321.2 | learning rate: 1.480510E-04 | global batch size:     8 | lm loss: 4.020332E+00 | loss scale: 32768.0 | grad norm: 0.670 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 09:14:13] iteration    27200/  500000 | consumed samples:       217600 | elapsed time per iteration (ms): 322.3 | learning rate: 1.480347E-04 | global batch size:     8 | lm loss: 3.996754E+00 | loss scale: 32768.0 | grad norm: 0.645 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 09:14:46] iteration    27300/  500000 | consumed samples:       218400 | elapsed time per iteration (ms): 323.3 | learning rate: 1.480183E-04 | global batch size:     8 | lm loss: 4.003437E+00 | loss scale: 65536.0 | grad norm: 0.610 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 09:15:18] iteration    27400/  500000 | consumed samples:       219200 | elapsed time per iteration (ms): 322.6 | learning rate: 1.480019E-04 | global batch size:     8 | lm loss: 3.977790E+00 | loss scale: 65536.0 | grad norm: 0.629 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 09:15:50] iteration    27500/  500000 | consumed samples:       220000 | elapsed time per iteration (ms): 322.1 | learning rate: 1.479854E-04 | global batch size:     8 | lm loss: 3.995775E+00 | loss scale: 65536.0 | grad norm: 0.676 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 09:16:22] iteration    27600/  500000 | consumed samples:       220800 | elapsed time per iteration (ms): 321.8 | learning rate: 1.479688E-04 | global batch size:     8 | lm loss: 3.977639E+00 | loss scale: 65536.0 | grad norm: 0.685 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 09:16:54] iteration    27700/  500000 | consumed samples:       221600 | elapsed time per iteration (ms): 319.5 | learning rate: 1.479522E-04 | global batch size:     8 | lm loss: 4.009354E+00 | loss scale: 65536.0 | grad norm: 0.648 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 09:17:26] iteration    27800/  500000 | consumed samples:       222400 | elapsed time per iteration (ms): 321.6 | learning rate: 1.479355E-04 | global batch size:     8 | lm loss: 4.031828E+00 | loss scale: 65536.0 | grad norm: 0.628 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 09:17:59] iteration    27900/  500000 | consumed samples:       223200 | elapsed time per iteration (ms): 321.5 | learning rate: 1.479187E-04 | global batch size:     8 | lm loss: 3.976456E+00 | loss scale: 65536.0 | grad norm: 0.694 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 09:18:31] iteration    28000/  500000 | consumed samples:       224000 | elapsed time per iteration (ms): 321.4 | learning rate: 1.479019E-04 | global batch size:     8 | lm loss: 4.016679E+00 | loss scale: 65536.0 | grad norm: 0.703 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1063.98, 1063.98)
-------------------------------------------------------------------------------------------------
 validation loss at iteration 28000 | lm loss value: 4.055794E+00 | lm loss PPL: 5.773100E+01 | 
-------------------------------------------------------------------------------------------------
 [2024-06-21 09:19:04] iteration    28100/  500000 | consumed samples:       224800 | elapsed time per iteration (ms): 322.1 | learning rate: 1.478849E-04 | global batch size:     8 | lm loss: 3.971831E+00 | loss scale: 65536.0 | grad norm: 0.665 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 09:19:36] iteration    28200/  500000 | consumed samples:       225600 | elapsed time per iteration (ms): 322.6 | learning rate: 1.478680E-04 | global batch size:     8 | lm loss: 3.981543E+00 | loss scale: 65536.0 | grad norm: 0.808 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 09:20:09] iteration    28300/  500000 | consumed samples:       226400 | elapsed time per iteration (ms): 322.8 | learning rate: 1.478509E-04 | global batch size:     8 | lm loss: 3.969878E+00 | loss scale: 131072.0 | grad norm: 0.684 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 09:20:41] iteration    28400/  500000 | consumed samples:       227200 | elapsed time per iteration (ms): 320.9 | learning rate: 1.478338E-04 | global batch size:     8 | lm loss: 3.980888E+00 | loss scale: 131072.0 | grad norm: 0.650 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 09:21:13] iteration    28500/  500000 | consumed samples:       228000 | elapsed time per iteration (ms): 322.0 | learning rate: 1.478167E-04 | global batch size:     8 | lm loss: 3.986864E+00 | loss scale: 131072.0 | grad norm: 0.649 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 09:21:45] iteration    28600/  500000 | consumed samples:       228800 | elapsed time per iteration (ms): 321.7 | learning rate: 1.477994E-04 | global batch size:     8 | lm loss: 3.916302E+00 | loss scale: 131072.0 | grad norm: 0.649 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 09:22:17] iteration    28700/  500000 | consumed samples:       229600 | elapsed time per iteration (ms): 323.0 | learning rate: 1.477821E-04 | global batch size:     8 | lm loss: 3.946211E+00 | loss scale: 131072.0 | grad norm: 0.627 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 09:22:49] iteration    28800/  500000 | consumed samples:       230400 | elapsed time per iteration (ms): 322.1 | learning rate: 1.477648E-04 | global batch size:     8 | lm loss: 3.929950E+00 | loss scale: 131072.0 | grad norm: 0.648 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 09:23:22] iteration    28900/  500000 | consumed samples:       231200 | elapsed time per iteration (ms): 321.3 | learning rate: 1.477473E-04 | global batch size:     8 | lm loss: 3.980392E+00 | loss scale: 131072.0 | grad norm: 0.619 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 09:23:54] iteration    29000/  500000 | consumed samples:       232000 | elapsed time per iteration (ms): 321.8 | learning rate: 1.477298E-04 | global batch size:     8 | lm loss: 3.972602E+00 | loss scale: 131072.0 | grad norm: 0.630 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1062.71, 1062.71)
-------------------------------------------------------------------------------------------------
 validation loss at iteration 29000 | lm loss value: 4.162536E+00 | lm loss PPL: 6.423419E+01 | 
-------------------------------------------------------------------------------------------------
 [2024-06-21 09:24:27] iteration    29100/  500000 | consumed samples:       232800 | elapsed time per iteration (ms): 321.3 | learning rate: 1.477123E-04 | global batch size:     8 | lm loss: 4.011067E+00 | loss scale: 131072.0 | grad norm: 0.615 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 09:24:59] iteration    29200/  500000 | consumed samples:       233600 | elapsed time per iteration (ms): 322.5 | learning rate: 1.476946E-04 | global batch size:     8 | lm loss: 3.952779E+00 | loss scale: 131072.0 | grad norm: 0.669 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 09:25:32] iteration    29300/  500000 | consumed samples:       234400 | elapsed time per iteration (ms): 322.7 | learning rate: 1.476769E-04 | global batch size:     8 | lm loss: 3.940910E+00 | loss scale: 262144.0 | grad norm: 0.663 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 09:26:04] iteration    29400/  500000 | consumed samples:       235200 | elapsed time per iteration (ms): 321.2 | learning rate: 1.476592E-04 | global batch size:     8 | lm loss: 3.961208E+00 | loss scale: 262144.0 | grad norm: 0.643 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 09:26:36] iteration    29500/  500000 | consumed samples:       236000 | elapsed time per iteration (ms): 321.6 | learning rate: 1.476413E-04 | global batch size:     8 | lm loss: 3.983172E+00 | loss scale: 262144.0 | grad norm: 0.681 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 09:27:08] iteration    29600/  500000 | consumed samples:       236800 | elapsed time per iteration (ms): 318.7 | learning rate: 1.476234E-04 | global batch size:     8 | lm loss: 3.992762E+00 | loss scale: 262144.0 | grad norm: 0.636 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 09:27:40] iteration    29700/  500000 | consumed samples:       237600 | elapsed time per iteration (ms): 323.9 | learning rate: 1.476055E-04 | global batch size:     8 | lm loss: 3.982456E+00 | loss scale: 262144.0 | grad norm: 0.636 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 09:28:12] iteration    29800/  500000 | consumed samples:       238400 | elapsed time per iteration (ms): 321.8 | learning rate: 1.475874E-04 | global batch size:     8 | lm loss: 3.954489E+00 | loss scale: 262144.0 | grad norm: 0.641 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 09:28:45] iteration    29900/  500000 | consumed samples:       239200 | elapsed time per iteration (ms): 323.3 | learning rate: 1.475695E-04 | global batch size:     8 | lm loss: 3.971094E+00 | loss scale: 262144.0 | grad norm: 0.644 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-21 09:29:17] iteration    30000/  500000 | consumed samples:       240000 | elapsed time per iteration (ms): 321.0 | learning rate: 1.475513E-04 | global batch size:     8 | lm loss: 3.966318E+00 | loss scale: 262144.0 | grad norm: 0.648 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1064.94, 1064.94)
-------------------------------------------------------------------------------------------------
 validation loss at iteration 30000 | lm loss value: 4.107636E+00 | lm loss PPL: 6.080284E+01 | 
-------------------------------------------------------------------------------------------------
saving checkpoint at iteration   30000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-max in torch format
  successfully saved checkpoint at iteration   30000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-max
(min, max) time across ranks (ms):
    save-checkpoint ................................: (5768.08, 5768.08)
 [2024-06-21 09:29:56] iteration    30100/  500000 | consumed samples:       240800 | elapsed time per iteration (ms): 323.8 | learning rate: 1.475331E-04 | global batch size:     8 | lm loss: 3.942233E+00 | loss scale: 262144.0 | grad norm: 0.642 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 09:30:28] iteration    30200/  500000 | consumed samples:       241600 | elapsed time per iteration (ms): 321.3 | learning rate: 1.475150E-04 | global batch size:     8 | lm loss: 3.920882E+00 | loss scale: 131072.0 | grad norm: 0.644 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-21 09:31:00] iteration    30300/  500000 | consumed samples:       242400 | elapsed time per iteration (ms): 320.2 | learning rate: 1.474970E-04 | global batch size:     8 | lm loss: 3.964300E+00 | loss scale: 32768.0 | grad norm: 0.659 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-21 09:31:32] iteration    30400/  500000 | consumed samples:       243200 | elapsed time per iteration (ms): 322.7 | learning rate: 1.474786E-04 | global batch size:     8 | lm loss: 3.972750E+00 | loss scale: 32768.0 | grad norm: 0.651 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 09:32:04] iteration    30500/  500000 | consumed samples:       244000 | elapsed time per iteration (ms): 320.7 | learning rate: 1.474601E-04 | global batch size:     8 | lm loss: 3.900037E+00 | loss scale: 32768.0 | grad norm: 0.791 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 09:32:37] iteration    30600/  500000 | consumed samples:       244800 | elapsed time per iteration (ms): 322.2 | learning rate: 1.474415E-04 | global batch size:     8 | lm loss: 3.946166E+00 | loss scale: 32768.0 | grad norm: 0.619 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 09:33:09] iteration    30700/  500000 | consumed samples:       245600 | elapsed time per iteration (ms): 320.1 | learning rate: 1.474229E-04 | global batch size:     8 | lm loss: 3.958513E+00 | loss scale: 32768.0 | grad norm: 0.623 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 09:33:41] iteration    30800/  500000 | consumed samples:       246400 | elapsed time per iteration (ms): 321.2 | learning rate: 1.474042E-04 | global batch size:     8 | lm loss: 3.942093E+00 | loss scale: 32768.0 | grad norm: 0.651 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 09:34:13] iteration    30900/  500000 | consumed samples:       247200 | elapsed time per iteration (ms): 322.5 | learning rate: 1.473854E-04 | global batch size:     8 | lm loss: 3.948938E+00 | loss scale: 32768.0 | grad norm: 0.739 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 09:34:45] iteration    31000/  500000 | consumed samples:       248000 | elapsed time per iteration (ms): 323.7 | learning rate: 1.473666E-04 | global batch size:     8 | lm loss: 3.918893E+00 | loss scale: 32768.0 | grad norm: 0.679 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1062.58, 1062.58)
-------------------------------------------------------------------------------------------------
 validation loss at iteration 31000 | lm loss value: 4.122070E+00 | lm loss PPL: 6.168682E+01 | 
-------------------------------------------------------------------------------------------------
 [2024-06-21 09:35:18] iteration    31100/  500000 | consumed samples:       248800 | elapsed time per iteration (ms): 320.8 | learning rate: 1.473477E-04 | global batch size:     8 | lm loss: 3.964289E+00 | loss scale: 32768.0 | grad norm: 0.640 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 09:35:50] iteration    31200/  500000 | consumed samples:       249600 | elapsed time per iteration (ms): 319.4 | learning rate: 1.473287E-04 | global batch size:     8 | lm loss: 3.932398E+00 | loss scale: 32768.0 | grad norm: 0.635 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 09:36:22] iteration    31300/  500000 | consumed samples:       250400 | elapsed time per iteration (ms): 319.5 | learning rate: 1.473097E-04 | global batch size:     8 | lm loss: 3.942913E+00 | loss scale: 65536.0 | grad norm: 0.642 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 09:36:54] iteration    31400/  500000 | consumed samples:       251200 | elapsed time per iteration (ms): 319.9 | learning rate: 1.472906E-04 | global batch size:     8 | lm loss: 3.939391E+00 | loss scale: 65536.0 | grad norm: 0.624 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 09:37:26] iteration    31500/  500000 | consumed samples:       252000 | elapsed time per iteration (ms): 319.4 | learning rate: 1.472715E-04 | global batch size:     8 | lm loss: 3.950734E+00 | loss scale: 65536.0 | grad norm: 0.667 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 09:37:58] iteration    31600/  500000 | consumed samples:       252800 | elapsed time per iteration (ms): 322.0 | learning rate: 1.472522E-04 | global batch size:     8 | lm loss: 3.929784E+00 | loss scale: 65536.0 | grad norm: 0.607 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 09:38:31] iteration    31700/  500000 | consumed samples:       253600 | elapsed time per iteration (ms): 321.1 | learning rate: 1.472329E-04 | global batch size:     8 | lm loss: 3.940597E+00 | loss scale: 65536.0 | grad norm: 0.622 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 09:39:03] iteration    31800/  500000 | consumed samples:       254400 | elapsed time per iteration (ms): 321.5 | learning rate: 1.472136E-04 | global batch size:     8 | lm loss: 3.937099E+00 | loss scale: 65536.0 | grad norm: 0.607 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 09:39:35] iteration    31900/  500000 | consumed samples:       255200 | elapsed time per iteration (ms): 321.7 | learning rate: 1.471942E-04 | global batch size:     8 | lm loss: 3.918603E+00 | loss scale: 65536.0 | grad norm: 0.683 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 09:40:07] iteration    32000/  500000 | consumed samples:       256000 | elapsed time per iteration (ms): 320.0 | learning rate: 1.471747E-04 | global batch size:     8 | lm loss: 3.903343E+00 | loss scale: 65536.0 | grad norm: 0.662 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1063.37, 1063.37)
-------------------------------------------------------------------------------------------------
 validation loss at iteration 32000 | lm loss value: 4.045453E+00 | lm loss PPL: 5.713704E+01 | 
-------------------------------------------------------------------------------------------------
 [2024-06-21 09:40:40] iteration    32100/  500000 | consumed samples:       256800 | elapsed time per iteration (ms): 323.5 | learning rate: 1.471551E-04 | global batch size:     8 | lm loss: 3.909047E+00 | loss scale: 65536.0 | grad norm: 0.663 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 09:41:13] iteration    32200/  500000 | consumed samples:       257600 | elapsed time per iteration (ms): 323.2 | learning rate: 1.471355E-04 | global batch size:     8 | lm loss: 3.908300E+00 | loss scale: 65536.0 | grad norm: 0.657 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 09:41:45] iteration    32300/  500000 | consumed samples:       258400 | elapsed time per iteration (ms): 321.5 | learning rate: 1.471158E-04 | global batch size:     8 | lm loss: 3.989146E+00 | loss scale: 131072.0 | grad norm: 0.656 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 09:42:17] iteration    32400/  500000 | consumed samples:       259200 | elapsed time per iteration (ms): 321.6 | learning rate: 1.470961E-04 | global batch size:     8 | lm loss: 3.895360E+00 | loss scale: 131072.0 | grad norm: 0.624 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 09:42:49] iteration    32500/  500000 | consumed samples:       260000 | elapsed time per iteration (ms): 322.2 | learning rate: 1.470762E-04 | global batch size:     8 | lm loss: 3.932311E+00 | loss scale: 131072.0 | grad norm: 0.641 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 09:43:21] iteration    32600/  500000 | consumed samples:       260800 | elapsed time per iteration (ms): 319.9 | learning rate: 1.470565E-04 | global batch size:     8 | lm loss: 3.894250E+00 | loss scale: 131072.0 | grad norm: 0.654 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-21 09:43:53] iteration    32700/  500000 | consumed samples:       261600 | elapsed time per iteration (ms): 322.2 | learning rate: 1.470366E-04 | global batch size:     8 | lm loss: 3.903519E+00 | loss scale: 131072.0 | grad norm: 0.623 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 09:44:26] iteration    32800/  500000 | consumed samples:       262400 | elapsed time per iteration (ms): 321.2 | learning rate: 1.470166E-04 | global batch size:     8 | lm loss: 3.955764E+00 | loss scale: 131072.0 | grad norm: 0.660 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 09:44:58] iteration    32900/  500000 | consumed samples:       263200 | elapsed time per iteration (ms): 320.7 | learning rate: 1.469967E-04 | global batch size:     8 | lm loss: 3.913726E+00 | loss scale: 65536.0 | grad norm: 0.642 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-21 09:45:30] iteration    33000/  500000 | consumed samples:       264000 | elapsed time per iteration (ms): 322.3 | learning rate: 1.469765E-04 | global batch size:     8 | lm loss: 3.871269E+00 | loss scale: 65536.0 | grad norm: 0.645 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1063.02, 1063.02)
-------------------------------------------------------------------------------------------------
 validation loss at iteration 33000 | lm loss value: 4.149984E+00 | lm loss PPL: 6.343298E+01 | 
-------------------------------------------------------------------------------------------------
 [2024-06-21 09:46:03] iteration    33100/  500000 | consumed samples:       264800 | elapsed time per iteration (ms): 319.1 | learning rate: 1.469563E-04 | global batch size:     8 | lm loss: 3.902165E+00 | loss scale: 65536.0 | grad norm: 0.626 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 09:46:35] iteration    33200/  500000 | consumed samples:       265600 | elapsed time per iteration (ms): 318.8 | learning rate: 1.469361E-04 | global batch size:     8 | lm loss: 3.904193E+00 | loss scale: 65536.0 | grad norm: 0.623 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 09:47:07] iteration    33300/  500000 | consumed samples:       266400 | elapsed time per iteration (ms): 323.0 | learning rate: 1.469157E-04 | global batch size:     8 | lm loss: 3.905129E+00 | loss scale: 65536.0 | grad norm: 0.694 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 09:47:39] iteration    33400/  500000 | consumed samples:       267200 | elapsed time per iteration (ms): 321.5 | learning rate: 1.468953E-04 | global batch size:     8 | lm loss: 3.911053E+00 | loss scale: 65536.0 | grad norm: 0.632 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 09:48:11] iteration    33500/  500000 | consumed samples:       268000 | elapsed time per iteration (ms): 321.3 | learning rate: 1.468748E-04 | global batch size:     8 | lm loss: 3.954871E+00 | loss scale: 65536.0 | grad norm: 0.677 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 09:48:44] iteration    33600/  500000 | consumed samples:       268800 | elapsed time per iteration (ms): 322.7 | learning rate: 1.468543E-04 | global batch size:     8 | lm loss: 3.903654E+00 | loss scale: 65536.0 | grad norm: 0.637 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 09:49:16] iteration    33700/  500000 | consumed samples:       269600 | elapsed time per iteration (ms): 321.1 | learning rate: 1.468337E-04 | global batch size:     8 | lm loss: 3.915302E+00 | loss scale: 65536.0 | grad norm: 12.500 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 09:49:48] iteration    33800/  500000 | consumed samples:       270400 | elapsed time per iteration (ms): 323.6 | learning rate: 1.468130E-04 | global batch size:     8 | lm loss: 3.948358E+00 | loss scale: 65536.0 | grad norm: 0.667 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 09:50:20] iteration    33900/  500000 | consumed samples:       271200 | elapsed time per iteration (ms): 319.0 | learning rate: 1.467923E-04 | global batch size:     8 | lm loss: 3.873085E+00 | loss scale: 131072.0 | grad norm: 0.644 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 09:50:52] iteration    34000/  500000 | consumed samples:       272000 | elapsed time per iteration (ms): 322.2 | learning rate: 1.467714E-04 | global batch size:     8 | lm loss: 3.922803E+00 | loss scale: 131072.0 | grad norm: 0.653 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1064.78, 1064.78)
-------------------------------------------------------------------------------------------------
 validation loss at iteration 34000 | lm loss value: 3.946623E+00 | lm loss PPL: 5.176027E+01 | 
-------------------------------------------------------------------------------------------------
 [2024-06-21 09:51:25] iteration    34100/  500000 | consumed samples:       272800 | elapsed time per iteration (ms): 323.2 | learning rate: 1.467506E-04 | global batch size:     8 | lm loss: 3.931572E+00 | loss scale: 131072.0 | grad norm: 0.649 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 09:51:57] iteration    34200/  500000 | consumed samples:       273600 | elapsed time per iteration (ms): 319.6 | learning rate: 1.467296E-04 | global batch size:     8 | lm loss: 3.894867E+00 | loss scale: 131072.0 | grad norm: 0.665 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 09:52:30] iteration    34300/  500000 | consumed samples:       274400 | elapsed time per iteration (ms): 320.6 | learning rate: 1.467086E-04 | global batch size:     8 | lm loss: 3.921912E+00 | loss scale: 131072.0 | grad norm: 0.643 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 09:53:01] iteration    34400/  500000 | consumed samples:       275200 | elapsed time per iteration (ms): 319.9 | learning rate: 1.466876E-04 | global batch size:     8 | lm loss: 3.891576E+00 | loss scale: 131072.0 | grad norm: 0.630 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 09:53:34] iteration    34500/  500000 | consumed samples:       276000 | elapsed time per iteration (ms): 321.9 | learning rate: 1.466664E-04 | global batch size:     8 | lm loss: 3.870645E+00 | loss scale: 131072.0 | grad norm: 0.606 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 09:54:06] iteration    34600/  500000 | consumed samples:       276800 | elapsed time per iteration (ms): 324.1 | learning rate: 1.466452E-04 | global batch size:     8 | lm loss: 3.870628E+00 | loss scale: 131072.0 | grad norm: 0.678 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 09:54:38] iteration    34700/  500000 | consumed samples:       277600 | elapsed time per iteration (ms): 322.7 | learning rate: 1.466240E-04 | global batch size:     8 | lm loss: 3.925732E+00 | loss scale: 131072.0 | grad norm: 0.627 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 09:55:11] iteration    34800/  500000 | consumed samples:       278400 | elapsed time per iteration (ms): 322.4 | learning rate: 1.466026E-04 | global batch size:     8 | lm loss: 3.869524E+00 | loss scale: 131072.0 | grad norm: 0.640 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 09:55:43] iteration    34900/  500000 | consumed samples:       279200 | elapsed time per iteration (ms): 323.0 | learning rate: 1.465812E-04 | global batch size:     8 | lm loss: 3.907871E+00 | loss scale: 262144.0 | grad norm: 0.643 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 09:56:15] iteration    35000/  500000 | consumed samples:       280000 | elapsed time per iteration (ms): 321.3 | learning rate: 1.465598E-04 | global batch size:     8 | lm loss: 3.879186E+00 | loss scale: 262144.0 | grad norm: 0.639 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1065.75, 1065.75)
-------------------------------------------------------------------------------------------------
 validation loss at iteration 35000 | lm loss value: 3.981071E+00 | lm loss PPL: 5.357441E+01 | 
-------------------------------------------------------------------------------------------------
 [2024-06-21 09:56:48] iteration    35100/  500000 | consumed samples:       280800 | elapsed time per iteration (ms): 323.1 | learning rate: 1.465383E-04 | global batch size:     8 | lm loss: 3.856075E+00 | loss scale: 262144.0 | grad norm: 0.670 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 09:57:20] iteration    35200/  500000 | consumed samples:       281600 | elapsed time per iteration (ms): 320.6 | learning rate: 1.465167E-04 | global batch size:     8 | lm loss: 3.892548E+00 | loss scale: 262144.0 | grad norm: 0.697 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 09:57:53] iteration    35300/  500000 | consumed samples:       282400 | elapsed time per iteration (ms): 322.9 | learning rate: 1.464952E-04 | global batch size:     8 | lm loss: 3.880915E+00 | loss scale: 262144.0 | grad norm: 0.627 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-21 09:58:25] iteration    35400/  500000 | consumed samples:       283200 | elapsed time per iteration (ms): 321.2 | learning rate: 1.464737E-04 | global batch size:     8 | lm loss: 3.888937E+00 | loss scale: 131072.0 | grad norm: 0.805 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-21 09:58:57] iteration    35500/  500000 | consumed samples:       284000 | elapsed time per iteration (ms): 322.0 | learning rate: 1.464519E-04 | global batch size:     8 | lm loss: 3.886880E+00 | loss scale: 131072.0 | grad norm: 0.757 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 09:59:29] iteration    35600/  500000 | consumed samples:       284800 | elapsed time per iteration (ms): 319.4 | learning rate: 1.464301E-04 | global batch size:     8 | lm loss: 3.880676E+00 | loss scale: 131072.0 | grad norm: 0.605 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 10:00:02] iteration    35700/  500000 | consumed samples:       285600 | elapsed time per iteration (ms): 325.5 | learning rate: 1.464082E-04 | global batch size:     8 | lm loss: 3.897526E+00 | loss scale: 131072.0 | grad norm: 0.644 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 10:00:34] iteration    35800/  500000 | consumed samples:       286400 | elapsed time per iteration (ms): 324.7 | learning rate: 1.463862E-04 | global batch size:     8 | lm loss: 3.917731E+00 | loss scale: 131072.0 | grad norm: 0.642 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 10:01:06] iteration    35900/  500000 | consumed samples:       287200 | elapsed time per iteration (ms): 322.5 | learning rate: 1.463641E-04 | global batch size:     8 | lm loss: 3.886183E+00 | loss scale: 131072.0 | grad norm: 0.662 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 10:01:39] iteration    36000/  500000 | consumed samples:       288000 | elapsed time per iteration (ms): 325.9 | learning rate: 1.463420E-04 | global batch size:     8 | lm loss: 3.855762E+00 | loss scale: 131072.0 | grad norm: 0.607 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1064.25, 1064.25)
-------------------------------------------------------------------------------------------------
 validation loss at iteration 36000 | lm loss value: 4.002044E+00 | lm loss PPL: 5.470987E+01 | 
-------------------------------------------------------------------------------------------------
 [2024-06-21 10:02:12] iteration    36100/  500000 | consumed samples:       288800 | elapsed time per iteration (ms): 322.4 | learning rate: 1.463198E-04 | global batch size:     8 | lm loss: 3.854335E+00 | loss scale: 131072.0 | grad norm: 0.603 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 10:02:44] iteration    36200/  500000 | consumed samples:       289600 | elapsed time per iteration (ms): 322.6 | learning rate: 1.462976E-04 | global batch size:     8 | lm loss: 3.895622E+00 | loss scale: 131072.0 | grad norm: 0.616 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 10:03:17] iteration    36300/  500000 | consumed samples:       290400 | elapsed time per iteration (ms): 322.2 | learning rate: 1.462755E-04 | global batch size:     8 | lm loss: 3.883219E+00 | loss scale: 65536.0 | grad norm: 0.639 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-21 10:03:49] iteration    36400/  500000 | consumed samples:       291200 | elapsed time per iteration (ms): 324.5 | learning rate: 1.462531E-04 | global batch size:     8 | lm loss: 3.885367E+00 | loss scale: 65536.0 | grad norm: 0.639 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 10:04:21] iteration    36500/  500000 | consumed samples:       292000 | elapsed time per iteration (ms): 320.6 | learning rate: 1.462307E-04 | global batch size:     8 | lm loss: 3.876538E+00 | loss scale: 65536.0 | grad norm: 0.655 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 10:04:53] iteration    36600/  500000 | consumed samples:       292800 | elapsed time per iteration (ms): 322.9 | learning rate: 1.462082E-04 | global batch size:     8 | lm loss: 3.870399E+00 | loss scale: 65536.0 | grad norm: 0.601 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 10:05:26] iteration    36700/  500000 | consumed samples:       293600 | elapsed time per iteration (ms): 321.6 | learning rate: 1.461856E-04 | global batch size:     8 | lm loss: 3.853156E+00 | loss scale: 65536.0 | grad norm: 0.678 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 10:05:58] iteration    36800/  500000 | consumed samples:       294400 | elapsed time per iteration (ms): 321.2 | learning rate: 1.461630E-04 | global batch size:     8 | lm loss: 3.850950E+00 | loss scale: 65536.0 | grad norm: 0.614 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 10:06:30] iteration    36900/  500000 | consumed samples:       295200 | elapsed time per iteration (ms): 322.9 | learning rate: 1.461403E-04 | global batch size:     8 | lm loss: 3.856842E+00 | loss scale: 65536.0 | grad norm: 0.794 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 10:07:02] iteration    37000/  500000 | consumed samples:       296000 | elapsed time per iteration (ms): 321.3 | learning rate: 1.461175E-04 | global batch size:     8 | lm loss: 3.874020E+00 | loss scale: 65536.0 | grad norm: 0.611 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1063.11, 1063.11)
-------------------------------------------------------------------------------------------------
 validation loss at iteration 37000 | lm loss value: 4.114670E+00 | lm loss PPL: 6.123199E+01 | 
-------------------------------------------------------------------------------------------------
 [2024-06-21 10:07:35] iteration    37100/  500000 | consumed samples:       296800 | elapsed time per iteration (ms): 322.0 | learning rate: 1.460947E-04 | global batch size:     8 | lm loss: 3.881010E+00 | loss scale: 65536.0 | grad norm: 0.659 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 10:08:08] iteration    37200/  500000 | consumed samples:       297600 | elapsed time per iteration (ms): 321.9 | learning rate: 1.460718E-04 | global batch size:     8 | lm loss: 3.861040E+00 | loss scale: 65536.0 | grad norm: 0.614 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 10:08:40] iteration    37300/  500000 | consumed samples:       298400 | elapsed time per iteration (ms): 321.5 | learning rate: 1.460488E-04 | global batch size:     8 | lm loss: 3.865515E+00 | loss scale: 131072.0 | grad norm: 0.633 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 10:09:12] iteration    37400/  500000 | consumed samples:       299200 | elapsed time per iteration (ms): 321.0 | learning rate: 1.460258E-04 | global batch size:     8 | lm loss: 3.869813E+00 | loss scale: 131072.0 | grad norm: 0.605 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 10:09:44] iteration    37500/  500000 | consumed samples:       300000 | elapsed time per iteration (ms): 322.8 | learning rate: 1.460027E-04 | global batch size:     8 | lm loss: 3.895739E+00 | loss scale: 131072.0 | grad norm: 0.657 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 10:10:16] iteration    37600/  500000 | consumed samples:       300800 | elapsed time per iteration (ms): 321.7 | learning rate: 1.459796E-04 | global batch size:     8 | lm loss: 3.894754E+00 | loss scale: 131072.0 | grad norm: 0.623 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 10:10:49] iteration    37700/  500000 | consumed samples:       301600 | elapsed time per iteration (ms): 324.3 | learning rate: 1.459564E-04 | global batch size:     8 | lm loss: 3.875462E+00 | loss scale: 131072.0 | grad norm: 0.626 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 10:11:21] iteration    37800/  500000 | consumed samples:       302400 | elapsed time per iteration (ms): 323.0 | learning rate: 1.459333E-04 | global batch size:     8 | lm loss: 3.867045E+00 | loss scale: 131072.0 | grad norm: 0.630 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-21 10:11:53] iteration    37900/  500000 | consumed samples:       303200 | elapsed time per iteration (ms): 322.7 | learning rate: 1.459100E-04 | global batch size:     8 | lm loss: 3.857103E+00 | loss scale: 131072.0 | grad norm: 0.613 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 10:12:25] iteration    38000/  500000 | consumed samples:       304000 | elapsed time per iteration (ms): 319.3 | learning rate: 1.458868E-04 | global batch size:     8 | lm loss: 3.880044E+00 | loss scale: 65536.0 | grad norm: 0.633 | number of skipped iterations:   1 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1062.79, 1062.79)
-------------------------------------------------------------------------------------------------
 validation loss at iteration 38000 | lm loss value: 3.878897E+00 | lm loss PPL: 4.837085E+01 | 
-------------------------------------------------------------------------------------------------
 [2024-06-21 10:12:58] iteration    38100/  500000 | consumed samples:       304800 | elapsed time per iteration (ms): 321.5 | learning rate: 1.458633E-04 | global batch size:     8 | lm loss: 3.876467E+00 | loss scale: 65536.0 | grad norm: 0.622 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 10:13:31] iteration    38200/  500000 | consumed samples:       305600 | elapsed time per iteration (ms): 320.7 | learning rate: 1.458398E-04 | global batch size:     8 | lm loss: 3.847625E+00 | loss scale: 65536.0 | grad norm: 0.651 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 10:14:03] iteration    38300/  500000 | consumed samples:       306400 | elapsed time per iteration (ms): 321.4 | learning rate: 1.458162E-04 | global batch size:     8 | lm loss: 3.837320E+00 | loss scale: 65536.0 | grad norm: 0.628 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 10:14:35] iteration    38400/  500000 | consumed samples:       307200 | elapsed time per iteration (ms): 321.9 | learning rate: 1.457925E-04 | global batch size:     8 | lm loss: 3.840028E+00 | loss scale: 65536.0 | grad norm: 0.646 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 10:15:07] iteration    38500/  500000 | consumed samples:       308000 | elapsed time per iteration (ms): 319.9 | learning rate: 1.457687E-04 | global batch size:     8 | lm loss: 3.830146E+00 | loss scale: 65536.0 | grad norm: 0.701 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 10:15:39] iteration    38600/  500000 | consumed samples:       308800 | elapsed time per iteration (ms): 324.0 | learning rate: 1.457449E-04 | global batch size:     8 | lm loss: 3.851442E+00 | loss scale: 65536.0 | grad norm: 0.657 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 10:16:11] iteration    38700/  500000 | consumed samples:       309600 | elapsed time per iteration (ms): 320.1 | learning rate: 1.457211E-04 | global batch size:     8 | lm loss: 3.850736E+00 | loss scale: 65536.0 | grad norm: 1.181 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 10:16:43] iteration    38800/  500000 | consumed samples:       310400 | elapsed time per iteration (ms): 321.2 | learning rate: 1.456971E-04 | global batch size:     8 | lm loss: 3.893760E+00 | loss scale: 65536.0 | grad norm: 0.633 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 10:17:15] iteration    38900/  500000 | consumed samples:       311200 | elapsed time per iteration (ms): 320.8 | learning rate: 1.456732E-04 | global batch size:     8 | lm loss: 3.848596E+00 | loss scale: 65536.0 | grad norm: 0.642 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 10:17:48] iteration    39000/  500000 | consumed samples:       312000 | elapsed time per iteration (ms): 321.9 | learning rate: 1.456491E-04 | global batch size:     8 | lm loss: 3.825931E+00 | loss scale: 131072.0 | grad norm: 0.688 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1064.65, 1064.65)
-------------------------------------------------------------------------------------------------
 validation loss at iteration 39000 | lm loss value: 3.968808E+00 | lm loss PPL: 5.292143E+01 | 
-------------------------------------------------------------------------------------------------
 [2024-06-21 10:18:21] iteration    39100/  500000 | consumed samples:       312800 | elapsed time per iteration (ms): 320.9 | learning rate: 1.456250E-04 | global batch size:     8 | lm loss: 3.844378E+00 | loss scale: 131072.0 | grad norm: 0.628 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 10:18:53] iteration    39200/  500000 | consumed samples:       313600 | elapsed time per iteration (ms): 322.8 | learning rate: 1.456008E-04 | global batch size:     8 | lm loss: 3.869214E+00 | loss scale: 131072.0 | grad norm: 0.626 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 10:19:25] iteration    39300/  500000 | consumed samples:       314400 | elapsed time per iteration (ms): 320.0 | learning rate: 1.455765E-04 | global batch size:     8 | lm loss: 3.814191E+00 | loss scale: 131072.0 | grad norm: 0.602 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 10:19:57] iteration    39400/  500000 | consumed samples:       315200 | elapsed time per iteration (ms): 321.7 | learning rate: 1.455522E-04 | global batch size:     8 | lm loss: 3.833629E+00 | loss scale: 131072.0 | grad norm: 0.709 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 10:20:29] iteration    39500/  500000 | consumed samples:       316000 | elapsed time per iteration (ms): 321.1 | learning rate: 1.455278E-04 | global batch size:     8 | lm loss: 3.847142E+00 | loss scale: 131072.0 | grad norm: 0.627 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 10:21:01] iteration    39600/  500000 | consumed samples:       316800 | elapsed time per iteration (ms): 320.3 | learning rate: 1.455034E-04 | global batch size:     8 | lm loss: 3.808231E+00 | loss scale: 131072.0 | grad norm: 0.646 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 10:21:34] iteration    39700/  500000 | consumed samples:       317600 | elapsed time per iteration (ms): 321.5 | learning rate: 1.454789E-04 | global batch size:     8 | lm loss: 3.884445E+00 | loss scale: 131072.0 | grad norm: 0.642 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 10:22:06] iteration    39800/  500000 | consumed samples:       318400 | elapsed time per iteration (ms): 320.1 | learning rate: 1.454543E-04 | global batch size:     8 | lm loss: 3.834707E+00 | loss scale: 131072.0 | grad norm: 0.631 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 10:22:38] iteration    39900/  500000 | consumed samples:       319200 | elapsed time per iteration (ms): 322.2 | learning rate: 1.454297E-04 | global batch size:     8 | lm loss: 3.829596E+00 | loss scale: 131072.0 | grad norm: 0.674 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 10:23:10] iteration    40000/  500000 | consumed samples:       320000 | elapsed time per iteration (ms): 322.8 | learning rate: 1.454050E-04 | global batch size:     8 | lm loss: 3.829149E+00 | loss scale: 262144.0 | grad norm: 0.643 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1064.25, 1064.25)
-------------------------------------------------------------------------------------------------
 validation loss at iteration 40000 | lm loss value: 3.944436E+00 | lm loss PPL: 5.164722E+01 | 
-------------------------------------------------------------------------------------------------
saving checkpoint at iteration   40000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-max in torch format
  successfully saved checkpoint at iteration   40000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-max
(min, max) time across ranks (ms):
    save-checkpoint ................................: (5726.32, 5726.32)
 [2024-06-21 10:23:49] iteration    40100/  500000 | consumed samples:       320800 | elapsed time per iteration (ms): 320.9 | learning rate: 1.453802E-04 | global batch size:     8 | lm loss: 3.830076E+00 | loss scale: 262144.0 | grad norm: 0.641 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 10:24:21] iteration    40200/  500000 | consumed samples:       321600 | elapsed time per iteration (ms): 321.0 | learning rate: 1.453556E-04 | global batch size:     8 | lm loss: 3.821756E+00 | loss scale: 262144.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-21 10:24:53] iteration    40300/  500000 | consumed samples:       322400 | elapsed time per iteration (ms): 321.0 | learning rate: 1.453312E-04 | global batch size:     8 | lm loss: 3.829385E+00 | loss scale: 65536.0 | grad norm: 0.633 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-21 10:25:25] iteration    40400/  500000 | consumed samples:       323200 | elapsed time per iteration (ms): 323.0 | learning rate: 1.453062E-04 | global batch size:     8 | lm loss: 3.870519E+00 | loss scale: 65536.0 | grad norm: 0.623 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 10:25:58] iteration    40500/  500000 | consumed samples:       324000 | elapsed time per iteration (ms): 322.6 | learning rate: 1.452812E-04 | global batch size:     8 | lm loss: 3.845746E+00 | loss scale: 65536.0 | grad norm: 0.601 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 10:26:30] iteration    40600/  500000 | consumed samples:       324800 | elapsed time per iteration (ms): 323.6 | learning rate: 1.452561E-04 | global batch size:     8 | lm loss: 3.826729E+00 | loss scale: 65536.0 | grad norm: 0.646 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 10:27:02] iteration    40700/  500000 | consumed samples:       325600 | elapsed time per iteration (ms): 322.3 | learning rate: 1.452310E-04 | global batch size:     8 | lm loss: 3.811423E+00 | loss scale: 65536.0 | grad norm: 0.629 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 10:27:35] iteration    40800/  500000 | consumed samples:       326400 | elapsed time per iteration (ms): 324.3 | learning rate: 1.452058E-04 | global batch size:     8 | lm loss: 3.785858E+00 | loss scale: 65536.0 | grad norm: 0.604 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 10:28:07] iteration    40900/  500000 | consumed samples:       327200 | elapsed time per iteration (ms): 322.5 | learning rate: 1.451805E-04 | global batch size:     8 | lm loss: 3.819091E+00 | loss scale: 65536.0 | grad norm: 0.622 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 10:28:39] iteration    41000/  500000 | consumed samples:       328000 | elapsed time per iteration (ms): 324.1 | learning rate: 1.451551E-04 | global batch size:     8 | lm loss: 3.825147E+00 | loss scale: 65536.0 | grad norm: 0.622 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1064.31, 1064.31)
-------------------------------------------------------------------------------------------------
 validation loss at iteration 41000 | lm loss value: 3.951659E+00 | lm loss PPL: 5.202160E+01 | 
-------------------------------------------------------------------------------------------------
 [2024-06-21 10:29:12] iteration    41100/  500000 | consumed samples:       328800 | elapsed time per iteration (ms): 319.4 | learning rate: 1.451297E-04 | global batch size:     8 | lm loss: 3.833657E+00 | loss scale: 65536.0 | grad norm: 0.622 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 10:29:45] iteration    41200/  500000 | consumed samples:       329600 | elapsed time per iteration (ms): 323.9 | learning rate: 1.451043E-04 | global batch size:     8 | lm loss: 3.817067E+00 | loss scale: 65536.0 | grad norm: 0.651 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 10:30:17] iteration    41300/  500000 | consumed samples:       330400 | elapsed time per iteration (ms): 321.3 | learning rate: 1.450787E-04 | global batch size:     8 | lm loss: 3.832448E+00 | loss scale: 131072.0 | grad norm: 0.720 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 10:30:49] iteration    41400/  500000 | consumed samples:       331200 | elapsed time per iteration (ms): 322.9 | learning rate: 1.450531E-04 | global batch size:     8 | lm loss: 3.830898E+00 | loss scale: 131072.0 | grad norm: 0.661 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 10:31:21] iteration    41500/  500000 | consumed samples:       332000 | elapsed time per iteration (ms): 319.2 | learning rate: 1.450275E-04 | global batch size:     8 | lm loss: 3.818538E+00 | loss scale: 131072.0 | grad norm: 0.620 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 10:31:53] iteration    41600/  500000 | consumed samples:       332800 | elapsed time per iteration (ms): 320.8 | learning rate: 1.450017E-04 | global batch size:     8 | lm loss: 3.816927E+00 | loss scale: 131072.0 | grad norm: 0.612 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 10:32:25] iteration    41700/  500000 | consumed samples:       333600 | elapsed time per iteration (ms): 320.9 | learning rate: 1.449759E-04 | global batch size:     8 | lm loss: 3.779574E+00 | loss scale: 131072.0 | grad norm: 0.647 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 10:32:57] iteration    41800/  500000 | consumed samples:       334400 | elapsed time per iteration (ms): 321.8 | learning rate: 1.449501E-04 | global batch size:     8 | lm loss: 3.808884E+00 | loss scale: 131072.0 | grad norm: 0.641 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 10:33:30] iteration    41900/  500000 | consumed samples:       335200 | elapsed time per iteration (ms): 320.9 | learning rate: 1.449242E-04 | global batch size:     8 | lm loss: 3.758365E+00 | loss scale: 131072.0 | grad norm: 0.691 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 10:34:02] iteration    42000/  500000 | consumed samples:       336000 | elapsed time per iteration (ms): 324.3 | learning rate: 1.448982E-04 | global batch size:     8 | lm loss: 3.795447E+00 | loss scale: 131072.0 | grad norm: 0.646 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1069.34, 1069.34)
-------------------------------------------------------------------------------------------------
 validation loss at iteration 42000 | lm loss value: 3.921518E+00 | lm loss PPL: 5.047702E+01 | 
-------------------------------------------------------------------------------------------------
 [2024-06-21 10:34:35] iteration    42100/  500000 | consumed samples:       336800 | elapsed time per iteration (ms): 320.5 | learning rate: 1.448721E-04 | global batch size:     8 | lm loss: 3.820885E+00 | loss scale: 131072.0 | grad norm: 0.652 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 10:35:07] iteration    42200/  500000 | consumed samples:       337600 | elapsed time per iteration (ms): 319.9 | learning rate: 1.448460E-04 | global batch size:     8 | lm loss: 3.824232E+00 | loss scale: 131072.0 | grad norm: 0.660 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 10:35:39] iteration    42300/  500000 | consumed samples:       338400 | elapsed time per iteration (ms): 322.0 | learning rate: 1.448199E-04 | global batch size:     8 | lm loss: 3.830618E+00 | loss scale: 262144.0 | grad norm: 0.614 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 10:36:11] iteration    42400/  500000 | consumed samples:       339200 | elapsed time per iteration (ms): 319.9 | learning rate: 1.447939E-04 | global batch size:     8 | lm loss: 3.820971E+00 | loss scale: 262144.0 | grad norm: 0.628 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-21 10:36:44] iteration    42500/  500000 | consumed samples:       340000 | elapsed time per iteration (ms): 323.8 | learning rate: 1.447676E-04 | global batch size:     8 | lm loss: 3.808911E+00 | loss scale: 262144.0 | grad norm: 0.592 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 10:37:16] iteration    42600/  500000 | consumed samples:       340800 | elapsed time per iteration (ms): 322.0 | learning rate: 1.447412E-04 | global batch size:     8 | lm loss: 3.809410E+00 | loss scale: 262144.0 | grad norm: 0.686 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 10:37:48] iteration    42700/  500000 | consumed samples:       341600 | elapsed time per iteration (ms): 321.7 | learning rate: 1.447148E-04 | global batch size:     8 | lm loss: 3.802108E+00 | loss scale: 262144.0 | grad norm: 0.631 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 10:38:20] iteration    42800/  500000 | consumed samples:       342400 | elapsed time per iteration (ms): 321.3 | learning rate: 1.446886E-04 | global batch size:     8 | lm loss: 3.811925E+00 | loss scale: 131072.0 | grad norm: 0.635 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-21 10:38:53] iteration    42900/  500000 | consumed samples:       343200 | elapsed time per iteration (ms): 324.1 | learning rate: 1.446623E-04 | global batch size:     8 | lm loss: 3.813221E+00 | loss scale: 65536.0 | grad norm: 0.629 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-21 10:39:25] iteration    43000/  500000 | consumed samples:       344000 | elapsed time per iteration (ms): 321.6 | learning rate: 1.446356E-04 | global batch size:     8 | lm loss: 3.783137E+00 | loss scale: 65536.0 | grad norm: 0.622 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1064.24, 1064.24)
-------------------------------------------------------------------------------------------------
 validation loss at iteration 43000 | lm loss value: 3.871925E+00 | lm loss PPL: 4.803477E+01 | 
-------------------------------------------------------------------------------------------------
 [2024-06-21 10:39:58] iteration    43100/  500000 | consumed samples:       344800 | elapsed time per iteration (ms): 320.4 | learning rate: 1.446090E-04 | global batch size:     8 | lm loss: 3.789821E+00 | loss scale: 65536.0 | grad norm: 0.652 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 10:40:30] iteration    43200/  500000 | consumed samples:       345600 | elapsed time per iteration (ms): 322.3 | learning rate: 1.445822E-04 | global batch size:     8 | lm loss: 3.798658E+00 | loss scale: 65536.0 | grad norm: 0.649 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 10:41:02] iteration    43300/  500000 | consumed samples:       346400 | elapsed time per iteration (ms): 323.6 | learning rate: 1.445557E-04 | global batch size:     8 | lm loss: 3.837719E+00 | loss scale: 32768.0 | grad norm: 0.634 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-21 10:41:35] iteration    43400/  500000 | consumed samples:       347200 | elapsed time per iteration (ms): 320.9 | learning rate: 1.445288E-04 | global batch size:     8 | lm loss: 3.809108E+00 | loss scale: 32768.0 | grad norm: 0.647 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 10:42:07] iteration    43500/  500000 | consumed samples:       348000 | elapsed time per iteration (ms): 321.4 | learning rate: 1.445019E-04 | global batch size:     8 | lm loss: 3.754012E+00 | loss scale: 32768.0 | grad norm: 0.619 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 10:42:39] iteration    43600/  500000 | consumed samples:       348800 | elapsed time per iteration (ms): 323.7 | learning rate: 1.444749E-04 | global batch size:     8 | lm loss: 3.798352E+00 | loss scale: 32768.0 | grad norm: 0.631 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 10:43:11] iteration    43700/  500000 | consumed samples:       349600 | elapsed time per iteration (ms): 323.4 | learning rate: 1.444478E-04 | global batch size:     8 | lm loss: 3.789093E+00 | loss scale: 32768.0 | grad norm: 0.595 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 10:43:44] iteration    43800/  500000 | consumed samples:       350400 | elapsed time per iteration (ms): 323.4 | learning rate: 1.444207E-04 | global batch size:     8 | lm loss: 3.791555E+00 | loss scale: 32768.0 | grad norm: 0.615 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 10:44:16] iteration    43900/  500000 | consumed samples:       351200 | elapsed time per iteration (ms): 319.8 | learning rate: 1.443935E-04 | global batch size:     8 | lm loss: 3.803862E+00 | loss scale: 32768.0 | grad norm: 0.669 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 10:44:48] iteration    44000/  500000 | consumed samples:       352000 | elapsed time per iteration (ms): 320.9 | learning rate: 1.443662E-04 | global batch size:     8 | lm loss: 3.789401E+00 | loss scale: 32768.0 | grad norm: 0.623 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1062.50, 1062.50)
-------------------------------------------------------------------------------------------------
 validation loss at iteration 44000 | lm loss value: 3.927958E+00 | lm loss PPL: 5.080311E+01 | 
-------------------------------------------------------------------------------------------------
 [2024-06-21 10:45:21] iteration    44100/  500000 | consumed samples:       352800 | elapsed time per iteration (ms): 323.0 | learning rate: 1.443389E-04 | global batch size:     8 | lm loss: 3.796270E+00 | loss scale: 32768.0 | grad norm: 0.623 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 10:45:53] iteration    44200/  500000 | consumed samples:       353600 | elapsed time per iteration (ms): 320.5 | learning rate: 1.443115E-04 | global batch size:     8 | lm loss: 3.772236E+00 | loss scale: 32768.0 | grad norm: 0.592 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 10:46:25] iteration    44300/  500000 | consumed samples:       354400 | elapsed time per iteration (ms): 321.7 | learning rate: 1.442841E-04 | global batch size:     8 | lm loss: 3.791841E+00 | loss scale: 65536.0 | grad norm: 0.672 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 10:46:57] iteration    44400/  500000 | consumed samples:       355200 | elapsed time per iteration (ms): 319.4 | learning rate: 1.442566E-04 | global batch size:     8 | lm loss: 3.787267E+00 | loss scale: 65536.0 | grad norm: 0.609 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 10:47:29] iteration    44500/  500000 | consumed samples:       356000 | elapsed time per iteration (ms): 320.2 | learning rate: 1.442290E-04 | global batch size:     8 | lm loss: 3.786764E+00 | loss scale: 65536.0 | grad norm: 0.606 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 10:48:02] iteration    44600/  500000 | consumed samples:       356800 | elapsed time per iteration (ms): 321.7 | learning rate: 1.442014E-04 | global batch size:     8 | lm loss: 3.765002E+00 | loss scale: 65536.0 | grad norm: 0.675 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 10:48:34] iteration    44700/  500000 | consumed samples:       357600 | elapsed time per iteration (ms): 324.0 | learning rate: 1.441737E-04 | global batch size:     8 | lm loss: 3.815536E+00 | loss scale: 65536.0 | grad norm: 0.668 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 10:49:06] iteration    44800/  500000 | consumed samples:       358400 | elapsed time per iteration (ms): 322.7 | learning rate: 1.441459E-04 | global batch size:     8 | lm loss: 3.782944E+00 | loss scale: 65536.0 | grad norm: 0.652 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 10:49:39] iteration    44900/  500000 | consumed samples:       359200 | elapsed time per iteration (ms): 325.9 | learning rate: 1.441181E-04 | global batch size:     8 | lm loss: 3.736106E+00 | loss scale: 65536.0 | grad norm: 0.643 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 10:50:11] iteration    45000/  500000 | consumed samples:       360000 | elapsed time per iteration (ms): 321.7 | learning rate: 1.440902E-04 | global batch size:     8 | lm loss: 3.797734E+00 | loss scale: 65536.0 | grad norm: 0.616 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1064.43, 1064.43)
-------------------------------------------------------------------------------------------------
 validation loss at iteration 45000 | lm loss value: 3.887746E+00 | lm loss PPL: 4.880077E+01 | 
-------------------------------------------------------------------------------------------------
 [2024-06-21 10:50:44] iteration    45100/  500000 | consumed samples:       360800 | elapsed time per iteration (ms): 323.1 | learning rate: 1.440623E-04 | global batch size:     8 | lm loss: 3.785170E+00 | loss scale: 65536.0 | grad norm: 0.613 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 10:51:17] iteration    45200/  500000 | consumed samples:       361600 | elapsed time per iteration (ms): 322.1 | learning rate: 1.440343E-04 | global batch size:     8 | lm loss: 3.780556E+00 | loss scale: 65536.0 | grad norm: 0.657 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 10:51:49] iteration    45300/  500000 | consumed samples:       362400 | elapsed time per iteration (ms): 322.4 | learning rate: 1.440062E-04 | global batch size:     8 | lm loss: 3.771944E+00 | loss scale: 131072.0 | grad norm: 0.626 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 10:52:21] iteration    45400/  500000 | consumed samples:       363200 | elapsed time per iteration (ms): 322.3 | learning rate: 1.439781E-04 | global batch size:     8 | lm loss: 3.800677E+00 | loss scale: 131072.0 | grad norm: 0.675 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 10:52:53] iteration    45500/  500000 | consumed samples:       364000 | elapsed time per iteration (ms): 321.5 | learning rate: 1.439499E-04 | global batch size:     8 | lm loss: 3.783256E+00 | loss scale: 131072.0 | grad norm: 0.625 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 10:53:25] iteration    45600/  500000 | consumed samples:       364800 | elapsed time per iteration (ms): 322.7 | learning rate: 1.439216E-04 | global batch size:     8 | lm loss: 3.799580E+00 | loss scale: 131072.0 | grad norm: 0.666 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 10:53:58] iteration    45700/  500000 | consumed samples:       365600 | elapsed time per iteration (ms): 322.6 | learning rate: 1.438933E-04 | global batch size:     8 | lm loss: 3.759548E+00 | loss scale: 131072.0 | grad norm: 0.593 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 10:54:30] iteration    45800/  500000 | consumed samples:       366400 | elapsed time per iteration (ms): 320.6 | learning rate: 1.438649E-04 | global batch size:     8 | lm loss: 3.774504E+00 | loss scale: 131072.0 | grad norm: 0.612 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 10:55:02] iteration    45900/  500000 | consumed samples:       367200 | elapsed time per iteration (ms): 321.0 | learning rate: 1.438365E-04 | global batch size:     8 | lm loss: 3.791402E+00 | loss scale: 131072.0 | grad norm: 0.658 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 10:55:34] iteration    46000/  500000 | consumed samples:       368000 | elapsed time per iteration (ms): 321.0 | learning rate: 1.438079E-04 | global batch size:     8 | lm loss: 3.792379E+00 | loss scale: 131072.0 | grad norm: 0.677 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1065.24, 1065.24)
-------------------------------------------------------------------------------------------------
 validation loss at iteration 46000 | lm loss value: 4.020811E+00 | lm loss PPL: 5.574628E+01 | 
-------------------------------------------------------------------------------------------------
 [2024-06-21 10:56:07] iteration    46100/  500000 | consumed samples:       368800 | elapsed time per iteration (ms): 320.8 | learning rate: 1.437794E-04 | global batch size:     8 | lm loss: 3.728558E+00 | loss scale: 131072.0 | grad norm: 0.644 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 10:56:39] iteration    46200/  500000 | consumed samples:       369600 | elapsed time per iteration (ms): 322.5 | learning rate: 1.437507E-04 | global batch size:     8 | lm loss: 3.763260E+00 | loss scale: 131072.0 | grad norm: 0.632 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 10:57:12] iteration    46300/  500000 | consumed samples:       370400 | elapsed time per iteration (ms): 321.5 | learning rate: 1.437220E-04 | global batch size:     8 | lm loss: 3.786177E+00 | loss scale: 262144.0 | grad norm: 0.618 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 10:57:44] iteration    46400/  500000 | consumed samples:       371200 | elapsed time per iteration (ms): 322.4 | learning rate: 1.436933E-04 | global batch size:     8 | lm loss: 3.740633E+00 | loss scale: 262144.0 | grad norm: 0.596 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 10:58:16] iteration    46500/  500000 | consumed samples:       372000 | elapsed time per iteration (ms): 320.0 | learning rate: 1.436644E-04 | global batch size:     8 | lm loss: 3.738883E+00 | loss scale: 262144.0 | grad norm: 0.622 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 10:58:48] iteration    46600/  500000 | consumed samples:       372800 | elapsed time per iteration (ms): 320.7 | learning rate: 1.436355E-04 | global batch size:     8 | lm loss: 3.755992E+00 | loss scale: 262144.0 | grad norm: 0.617 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 10:59:20] iteration    46700/  500000 | consumed samples:       373600 | elapsed time per iteration (ms): 321.2 | learning rate: 1.436066E-04 | global batch size:     8 | lm loss: 3.739171E+00 | loss scale: 262144.0 | grad norm: 0.630 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 10:59:52] iteration    46800/  500000 | consumed samples:       374400 | elapsed time per iteration (ms): 320.4 | learning rate: 1.435776E-04 | global batch size:     8 | lm loss: 3.744829E+00 | loss scale: 262144.0 | grad norm: 0.661 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 11:00:24] iteration    46900/  500000 | consumed samples:       375200 | elapsed time per iteration (ms): 322.4 | learning rate: 1.435485E-04 | global batch size:     8 | lm loss: 3.747298E+00 | loss scale: 262144.0 | grad norm: 0.656 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 11:00:56] iteration    47000/  500000 | consumed samples:       376000 | elapsed time per iteration (ms): 321.2 | learning rate: 1.435194E-04 | global batch size:     8 | lm loss: 3.775704E+00 | loss scale: 262144.0 | grad norm: 0.624 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1063.92, 1063.92)
-------------------------------------------------------------------------------------------------
 validation loss at iteration 47000 | lm loss value: 3.941063E+00 | lm loss PPL: 5.147331E+01 | 
-------------------------------------------------------------------------------------------------
 [2024-06-21 11:01:30] iteration    47100/  500000 | consumed samples:       376800 | elapsed time per iteration (ms): 321.0 | learning rate: 1.434902E-04 | global batch size:     8 | lm loss: 3.744551E+00 | loss scale: 262144.0 | grad norm: 0.625 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 11:02:02] iteration    47200/  500000 | consumed samples:       377600 | elapsed time per iteration (ms): 322.9 | learning rate: 1.434609E-04 | global batch size:     8 | lm loss: 3.744181E+00 | loss scale: 262144.0 | grad norm: 0.638 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 11:02:34] iteration    47300/  500000 | consumed samples:       378400 | elapsed time per iteration (ms): 323.8 | learning rate: 1.434316E-04 | global batch size:     8 | lm loss: 3.726201E+00 | loss scale: 524288.0 | grad norm: 0.787 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 11:03:07] iteration    47400/  500000 | consumed samples:       379200 | elapsed time per iteration (ms): 323.4 | learning rate: 1.434022E-04 | global batch size:     8 | lm loss: 3.798028E+00 | loss scale: 524288.0 | grad norm: 0.633 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 11:03:39] iteration    47500/  500000 | consumed samples:       380000 | elapsed time per iteration (ms): 325.7 | learning rate: 1.433727E-04 | global batch size:     8 | lm loss: 3.765479E+00 | loss scale: 524288.0 | grad norm: 0.649 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 11:04:11] iteration    47600/  500000 | consumed samples:       380800 | elapsed time per iteration (ms): 320.6 | learning rate: 1.433438E-04 | global batch size:     8 | lm loss: 3.769648E+00 | loss scale: 262144.0 | grad norm: 0.646 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-21 11:04:43] iteration    47700/  500000 | consumed samples:       381600 | elapsed time per iteration (ms): 322.2 | learning rate: 1.433142E-04 | global batch size:     8 | lm loss: 3.774202E+00 | loss scale: 262144.0 | grad norm: 0.624 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 11:05:15] iteration    47800/  500000 | consumed samples:       382400 | elapsed time per iteration (ms): 321.1 | learning rate: 1.432846E-04 | global batch size:     8 | lm loss: 3.705034E+00 | loss scale: 262144.0 | grad norm: 0.634 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 11:05:48] iteration    47900/  500000 | consumed samples:       383200 | elapsed time per iteration (ms): 320.9 | learning rate: 1.432549E-04 | global batch size:     8 | lm loss: 3.765547E+00 | loss scale: 262144.0 | grad norm: 0.605 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 11:06:20] iteration    48000/  500000 | consumed samples:       384000 | elapsed time per iteration (ms): 322.0 | learning rate: 1.432251E-04 | global batch size:     8 | lm loss: 3.725483E+00 | loss scale: 262144.0 | grad norm: 0.687 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1063.44, 1063.44)
-------------------------------------------------------------------------------------------------
 validation loss at iteration 48000 | lm loss value: 3.769362E+00 | lm loss PPL: 4.335241E+01 | 
-------------------------------------------------------------------------------------------------
 [2024-06-21 11:06:53] iteration    48100/  500000 | consumed samples:       384800 | elapsed time per iteration (ms): 323.2 | learning rate: 1.431953E-04 | global batch size:     8 | lm loss: 3.761308E+00 | loss scale: 262144.0 | grad norm: 0.621 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 11:07:25] iteration    48200/  500000 | consumed samples:       385600 | elapsed time per iteration (ms): 322.2 | learning rate: 1.431654E-04 | global batch size:     8 | lm loss: 3.753640E+00 | loss scale: 262144.0 | grad norm: 0.659 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 11:07:58] iteration    48300/  500000 | consumed samples:       386400 | elapsed time per iteration (ms): 323.7 | learning rate: 1.431355E-04 | global batch size:     8 | lm loss: 3.779077E+00 | loss scale: 262144.0 | grad norm: 0.626 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 11:08:30] iteration    48400/  500000 | consumed samples:       387200 | elapsed time per iteration (ms): 321.1 | learning rate: 1.431055E-04 | global batch size:     8 | lm loss: 3.790214E+00 | loss scale: 262144.0 | grad norm: 0.649 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 11:09:02] iteration    48500/  500000 | consumed samples:       388000 | elapsed time per iteration (ms): 322.6 | learning rate: 1.430754E-04 | global batch size:     8 | lm loss: 3.748126E+00 | loss scale: 262144.0 | grad norm: 0.609 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 11:09:34] iteration    48600/  500000 | consumed samples:       388800 | elapsed time per iteration (ms): 322.0 | learning rate: 1.430453E-04 | global batch size:     8 | lm loss: 3.752655E+00 | loss scale: 524288.0 | grad norm: 0.618 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 11:10:06] iteration    48700/  500000 | consumed samples:       389600 | elapsed time per iteration (ms): 321.5 | learning rate: 1.430151E-04 | global batch size:     8 | lm loss: 3.749406E+00 | loss scale: 524288.0 | grad norm: 0.650 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 11:10:39] iteration    48800/  500000 | consumed samples:       390400 | elapsed time per iteration (ms): 324.5 | learning rate: 1.429848E-04 | global batch size:     8 | lm loss: 3.749890E+00 | loss scale: 524288.0 | grad norm: 0.632 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 11:11:11] iteration    48900/  500000 | consumed samples:       391200 | elapsed time per iteration (ms): 321.8 | learning rate: 1.429545E-04 | global batch size:     8 | lm loss: 3.766461E+00 | loss scale: 524288.0 | grad norm: 0.635 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 11:11:43] iteration    49000/  500000 | consumed samples:       392000 | elapsed time per iteration (ms): 321.0 | learning rate: 1.429241E-04 | global batch size:     8 | lm loss: 3.728059E+00 | loss scale: 524288.0 | grad norm: 0.617 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1063.48, 1063.48)
-------------------------------------------------------------------------------------------------
 validation loss at iteration 49000 | lm loss value: 3.892417E+00 | lm loss PPL: 4.902923E+01 | 
-------------------------------------------------------------------------------------------------
 [2024-06-21 11:12:16] iteration    49100/  500000 | consumed samples:       392800 | elapsed time per iteration (ms): 321.0 | learning rate: 1.428937E-04 | global batch size:     8 | lm loss: 3.759720E+00 | loss scale: 524288.0 | grad norm: 0.624 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 11:12:49] iteration    49200/  500000 | consumed samples:       393600 | elapsed time per iteration (ms): 322.0 | learning rate: 1.428632E-04 | global batch size:     8 | lm loss: 3.760339E+00 | loss scale: 524288.0 | grad norm: 0.656 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 11:13:21] iteration    49300/  500000 | consumed samples:       394400 | elapsed time per iteration (ms): 321.5 | learning rate: 1.428326E-04 | global batch size:     8 | lm loss: 3.776768E+00 | loss scale: 524288.0 | grad norm: 0.632 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 11:13:53] iteration    49400/  500000 | consumed samples:       395200 | elapsed time per iteration (ms): 319.3 | learning rate: 1.428020E-04 | global batch size:     8 | lm loss: 3.696518E+00 | loss scale: 524288.0 | grad norm: 0.623 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 11:14:25] iteration    49500/  500000 | consumed samples:       396000 | elapsed time per iteration (ms): 320.1 | learning rate: 1.427713E-04 | global batch size:     8 | lm loss: 3.742037E+00 | loss scale: 524288.0 | grad norm: 0.609 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 11:14:57] iteration    49600/  500000 | consumed samples:       396800 | elapsed time per iteration (ms): 320.7 | learning rate: 1.427405E-04 | global batch size:     8 | lm loss: 3.707064E+00 | loss scale: 1048576.0 | grad norm: 0.619 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 11:15:29] iteration    49700/  500000 | consumed samples:       397600 | elapsed time per iteration (ms): 319.3 | learning rate: 1.427103E-04 | global batch size:     8 | lm loss: 3.734895E+00 | loss scale: 524288.0 | grad norm: 0.632 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-21 11:16:01] iteration    49800/  500000 | consumed samples:       398400 | elapsed time per iteration (ms): 320.1 | learning rate: 1.426794E-04 | global batch size:     8 | lm loss: 3.726321E+00 | loss scale: 524288.0 | grad norm: 0.606 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 11:16:33] iteration    49900/  500000 | consumed samples:       399200 | elapsed time per iteration (ms): 320.2 | learning rate: 1.426485E-04 | global batch size:     8 | lm loss: 3.733509E+00 | loss scale: 524288.0 | grad norm: 0.624 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 11:17:05] iteration    50000/  500000 | consumed samples:       400000 | elapsed time per iteration (ms): 321.5 | learning rate: 1.426175E-04 | global batch size:     8 | lm loss: 3.738680E+00 | loss scale: 524288.0 | grad norm: 0.641 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1062.12, 1062.12)
-------------------------------------------------------------------------------------------------
 validation loss at iteration 50000 | lm loss value: 3.894644E+00 | lm loss PPL: 4.913858E+01 | 
-------------------------------------------------------------------------------------------------
saving checkpoint at iteration   50000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-max in torch format
  successfully saved checkpoint at iteration   50000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-max
(min, max) time across ranks (ms):
    save-checkpoint ................................: (5618.61, 5618.61)
 [2024-06-21 11:17:44] iteration    50100/  500000 | consumed samples:       400800 | elapsed time per iteration (ms): 322.1 | learning rate: 1.425864E-04 | global batch size:     8 | lm loss: 3.734958E+00 | loss scale: 524288.0 | grad norm: 0.644 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 11:18:16] iteration    50200/  500000 | consumed samples:       401600 | elapsed time per iteration (ms): 320.5 | learning rate: 1.425553E-04 | global batch size:     8 | lm loss: 3.732671E+00 | loss scale: 524288.0 | grad norm: 0.587 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 11:18:48] iteration    50300/  500000 | consumed samples:       402400 | elapsed time per iteration (ms): 322.1 | learning rate: 1.425241E-04 | global batch size:     8 | lm loss: 3.758730E+00 | loss scale: 524288.0 | grad norm: 0.746 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 11:19:20] iteration    50400/  500000 | consumed samples:       403200 | elapsed time per iteration (ms): 320.8 | learning rate: 1.424932E-04 | global batch size:     8 | lm loss: 3.730942E+00 | loss scale: 262144.0 | grad norm: 0.622 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-21 11:19:52] iteration    50500/  500000 | consumed samples:       404000 | elapsed time per iteration (ms): 323.2 | learning rate: 1.424619E-04 | global batch size:     8 | lm loss: 3.759302E+00 | loss scale: 262144.0 | grad norm: 0.660 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 11:20:25] iteration    50600/  500000 | consumed samples:       404800 | elapsed time per iteration (ms): 322.0 | learning rate: 1.424305E-04 | global batch size:     8 | lm loss: 3.687791E+00 | loss scale: 262144.0 | grad norm: 0.614 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 11:20:57] iteration    50700/  500000 | consumed samples:       405600 | elapsed time per iteration (ms): 320.6 | learning rate: 1.423991E-04 | global batch size:     8 | lm loss: 3.781517E+00 | loss scale: 262144.0 | grad norm: 0.688 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 11:21:29] iteration    50800/  500000 | consumed samples:       406400 | elapsed time per iteration (ms): 323.3 | learning rate: 1.423676E-04 | global batch size:     8 | lm loss: 3.683297E+00 | loss scale: 262144.0 | grad norm: 0.622 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 11:22:01] iteration    50900/  500000 | consumed samples:       407200 | elapsed time per iteration (ms): 321.9 | learning rate: 1.423361E-04 | global batch size:     8 | lm loss: 3.725172E+00 | loss scale: 262144.0 | grad norm: 0.629 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 11:22:33] iteration    51000/  500000 | consumed samples:       408000 | elapsed time per iteration (ms): 320.6 | learning rate: 1.423045E-04 | global batch size:     8 | lm loss: 3.770828E+00 | loss scale: 262144.0 | grad norm: 0.627 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1062.39, 1062.39)
-------------------------------------------------------------------------------------------------
 validation loss at iteration 51000 | lm loss value: 3.944079E+00 | lm loss PPL: 5.162877E+01 | 
-------------------------------------------------------------------------------------------------
 [2024-06-21 11:23:06] iteration    51100/  500000 | consumed samples:       408800 | elapsed time per iteration (ms): 321.8 | learning rate: 1.422728E-04 | global batch size:     8 | lm loss: 3.732117E+00 | loss scale: 262144.0 | grad norm: 0.625 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 11:23:39] iteration    51200/  500000 | consumed samples:       409600 | elapsed time per iteration (ms): 320.8 | learning rate: 1.422411E-04 | global batch size:     8 | lm loss: 3.758949E+00 | loss scale: 262144.0 | grad norm: 0.633 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 11:24:11] iteration    51300/  500000 | consumed samples:       410400 | elapsed time per iteration (ms): 322.2 | learning rate: 1.422093E-04 | global batch size:     8 | lm loss: 3.755054E+00 | loss scale: 262144.0 | grad norm: 0.602 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 11:24:43] iteration    51400/  500000 | consumed samples:       411200 | elapsed time per iteration (ms): 322.9 | learning rate: 1.421774E-04 | global batch size:     8 | lm loss: 3.746960E+00 | loss scale: 524288.0 | grad norm: 0.633 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 11:25:15] iteration    51500/  500000 | consumed samples:       412000 | elapsed time per iteration (ms): 323.2 | learning rate: 1.421455E-04 | global batch size:     8 | lm loss: 3.718830E+00 | loss scale: 524288.0 | grad norm: 0.622 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 11:25:48] iteration    51600/  500000 | consumed samples:       412800 | elapsed time per iteration (ms): 324.2 | learning rate: 1.421135E-04 | global batch size:     8 | lm loss: 3.708970E+00 | loss scale: 524288.0 | grad norm: 0.618 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 11:26:20] iteration    51700/  500000 | consumed samples:       413600 | elapsed time per iteration (ms): 322.2 | learning rate: 1.420821E-04 | global batch size:     8 | lm loss: 3.673850E+00 | loss scale: 262144.0 | grad norm: 0.637 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-21 11:26:52] iteration    51800/  500000 | consumed samples:       414400 | elapsed time per iteration (ms): 321.1 | learning rate: 1.420503E-04 | global batch size:     8 | lm loss: 3.724612E+00 | loss scale: 131072.0 | grad norm: 0.623 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-21 11:27:24] iteration    51900/  500000 | consumed samples:       415200 | elapsed time per iteration (ms): 322.2 | learning rate: 1.420182E-04 | global batch size:     8 | lm loss: 3.739931E+00 | loss scale: 131072.0 | grad norm: 0.662 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 11:27:56] iteration    52000/  500000 | consumed samples:       416000 | elapsed time per iteration (ms): 321.3 | learning rate: 1.419863E-04 | global batch size:     8 | lm loss: 3.730946E+00 | loss scale: 65536.0 | grad norm: 0.631 | number of skipped iterations:   1 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1065.35, 1065.35)
-------------------------------------------------------------------------------------------------
 validation loss at iteration 52000 | lm loss value: 3.878365E+00 | lm loss PPL: 4.834512E+01 | 
-------------------------------------------------------------------------------------------------
 [2024-06-21 11:28:30] iteration    52100/  500000 | consumed samples:       416800 | elapsed time per iteration (ms): 321.1 | learning rate: 1.419540E-04 | global batch size:     8 | lm loss: 3.769229E+00 | loss scale: 65536.0 | grad norm: 0.630 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 11:29:02] iteration    52200/  500000 | consumed samples:       417600 | elapsed time per iteration (ms): 322.9 | learning rate: 1.419216E-04 | global batch size:     8 | lm loss: 3.716483E+00 | loss scale: 65536.0 | grad norm: 0.625 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 11:29:34] iteration    52300/  500000 | consumed samples:       418400 | elapsed time per iteration (ms): 321.4 | learning rate: 1.418892E-04 | global batch size:     8 | lm loss: 3.694204E+00 | loss scale: 65536.0 | grad norm: 0.624 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 11:30:06] iteration    52400/  500000 | consumed samples:       419200 | elapsed time per iteration (ms): 323.9 | learning rate: 1.418568E-04 | global batch size:     8 | lm loss: 3.769918E+00 | loss scale: 65536.0 | grad norm: 0.641 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 11:30:39] iteration    52500/  500000 | consumed samples:       420000 | elapsed time per iteration (ms): 320.6 | learning rate: 1.418242E-04 | global batch size:     8 | lm loss: 3.676542E+00 | loss scale: 65536.0 | grad norm: 0.629 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 11:31:10] iteration    52600/  500000 | consumed samples:       420800 | elapsed time per iteration (ms): 319.0 | learning rate: 1.417917E-04 | global batch size:     8 | lm loss: 3.755466E+00 | loss scale: 65536.0 | grad norm: 0.604 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 11:31:42] iteration    52700/  500000 | consumed samples:       421600 | elapsed time per iteration (ms): 320.3 | learning rate: 1.417590E-04 | global batch size:     8 | lm loss: 3.742294E+00 | loss scale: 65536.0 | grad norm: 0.621 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 11:32:15] iteration    52800/  500000 | consumed samples:       422400 | elapsed time per iteration (ms): 320.6 | learning rate: 1.417263E-04 | global batch size:     8 | lm loss: 3.697435E+00 | loss scale: 65536.0 | grad norm: 0.638 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 11:32:47] iteration    52900/  500000 | consumed samples:       423200 | elapsed time per iteration (ms): 321.8 | learning rate: 1.416935E-04 | global batch size:     8 | lm loss: 3.737895E+00 | loss scale: 65536.0 | grad norm: 0.620 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 11:33:19] iteration    53000/  500000 | consumed samples:       424000 | elapsed time per iteration (ms): 324.0 | learning rate: 1.416607E-04 | global batch size:     8 | lm loss: 3.697284E+00 | loss scale: 131072.0 | grad norm: 0.637 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1064.71, 1064.71)
-------------------------------------------------------------------------------------------------
 validation loss at iteration 53000 | lm loss value: 3.818558E+00 | lm loss PPL: 4.553852E+01 | 
-------------------------------------------------------------------------------------------------
 [2024-06-21 11:33:52] iteration    53100/  500000 | consumed samples:       424800 | elapsed time per iteration (ms): 322.5 | learning rate: 1.416278E-04 | global batch size:     8 | lm loss: 3.721302E+00 | loss scale: 131072.0 | grad norm: 0.606 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 11:34:25] iteration    53200/  500000 | consumed samples:       425600 | elapsed time per iteration (ms): 321.8 | learning rate: 1.415949E-04 | global batch size:     8 | lm loss: 3.709436E+00 | loss scale: 131072.0 | grad norm: 0.603 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 11:34:57] iteration    53300/  500000 | consumed samples:       426400 | elapsed time per iteration (ms): 322.5 | learning rate: 1.415619E-04 | global batch size:     8 | lm loss: 3.726469E+00 | loss scale: 131072.0 | grad norm: 0.615 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 11:35:29] iteration    53400/  500000 | consumed samples:       427200 | elapsed time per iteration (ms): 323.0 | learning rate: 1.415288E-04 | global batch size:     8 | lm loss: 3.700037E+00 | loss scale: 131072.0 | grad norm: 0.615 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 11:36:01] iteration    53500/  500000 | consumed samples:       428000 | elapsed time per iteration (ms): 323.3 | learning rate: 1.414957E-04 | global batch size:     8 | lm loss: 3.730918E+00 | loss scale: 131072.0 | grad norm: 0.655 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 11:36:34] iteration    53600/  500000 | consumed samples:       428800 | elapsed time per iteration (ms): 321.0 | learning rate: 1.414625E-04 | global batch size:     8 | lm loss: 3.637906E+00 | loss scale: 131072.0 | grad norm: 0.620 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 11:37:06] iteration    53700/  500000 | consumed samples:       429600 | elapsed time per iteration (ms): 319.6 | learning rate: 1.414292E-04 | global batch size:     8 | lm loss: 3.675925E+00 | loss scale: 131072.0 | grad norm: 0.623 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 11:37:38] iteration    53800/  500000 | consumed samples:       430400 | elapsed time per iteration (ms): 324.8 | learning rate: 1.413959E-04 | global batch size:     8 | lm loss: 3.680169E+00 | loss scale: 131072.0 | grad norm: 0.614 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 11:38:10] iteration    53900/  500000 | consumed samples:       431200 | elapsed time per iteration (ms): 322.9 | learning rate: 1.413625E-04 | global batch size:     8 | lm loss: 3.677253E+00 | loss scale: 131072.0 | grad norm: 0.646 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 11:38:42] iteration    54000/  500000 | consumed samples:       432000 | elapsed time per iteration (ms): 321.8 | learning rate: 1.413291E-04 | global batch size:     8 | lm loss: 3.698313E+00 | loss scale: 262144.0 | grad norm: 0.619 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1067.64, 1067.64)
-------------------------------------------------------------------------------------------------
 validation loss at iteration 54000 | lm loss value: 3.863912E+00 | lm loss PPL: 4.765142E+01 | 
-------------------------------------------------------------------------------------------------
 [2024-06-21 11:39:16] iteration    54100/  500000 | consumed samples:       432800 | elapsed time per iteration (ms): 320.7 | learning rate: 1.412956E-04 | global batch size:     8 | lm loss: 3.691472E+00 | loss scale: 262144.0 | grad norm: 0.631 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 11:39:48] iteration    54200/  500000 | consumed samples:       433600 | elapsed time per iteration (ms): 322.8 | learning rate: 1.412620E-04 | global batch size:     8 | lm loss: 3.648180E+00 | loss scale: 262144.0 | grad norm: 0.605 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 11:40:20] iteration    54300/  500000 | consumed samples:       434400 | elapsed time per iteration (ms): 321.5 | learning rate: 1.412288E-04 | global batch size:     8 | lm loss: 3.702398E+00 | loss scale: 262144.0 | grad norm: 0.619 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-21 11:40:52] iteration    54400/  500000 | consumed samples:       435200 | elapsed time per iteration (ms): 323.1 | learning rate: 1.411951E-04 | global batch size:     8 | lm loss: 3.709700E+00 | loss scale: 262144.0 | grad norm: 0.610 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 11:41:25] iteration    54500/  500000 | consumed samples:       436000 | elapsed time per iteration (ms): 322.1 | learning rate: 1.411614E-04 | global batch size:     8 | lm loss: 3.675126E+00 | loss scale: 262144.0 | grad norm: 0.625 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 11:41:57] iteration    54600/  500000 | consumed samples:       436800 | elapsed time per iteration (ms): 319.9 | learning rate: 1.411276E-04 | global batch size:     8 | lm loss: 3.685975E+00 | loss scale: 262144.0 | grad norm: 0.616 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 11:42:29] iteration    54700/  500000 | consumed samples:       437600 | elapsed time per iteration (ms): 321.8 | learning rate: 1.410937E-04 | global batch size:     8 | lm loss: 3.675564E+00 | loss scale: 262144.0 | grad norm: 0.617 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 11:43:01] iteration    54800/  500000 | consumed samples:       438400 | elapsed time per iteration (ms): 321.7 | learning rate: 1.410598E-04 | global batch size:     8 | lm loss: 3.713808E+00 | loss scale: 262144.0 | grad norm: 0.609 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 11:43:33] iteration    54900/  500000 | consumed samples:       439200 | elapsed time per iteration (ms): 322.2 | learning rate: 1.410258E-04 | global batch size:     8 | lm loss: 3.727794E+00 | loss scale: 262144.0 | grad norm: 0.624 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 11:44:05] iteration    55000/  500000 | consumed samples:       440000 | elapsed time per iteration (ms): 320.3 | learning rate: 1.409921E-04 | global batch size:     8 | lm loss: 3.738879E+00 | loss scale: 131072.0 | grad norm: 0.630 | number of skipped iterations:   1 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1062.94, 1062.94)
-------------------------------------------------------------------------------------------------
 validation loss at iteration 55000 | lm loss value: 3.827781E+00 | lm loss PPL: 4.596046E+01 | 
-------------------------------------------------------------------------------------------------
 [2024-06-21 11:44:38] iteration    55100/  500000 | consumed samples:       440800 | elapsed time per iteration (ms): 321.6 | learning rate: 1.409580E-04 | global batch size:     8 | lm loss: 3.703487E+00 | loss scale: 131072.0 | grad norm: 0.653 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 11:45:10] iteration    55200/  500000 | consumed samples:       441600 | elapsed time per iteration (ms): 320.9 | learning rate: 1.409239E-04 | global batch size:     8 | lm loss: 3.689154E+00 | loss scale: 131072.0 | grad norm: 0.656 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 11:45:43] iteration    55300/  500000 | consumed samples:       442400 | elapsed time per iteration (ms): 321.2 | learning rate: 1.408897E-04 | global batch size:     8 | lm loss: 3.703196E+00 | loss scale: 131072.0 | grad norm: 0.642 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 11:46:15] iteration    55400/  500000 | consumed samples:       443200 | elapsed time per iteration (ms): 321.0 | learning rate: 1.408554E-04 | global batch size:     8 | lm loss: 3.695378E+00 | loss scale: 131072.0 | grad norm: 0.632 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 11:46:47] iteration    55500/  500000 | consumed samples:       444000 | elapsed time per iteration (ms): 322.3 | learning rate: 1.408211E-04 | global batch size:     8 | lm loss: 3.729254E+00 | loss scale: 131072.0 | grad norm: 0.609 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 11:47:19] iteration    55600/  500000 | consumed samples:       444800 | elapsed time per iteration (ms): 320.9 | learning rate: 1.407867E-04 | global batch size:     8 | lm loss: 3.704654E+00 | loss scale: 131072.0 | grad norm: 0.590 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 11:47:51] iteration    55700/  500000 | consumed samples:       445600 | elapsed time per iteration (ms): 319.6 | learning rate: 1.407522E-04 | global batch size:     8 | lm loss: 3.698810E+00 | loss scale: 131072.0 | grad norm: 0.616 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 11:48:23] iteration    55800/  500000 | consumed samples:       446400 | elapsed time per iteration (ms): 322.4 | learning rate: 1.407177E-04 | global batch size:     8 | lm loss: 3.681418E+00 | loss scale: 131072.0 | grad norm: 0.672 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 11:48:55] iteration    55900/  500000 | consumed samples:       447200 | elapsed time per iteration (ms): 319.7 | learning rate: 1.406831E-04 | global batch size:     8 | lm loss: 3.637962E+00 | loss scale: 131072.0 | grad norm: 0.622 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 11:49:27] iteration    56000/  500000 | consumed samples:       448000 | elapsed time per iteration (ms): 318.7 | learning rate: 1.406485E-04 | global batch size:     8 | lm loss: 3.680021E+00 | loss scale: 262144.0 | grad norm: 0.627 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1063.92, 1063.92)
-------------------------------------------------------------------------------------------------
 validation loss at iteration 56000 | lm loss value: 3.845932E+00 | lm loss PPL: 4.680227E+01 | 
-------------------------------------------------------------------------------------------------
 [2024-06-21 11:50:00] iteration    56100/  500000 | consumed samples:       448800 | elapsed time per iteration (ms): 321.0 | learning rate: 1.406138E-04 | global batch size:     8 | lm loss: 3.700889E+00 | loss scale: 262144.0 | grad norm: 0.618 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 11:50:32] iteration    56200/  500000 | consumed samples:       449600 | elapsed time per iteration (ms): 322.2 | learning rate: 1.405790E-04 | global batch size:     8 | lm loss: 3.755607E+00 | loss scale: 262144.0 | grad norm: 0.606 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 11:51:05] iteration    56300/  500000 | consumed samples:       450400 | elapsed time per iteration (ms): 322.5 | learning rate: 1.405442E-04 | global batch size:     8 | lm loss: 3.701864E+00 | loss scale: 262144.0 | grad norm: 0.621 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 11:51:37] iteration    56400/  500000 | consumed samples:       451200 | elapsed time per iteration (ms): 320.6 | learning rate: 1.405097E-04 | global batch size:     8 | lm loss: 3.688211E+00 | loss scale: 262144.0 | grad norm: 0.610 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-21 11:52:09] iteration    56500/  500000 | consumed samples:       452000 | elapsed time per iteration (ms): 322.2 | learning rate: 1.404751E-04 | global batch size:     8 | lm loss: 3.692634E+00 | loss scale: 131072.0 | grad norm: 0.602 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-21 11:52:41] iteration    56600/  500000 | consumed samples:       452800 | elapsed time per iteration (ms): 322.6 | learning rate: 1.404405E-04 | global batch size:     8 | lm loss: 3.683195E+00 | loss scale: 65536.0 | grad norm: 0.931 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-21 11:53:14] iteration    56700/  500000 | consumed samples:       453600 | elapsed time per iteration (ms): 323.5 | learning rate: 1.404054E-04 | global batch size:     8 | lm loss: 3.672783E+00 | loss scale: 65536.0 | grad norm: 0.607 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 11:53:46] iteration    56800/  500000 | consumed samples:       454400 | elapsed time per iteration (ms): 323.3 | learning rate: 1.403703E-04 | global batch size:     8 | lm loss: 3.701569E+00 | loss scale: 65536.0 | grad norm: 0.617 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 11:54:18] iteration    56900/  500000 | consumed samples:       455200 | elapsed time per iteration (ms): 323.2 | learning rate: 1.403352E-04 | global batch size:     8 | lm loss: 3.725351E+00 | loss scale: 65536.0 | grad norm: 0.639 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 11:54:50] iteration    57000/  500000 | consumed samples:       456000 | elapsed time per iteration (ms): 322.0 | learning rate: 1.402999E-04 | global batch size:     8 | lm loss: 3.688207E+00 | loss scale: 65536.0 | grad norm: 0.606 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1063.31, 1063.31)
-------------------------------------------------------------------------------------------------
 validation loss at iteration 57000 | lm loss value: 3.866380E+00 | lm loss PPL: 4.776915E+01 | 
-------------------------------------------------------------------------------------------------
 [2024-06-21 11:55:24] iteration    57100/  500000 | consumed samples:       456800 | elapsed time per iteration (ms): 321.5 | learning rate: 1.402647E-04 | global batch size:     8 | lm loss: 3.677485E+00 | loss scale: 65536.0 | grad norm: 0.592 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 11:55:56] iteration    57200/  500000 | consumed samples:       457600 | elapsed time per iteration (ms): 324.6 | learning rate: 1.402293E-04 | global batch size:     8 | lm loss: 3.688265E+00 | loss scale: 65536.0 | grad norm: 0.637 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 11:56:28] iteration    57300/  500000 | consumed samples:       458400 | elapsed time per iteration (ms): 322.1 | learning rate: 1.401939E-04 | global batch size:     8 | lm loss: 3.684392E+00 | loss scale: 65536.0 | grad norm: 0.617 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 11:57:01] iteration    57400/  500000 | consumed samples:       459200 | elapsed time per iteration (ms): 323.0 | learning rate: 1.401584E-04 | global batch size:     8 | lm loss: 3.700782E+00 | loss scale: 65536.0 | grad norm: 0.668 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 11:57:33] iteration    57500/  500000 | consumed samples:       460000 | elapsed time per iteration (ms): 321.0 | learning rate: 1.401229E-04 | global batch size:     8 | lm loss: 3.687333E+00 | loss scale: 65536.0 | grad norm: 0.625 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 11:58:05] iteration    57600/  500000 | consumed samples:       460800 | elapsed time per iteration (ms): 322.9 | learning rate: 1.400873E-04 | global batch size:     8 | lm loss: 3.712711E+00 | loss scale: 131072.0 | grad norm: 0.630 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 11:58:37] iteration    57700/  500000 | consumed samples:       461600 | elapsed time per iteration (ms): 321.1 | learning rate: 1.400517E-04 | global batch size:     8 | lm loss: 3.668136E+00 | loss scale: 131072.0 | grad norm: 0.692 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 11:59:09] iteration    57800/  500000 | consumed samples:       462400 | elapsed time per iteration (ms): 322.6 | learning rate: 1.400160E-04 | global batch size:     8 | lm loss: 3.680220E+00 | loss scale: 131072.0 | grad norm: 0.635 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 11:59:41] iteration    57900/  500000 | consumed samples:       463200 | elapsed time per iteration (ms): 321.4 | learning rate: 1.399806E-04 | global batch size:     8 | lm loss: 3.662210E+00 | loss scale: 131072.0 | grad norm: 0.616 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-21 12:00:14] iteration    58000/  500000 | consumed samples:       464000 | elapsed time per iteration (ms): 321.6 | learning rate: 1.399448E-04 | global batch size:     8 | lm loss: 3.673853E+00 | loss scale: 131072.0 | grad norm: 0.621 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1064.57, 1064.57)
-------------------------------------------------------------------------------------------------
 validation loss at iteration 58000 | lm loss value: 3.755913E+00 | lm loss PPL: 4.277324E+01 | 
-------------------------------------------------------------------------------------------------
 [2024-06-21 12:00:47] iteration    58100/  500000 | consumed samples:       464800 | elapsed time per iteration (ms): 321.4 | learning rate: 1.399089E-04 | global batch size:     8 | lm loss: 3.665895E+00 | loss scale: 131072.0 | grad norm: 0.675 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 12:01:19] iteration    58200/  500000 | consumed samples:       465600 | elapsed time per iteration (ms): 322.5 | learning rate: 1.398730E-04 | global batch size:     8 | lm loss: 3.676335E+00 | loss scale: 131072.0 | grad norm: 0.629 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 12:01:51] iteration    58300/  500000 | consumed samples:       466400 | elapsed time per iteration (ms): 322.6 | learning rate: 1.398370E-04 | global batch size:     8 | lm loss: 3.669013E+00 | loss scale: 131072.0 | grad norm: 0.632 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 12:02:24] iteration    58400/  500000 | consumed samples:       467200 | elapsed time per iteration (ms): 323.2 | learning rate: 1.398009E-04 | global batch size:     8 | lm loss: 3.680814E+00 | loss scale: 131072.0 | grad norm: 0.653 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 12:02:56] iteration    58500/  500000 | consumed samples:       468000 | elapsed time per iteration (ms): 323.1 | learning rate: 1.397648E-04 | global batch size:     8 | lm loss: 3.679173E+00 | loss scale: 131072.0 | grad norm: 0.638 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 12:03:28] iteration    58600/  500000 | consumed samples:       468800 | elapsed time per iteration (ms): 322.2 | learning rate: 1.397287E-04 | global batch size:     8 | lm loss: 3.705930E+00 | loss scale: 131072.0 | grad norm: 0.631 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 12:04:00] iteration    58700/  500000 | consumed samples:       469600 | elapsed time per iteration (ms): 322.9 | learning rate: 1.396924E-04 | global batch size:     8 | lm loss: 3.690535E+00 | loss scale: 131072.0 | grad norm: 0.577 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 12:04:33] iteration    58800/  500000 | consumed samples:       470400 | elapsed time per iteration (ms): 322.5 | learning rate: 1.396561E-04 | global batch size:     8 | lm loss: 3.693851E+00 | loss scale: 131072.0 | grad norm: 0.668 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 12:05:05] iteration    58900/  500000 | consumed samples:       471200 | elapsed time per iteration (ms): 323.5 | learning rate: 1.396198E-04 | global batch size:     8 | lm loss: 3.706573E+00 | loss scale: 262144.0 | grad norm: 0.615 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 12:05:37] iteration    59000/  500000 | consumed samples:       472000 | elapsed time per iteration (ms): 323.0 | learning rate: 1.395834E-04 | global batch size:     8 | lm loss: 3.710594E+00 | loss scale: 262144.0 | grad norm: 0.645 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1062.52, 1062.52)
-------------------------------------------------------------------------------------------------
 validation loss at iteration 59000 | lm loss value: 3.868958E+00 | lm loss PPL: 4.789246E+01 | 
-------------------------------------------------------------------------------------------------
 [2024-06-21 12:06:11] iteration    59100/  500000 | consumed samples:       472800 | elapsed time per iteration (ms): 321.1 | learning rate: 1.395469E-04 | global batch size:     8 | lm loss: 3.639720E+00 | loss scale: 262144.0 | grad norm: 0.622 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 12:06:43] iteration    59200/  500000 | consumed samples:       473600 | elapsed time per iteration (ms): 320.3 | learning rate: 1.395104E-04 | global batch size:     8 | lm loss: 3.697386E+00 | loss scale: 262144.0 | grad norm: 0.636 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 12:07:15] iteration    59300/  500000 | consumed samples:       474400 | elapsed time per iteration (ms): 321.5 | learning rate: 1.394738E-04 | global batch size:     8 | lm loss: 3.685885E+00 | loss scale: 262144.0 | grad norm: 0.607 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 12:07:47] iteration    59400/  500000 | consumed samples:       475200 | elapsed time per iteration (ms): 322.8 | learning rate: 1.394372E-04 | global batch size:     8 | lm loss: 3.622346E+00 | loss scale: 262144.0 | grad norm: 0.626 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 12:08:19] iteration    59500/  500000 | consumed samples:       476000 | elapsed time per iteration (ms): 321.3 | learning rate: 1.394005E-04 | global batch size:     8 | lm loss: 3.640343E+00 | loss scale: 262144.0 | grad norm: 0.616 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 12:08:51] iteration    59600/  500000 | consumed samples:       476800 | elapsed time per iteration (ms): 321.9 | learning rate: 1.393637E-04 | global batch size:     8 | lm loss: 3.693563E+00 | loss scale: 262144.0 | grad norm: 0.629 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 12:09:23] iteration    59700/  500000 | consumed samples:       477600 | elapsed time per iteration (ms): 321.3 | learning rate: 1.393269E-04 | global batch size:     8 | lm loss: 3.671628E+00 | loss scale: 262144.0 | grad norm: 0.691 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 12:09:56] iteration    59800/  500000 | consumed samples:       478400 | elapsed time per iteration (ms): 321.5 | learning rate: 1.392900E-04 | global batch size:     8 | lm loss: 3.693897E+00 | loss scale: 262144.0 | grad norm: 0.585 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 12:10:28] iteration    59900/  500000 | consumed samples:       479200 | elapsed time per iteration (ms): 322.2 | learning rate: 1.392535E-04 | global batch size:     8 | lm loss: 3.668142E+00 | loss scale: 524288.0 | grad norm: 0.636 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-21 12:11:00] iteration    60000/  500000 | consumed samples:       480000 | elapsed time per iteration (ms): 323.3 | learning rate: 1.392165E-04 | global batch size:     8 | lm loss: 3.638354E+00 | loss scale: 524288.0 | grad norm: 0.602 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1063.20, 1063.20)
-------------------------------------------------------------------------------------------------
 validation loss at iteration 60000 | lm loss value: 3.851043E+00 | lm loss PPL: 4.704210E+01 | 
-------------------------------------------------------------------------------------------------
saving checkpoint at iteration   60000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-max in torch format
  successfully saved checkpoint at iteration   60000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-max
(min, max) time across ranks (ms):
    save-checkpoint ................................: (5768.26, 5768.26)
 [2024-06-21 12:11:39] iteration    60100/  500000 | consumed samples:       480800 | elapsed time per iteration (ms): 321.5 | learning rate: 1.391795E-04 | global batch size:     8 | lm loss: 3.659028E+00 | loss scale: 524288.0 | grad norm: 0.623 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 12:12:11] iteration    60200/  500000 | consumed samples:       481600 | elapsed time per iteration (ms): 322.6 | learning rate: 1.391423E-04 | global batch size:     8 | lm loss: 3.682668E+00 | loss scale: 524288.0 | grad norm: 0.665 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 12:12:44] iteration    60300/  500000 | consumed samples:       482400 | elapsed time per iteration (ms): 325.8 | learning rate: 1.391052E-04 | global batch size:     8 | lm loss: 3.667708E+00 | loss scale: 524288.0 | grad norm: 0.629 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 12:13:16] iteration    60400/  500000 | consumed samples:       483200 | elapsed time per iteration (ms): 323.6 | learning rate: 1.390680E-04 | global batch size:     8 | lm loss: 3.646516E+00 | loss scale: 524288.0 | grad norm: 0.620 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 12:13:49] iteration    60500/  500000 | consumed samples:       484000 | elapsed time per iteration (ms): 323.8 | learning rate: 1.390307E-04 | global batch size:     8 | lm loss: 3.682143E+00 | loss scale: 524288.0 | grad norm: 0.611 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 12:14:21] iteration    60600/  500000 | consumed samples:       484800 | elapsed time per iteration (ms): 321.2 | learning rate: 1.389933E-04 | global batch size:     8 | lm loss: 3.703515E+00 | loss scale: 524288.0 | grad norm: 0.656 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 12:14:53] iteration    60700/  500000 | consumed samples:       485600 | elapsed time per iteration (ms): 321.7 | learning rate: 1.389560E-04 | global batch size:     8 | lm loss: 3.670081E+00 | loss scale: 524288.0 | grad norm: 0.620 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 12:15:25] iteration    60800/  500000 | consumed samples:       486400 | elapsed time per iteration (ms): 322.9 | learning rate: 1.389185E-04 | global batch size:     8 | lm loss: 3.645098E+00 | loss scale: 524288.0 | grad norm: 0.638 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 12:15:58] iteration    60900/  500000 | consumed samples:       487200 | elapsed time per iteration (ms): 323.3 | learning rate: 1.388817E-04 | global batch size:     8 | lm loss: 3.664332E+00 | loss scale: 524288.0 | grad norm: 0.616 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-21 12:16:30] iteration    61000/  500000 | consumed samples:       488000 | elapsed time per iteration (ms): 321.8 | learning rate: 1.388446E-04 | global batch size:     8 | lm loss: 3.636749E+00 | loss scale: 262144.0 | grad norm: 0.585 | number of skipped iterations:   1 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1063.50, 1063.50)
-------------------------------------------------------------------------------------------------
 validation loss at iteration 61000 | lm loss value: 3.794585E+00 | lm loss PPL: 4.445980E+01 | 
-------------------------------------------------------------------------------------------------
 [2024-06-21 12:17:03] iteration    61100/  500000 | consumed samples:       488800 | elapsed time per iteration (ms): 321.2 | learning rate: 1.388069E-04 | global batch size:     8 | lm loss: 3.640471E+00 | loss scale: 262144.0 | grad norm: 0.635 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 12:17:35] iteration    61200/  500000 | consumed samples:       489600 | elapsed time per iteration (ms): 321.2 | learning rate: 1.387692E-04 | global batch size:     8 | lm loss: 3.645347E+00 | loss scale: 262144.0 | grad norm: 0.640 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 12:18:07] iteration    61300/  500000 | consumed samples:       490400 | elapsed time per iteration (ms): 321.8 | learning rate: 1.387315E-04 | global batch size:     8 | lm loss: 3.672766E+00 | loss scale: 262144.0 | grad norm: 0.608 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 12:18:39] iteration    61400/  500000 | consumed samples:       491200 | elapsed time per iteration (ms): 321.6 | learning rate: 1.386937E-04 | global batch size:     8 | lm loss: 3.656995E+00 | loss scale: 262144.0 | grad norm: 0.980 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 12:19:12] iteration    61500/  500000 | consumed samples:       492000 | elapsed time per iteration (ms): 321.8 | learning rate: 1.386558E-04 | global batch size:     8 | lm loss: 3.641998E+00 | loss scale: 262144.0 | grad norm: 0.756 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 12:19:44] iteration    61600/  500000 | consumed samples:       492800 | elapsed time per iteration (ms): 323.7 | learning rate: 1.386179E-04 | global batch size:     8 | lm loss: 3.653011E+00 | loss scale: 262144.0 | grad norm: 0.634 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 12:20:16] iteration    61700/  500000 | consumed samples:       493600 | elapsed time per iteration (ms): 322.6 | learning rate: 1.385800E-04 | global batch size:     8 | lm loss: 3.654423E+00 | loss scale: 262144.0 | grad norm: 0.632 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 12:20:48] iteration    61800/  500000 | consumed samples:       494400 | elapsed time per iteration (ms): 322.4 | learning rate: 1.385419E-04 | global batch size:     8 | lm loss: 3.674849E+00 | loss scale: 262144.0 | grad norm: 0.627 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 12:21:21] iteration    61900/  500000 | consumed samples:       495200 | elapsed time per iteration (ms): 320.9 | learning rate: 1.385038E-04 | global batch size:     8 | lm loss: 3.645053E+00 | loss scale: 262144.0 | grad norm: 0.614 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 12:21:53] iteration    62000/  500000 | consumed samples:       496000 | elapsed time per iteration (ms): 322.3 | learning rate: 1.384657E-04 | global batch size:     8 | lm loss: 3.679885E+00 | loss scale: 524288.0 | grad norm: 0.636 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1061.71, 1061.71)
-------------------------------------------------------------------------------------------------
 validation loss at iteration 62000 | lm loss value: 3.793499E+00 | lm loss PPL: 4.441155E+01 | 
-------------------------------------------------------------------------------------------------
 [2024-06-21 12:22:26] iteration    62100/  500000 | consumed samples:       496800 | elapsed time per iteration (ms): 321.7 | learning rate: 1.384275E-04 | global batch size:     8 | lm loss: 3.646778E+00 | loss scale: 524288.0 | grad norm: 0.644 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 12:22:58] iteration    62200/  500000 | consumed samples:       497600 | elapsed time per iteration (ms): 323.8 | learning rate: 1.383892E-04 | global batch size:     8 | lm loss: 3.666462E+00 | loss scale: 524288.0 | grad norm: 0.622 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 12:23:30] iteration    62300/  500000 | consumed samples:       498400 | elapsed time per iteration (ms): 319.7 | learning rate: 1.383513E-04 | global batch size:     8 | lm loss: 3.648687E+00 | loss scale: 524288.0 | grad norm: 0.641 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-21 12:24:03] iteration    62400/  500000 | consumed samples:       499200 | elapsed time per iteration (ms): 322.4 | learning rate: 1.383129E-04 | global batch size:     8 | lm loss: 3.697885E+00 | loss scale: 524288.0 | grad norm: 0.607 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 12:24:35] iteration    62500/  500000 | consumed samples:       500000 | elapsed time per iteration (ms): 320.7 | learning rate: 1.382745E-04 | global batch size:     8 | lm loss: 3.655195E+00 | loss scale: 524288.0 | grad norm: 0.636 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 12:25:07] iteration    62600/  500000 | consumed samples:       500800 | elapsed time per iteration (ms): 321.7 | learning rate: 1.382360E-04 | global batch size:     8 | lm loss: 3.663273E+00 | loss scale: 524288.0 | grad norm: 0.633 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 12:25:39] iteration    62700/  500000 | consumed samples:       501600 | elapsed time per iteration (ms): 324.9 | learning rate: 1.381975E-04 | global batch size:     8 | lm loss: 3.620341E+00 | loss scale: 524288.0 | grad norm: 0.688 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 12:26:11] iteration    62800/  500000 | consumed samples:       502400 | elapsed time per iteration (ms): 321.1 | learning rate: 1.381589E-04 | global batch size:     8 | lm loss: 3.692555E+00 | loss scale: 524288.0 | grad norm: 0.651 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 12:26:44] iteration    62900/  500000 | consumed samples:       503200 | elapsed time per iteration (ms): 325.3 | learning rate: 1.381202E-04 | global batch size:     8 | lm loss: 3.662951E+00 | loss scale: 524288.0 | grad norm: 0.611 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 12:27:16] iteration    63000/  500000 | consumed samples:       504000 | elapsed time per iteration (ms): 321.6 | learning rate: 1.380815E-04 | global batch size:     8 | lm loss: 3.617595E+00 | loss scale: 524288.0 | grad norm: 0.632 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1064.12, 1064.12)
-------------------------------------------------------------------------------------------------
 validation loss at iteration 63000 | lm loss value: 3.720677E+00 | lm loss PPL: 4.129234E+01 | 
-------------------------------------------------------------------------------------------------
 [2024-06-21 12:27:49] iteration    63100/  500000 | consumed samples:       504800 | elapsed time per iteration (ms): 321.5 | learning rate: 1.380427E-04 | global batch size:     8 | lm loss: 3.630082E+00 | loss scale: 524288.0 | grad norm: 0.610 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 12:28:22] iteration    63200/  500000 | consumed samples:       505600 | elapsed time per iteration (ms): 321.7 | learning rate: 1.380039E-04 | global batch size:     8 | lm loss: 3.662205E+00 | loss scale: 524288.0 | grad norm: 0.626 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 12:28:54] iteration    63300/  500000 | consumed samples:       506400 | elapsed time per iteration (ms): 319.9 | learning rate: 1.379650E-04 | global batch size:     8 | lm loss: 3.597563E+00 | loss scale: 1048576.0 | grad norm: 0.606 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 12:29:26] iteration    63400/  500000 | consumed samples:       507200 | elapsed time per iteration (ms): 323.1 | learning rate: 1.379261E-04 | global batch size:     8 | lm loss: 3.633776E+00 | loss scale: 1048576.0 | grad norm: 0.634 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 12:29:58] iteration    63500/  500000 | consumed samples:       508000 | elapsed time per iteration (ms): 322.7 | learning rate: 1.378874E-04 | global batch size:     8 | lm loss: 3.639038E+00 | loss scale: 1048576.0 | grad norm: 0.649 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-21 12:30:30] iteration    63600/  500000 | consumed samples:       508800 | elapsed time per iteration (ms): 320.8 | learning rate: 1.378488E-04 | global batch size:     8 | lm loss: 3.642167E+00 | loss scale: 524288.0 | grad norm: 0.629 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-21 12:31:02] iteration    63700/  500000 | consumed samples:       509600 | elapsed time per iteration (ms): 320.2 | learning rate: 1.378101E-04 | global batch size:     8 | lm loss: 3.585719E+00 | loss scale: 262144.0 | grad norm: 0.618 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-21 12:31:34] iteration    63800/  500000 | consumed samples:       510400 | elapsed time per iteration (ms): 319.6 | learning rate: 1.377709E-04 | global batch size:     8 | lm loss: 3.607700E+00 | loss scale: 262144.0 | grad norm: 0.605 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 12:32:06] iteration    63900/  500000 | consumed samples:       511200 | elapsed time per iteration (ms): 321.9 | learning rate: 1.377317E-04 | global batch size:     8 | lm loss: 3.644577E+00 | loss scale: 262144.0 | grad norm: 0.640 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 12:32:39] iteration    64000/  500000 | consumed samples:       512000 | elapsed time per iteration (ms): 322.4 | learning rate: 1.376924E-04 | global batch size:     8 | lm loss: 3.655430E+00 | loss scale: 262144.0 | grad norm: 0.651 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1068.87, 1068.87)
-------------------------------------------------------------------------------------------------
 validation loss at iteration 64000 | lm loss value: 3.840129E+00 | lm loss PPL: 4.653148E+01 | 
-------------------------------------------------------------------------------------------------
 [2024-06-21 12:33:12] iteration    64100/  500000 | consumed samples:       512800 | elapsed time per iteration (ms): 320.7 | learning rate: 1.376530E-04 | global batch size:     8 | lm loss: 3.641946E+00 | loss scale: 262144.0 | grad norm: 0.671 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 12:33:44] iteration    64200/  500000 | consumed samples:       513600 | elapsed time per iteration (ms): 322.1 | learning rate: 1.376136E-04 | global batch size:     8 | lm loss: 3.686678E+00 | loss scale: 262144.0 | grad norm: 0.634 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 12:34:16] iteration    64300/  500000 | consumed samples:       514400 | elapsed time per iteration (ms): 321.6 | learning rate: 1.375742E-04 | global batch size:     8 | lm loss: 3.645336E+00 | loss scale: 262144.0 | grad norm: 0.622 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 12:34:48] iteration    64400/  500000 | consumed samples:       515200 | elapsed time per iteration (ms): 321.0 | learning rate: 1.375347E-04 | global batch size:     8 | lm loss: 3.634561E+00 | loss scale: 262144.0 | grad norm: 0.662 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 12:35:20] iteration    64500/  500000 | consumed samples:       516000 | elapsed time per iteration (ms): 320.4 | learning rate: 1.374951E-04 | global batch size:     8 | lm loss: 3.635791E+00 | loss scale: 262144.0 | grad norm: 0.656 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 12:35:53] iteration    64600/  500000 | consumed samples:       516800 | elapsed time per iteration (ms): 323.6 | learning rate: 1.374555E-04 | global batch size:     8 | lm loss: 3.634796E+00 | loss scale: 262144.0 | grad norm: 0.781 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 12:36:25] iteration    64700/  500000 | consumed samples:       517600 | elapsed time per iteration (ms): 322.4 | learning rate: 1.374162E-04 | global batch size:     8 | lm loss: 3.606556E+00 | loss scale: 524288.0 | grad norm: 0.661 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-21 12:36:57] iteration    64800/  500000 | consumed samples:       518400 | elapsed time per iteration (ms): 321.1 | learning rate: 1.373765E-04 | global batch size:     8 | lm loss: 3.632588E+00 | loss scale: 524288.0 | grad norm: 0.621 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 12:37:29] iteration    64900/  500000 | consumed samples:       519200 | elapsed time per iteration (ms): 323.7 | learning rate: 1.373367E-04 | global batch size:     8 | lm loss: 3.640632E+00 | loss scale: 524288.0 | grad norm: 0.655 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 12:38:01] iteration    65000/  500000 | consumed samples:       520000 | elapsed time per iteration (ms): 321.7 | learning rate: 1.372968E-04 | global batch size:     8 | lm loss: 3.665716E+00 | loss scale: 524288.0 | grad norm: 0.620 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1065.64, 1065.64)
-------------------------------------------------------------------------------------------------
 validation loss at iteration 65000 | lm loss value: 3.900299E+00 | lm loss PPL: 4.941721E+01 | 
-------------------------------------------------------------------------------------------------
 [2024-06-21 12:38:35] iteration    65100/  500000 | consumed samples:       520800 | elapsed time per iteration (ms): 323.2 | learning rate: 1.372569E-04 | global batch size:     8 | lm loss: 3.632198E+00 | loss scale: 524288.0 | grad norm: 0.618 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 12:39:07] iteration    65200/  500000 | consumed samples:       521600 | elapsed time per iteration (ms): 322.4 | learning rate: 1.372169E-04 | global batch size:     8 | lm loss: 3.633893E+00 | loss scale: 524288.0 | grad norm: 0.625 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 12:39:39] iteration    65300/  500000 | consumed samples:       522400 | elapsed time per iteration (ms): 321.8 | learning rate: 1.371769E-04 | global batch size:     8 | lm loss: 3.634176E+00 | loss scale: 524288.0 | grad norm: 0.625 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 12:40:11] iteration    65400/  500000 | consumed samples:       523200 | elapsed time per iteration (ms): 322.2 | learning rate: 1.371369E-04 | global batch size:     8 | lm loss: 3.593687E+00 | loss scale: 524288.0 | grad norm: 0.630 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 12:40:44] iteration    65500/  500000 | consumed samples:       524000 | elapsed time per iteration (ms): 320.5 | learning rate: 1.370967E-04 | global batch size:     8 | lm loss: 3.614945E+00 | loss scale: 524288.0 | grad norm: 0.643 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 12:41:16] iteration    65600/  500000 | consumed samples:       524800 | elapsed time per iteration (ms): 323.4 | learning rate: 1.370565E-04 | global batch size:     8 | lm loss: 3.654970E+00 | loss scale: 524288.0 | grad norm: 0.652 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 12:41:48] iteration    65700/  500000 | consumed samples:       525600 | elapsed time per iteration (ms): 321.5 | learning rate: 1.370167E-04 | global batch size:     8 | lm loss: 3.608381E+00 | loss scale: 1048576.0 | grad norm: 0.626 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-21 12:42:20] iteration    65800/  500000 | consumed samples:       526400 | elapsed time per iteration (ms): 320.2 | learning rate: 1.369768E-04 | global batch size:     8 | lm loss: 3.635877E+00 | loss scale: 524288.0 | grad norm: 0.605 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-21 12:42:52] iteration    65900/  500000 | consumed samples:       527200 | elapsed time per iteration (ms): 323.2 | learning rate: 1.369364E-04 | global batch size:     8 | lm loss: 3.617802E+00 | loss scale: 524288.0 | grad norm: 0.628 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 12:43:24] iteration    66000/  500000 | consumed samples:       528000 | elapsed time per iteration (ms): 321.1 | learning rate: 1.368960E-04 | global batch size:     8 | lm loss: 3.627407E+00 | loss scale: 524288.0 | grad norm: 0.640 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1067.92, 1067.92)
-------------------------------------------------------------------------------------------------
 validation loss at iteration 66000 | lm loss value: 3.869959E+00 | lm loss PPL: 4.794044E+01 | 
-------------------------------------------------------------------------------------------------
 [2024-06-21 12:43:58] iteration    66100/  500000 | consumed samples:       528800 | elapsed time per iteration (ms): 321.1 | learning rate: 1.368556E-04 | global batch size:     8 | lm loss: 3.654982E+00 | loss scale: 524288.0 | grad norm: 0.621 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 12:44:30] iteration    66200/  500000 | consumed samples:       529600 | elapsed time per iteration (ms): 320.5 | learning rate: 1.368150E-04 | global batch size:     8 | lm loss: 3.675465E+00 | loss scale: 524288.0 | grad norm: 0.612 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 12:45:02] iteration    66300/  500000 | consumed samples:       530400 | elapsed time per iteration (ms): 321.5 | learning rate: 1.367745E-04 | global batch size:     8 | lm loss: 3.561730E+00 | loss scale: 524288.0 | grad norm: 0.623 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 12:45:34] iteration    66400/  500000 | consumed samples:       531200 | elapsed time per iteration (ms): 320.0 | learning rate: 1.367342E-04 | global batch size:     8 | lm loss: 3.623998E+00 | loss scale: 262144.0 | grad norm: 0.626 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-21 12:46:06] iteration    66500/  500000 | consumed samples:       532000 | elapsed time per iteration (ms): 321.8 | learning rate: 1.366940E-04 | global batch size:     8 | lm loss: 3.622081E+00 | loss scale: 131072.0 | grad norm: 0.610 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-21 12:46:38] iteration    66600/  500000 | consumed samples:       532800 | elapsed time per iteration (ms): 322.7 | learning rate: 1.366532E-04 | global batch size:     8 | lm loss: 3.649156E+00 | loss scale: 131072.0 | grad norm: 0.649 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 12:47:10] iteration    66700/  500000 | consumed samples:       533600 | elapsed time per iteration (ms): 320.8 | learning rate: 1.366124E-04 | global batch size:     8 | lm loss: 3.643104E+00 | loss scale: 131072.0 | grad norm: 0.627 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 12:47:43] iteration    66800/  500000 | consumed samples:       534400 | elapsed time per iteration (ms): 321.6 | learning rate: 1.365716E-04 | global batch size:     8 | lm loss: 3.589570E+00 | loss scale: 131072.0 | grad norm: 0.619 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 12:48:15] iteration    66900/  500000 | consumed samples:       535200 | elapsed time per iteration (ms): 321.1 | learning rate: 1.365306E-04 | global batch size:     8 | lm loss: 3.609100E+00 | loss scale: 131072.0 | grad norm: 0.624 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 12:48:47] iteration    67000/  500000 | consumed samples:       536000 | elapsed time per iteration (ms): 320.9 | learning rate: 1.364897E-04 | global batch size:     8 | lm loss: 3.657007E+00 | loss scale: 131072.0 | grad norm: 0.601 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1065.58, 1065.58)
-------------------------------------------------------------------------------------------------
 validation loss at iteration 67000 | lm loss value: 3.665294E+00 | lm loss PPL: 3.906762E+01 | 
-------------------------------------------------------------------------------------------------
 [2024-06-21 12:49:20] iteration    67100/  500000 | consumed samples:       536800 | elapsed time per iteration (ms): 320.7 | learning rate: 1.364487E-04 | global batch size:     8 | lm loss: 3.605202E+00 | loss scale: 131072.0 | grad norm: 0.620 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 12:49:52] iteration    67200/  500000 | consumed samples:       537600 | elapsed time per iteration (ms): 321.5 | learning rate: 1.364076E-04 | global batch size:     8 | lm loss: 3.641763E+00 | loss scale: 131072.0 | grad norm: 0.639 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 12:50:25] iteration    67300/  500000 | consumed samples:       538400 | elapsed time per iteration (ms): 325.3 | learning rate: 1.363664E-04 | global batch size:     8 | lm loss: 3.628336E+00 | loss scale: 131072.0 | grad norm: 0.632 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 12:50:57] iteration    67400/  500000 | consumed samples:       539200 | elapsed time per iteration (ms): 322.5 | learning rate: 1.363253E-04 | global batch size:     8 | lm loss: 3.575683E+00 | loss scale: 131072.0 | grad norm: 0.608 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 12:51:29] iteration    67500/  500000 | consumed samples:       540000 | elapsed time per iteration (ms): 318.8 | learning rate: 1.362840E-04 | global batch size:     8 | lm loss: 3.630340E+00 | loss scale: 262144.0 | grad norm: 0.621 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 12:52:01] iteration    67600/  500000 | consumed samples:       540800 | elapsed time per iteration (ms): 321.9 | learning rate: 1.362431E-04 | global batch size:     8 | lm loss: 3.619834E+00 | loss scale: 262144.0 | grad norm: 0.627 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-21 12:52:33] iteration    67700/  500000 | consumed samples:       541600 | elapsed time per iteration (ms): 322.4 | learning rate: 1.362018E-04 | global batch size:     8 | lm loss: 3.630491E+00 | loss scale: 262144.0 | grad norm: 0.676 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 12:53:05] iteration    67800/  500000 | consumed samples:       542400 | elapsed time per iteration (ms): 323.0 | learning rate: 1.361604E-04 | global batch size:     8 | lm loss: 3.574945E+00 | loss scale: 262144.0 | grad norm: 0.681 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 12:53:38] iteration    67900/  500000 | consumed samples:       543200 | elapsed time per iteration (ms): 322.6 | learning rate: 1.361189E-04 | global batch size:     8 | lm loss: 3.617887E+00 | loss scale: 262144.0 | grad norm: 0.637 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 12:54:10] iteration    68000/  500000 | consumed samples:       544000 | elapsed time per iteration (ms): 320.7 | learning rate: 1.360774E-04 | global batch size:     8 | lm loss: 3.664039E+00 | loss scale: 262144.0 | grad norm: 0.613 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1063.08, 1063.08)
-------------------------------------------------------------------------------------------------
 validation loss at iteration 68000 | lm loss value: 3.962291E+00 | lm loss PPL: 5.257764E+01 | 
-------------------------------------------------------------------------------------------------
 [2024-06-21 12:54:43] iteration    68100/  500000 | consumed samples:       544800 | elapsed time per iteration (ms): 323.5 | learning rate: 1.360358E-04 | global batch size:     8 | lm loss: 3.610323E+00 | loss scale: 262144.0 | grad norm: 0.605 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 12:55:16] iteration    68200/  500000 | consumed samples:       545600 | elapsed time per iteration (ms): 324.0 | learning rate: 1.359942E-04 | global batch size:     8 | lm loss: 3.599819E+00 | loss scale: 262144.0 | grad norm: 0.615 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 12:55:48] iteration    68300/  500000 | consumed samples:       546400 | elapsed time per iteration (ms): 323.4 | learning rate: 1.359525E-04 | global batch size:     8 | lm loss: 3.606605E+00 | loss scale: 262144.0 | grad norm: 0.616 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 12:56:20] iteration    68400/  500000 | consumed samples:       547200 | elapsed time per iteration (ms): 323.4 | learning rate: 1.359108E-04 | global batch size:     8 | lm loss: 3.659547E+00 | loss scale: 262144.0 | grad norm: 0.620 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 12:56:52] iteration    68500/  500000 | consumed samples:       548000 | elapsed time per iteration (ms): 322.4 | learning rate: 1.358690E-04 | global batch size:     8 | lm loss: 3.592970E+00 | loss scale: 262144.0 | grad norm: 0.631 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 12:57:25] iteration    68600/  500000 | consumed samples:       548800 | elapsed time per iteration (ms): 320.9 | learning rate: 1.358271E-04 | global batch size:     8 | lm loss: 3.582257E+00 | loss scale: 524288.0 | grad norm: 0.609 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 12:57:57] iteration    68700/  500000 | consumed samples:       549600 | elapsed time per iteration (ms): 320.2 | learning rate: 1.357852E-04 | global batch size:     8 | lm loss: 3.607120E+00 | loss scale: 524288.0 | grad norm: 0.615 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 12:58:29] iteration    68800/  500000 | consumed samples:       550400 | elapsed time per iteration (ms): 320.8 | learning rate: 1.357432E-04 | global batch size:     8 | lm loss: 3.579100E+00 | loss scale: 524288.0 | grad norm: 0.630 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 12:59:01] iteration    68900/  500000 | consumed samples:       551200 | elapsed time per iteration (ms): 321.5 | learning rate: 1.357016E-04 | global batch size:     8 | lm loss: 3.645168E+00 | loss scale: 524288.0 | grad norm: 0.657 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-21 12:59:33] iteration    69000/  500000 | consumed samples:       552000 | elapsed time per iteration (ms): 322.9 | learning rate: 1.356596E-04 | global batch size:     8 | lm loss: 3.616211E+00 | loss scale: 524288.0 | grad norm: 0.624 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1063.61, 1063.61)
-------------------------------------------------------------------------------------------------
 validation loss at iteration 69000 | lm loss value: 3.870422E+00 | lm loss PPL: 4.796263E+01 | 
-------------------------------------------------------------------------------------------------
 [2024-06-21 13:00:06] iteration    69100/  500000 | consumed samples:       552800 | elapsed time per iteration (ms): 321.6 | learning rate: 1.356175E-04 | global batch size:     8 | lm loss: 3.599564E+00 | loss scale: 524288.0 | grad norm: 0.632 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 13:00:39] iteration    69200/  500000 | consumed samples:       553600 | elapsed time per iteration (ms): 322.7 | learning rate: 1.355753E-04 | global batch size:     8 | lm loss: 3.658325E+00 | loss scale: 524288.0 | grad norm: 0.602 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 13:01:11] iteration    69300/  500000 | consumed samples:       554400 | elapsed time per iteration (ms): 323.4 | learning rate: 1.355330E-04 | global batch size:     8 | lm loss: 3.651869E+00 | loss scale: 524288.0 | grad norm: 0.649 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 13:01:43] iteration    69400/  500000 | consumed samples:       555200 | elapsed time per iteration (ms): 323.1 | learning rate: 1.354908E-04 | global batch size:     8 | lm loss: 3.622997E+00 | loss scale: 524288.0 | grad norm: 0.640 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 13:02:16] iteration    69500/  500000 | consumed samples:       556000 | elapsed time per iteration (ms): 323.1 | learning rate: 1.354484E-04 | global batch size:     8 | lm loss: 3.605800E+00 | loss scale: 524288.0 | grad norm: 0.623 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 13:02:48] iteration    69600/  500000 | consumed samples:       556800 | elapsed time per iteration (ms): 324.0 | learning rate: 1.354064E-04 | global batch size:     8 | lm loss: 3.574032E+00 | loss scale: 262144.0 | grad norm: 0.648 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-21 13:03:20] iteration    69700/  500000 | consumed samples:       557600 | elapsed time per iteration (ms): 321.4 | learning rate: 1.353640E-04 | global batch size:     8 | lm loss: 3.628083E+00 | loss scale: 262144.0 | grad norm: 0.638 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 13:03:52] iteration    69800/  500000 | consumed samples:       558400 | elapsed time per iteration (ms): 320.9 | learning rate: 1.353215E-04 | global batch size:     8 | lm loss: 3.595372E+00 | loss scale: 262144.0 | grad norm: 0.663 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 13:04:24] iteration    69900/  500000 | consumed samples:       559200 | elapsed time per iteration (ms): 322.5 | learning rate: 1.352789E-04 | global batch size:     8 | lm loss: 3.626155E+00 | loss scale: 262144.0 | grad norm: 0.636 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 13:04:56] iteration    70000/  500000 | consumed samples:       560000 | elapsed time per iteration (ms): 318.9 | learning rate: 1.352363E-04 | global batch size:     8 | lm loss: 3.610262E+00 | loss scale: 262144.0 | grad norm: 0.620 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1062.81, 1062.81)
-------------------------------------------------------------------------------------------------
 validation loss at iteration 70000 | lm loss value: 3.790131E+00 | lm loss PPL: 4.426221E+01 | 
-------------------------------------------------------------------------------------------------
saving checkpoint at iteration   70000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-max in torch format
  successfully saved checkpoint at iteration   70000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-max
(min, max) time across ranks (ms):
    save-checkpoint ................................: (5690.41, 5690.41)
 [2024-06-21 13:05:35] iteration    70100/  500000 | consumed samples:       560800 | elapsed time per iteration (ms): 318.4 | learning rate: 1.351936E-04 | global batch size:     8 | lm loss: 3.627849E+00 | loss scale: 262144.0 | grad norm: 0.702 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 13:06:07] iteration    70200/  500000 | consumed samples:       561600 | elapsed time per iteration (ms): 320.2 | learning rate: 1.351509E-04 | global batch size:     8 | lm loss: 3.626752E+00 | loss scale: 262144.0 | grad norm: 0.701 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 13:06:39] iteration    70300/  500000 | consumed samples:       562400 | elapsed time per iteration (ms): 324.8 | learning rate: 1.351081E-04 | global batch size:     8 | lm loss: 3.623838E+00 | loss scale: 262144.0 | grad norm: 0.608 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 13:07:11] iteration    70400/  500000 | consumed samples:       563200 | elapsed time per iteration (ms): 320.5 | learning rate: 1.350653E-04 | global batch size:     8 | lm loss: 3.650514E+00 | loss scale: 262144.0 | grad norm: 0.630 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 13:07:44] iteration    70500/  500000 | consumed samples:       564000 | elapsed time per iteration (ms): 321.6 | learning rate: 1.350224E-04 | global batch size:     8 | lm loss: 3.602763E+00 | loss scale: 262144.0 | grad norm: 0.643 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 13:08:16] iteration    70600/  500000 | consumed samples:       564800 | elapsed time per iteration (ms): 320.9 | learning rate: 1.349795E-04 | global batch size:     8 | lm loss: 3.618054E+00 | loss scale: 524288.0 | grad norm: 0.596 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 13:08:48] iteration    70700/  500000 | consumed samples:       565600 | elapsed time per iteration (ms): 321.4 | learning rate: 1.349365E-04 | global batch size:     8 | lm loss: 3.585356E+00 | loss scale: 524288.0 | grad norm: 0.597 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 13:09:20] iteration    70800/  500000 | consumed samples:       566400 | elapsed time per iteration (ms): 321.3 | learning rate: 1.348939E-04 | global batch size:     8 | lm loss: 3.595683E+00 | loss scale: 524288.0 | grad norm: 0.625 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-21 13:09:52] iteration    70900/  500000 | consumed samples:       567200 | elapsed time per iteration (ms): 321.8 | learning rate: 1.348508E-04 | global batch size:     8 | lm loss: 3.590003E+00 | loss scale: 524288.0 | grad norm: 0.648 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 13:10:24] iteration    71000/  500000 | consumed samples:       568000 | elapsed time per iteration (ms): 323.0 | learning rate: 1.348076E-04 | global batch size:     8 | lm loss: 3.653796E+00 | loss scale: 524288.0 | grad norm: 0.643 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1063.98, 1063.98)
-------------------------------------------------------------------------------------------------
 validation loss at iteration 71000 | lm loss value: 3.730025E+00 | lm loss PPL: 4.168014E+01 | 
-------------------------------------------------------------------------------------------------
 [2024-06-21 13:10:58] iteration    71100/  500000 | consumed samples:       568800 | elapsed time per iteration (ms): 320.4 | learning rate: 1.347644E-04 | global batch size:     8 | lm loss: 3.566686E+00 | loss scale: 524288.0 | grad norm: 0.648 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 13:11:30] iteration    71200/  500000 | consumed samples:       569600 | elapsed time per iteration (ms): 322.1 | learning rate: 1.347212E-04 | global batch size:     8 | lm loss: 3.645516E+00 | loss scale: 524288.0 | grad norm: 0.679 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 13:12:02] iteration    71300/  500000 | consumed samples:       570400 | elapsed time per iteration (ms): 323.0 | learning rate: 1.346778E-04 | global batch size:     8 | lm loss: 3.579157E+00 | loss scale: 524288.0 | grad norm: 0.648 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 13:12:34] iteration    71400/  500000 | consumed samples:       571200 | elapsed time per iteration (ms): 322.9 | learning rate: 1.346345E-04 | global batch size:     8 | lm loss: 3.632202E+00 | loss scale: 524288.0 | grad norm: 0.641 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 13:13:07] iteration    71500/  500000 | consumed samples:       572000 | elapsed time per iteration (ms): 321.7 | learning rate: 1.345915E-04 | global batch size:     8 | lm loss: 3.599133E+00 | loss scale: 262144.0 | grad norm: 0.632 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-21 13:13:39] iteration    71600/  500000 | consumed samples:       572800 | elapsed time per iteration (ms): 323.0 | learning rate: 1.345480E-04 | global batch size:     8 | lm loss: 3.575427E+00 | loss scale: 262144.0 | grad norm: 0.628 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 13:14:11] iteration    71700/  500000 | consumed samples:       573600 | elapsed time per iteration (ms): 319.7 | learning rate: 1.345045E-04 | global batch size:     8 | lm loss: 3.599341E+00 | loss scale: 262144.0 | grad norm: 0.602 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 13:14:43] iteration    71800/  500000 | consumed samples:       574400 | elapsed time per iteration (ms): 324.8 | learning rate: 1.344609E-04 | global batch size:     8 | lm loss: 3.581172E+00 | loss scale: 262144.0 | grad norm: 0.668 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 13:15:15] iteration    71900/  500000 | consumed samples:       575200 | elapsed time per iteration (ms): 321.5 | learning rate: 1.344173E-04 | global batch size:     8 | lm loss: 3.632733E+00 | loss scale: 262144.0 | grad norm: 0.632 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 13:15:48] iteration    72000/  500000 | consumed samples:       576000 | elapsed time per iteration (ms): 323.2 | learning rate: 1.343736E-04 | global batch size:     8 | lm loss: 3.616139E+00 | loss scale: 262144.0 | grad norm: 0.589 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1075.34, 1075.34)
-------------------------------------------------------------------------------------------------
 validation loss at iteration 72000 | lm loss value: 3.858307E+00 | lm loss PPL: 4.738508E+01 | 
-------------------------------------------------------------------------------------------------
 [2024-06-21 13:16:21] iteration    72100/  500000 | consumed samples:       576800 | elapsed time per iteration (ms): 321.7 | learning rate: 1.343298E-04 | global batch size:     8 | lm loss: 3.587788E+00 | loss scale: 262144.0 | grad norm: 0.631 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 13:16:53] iteration    72200/  500000 | consumed samples:       577600 | elapsed time per iteration (ms): 320.4 | learning rate: 1.342860E-04 | global batch size:     8 | lm loss: 3.634594E+00 | loss scale: 262144.0 | grad norm: 0.635 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 13:17:25] iteration    72300/  500000 | consumed samples:       578400 | elapsed time per iteration (ms): 320.1 | learning rate: 1.342422E-04 | global batch size:     8 | lm loss: 3.598036E+00 | loss scale: 262144.0 | grad norm: 0.630 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 13:17:57] iteration    72400/  500000 | consumed samples:       579200 | elapsed time per iteration (ms): 323.9 | learning rate: 1.341983E-04 | global batch size:     8 | lm loss: 3.576097E+00 | loss scale: 262144.0 | grad norm: 0.664 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 13:18:30] iteration    72500/  500000 | consumed samples:       580000 | elapsed time per iteration (ms): 320.7 | learning rate: 1.341543E-04 | global batch size:     8 | lm loss: 3.599854E+00 | loss scale: 524288.0 | grad norm: 0.633 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 13:19:02] iteration    72600/  500000 | consumed samples:       580800 | elapsed time per iteration (ms): 323.6 | learning rate: 1.341103E-04 | global batch size:     8 | lm loss: 3.595574E+00 | loss scale: 524288.0 | grad norm: 0.661 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 13:19:34] iteration    72700/  500000 | consumed samples:       581600 | elapsed time per iteration (ms): 321.7 | learning rate: 1.340662E-04 | global batch size:     8 | lm loss: 3.619026E+00 | loss scale: 524288.0 | grad norm: 0.627 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 13:20:06] iteration    72800/  500000 | consumed samples:       582400 | elapsed time per iteration (ms): 319.4 | learning rate: 1.340226E-04 | global batch size:     8 | lm loss: 3.541781E+00 | loss scale: 524288.0 | grad norm: 0.616 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-21 13:20:38] iteration    72900/  500000 | consumed samples:       583200 | elapsed time per iteration (ms): 322.7 | learning rate: 1.339784E-04 | global batch size:     8 | lm loss: 3.567860E+00 | loss scale: 524288.0 | grad norm: 0.662 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 13:21:10] iteration    73000/  500000 | consumed samples:       584000 | elapsed time per iteration (ms): 320.1 | learning rate: 1.339346E-04 | global batch size:     8 | lm loss: 3.572739E+00 | loss scale: 262144.0 | grad norm: 0.613 | number of skipped iterations:   1 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1062.94, 1062.94)
-------------------------------------------------------------------------------------------------
 validation loss at iteration 73000 | lm loss value: 3.747504E+00 | lm loss PPL: 4.241508E+01 | 
-------------------------------------------------------------------------------------------------
 [2024-06-21 13:21:43] iteration    73100/  500000 | consumed samples:       584800 | elapsed time per iteration (ms): 320.3 | learning rate: 1.338912E-04 | global batch size:     8 | lm loss: 3.597590E+00 | loss scale: 65536.0 | grad norm: 0.638 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-21 13:22:16] iteration    73200/  500000 | consumed samples:       585600 | elapsed time per iteration (ms): 321.1 | learning rate: 1.338473E-04 | global batch size:     8 | lm loss: 3.603943E+00 | loss scale: 32768.0 | grad norm: 0.631 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-21 13:22:48] iteration    73300/  500000 | consumed samples:       586400 | elapsed time per iteration (ms): 321.0 | learning rate: 1.338029E-04 | global batch size:     8 | lm loss: 3.611733E+00 | loss scale: 32768.0 | grad norm: 0.638 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 13:23:20] iteration    73400/  500000 | consumed samples:       587200 | elapsed time per iteration (ms): 322.5 | learning rate: 1.337585E-04 | global batch size:     8 | lm loss: 3.620081E+00 | loss scale: 32768.0 | grad norm: 0.631 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 13:23:52] iteration    73500/  500000 | consumed samples:       588000 | elapsed time per iteration (ms): 323.2 | learning rate: 1.337140E-04 | global batch size:     8 | lm loss: 3.557725E+00 | loss scale: 32768.0 | grad norm: 0.660 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 13:24:24] iteration    73600/  500000 | consumed samples:       588800 | elapsed time per iteration (ms): 322.3 | learning rate: 1.336695E-04 | global batch size:     8 | lm loss: 3.574035E+00 | loss scale: 32768.0 | grad norm: 0.632 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 13:24:57] iteration    73700/  500000 | consumed samples:       589600 | elapsed time per iteration (ms): 322.2 | learning rate: 1.336249E-04 | global batch size:     8 | lm loss: 3.597136E+00 | loss scale: 32768.0 | grad norm: 0.658 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 13:25:29] iteration    73800/  500000 | consumed samples:       590400 | elapsed time per iteration (ms): 322.2 | learning rate: 1.335803E-04 | global batch size:     8 | lm loss: 3.562302E+00 | loss scale: 32768.0 | grad norm: 0.653 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 13:26:01] iteration    73900/  500000 | consumed samples:       591200 | elapsed time per iteration (ms): 323.2 | learning rate: 1.335356E-04 | global batch size:     8 | lm loss: 3.601658E+00 | loss scale: 32768.0 | grad norm: 0.621 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 13:26:33] iteration    74000/  500000 | consumed samples:       592000 | elapsed time per iteration (ms): 322.1 | learning rate: 1.334908E-04 | global batch size:     8 | lm loss: 3.554167E+00 | loss scale: 32768.0 | grad norm: 0.636 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1062.12, 1062.12)
-------------------------------------------------------------------------------------------------
 validation loss at iteration 74000 | lm loss value: 3.814196E+00 | lm loss PPL: 4.534029E+01 | 
-------------------------------------------------------------------------------------------------
 [2024-06-21 13:27:06] iteration    74100/  500000 | consumed samples:       592800 | elapsed time per iteration (ms): 318.8 | learning rate: 1.334460E-04 | global batch size:     8 | lm loss: 3.593663E+00 | loss scale: 32768.0 | grad norm: 0.622 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 13:27:38] iteration    74200/  500000 | consumed samples:       593600 | elapsed time per iteration (ms): 319.9 | learning rate: 1.334011E-04 | global batch size:     8 | lm loss: 3.567429E+00 | loss scale: 65536.0 | grad norm: 0.594 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 13:28:10] iteration    74300/  500000 | consumed samples:       594400 | elapsed time per iteration (ms): 319.5 | learning rate: 1.333562E-04 | global batch size:     8 | lm loss: 3.593220E+00 | loss scale: 65536.0 | grad norm: 0.629 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 13:28:42] iteration    74400/  500000 | consumed samples:       595200 | elapsed time per iteration (ms): 322.1 | learning rate: 1.333113E-04 | global batch size:     8 | lm loss: 3.604241E+00 | loss scale: 65536.0 | grad norm: 0.598 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 13:29:15] iteration    74500/  500000 | consumed samples:       596000 | elapsed time per iteration (ms): 323.3 | learning rate: 1.332663E-04 | global batch size:     8 | lm loss: 3.556146E+00 | loss scale: 65536.0 | grad norm: 0.647 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 13:29:47] iteration    74600/  500000 | consumed samples:       596800 | elapsed time per iteration (ms): 323.2 | learning rate: 1.332212E-04 | global batch size:     8 | lm loss: 3.595365E+00 | loss scale: 65536.0 | grad norm: 0.639 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 13:30:19] iteration    74700/  500000 | consumed samples:       597600 | elapsed time per iteration (ms): 320.6 | learning rate: 1.331761E-04 | global batch size:     8 | lm loss: 3.580889E+00 | loss scale: 65536.0 | grad norm: 0.644 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 13:30:51] iteration    74800/  500000 | consumed samples:       598400 | elapsed time per iteration (ms): 322.6 | learning rate: 1.331309E-04 | global batch size:     8 | lm loss: 3.571068E+00 | loss scale: 65536.0 | grad norm: 0.629 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 13:31:24] iteration    74900/  500000 | consumed samples:       599200 | elapsed time per iteration (ms): 321.2 | learning rate: 1.330857E-04 | global batch size:     8 | lm loss: 3.605929E+00 | loss scale: 65536.0 | grad norm: 0.646 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 13:31:56] iteration    75000/  500000 | consumed samples:       600000 | elapsed time per iteration (ms): 324.4 | learning rate: 1.330404E-04 | global batch size:     8 | lm loss: 3.558872E+00 | loss scale: 65536.0 | grad norm: 0.647 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1072.48, 1072.48)
-------------------------------------------------------------------------------------------------
 validation loss at iteration 75000 | lm loss value: 3.887278E+00 | lm loss PPL: 4.877795E+01 | 
-------------------------------------------------------------------------------------------------
 [2024-06-21 13:32:29] iteration    75100/  500000 | consumed samples:       600800 | elapsed time per iteration (ms): 320.5 | learning rate: 1.329951E-04 | global batch size:     8 | lm loss: 3.518629E+00 | loss scale: 65536.0 | grad norm: 0.613 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 13:33:01] iteration    75200/  500000 | consumed samples:       601600 | elapsed time per iteration (ms): 320.7 | learning rate: 1.329497E-04 | global batch size:     8 | lm loss: 3.513168E+00 | loss scale: 131072.0 | grad norm: 0.675 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 13:33:33] iteration    75300/  500000 | consumed samples:       602400 | elapsed time per iteration (ms): 321.2 | learning rate: 1.329047E-04 | global batch size:     8 | lm loss: 3.574540E+00 | loss scale: 131072.0 | grad norm: 0.663 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-21 13:34:06] iteration    75400/  500000 | consumed samples:       603200 | elapsed time per iteration (ms): 324.2 | learning rate: 1.328593E-04 | global batch size:     8 | lm loss: 3.616030E+00 | loss scale: 131072.0 | grad norm: 0.662 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 13:34:38] iteration    75500/  500000 | consumed samples:       604000 | elapsed time per iteration (ms): 324.1 | learning rate: 1.328137E-04 | global batch size:     8 | lm loss: 3.566356E+00 | loss scale: 131072.0 | grad norm: 0.609 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 13:35:10] iteration    75600/  500000 | consumed samples:       604800 | elapsed time per iteration (ms): 318.7 | learning rate: 1.327681E-04 | global batch size:     8 | lm loss: 3.623453E+00 | loss scale: 131072.0 | grad norm: 0.579 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 13:35:42] iteration    75700/  500000 | consumed samples:       605600 | elapsed time per iteration (ms): 322.5 | learning rate: 1.327225E-04 | global batch size:     8 | lm loss: 3.588150E+00 | loss scale: 131072.0 | grad norm: 0.604 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 13:36:15] iteration    75800/  500000 | consumed samples:       606400 | elapsed time per iteration (ms): 322.8 | learning rate: 1.326768E-04 | global batch size:     8 | lm loss: 3.602751E+00 | loss scale: 131072.0 | grad norm: 0.617 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 13:36:47] iteration    75900/  500000 | consumed samples:       607200 | elapsed time per iteration (ms): 321.2 | learning rate: 1.326315E-04 | global batch size:     8 | lm loss: 3.555212E+00 | loss scale: 65536.0 | grad norm: 0.652 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-21 13:37:19] iteration    76000/  500000 | consumed samples:       608000 | elapsed time per iteration (ms): 322.5 | learning rate: 1.325857E-04 | global batch size:     8 | lm loss: 3.597676E+00 | loss scale: 65536.0 | grad norm: 0.616 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1064.94, 1064.94)
-------------------------------------------------------------------------------------------------
 validation loss at iteration 76000 | lm loss value: 3.611152E+00 | lm loss PPL: 3.700866E+01 | 
-------------------------------------------------------------------------------------------------
 [2024-06-21 13:37:52] iteration    76100/  500000 | consumed samples:       608800 | elapsed time per iteration (ms): 323.8 | learning rate: 1.325399E-04 | global batch size:     8 | lm loss: 3.570711E+00 | loss scale: 65536.0 | grad norm: 0.658 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 13:38:25] iteration    76200/  500000 | consumed samples:       609600 | elapsed time per iteration (ms): 322.4 | learning rate: 1.324940E-04 | global batch size:     8 | lm loss: 3.557415E+00 | loss scale: 65536.0 | grad norm: 0.632 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 13:38:57] iteration    76300/  500000 | consumed samples:       610400 | elapsed time per iteration (ms): 320.8 | learning rate: 1.324481E-04 | global batch size:     8 | lm loss: 3.560962E+00 | loss scale: 65536.0 | grad norm: 0.629 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 13:39:29] iteration    76400/  500000 | consumed samples:       611200 | elapsed time per iteration (ms): 321.7 | learning rate: 1.324025E-04 | global batch size:     8 | lm loss: 3.614408E+00 | loss scale: 32768.0 | grad norm: 0.621 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-21 13:40:01] iteration    76500/  500000 | consumed samples:       612000 | elapsed time per iteration (ms): 323.9 | learning rate: 1.323565E-04 | global batch size:     8 | lm loss: 3.533918E+00 | loss scale: 32768.0 | grad norm: 0.617 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 13:40:34] iteration    76600/  500000 | consumed samples:       612800 | elapsed time per iteration (ms): 322.7 | learning rate: 1.323104E-04 | global batch size:     8 | lm loss: 3.606994E+00 | loss scale: 32768.0 | grad norm: 0.636 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 13:41:06] iteration    76700/  500000 | consumed samples:       613600 | elapsed time per iteration (ms): 323.1 | learning rate: 1.322642E-04 | global batch size:     8 | lm loss: 3.560526E+00 | loss scale: 32768.0 | grad norm: 0.664 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 13:41:38] iteration    76800/  500000 | consumed samples:       614400 | elapsed time per iteration (ms): 322.4 | learning rate: 1.322180E-04 | global batch size:     8 | lm loss: 3.572559E+00 | loss scale: 32768.0 | grad norm: 0.653 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 13:42:10] iteration    76900/  500000 | consumed samples:       615200 | elapsed time per iteration (ms): 319.9 | learning rate: 1.321718E-04 | global batch size:     8 | lm loss: 3.593439E+00 | loss scale: 32768.0 | grad norm: 0.627 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 13:42:42] iteration    77000/  500000 | consumed samples:       616000 | elapsed time per iteration (ms): 322.8 | learning rate: 1.321254E-04 | global batch size:     8 | lm loss: 3.605345E+00 | loss scale: 32768.0 | grad norm: 0.634 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1064.36, 1064.36)
-------------------------------------------------------------------------------------------------
 validation loss at iteration 77000 | lm loss value: 3.792022E+00 | lm loss PPL: 4.434596E+01 | 
-------------------------------------------------------------------------------------------------
 [2024-06-21 13:43:15] iteration    77100/  500000 | consumed samples:       616800 | elapsed time per iteration (ms): 320.3 | learning rate: 1.320791E-04 | global batch size:     8 | lm loss: 3.544485E+00 | loss scale: 32768.0 | grad norm: 0.629 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 13:43:48] iteration    77200/  500000 | consumed samples:       617600 | elapsed time per iteration (ms): 321.6 | learning rate: 1.320327E-04 | global batch size:     8 | lm loss: 3.549643E+00 | loss scale: 32768.0 | grad norm: 0.661 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 13:44:20] iteration    77300/  500000 | consumed samples:       618400 | elapsed time per iteration (ms): 321.8 | learning rate: 1.319862E-04 | global batch size:     8 | lm loss: 3.559899E+00 | loss scale: 32768.0 | grad norm: 0.623 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 13:44:52] iteration    77400/  500000 | consumed samples:       619200 | elapsed time per iteration (ms): 323.4 | learning rate: 1.319397E-04 | global batch size:     8 | lm loss: 3.542297E+00 | loss scale: 65536.0 | grad norm: 0.622 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 13:45:24] iteration    77500/  500000 | consumed samples:       620000 | elapsed time per iteration (ms): 320.4 | learning rate: 1.318931E-04 | global batch size:     8 | lm loss: 3.553950E+00 | loss scale: 65536.0 | grad norm: 0.609 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 13:45:56] iteration    77600/  500000 | consumed samples:       620800 | elapsed time per iteration (ms): 323.1 | learning rate: 1.318465E-04 | global batch size:     8 | lm loss: 3.553531E+00 | loss scale: 65536.0 | grad norm: 0.641 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 13:46:29] iteration    77700/  500000 | consumed samples:       621600 | elapsed time per iteration (ms): 321.5 | learning rate: 1.317999E-04 | global batch size:     8 | lm loss: 3.556888E+00 | loss scale: 65536.0 | grad norm: 0.667 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 13:47:01] iteration    77800/  500000 | consumed samples:       622400 | elapsed time per iteration (ms): 322.6 | learning rate: 1.317531E-04 | global batch size:     8 | lm loss: 3.541228E+00 | loss scale: 65536.0 | grad norm: 0.623 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 13:47:33] iteration    77900/  500000 | consumed samples:       623200 | elapsed time per iteration (ms): 321.8 | learning rate: 1.317064E-04 | global batch size:     8 | lm loss: 3.566532E+00 | loss scale: 65536.0 | grad norm: 0.708 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 13:48:05] iteration    78000/  500000 | consumed samples:       624000 | elapsed time per iteration (ms): 323.0 | learning rate: 1.316596E-04 | global batch size:     8 | lm loss: 3.579623E+00 | loss scale: 65536.0 | grad norm: 0.631 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1062.68, 1062.68)
-------------------------------------------------------------------------------------------------
 validation loss at iteration 78000 | lm loss value: 3.741475E+00 | lm loss PPL: 4.216012E+01 | 
-------------------------------------------------------------------------------------------------
 [2024-06-21 13:48:39] iteration    78100/  500000 | consumed samples:       624800 | elapsed time per iteration (ms): 322.6 | learning rate: 1.316127E-04 | global batch size:     8 | lm loss: 3.600054E+00 | loss scale: 65536.0 | grad norm: 0.621 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 13:49:11] iteration    78200/  500000 | consumed samples:       625600 | elapsed time per iteration (ms): 322.1 | learning rate: 1.315658E-04 | global batch size:     8 | lm loss: 3.557848E+00 | loss scale: 65536.0 | grad norm: 0.643 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 13:49:43] iteration    78300/  500000 | consumed samples:       626400 | elapsed time per iteration (ms): 323.2 | learning rate: 1.315188E-04 | global batch size:     8 | lm loss: 3.552957E+00 | loss scale: 65536.0 | grad norm: 0.619 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 13:50:15] iteration    78400/  500000 | consumed samples:       627200 | elapsed time per iteration (ms): 322.6 | learning rate: 1.314718E-04 | global batch size:     8 | lm loss: 3.580901E+00 | loss scale: 131072.0 | grad norm: 0.629 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 13:50:48] iteration    78500/  500000 | consumed samples:       628000 | elapsed time per iteration (ms): 321.8 | learning rate: 1.314247E-04 | global batch size:     8 | lm loss: 3.611768E+00 | loss scale: 131072.0 | grad norm: 0.628 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 13:51:20] iteration    78600/  500000 | consumed samples:       628800 | elapsed time per iteration (ms): 320.4 | learning rate: 1.313776E-04 | global batch size:     8 | lm loss: 3.556193E+00 | loss scale: 131072.0 | grad norm: 0.612 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 13:51:52] iteration    78700/  500000 | consumed samples:       629600 | elapsed time per iteration (ms): 320.7 | learning rate: 1.313304E-04 | global batch size:     8 | lm loss: 3.595886E+00 | loss scale: 131072.0 | grad norm: 0.604 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 13:52:24] iteration    78800/  500000 | consumed samples:       630400 | elapsed time per iteration (ms): 323.8 | learning rate: 1.312832E-04 | global batch size:     8 | lm loss: 3.549052E+00 | loss scale: 131072.0 | grad norm: 0.642 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 13:52:56] iteration    78900/  500000 | consumed samples:       631200 | elapsed time per iteration (ms): 322.5 | learning rate: 1.312359E-04 | global batch size:     8 | lm loss: 3.582475E+00 | loss scale: 131072.0 | grad norm: 0.673 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 13:53:28] iteration    79000/  500000 | consumed samples:       632000 | elapsed time per iteration (ms): 320.3 | learning rate: 1.311886E-04 | global batch size:     8 | lm loss: 3.557633E+00 | loss scale: 131072.0 | grad norm: 0.674 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1065.59, 1065.59)
-------------------------------------------------------------------------------------------------
 validation loss at iteration 79000 | lm loss value: 3.715939E+00 | lm loss PPL: 4.109717E+01 | 
-------------------------------------------------------------------------------------------------
 [2024-06-21 13:54:01] iteration    79100/  500000 | consumed samples:       632800 | elapsed time per iteration (ms): 319.2 | learning rate: 1.311412E-04 | global batch size:     8 | lm loss: 3.565380E+00 | loss scale: 131072.0 | grad norm: 0.614 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 13:54:34] iteration    79200/  500000 | consumed samples:       633600 | elapsed time per iteration (ms): 322.4 | learning rate: 1.310938E-04 | global batch size:     8 | lm loss: 3.544090E+00 | loss scale: 131072.0 | grad norm: 0.604 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 13:55:06] iteration    79300/  500000 | consumed samples:       634400 | elapsed time per iteration (ms): 322.8 | learning rate: 1.310463E-04 | global batch size:     8 | lm loss: 3.560508E+00 | loss scale: 131072.0 | grad norm: 0.636 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 13:55:38] iteration    79400/  500000 | consumed samples:       635200 | elapsed time per iteration (ms): 323.9 | learning rate: 1.309988E-04 | global batch size:     8 | lm loss: 3.538345E+00 | loss scale: 262144.0 | grad norm: 0.602 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 13:56:10] iteration    79500/  500000 | consumed samples:       636000 | elapsed time per iteration (ms): 321.0 | learning rate: 1.309512E-04 | global batch size:     8 | lm loss: 3.575656E+00 | loss scale: 262144.0 | grad norm: 0.652 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 13:56:43] iteration    79600/  500000 | consumed samples:       636800 | elapsed time per iteration (ms): 322.0 | learning rate: 1.309036E-04 | global batch size:     8 | lm loss: 3.534081E+00 | loss scale: 262144.0 | grad norm: 0.630 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 13:57:15] iteration    79700/  500000 | consumed samples:       637600 | elapsed time per iteration (ms): 323.7 | learning rate: 1.308559E-04 | global batch size:     8 | lm loss: 3.558862E+00 | loss scale: 262144.0 | grad norm: 0.647 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 13:57:47] iteration    79800/  500000 | consumed samples:       638400 | elapsed time per iteration (ms): 320.4 | learning rate: 1.308082E-04 | global batch size:     8 | lm loss: 3.545169E+00 | loss scale: 262144.0 | grad norm: 0.626 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 13:58:19] iteration    79900/  500000 | consumed samples:       639200 | elapsed time per iteration (ms): 320.9 | learning rate: 1.307604E-04 | global batch size:     8 | lm loss: 3.579907E+00 | loss scale: 262144.0 | grad norm: 0.617 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 13:58:51] iteration    80000/  500000 | consumed samples:       640000 | elapsed time per iteration (ms): 322.1 | learning rate: 1.307126E-04 | global batch size:     8 | lm loss: 3.562299E+00 | loss scale: 262144.0 | grad norm: 0.649 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1070.69, 1070.69)
-------------------------------------------------------------------------------------------------
 validation loss at iteration 80000 | lm loss value: 3.861598E+00 | lm loss PPL: 4.754125E+01 | 
-------------------------------------------------------------------------------------------------
saving checkpoint at iteration   80000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-max in torch format
  successfully saved checkpoint at iteration   80000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-max
(min, max) time across ranks (ms):
    save-checkpoint ................................: (5647.65, 5647.65)
 [2024-06-21 13:59:30] iteration    80100/  500000 | consumed samples:       640800 | elapsed time per iteration (ms): 321.6 | learning rate: 1.306652E-04 | global batch size:     8 | lm loss: 3.562302E+00 | loss scale: 262144.0 | grad norm: 0.649 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-21 14:00:02] iteration    80200/  500000 | consumed samples:       641600 | elapsed time per iteration (ms): 321.8 | learning rate: 1.306173E-04 | global batch size:     8 | lm loss: 3.523451E+00 | loss scale: 262144.0 | grad norm: 0.667 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 14:00:34] iteration    80300/  500000 | consumed samples:       642400 | elapsed time per iteration (ms): 320.7 | learning rate: 1.305693E-04 | global batch size:     8 | lm loss: 3.552411E+00 | loss scale: 262144.0 | grad norm: 0.640 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 14:01:07] iteration    80400/  500000 | consumed samples:       643200 | elapsed time per iteration (ms): 322.7 | learning rate: 1.305213E-04 | global batch size:     8 | lm loss: 3.582244E+00 | loss scale: 262144.0 | grad norm: 0.942 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 14:01:39] iteration    80500/  500000 | consumed samples:       644000 | elapsed time per iteration (ms): 322.4 | learning rate: 1.304732E-04 | global batch size:     8 | lm loss: 3.531141E+00 | loss scale: 262144.0 | grad norm: 0.635 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 14:02:11] iteration    80600/  500000 | consumed samples:       644800 | elapsed time per iteration (ms): 320.1 | learning rate: 1.304251E-04 | global batch size:     8 | lm loss: 3.534038E+00 | loss scale: 262144.0 | grad norm: 0.632 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 14:02:43] iteration    80700/  500000 | consumed samples:       645600 | elapsed time per iteration (ms): 321.7 | learning rate: 1.303769E-04 | global batch size:     8 | lm loss: 3.539722E+00 | loss scale: 262144.0 | grad norm: 0.632 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 14:03:15] iteration    80800/  500000 | consumed samples:       646400 | elapsed time per iteration (ms): 322.9 | learning rate: 1.303287E-04 | global batch size:     8 | lm loss: 3.554925E+00 | loss scale: 262144.0 | grad norm: 0.649 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 14:03:48] iteration    80900/  500000 | consumed samples:       647200 | elapsed time per iteration (ms): 322.7 | learning rate: 1.302804E-04 | global batch size:     8 | lm loss: 3.528142E+00 | loss scale: 262144.0 | grad norm: 0.736 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 14:04:20] iteration    81000/  500000 | consumed samples:       648000 | elapsed time per iteration (ms): 322.7 | learning rate: 1.302321E-04 | global batch size:     8 | lm loss: 3.564925E+00 | loss scale: 262144.0 | grad norm: 0.711 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1062.29, 1062.29)
-------------------------------------------------------------------------------------------------
 validation loss at iteration 81000 | lm loss value: 3.673161E+00 | lm loss PPL: 3.937616E+01 | 
-------------------------------------------------------------------------------------------------
 [2024-06-21 14:04:53] iteration    81100/  500000 | consumed samples:       648800 | elapsed time per iteration (ms): 323.1 | learning rate: 1.301837E-04 | global batch size:     8 | lm loss: 3.559295E+00 | loss scale: 524288.0 | grad norm: 0.637 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 14:05:26] iteration    81200/  500000 | consumed samples:       649600 | elapsed time per iteration (ms): 322.5 | learning rate: 1.301358E-04 | global batch size:     8 | lm loss: 3.523669E+00 | loss scale: 524288.0 | grad norm: 0.636 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-21 14:05:58] iteration    81300/  500000 | consumed samples:       650400 | elapsed time per iteration (ms): 321.9 | learning rate: 1.300878E-04 | global batch size:     8 | lm loss: 3.557829E+00 | loss scale: 262144.0 | grad norm: 0.642 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-21 14:06:30] iteration    81400/  500000 | consumed samples:       651200 | elapsed time per iteration (ms): 321.6 | learning rate: 1.300393E-04 | global batch size:     8 | lm loss: 3.537602E+00 | loss scale: 262144.0 | grad norm: 0.620 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 14:07:02] iteration    81500/  500000 | consumed samples:       652000 | elapsed time per iteration (ms): 320.2 | learning rate: 1.299907E-04 | global batch size:     8 | lm loss: 3.550956E+00 | loss scale: 262144.0 | grad norm: 0.625 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 14:07:34] iteration    81600/  500000 | consumed samples:       652800 | elapsed time per iteration (ms): 321.5 | learning rate: 1.299421E-04 | global batch size:     8 | lm loss: 3.489833E+00 | loss scale: 262144.0 | grad norm: 0.624 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 14:08:06] iteration    81700/  500000 | consumed samples:       653600 | elapsed time per iteration (ms): 323.1 | learning rate: 1.298935E-04 | global batch size:     8 | lm loss: 3.563088E+00 | loss scale: 262144.0 | grad norm: 0.590 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 14:08:39] iteration    81800/  500000 | consumed samples:       654400 | elapsed time per iteration (ms): 322.7 | learning rate: 1.298447E-04 | global batch size:     8 | lm loss: 3.554084E+00 | loss scale: 262144.0 | grad norm: 0.647 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 14:09:11] iteration    81900/  500000 | consumed samples:       655200 | elapsed time per iteration (ms): 319.4 | learning rate: 1.297960E-04 | global batch size:     8 | lm loss: 3.581123E+00 | loss scale: 262144.0 | grad norm: 0.637 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 14:09:43] iteration    82000/  500000 | consumed samples:       656000 | elapsed time per iteration (ms): 320.5 | learning rate: 1.297472E-04 | global batch size:     8 | lm loss: 3.542006E+00 | loss scale: 262144.0 | grad norm: 0.638 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1064.08, 1064.08)
-------------------------------------------------------------------------------------------------
 validation loss at iteration 82000 | lm loss value: 3.677170E+00 | lm loss PPL: 3.953436E+01 | 
-------------------------------------------------------------------------------------------------
 [2024-06-21 14:10:16] iteration    82100/  500000 | consumed samples:       656800 | elapsed time per iteration (ms): 320.4 | learning rate: 1.296983E-04 | global batch size:     8 | lm loss: 3.497125E+00 | loss scale: 262144.0 | grad norm: 0.644 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 14:10:48] iteration    82200/  500000 | consumed samples:       657600 | elapsed time per iteration (ms): 322.3 | learning rate: 1.296494E-04 | global batch size:     8 | lm loss: 3.572950E+00 | loss scale: 262144.0 | grad norm: 0.662 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 14:11:20] iteration    82300/  500000 | consumed samples:       658400 | elapsed time per iteration (ms): 322.2 | learning rate: 1.296009E-04 | global batch size:     8 | lm loss: 3.545289E+00 | loss scale: 131072.0 | grad norm: 0.596 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-21 14:11:53] iteration    82400/  500000 | consumed samples:       659200 | elapsed time per iteration (ms): 324.1 | learning rate: 1.295519E-04 | global batch size:     8 | lm loss: 3.539836E+00 | loss scale: 131072.0 | grad norm: 0.684 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 14:12:25] iteration    82500/  500000 | consumed samples:       660000 | elapsed time per iteration (ms): 320.9 | learning rate: 1.295029E-04 | global batch size:     8 | lm loss: 3.496627E+00 | loss scale: 131072.0 | grad norm: 0.633 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 14:12:57] iteration    82600/  500000 | consumed samples:       660800 | elapsed time per iteration (ms): 319.6 | learning rate: 1.294538E-04 | global batch size:     8 | lm loss: 3.526010E+00 | loss scale: 131072.0 | grad norm: 0.679 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 14:13:29] iteration    82700/  500000 | consumed samples:       661600 | elapsed time per iteration (ms): 321.4 | learning rate: 1.294046E-04 | global batch size:     8 | lm loss: 3.544594E+00 | loss scale: 131072.0 | grad norm: 0.648 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 14:14:01] iteration    82800/  500000 | consumed samples:       662400 | elapsed time per iteration (ms): 321.7 | learning rate: 1.293554E-04 | global batch size:     8 | lm loss: 3.487177E+00 | loss scale: 131072.0 | grad norm: 0.666 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 14:14:33] iteration    82900/  500000 | consumed samples:       663200 | elapsed time per iteration (ms): 319.8 | learning rate: 1.293062E-04 | global batch size:     8 | lm loss: 3.531880E+00 | loss scale: 131072.0 | grad norm: 0.617 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 14:15:05] iteration    83000/  500000 | consumed samples:       664000 | elapsed time per iteration (ms): 319.9 | learning rate: 1.292569E-04 | global batch size:     8 | lm loss: 3.546840E+00 | loss scale: 131072.0 | grad norm: 0.642 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1063.28, 1063.28)
-------------------------------------------------------------------------------------------------
 validation loss at iteration 83000 | lm loss value: 3.765032E+00 | lm loss PPL: 4.316508E+01 | 
-------------------------------------------------------------------------------------------------
 [2024-06-21 14:15:38] iteration    83100/  500000 | consumed samples:       664800 | elapsed time per iteration (ms): 322.0 | learning rate: 1.292075E-04 | global batch size:     8 | lm loss: 3.466375E+00 | loss scale: 131072.0 | grad norm: 0.593 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 14:16:10] iteration    83200/  500000 | consumed samples:       665600 | elapsed time per iteration (ms): 318.7 | learning rate: 1.291581E-04 | global batch size:     8 | lm loss: 3.570953E+00 | loss scale: 131072.0 | grad norm: 0.623 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 14:16:42] iteration    83300/  500000 | consumed samples:       666400 | elapsed time per iteration (ms): 319.7 | learning rate: 1.291087E-04 | global batch size:     8 | lm loss: 3.501639E+00 | loss scale: 262144.0 | grad norm: 0.641 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 14:17:14] iteration    83400/  500000 | consumed samples:       667200 | elapsed time per iteration (ms): 321.4 | learning rate: 1.290592E-04 | global batch size:     8 | lm loss: 3.561009E+00 | loss scale: 262144.0 | grad norm: 0.599 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 14:17:46] iteration    83500/  500000 | consumed samples:       668000 | elapsed time per iteration (ms): 320.8 | learning rate: 1.290097E-04 | global batch size:     8 | lm loss: 3.541653E+00 | loss scale: 262144.0 | grad norm: 0.632 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 14:18:18] iteration    83600/  500000 | consumed samples:       668800 | elapsed time per iteration (ms): 321.8 | learning rate: 1.289601E-04 | global batch size:     8 | lm loss: 3.529663E+00 | loss scale: 262144.0 | grad norm: 0.635 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 14:18:50] iteration    83700/  500000 | consumed samples:       669600 | elapsed time per iteration (ms): 319.3 | learning rate: 1.289104E-04 | global batch size:     8 | lm loss: 3.520704E+00 | loss scale: 262144.0 | grad norm: 0.649 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 14:19:23] iteration    83800/  500000 | consumed samples:       670400 | elapsed time per iteration (ms): 322.5 | learning rate: 1.288607E-04 | global batch size:     8 | lm loss: 3.553278E+00 | loss scale: 262144.0 | grad norm: 0.623 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 14:19:55] iteration    83900/  500000 | consumed samples:       671200 | elapsed time per iteration (ms): 321.8 | learning rate: 1.288110E-04 | global batch size:     8 | lm loss: 3.534367E+00 | loss scale: 262144.0 | grad norm: 0.954 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 14:20:27] iteration    84000/  500000 | consumed samples:       672000 | elapsed time per iteration (ms): 323.2 | learning rate: 1.287617E-04 | global batch size:     8 | lm loss: 3.537288E+00 | loss scale: 262144.0 | grad norm: 0.649 | number of skipped iterations:   1 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1063.00, 1063.00)
-------------------------------------------------------------------------------------------------
 validation loss at iteration 84000 | lm loss value: 3.602965E+00 | lm loss PPL: 3.670690E+01 | 
-------------------------------------------------------------------------------------------------
 [2024-06-21 14:21:01] iteration    84100/  500000 | consumed samples:       672800 | elapsed time per iteration (ms): 323.3 | learning rate: 1.287119E-04 | global batch size:     8 | lm loss: 3.549193E+00 | loss scale: 262144.0 | grad norm: 0.627 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 14:21:33] iteration    84200/  500000 | consumed samples:       673600 | elapsed time per iteration (ms): 324.9 | learning rate: 1.286620E-04 | global batch size:     8 | lm loss: 3.526470E+00 | loss scale: 262144.0 | grad norm: 0.609 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 14:22:05] iteration    84300/  500000 | consumed samples:       674400 | elapsed time per iteration (ms): 321.7 | learning rate: 1.286126E-04 | global batch size:     8 | lm loss: 3.519267E+00 | loss scale: 131072.0 | grad norm: 0.628 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-21 14:22:38] iteration    84400/  500000 | consumed samples:       675200 | elapsed time per iteration (ms): 323.6 | learning rate: 1.285626E-04 | global batch size:     8 | lm loss: 3.539559E+00 | loss scale: 131072.0 | grad norm: 0.663 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 14:23:10] iteration    84500/  500000 | consumed samples:       676000 | elapsed time per iteration (ms): 322.7 | learning rate: 1.285126E-04 | global batch size:     8 | lm loss: 3.545438E+00 | loss scale: 131072.0 | grad norm: 0.711 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 14:23:42] iteration    84600/  500000 | consumed samples:       676800 | elapsed time per iteration (ms): 321.9 | learning rate: 1.284625E-04 | global batch size:     8 | lm loss: 3.496802E+00 | loss scale: 131072.0 | grad norm: 0.631 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 14:24:14] iteration    84700/  500000 | consumed samples:       677600 | elapsed time per iteration (ms): 323.7 | learning rate: 1.284124E-04 | global batch size:     8 | lm loss: 3.541425E+00 | loss scale: 131072.0 | grad norm: 0.633 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 14:24:47] iteration    84800/  500000 | consumed samples:       678400 | elapsed time per iteration (ms): 324.2 | learning rate: 1.283623E-04 | global batch size:     8 | lm loss: 3.546607E+00 | loss scale: 131072.0 | grad norm: 0.610 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 14:25:19] iteration    84900/  500000 | consumed samples:       679200 | elapsed time per iteration (ms): 320.7 | learning rate: 1.283121E-04 | global batch size:     8 | lm loss: 3.520168E+00 | loss scale: 131072.0 | grad norm: 0.654 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 14:25:51] iteration    85000/  500000 | consumed samples:       680000 | elapsed time per iteration (ms): 321.9 | learning rate: 1.282618E-04 | global batch size:     8 | lm loss: 3.478538E+00 | loss scale: 131072.0 | grad norm: 0.701 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1063.72, 1063.72)
-------------------------------------------------------------------------------------------------
 validation loss at iteration 85000 | lm loss value: 3.766997E+00 | lm loss PPL: 4.324999E+01 | 
-------------------------------------------------------------------------------------------------
 [2024-06-21 14:26:24] iteration    85100/  500000 | consumed samples:       680800 | elapsed time per iteration (ms): 322.2 | learning rate: 1.282115E-04 | global batch size:     8 | lm loss: 3.512203E+00 | loss scale: 131072.0 | grad norm: 0.635 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 14:26:57] iteration    85200/  500000 | consumed samples:       681600 | elapsed time per iteration (ms): 324.7 | learning rate: 1.281611E-04 | global batch size:     8 | lm loss: 3.543730E+00 | loss scale: 131072.0 | grad norm: 0.630 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 14:27:29] iteration    85300/  500000 | consumed samples:       682400 | elapsed time per iteration (ms): 322.6 | learning rate: 1.281108E-04 | global batch size:     8 | lm loss: 3.529413E+00 | loss scale: 262144.0 | grad norm: 0.662 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 14:28:01] iteration    85400/  500000 | consumed samples:       683200 | elapsed time per iteration (ms): 322.4 | learning rate: 1.280603E-04 | global batch size:     8 | lm loss: 3.529379E+00 | loss scale: 262144.0 | grad norm: 0.620 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 14:28:34] iteration    85500/  500000 | consumed samples:       684000 | elapsed time per iteration (ms): 323.3 | learning rate: 1.280098E-04 | global batch size:     8 | lm loss: 3.488006E+00 | loss scale: 262144.0 | grad norm: 0.650 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 14:29:06] iteration    85600/  500000 | consumed samples:       684800 | elapsed time per iteration (ms): 322.3 | learning rate: 1.279593E-04 | global batch size:     8 | lm loss: 3.569428E+00 | loss scale: 262144.0 | grad norm: 0.682 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 14:29:38] iteration    85700/  500000 | consumed samples:       685600 | elapsed time per iteration (ms): 324.7 | learning rate: 1.279087E-04 | global batch size:     8 | lm loss: 3.517304E+00 | loss scale: 262144.0 | grad norm: 0.620 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 14:30:10] iteration    85800/  500000 | consumed samples:       686400 | elapsed time per iteration (ms): 320.8 | learning rate: 1.278580E-04 | global batch size:     8 | lm loss: 3.526957E+00 | loss scale: 262144.0 | grad norm: 0.650 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 14:30:43] iteration    85900/  500000 | consumed samples:       687200 | elapsed time per iteration (ms): 321.6 | learning rate: 1.278074E-04 | global batch size:     8 | lm loss: 3.538973E+00 | loss scale: 262144.0 | grad norm: 0.678 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 14:31:15] iteration    86000/  500000 | consumed samples:       688000 | elapsed time per iteration (ms): 322.1 | learning rate: 1.277566E-04 | global batch size:     8 | lm loss: 3.501206E+00 | loss scale: 262144.0 | grad norm: 0.650 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1064.09, 1064.09)
-------------------------------------------------------------------------------------------------
 validation loss at iteration 86000 | lm loss value: 3.792351E+00 | lm loss PPL: 4.436059E+01 | 
-------------------------------------------------------------------------------------------------
 [2024-06-21 14:31:48] iteration    86100/  500000 | consumed samples:       688800 | elapsed time per iteration (ms): 321.9 | learning rate: 1.277059E-04 | global batch size:     8 | lm loss: 3.486282E+00 | loss scale: 262144.0 | grad norm: 0.635 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 14:32:20] iteration    86200/  500000 | consumed samples:       689600 | elapsed time per iteration (ms): 320.2 | learning rate: 1.276550E-04 | global batch size:     8 | lm loss: 3.517491E+00 | loss scale: 262144.0 | grad norm: 0.606 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 14:32:52] iteration    86300/  500000 | consumed samples:       690400 | elapsed time per iteration (ms): 319.5 | learning rate: 1.276042E-04 | global batch size:     8 | lm loss: 3.531705E+00 | loss scale: 524288.0 | grad norm: 0.647 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 14:33:24] iteration    86400/  500000 | consumed samples:       691200 | elapsed time per iteration (ms): 319.9 | learning rate: 1.275533E-04 | global batch size:     8 | lm loss: 3.489676E+00 | loss scale: 524288.0 | grad norm: 0.622 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 14:33:56] iteration    86500/  500000 | consumed samples:       692000 | elapsed time per iteration (ms): 322.8 | learning rate: 1.275023E-04 | global batch size:     8 | lm loss: 3.538142E+00 | loss scale: 524288.0 | grad norm: 0.644 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 14:34:28] iteration    86600/  500000 | consumed samples:       692800 | elapsed time per iteration (ms): 320.8 | learning rate: 1.274513E-04 | global batch size:     8 | lm loss: 3.528685E+00 | loss scale: 524288.0 | grad norm: 0.700 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 14:35:01] iteration    86700/  500000 | consumed samples:       693600 | elapsed time per iteration (ms): 321.7 | learning rate: 1.274002E-04 | global batch size:     8 | lm loss: 3.483297E+00 | loss scale: 524288.0 | grad norm: 0.672 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 14:35:33] iteration    86800/  500000 | consumed samples:       694400 | elapsed time per iteration (ms): 322.6 | learning rate: 1.273491E-04 | global batch size:     8 | lm loss: 3.506171E+00 | loss scale: 524288.0 | grad norm: 0.629 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 14:36:05] iteration    86900/  500000 | consumed samples:       695200 | elapsed time per iteration (ms): 320.9 | learning rate: 1.272980E-04 | global batch size:     8 | lm loss: 3.546477E+00 | loss scale: 524288.0 | grad norm: 0.629 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 14:36:37] iteration    87000/  500000 | consumed samples:       696000 | elapsed time per iteration (ms): 319.8 | learning rate: 1.272468E-04 | global batch size:     8 | lm loss: 3.510681E+00 | loss scale: 524288.0 | grad norm: 0.622 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1066.72, 1066.72)
-------------------------------------------------------------------------------------------------
 validation loss at iteration 87000 | lm loss value: 3.763839E+00 | lm loss PPL: 4.311362E+01 | 
-------------------------------------------------------------------------------------------------
 [2024-06-21 14:37:10] iteration    87100/  500000 | consumed samples:       696800 | elapsed time per iteration (ms): 324.0 | learning rate: 1.271960E-04 | global batch size:     8 | lm loss: 3.523013E+00 | loss scale: 524288.0 | grad norm: 0.623 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-21 14:37:43] iteration    87200/  500000 | consumed samples:       697600 | elapsed time per iteration (ms): 321.9 | learning rate: 1.271453E-04 | global batch size:     8 | lm loss: 3.506678E+00 | loss scale: 262144.0 | grad norm: 0.643 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-21 14:38:15] iteration    87300/  500000 | consumed samples:       698400 | elapsed time per iteration (ms): 321.1 | learning rate: 1.270939E-04 | global batch size:     8 | lm loss: 3.537430E+00 | loss scale: 262144.0 | grad norm: 0.635 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 14:38:47] iteration    87400/  500000 | consumed samples:       699200 | elapsed time per iteration (ms): 322.7 | learning rate: 1.270425E-04 | global batch size:     8 | lm loss: 3.540131E+00 | loss scale: 262144.0 | grad norm: 0.646 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 14:39:19] iteration    87500/  500000 | consumed samples:       700000 | elapsed time per iteration (ms): 322.2 | learning rate: 1.269911E-04 | global batch size:     8 | lm loss: 3.537593E+00 | loss scale: 262144.0 | grad norm: 0.627 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 14:39:51] iteration    87600/  500000 | consumed samples:       700800 | elapsed time per iteration (ms): 321.8 | learning rate: 1.269396E-04 | global batch size:     8 | lm loss: 3.533484E+00 | loss scale: 262144.0 | grad norm: 0.642 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 14:40:23] iteration    87700/  500000 | consumed samples:       701600 | elapsed time per iteration (ms): 319.6 | learning rate: 1.268881E-04 | global batch size:     8 | lm loss: 3.508727E+00 | loss scale: 262144.0 | grad norm: 0.609 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 14:40:55] iteration    87800/  500000 | consumed samples:       702400 | elapsed time per iteration (ms): 322.0 | learning rate: 1.268366E-04 | global batch size:     8 | lm loss: 3.473103E+00 | loss scale: 262144.0 | grad norm: 0.635 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 14:41:28] iteration    87900/  500000 | consumed samples:       703200 | elapsed time per iteration (ms): 323.6 | learning rate: 1.267850E-04 | global batch size:     8 | lm loss: 3.501594E+00 | loss scale: 262144.0 | grad norm: 0.638 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 14:42:00] iteration    88000/  500000 | consumed samples:       704000 | elapsed time per iteration (ms): 321.4 | learning rate: 1.267333E-04 | global batch size:     8 | lm loss: 3.496344E+00 | loss scale: 262144.0 | grad norm: 0.657 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1062.86, 1062.86)
-------------------------------------------------------------------------------------------------
 validation loss at iteration 88000 | lm loss value: 3.697394E+00 | lm loss PPL: 4.034204E+01 | 
-------------------------------------------------------------------------------------------------
 [2024-06-21 14:42:33] iteration    88100/  500000 | consumed samples:       704800 | elapsed time per iteration (ms): 323.2 | learning rate: 1.266816E-04 | global batch size:     8 | lm loss: 3.480941E+00 | loss scale: 262144.0 | grad norm: 0.625 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 14:43:06] iteration    88200/  500000 | consumed samples:       705600 | elapsed time per iteration (ms): 322.8 | learning rate: 1.266298E-04 | global batch size:     8 | lm loss: 3.545916E+00 | loss scale: 524288.0 | grad norm: 0.639 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 14:43:38] iteration    88300/  500000 | consumed samples:       706400 | elapsed time per iteration (ms): 322.1 | learning rate: 1.265786E-04 | global batch size:     8 | lm loss: 3.497283E+00 | loss scale: 524288.0 | grad norm: 0.621 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-21 14:44:10] iteration    88400/  500000 | consumed samples:       707200 | elapsed time per iteration (ms): 320.3 | learning rate: 1.265267E-04 | global batch size:     8 | lm loss: 3.524879E+00 | loss scale: 524288.0 | grad norm: 0.635 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 14:44:42] iteration    88500/  500000 | consumed samples:       708000 | elapsed time per iteration (ms): 319.9 | learning rate: 1.264748E-04 | global batch size:     8 | lm loss: 3.503029E+00 | loss scale: 524288.0 | grad norm: 0.633 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 14:45:14] iteration    88600/  500000 | consumed samples:       708800 | elapsed time per iteration (ms): 320.9 | learning rate: 1.264229E-04 | global batch size:     8 | lm loss: 3.491763E+00 | loss scale: 524288.0 | grad norm: 0.643 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 14:45:46] iteration    88700/  500000 | consumed samples:       709600 | elapsed time per iteration (ms): 321.8 | learning rate: 1.263709E-04 | global batch size:     8 | lm loss: 3.461548E+00 | loss scale: 524288.0 | grad norm: 0.629 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 14:46:18] iteration    88800/  500000 | consumed samples:       710400 | elapsed time per iteration (ms): 321.1 | learning rate: 1.263189E-04 | global batch size:     8 | lm loss: 3.473949E+00 | loss scale: 524288.0 | grad norm: 0.647 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 14:46:51] iteration    88900/  500000 | consumed samples:       711200 | elapsed time per iteration (ms): 322.8 | learning rate: 1.262668E-04 | global batch size:     8 | lm loss: 3.506280E+00 | loss scale: 524288.0 | grad norm: 0.675 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 14:47:23] iteration    89000/  500000 | consumed samples:       712000 | elapsed time per iteration (ms): 322.1 | learning rate: 1.262147E-04 | global batch size:     8 | lm loss: 3.511546E+00 | loss scale: 524288.0 | grad norm: 0.630 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1062.89, 1062.89)
-------------------------------------------------------------------------------------------------
 validation loss at iteration 89000 | lm loss value: 3.839461E+00 | lm loss PPL: 4.650041E+01 | 
-------------------------------------------------------------------------------------------------
 [2024-06-21 14:47:56] iteration    89100/  500000 | consumed samples:       712800 | elapsed time per iteration (ms): 322.4 | learning rate: 1.261626E-04 | global batch size:     8 | lm loss: 3.535474E+00 | loss scale: 524288.0 | grad norm: 0.647 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 14:48:28] iteration    89200/  500000 | consumed samples:       713600 | elapsed time per iteration (ms): 322.9 | learning rate: 1.261104E-04 | global batch size:     8 | lm loss: 3.500385E+00 | loss scale: 524288.0 | grad norm: 0.652 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 14:49:00] iteration    89300/  500000 | consumed samples:       714400 | elapsed time per iteration (ms): 321.1 | learning rate: 1.260591E-04 | global batch size:     8 | lm loss: 3.513025E+00 | loss scale: 524288.0 | grad norm: 0.654 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-21 14:49:33] iteration    89400/  500000 | consumed samples:       715200 | elapsed time per iteration (ms): 322.0 | learning rate: 1.260069E-04 | global batch size:     8 | lm loss: 3.558990E+00 | loss scale: 524288.0 | grad norm: 0.616 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 14:50:05] iteration    89500/  500000 | consumed samples:       716000 | elapsed time per iteration (ms): 323.6 | learning rate: 1.259545E-04 | global batch size:     8 | lm loss: 3.531547E+00 | loss scale: 524288.0 | grad norm: 0.640 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 14:50:37] iteration    89600/  500000 | consumed samples:       716800 | elapsed time per iteration (ms): 322.3 | learning rate: 1.259021E-04 | global batch size:     8 | lm loss: 3.540655E+00 | loss scale: 524288.0 | grad norm: 0.662 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 14:51:09] iteration    89700/  500000 | consumed samples:       717600 | elapsed time per iteration (ms): 321.8 | learning rate: 1.258497E-04 | global batch size:     8 | lm loss: 3.555031E+00 | loss scale: 524288.0 | grad norm: 0.645 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 14:51:41] iteration    89800/  500000 | consumed samples:       718400 | elapsed time per iteration (ms): 319.7 | learning rate: 1.257977E-04 | global batch size:     8 | lm loss: 3.510693E+00 | loss scale: 262144.0 | grad norm: 0.610 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-21 14:52:14] iteration    89900/  500000 | consumed samples:       719200 | elapsed time per iteration (ms): 321.3 | learning rate: 1.257457E-04 | global batch size:     8 | lm loss: 3.487459E+00 | loss scale: 131072.0 | grad norm: 0.655 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-21 14:52:46] iteration    90000/  500000 | consumed samples:       720000 | elapsed time per iteration (ms): 321.5 | learning rate: 1.256932E-04 | global batch size:     8 | lm loss: 3.501436E+00 | loss scale: 131072.0 | grad norm: 0.643 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1063.61, 1063.61)
-------------------------------------------------------------------------------------------------
 validation loss at iteration 90000 | lm loss value: 3.757364E+00 | lm loss PPL: 4.283537E+01 | 
-------------------------------------------------------------------------------------------------
saving checkpoint at iteration   90000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-max in torch format
  successfully saved checkpoint at iteration   90000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-max
(min, max) time across ranks (ms):
    save-checkpoint ................................: (5630.10, 5630.10)
 [2024-06-21 14:53:25] iteration    90100/  500000 | consumed samples:       720800 | elapsed time per iteration (ms): 321.4 | learning rate: 1.256406E-04 | global batch size:     8 | lm loss: 3.525049E+00 | loss scale: 131072.0 | grad norm: 0.714 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 14:53:57] iteration    90200/  500000 | consumed samples:       721600 | elapsed time per iteration (ms): 320.4 | learning rate: 1.255879E-04 | global batch size:     8 | lm loss: 3.515411E+00 | loss scale: 131072.0 | grad norm: 0.634 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 14:54:29] iteration    90300/  500000 | consumed samples:       722400 | elapsed time per iteration (ms): 320.1 | learning rate: 1.255352E-04 | global batch size:     8 | lm loss: 3.484092E+00 | loss scale: 131072.0 | grad norm: 0.654 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 14:55:00] iteration    90400/  500000 | consumed samples:       723200 | elapsed time per iteration (ms): 319.2 | learning rate: 1.254825E-04 | global batch size:     8 | lm loss: 3.555964E+00 | loss scale: 131072.0 | grad norm: 0.633 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 14:55:33] iteration    90500/  500000 | consumed samples:       724000 | elapsed time per iteration (ms): 320.3 | learning rate: 1.254297E-04 | global batch size:     8 | lm loss: 3.481654E+00 | loss scale: 131072.0 | grad norm: 0.606 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 14:56:05] iteration    90600/  500000 | consumed samples:       724800 | elapsed time per iteration (ms): 320.4 | learning rate: 1.253769E-04 | global batch size:     8 | lm loss: 3.506843E+00 | loss scale: 131072.0 | grad norm: 0.626 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 14:56:37] iteration    90700/  500000 | consumed samples:       725600 | elapsed time per iteration (ms): 321.2 | learning rate: 1.253240E-04 | global batch size:     8 | lm loss: 3.505017E+00 | loss scale: 131072.0 | grad norm: 0.657 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 14:57:09] iteration    90800/  500000 | consumed samples:       726400 | elapsed time per iteration (ms): 321.2 | learning rate: 1.252710E-04 | global batch size:     8 | lm loss: 3.477408E+00 | loss scale: 131072.0 | grad norm: 0.648 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 14:57:41] iteration    90900/  500000 | consumed samples:       727200 | elapsed time per iteration (ms): 321.9 | learning rate: 1.252181E-04 | global batch size:     8 | lm loss: 3.483851E+00 | loss scale: 262144.0 | grad norm: 0.652 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 14:58:13] iteration    91000/  500000 | consumed samples:       728000 | elapsed time per iteration (ms): 322.0 | learning rate: 1.251651E-04 | global batch size:     8 | lm loss: 3.505693E+00 | loss scale: 262144.0 | grad norm: 0.697 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1063.74, 1063.74)
-------------------------------------------------------------------------------------------------
 validation loss at iteration 91000 | lm loss value: 3.711051E+00 | lm loss PPL: 4.089678E+01 | 
-------------------------------------------------------------------------------------------------
 [2024-06-21 14:58:47] iteration    91100/  500000 | consumed samples:       728800 | elapsed time per iteration (ms): 323.0 | learning rate: 1.251120E-04 | global batch size:     8 | lm loss: 3.479270E+00 | loss scale: 262144.0 | grad norm: 0.633 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 14:59:19] iteration    91200/  500000 | consumed samples:       729600 | elapsed time per iteration (ms): 321.4 | learning rate: 1.250589E-04 | global batch size:     8 | lm loss: 3.532993E+00 | loss scale: 262144.0 | grad norm: 0.633 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 14:59:51] iteration    91300/  500000 | consumed samples:       730400 | elapsed time per iteration (ms): 322.6 | learning rate: 1.250058E-04 | global batch size:     8 | lm loss: 3.463619E+00 | loss scale: 262144.0 | grad norm: 0.640 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 15:00:23] iteration    91400/  500000 | consumed samples:       731200 | elapsed time per iteration (ms): 321.2 | learning rate: 1.249526E-04 | global batch size:     8 | lm loss: 3.486150E+00 | loss scale: 262144.0 | grad norm: 0.672 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 15:00:55] iteration    91500/  500000 | consumed samples:       732000 | elapsed time per iteration (ms): 321.8 | learning rate: 1.248993E-04 | global batch size:     8 | lm loss: 3.503484E+00 | loss scale: 262144.0 | grad norm: 0.627 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 15:01:27] iteration    91600/  500000 | consumed samples:       732800 | elapsed time per iteration (ms): 319.3 | learning rate: 1.248461E-04 | global batch size:     8 | lm loss: 3.491925E+00 | loss scale: 262144.0 | grad norm: 0.672 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 15:01:59] iteration    91700/  500000 | consumed samples:       733600 | elapsed time per iteration (ms): 322.0 | learning rate: 1.247927E-04 | global batch size:     8 | lm loss: 3.530841E+00 | loss scale: 262144.0 | grad norm: 0.638 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 15:02:32] iteration    91800/  500000 | consumed samples:       734400 | elapsed time per iteration (ms): 321.9 | learning rate: 1.247399E-04 | global batch size:     8 | lm loss: 3.516069E+00 | loss scale: 262144.0 | grad norm: 0.619 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-21 15:03:04] iteration    91900/  500000 | consumed samples:       735200 | elapsed time per iteration (ms): 324.0 | learning rate: 1.246865E-04 | global batch size:     8 | lm loss: 3.496357E+00 | loss scale: 262144.0 | grad norm: 0.664 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 15:03:36] iteration    92000/  500000 | consumed samples:       736000 | elapsed time per iteration (ms): 323.4 | learning rate: 1.246336E-04 | global batch size:     8 | lm loss: 3.506684E+00 | loss scale: 131072.0 | grad norm: 0.623 | number of skipped iterations:   1 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1069.63, 1069.63)
-------------------------------------------------------------------------------------------------
 validation loss at iteration 92000 | lm loss value: 3.739422E+00 | lm loss PPL: 4.207365E+01 | 
-------------------------------------------------------------------------------------------------
 [2024-06-21 15:04:10] iteration    92100/  500000 | consumed samples:       736800 | elapsed time per iteration (ms): 322.4 | learning rate: 1.245806E-04 | global batch size:     8 | lm loss: 3.543327E+00 | loss scale: 65536.0 | grad norm: 0.609 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-21 15:04:42] iteration    92200/  500000 | consumed samples:       737600 | elapsed time per iteration (ms): 321.0 | learning rate: 1.245271E-04 | global batch size:     8 | lm loss: 3.473551E+00 | loss scale: 65536.0 | grad norm: 0.679 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 15:05:14] iteration    92300/  500000 | consumed samples:       738400 | elapsed time per iteration (ms): 322.5 | learning rate: 1.244735E-04 | global batch size:     8 | lm loss: 3.532447E+00 | loss scale: 65536.0 | grad norm: 0.687 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 15:05:46] iteration    92400/  500000 | consumed samples:       739200 | elapsed time per iteration (ms): 322.3 | learning rate: 1.244199E-04 | global batch size:     8 | lm loss: 3.480030E+00 | loss scale: 65536.0 | grad norm: 0.653 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 15:06:19] iteration    92500/  500000 | consumed samples:       740000 | elapsed time per iteration (ms): 323.3 | learning rate: 1.243662E-04 | global batch size:     8 | lm loss: 3.469147E+00 | loss scale: 65536.0 | grad norm: 0.690 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 15:06:51] iteration    92600/  500000 | consumed samples:       740800 | elapsed time per iteration (ms): 323.1 | learning rate: 1.243125E-04 | global batch size:     8 | lm loss: 3.447935E+00 | loss scale: 65536.0 | grad norm: 0.652 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 15:07:23] iteration    92700/  500000 | consumed samples:       741600 | elapsed time per iteration (ms): 322.0 | learning rate: 1.242587E-04 | global batch size:     8 | lm loss: 3.472466E+00 | loss scale: 65536.0 | grad norm: 0.646 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 15:07:55] iteration    92800/  500000 | consumed samples:       742400 | elapsed time per iteration (ms): 320.2 | learning rate: 1.242049E-04 | global batch size:     8 | lm loss: 3.502677E+00 | loss scale: 65536.0 | grad norm: 0.633 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 15:08:27] iteration    92900/  500000 | consumed samples:       743200 | elapsed time per iteration (ms): 323.3 | learning rate: 1.241511E-04 | global batch size:     8 | lm loss: 3.482121E+00 | loss scale: 65536.0 | grad norm: 0.635 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 15:09:00] iteration    93000/  500000 | consumed samples:       744000 | elapsed time per iteration (ms): 321.4 | learning rate: 1.240972E-04 | global batch size:     8 | lm loss: 3.499654E+00 | loss scale: 65536.0 | grad norm: 0.655 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1067.46, 1067.46)
-------------------------------------------------------------------------------------------------
 validation loss at iteration 93000 | lm loss value: 3.762278E+00 | lm loss PPL: 4.304638E+01 | 
-------------------------------------------------------------------------------------------------
 [2024-06-21 15:09:33] iteration    93100/  500000 | consumed samples:       744800 | elapsed time per iteration (ms): 321.7 | learning rate: 1.240433E-04 | global batch size:     8 | lm loss: 3.510461E+00 | loss scale: 131072.0 | grad norm: 0.605 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 15:10:05] iteration    93200/  500000 | consumed samples:       745600 | elapsed time per iteration (ms): 321.5 | learning rate: 1.239893E-04 | global batch size:     8 | lm loss: 3.506272E+00 | loss scale: 131072.0 | grad norm: 0.663 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 15:10:37] iteration    93300/  500000 | consumed samples:       746400 | elapsed time per iteration (ms): 323.0 | learning rate: 1.239353E-04 | global batch size:     8 | lm loss: 3.506254E+00 | loss scale: 131072.0 | grad norm: 0.659 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 15:11:10] iteration    93400/  500000 | consumed samples:       747200 | elapsed time per iteration (ms): 322.7 | learning rate: 1.238812E-04 | global batch size:     8 | lm loss: 3.463385E+00 | loss scale: 131072.0 | grad norm: 0.626 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 15:11:42] iteration    93500/  500000 | consumed samples:       748000 | elapsed time per iteration (ms): 323.0 | learning rate: 1.238271E-04 | global batch size:     8 | lm loss: 3.520250E+00 | loss scale: 131072.0 | grad norm: 0.647 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 15:12:14] iteration    93600/  500000 | consumed samples:       748800 | elapsed time per iteration (ms): 323.0 | learning rate: 1.237729E-04 | global batch size:     8 | lm loss: 3.481635E+00 | loss scale: 131072.0 | grad norm: 0.653 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 15:12:46] iteration    93700/  500000 | consumed samples:       749600 | elapsed time per iteration (ms): 321.0 | learning rate: 1.237188E-04 | global batch size:     8 | lm loss: 3.497243E+00 | loss scale: 131072.0 | grad norm: 0.629 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 15:13:19] iteration    93800/  500000 | consumed samples:       750400 | elapsed time per iteration (ms): 323.0 | learning rate: 1.236645E-04 | global batch size:     8 | lm loss: 3.512701E+00 | loss scale: 131072.0 | grad norm: 0.682 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 15:13:51] iteration    93900/  500000 | consumed samples:       751200 | elapsed time per iteration (ms): 324.3 | learning rate: 1.236102E-04 | global batch size:     8 | lm loss: 3.504344E+00 | loss scale: 131072.0 | grad norm: 0.664 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 15:14:23] iteration    94000/  500000 | consumed samples:       752000 | elapsed time per iteration (ms): 321.3 | learning rate: 1.235559E-04 | global batch size:     8 | lm loss: 3.507658E+00 | loss scale: 131072.0 | grad norm: 0.639 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1061.99, 1061.99)
-------------------------------------------------------------------------------------------------
 validation loss at iteration 94000 | lm loss value: 3.693038E+00 | lm loss PPL: 4.016667E+01 | 
-------------------------------------------------------------------------------------------------
 [2024-06-21 15:14:56] iteration    94100/  500000 | consumed samples:       752800 | elapsed time per iteration (ms): 322.6 | learning rate: 1.235016E-04 | global batch size:     8 | lm loss: 3.467546E+00 | loss scale: 262144.0 | grad norm: 0.655 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 15:15:29] iteration    94200/  500000 | consumed samples:       753600 | elapsed time per iteration (ms): 324.3 | learning rate: 1.234472E-04 | global batch size:     8 | lm loss: 3.492888E+00 | loss scale: 262144.0 | grad norm: 0.668 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 15:16:01] iteration    94300/  500000 | consumed samples:       754400 | elapsed time per iteration (ms): 321.4 | learning rate: 1.233927E-04 | global batch size:     8 | lm loss: 3.498874E+00 | loss scale: 262144.0 | grad norm: 0.650 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 15:16:33] iteration    94400/  500000 | consumed samples:       755200 | elapsed time per iteration (ms): 320.0 | learning rate: 1.233388E-04 | global batch size:     8 | lm loss: 3.448096E+00 | loss scale: 262144.0 | grad norm: 0.622 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-21 15:17:05] iteration    94500/  500000 | consumed samples:       756000 | elapsed time per iteration (ms): 322.3 | learning rate: 1.232842E-04 | global batch size:     8 | lm loss: 3.479746E+00 | loss scale: 262144.0 | grad norm: 0.607 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 15:17:37] iteration    94600/  500000 | consumed samples:       756800 | elapsed time per iteration (ms): 322.2 | learning rate: 1.232296E-04 | global batch size:     8 | lm loss: 3.471182E+00 | loss scale: 262144.0 | grad norm: 0.654 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 15:18:10] iteration    94700/  500000 | consumed samples:       757600 | elapsed time per iteration (ms): 321.5 | learning rate: 1.231750E-04 | global batch size:     8 | lm loss: 3.489193E+00 | loss scale: 262144.0 | grad norm: 0.669 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 15:18:42] iteration    94800/  500000 | consumed samples:       758400 | elapsed time per iteration (ms): 322.4 | learning rate: 1.231204E-04 | global batch size:     8 | lm loss: 3.452558E+00 | loss scale: 262144.0 | grad norm: 0.609 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 15:19:14] iteration    94900/  500000 | consumed samples:       759200 | elapsed time per iteration (ms): 320.6 | learning rate: 1.230657E-04 | global batch size:     8 | lm loss: 3.476311E+00 | loss scale: 262144.0 | grad norm: 0.642 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 15:19:46] iteration    95000/  500000 | consumed samples:       760000 | elapsed time per iteration (ms): 321.4 | learning rate: 1.230109E-04 | global batch size:     8 | lm loss: 3.510425E+00 | loss scale: 262144.0 | grad norm: 0.658 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1066.61, 1066.61)
-------------------------------------------------------------------------------------------------
 validation loss at iteration 95000 | lm loss value: 3.687677E+00 | lm loss PPL: 3.995194E+01 | 
-------------------------------------------------------------------------------------------------
 [2024-06-21 15:20:19] iteration    95100/  500000 | consumed samples:       760800 | elapsed time per iteration (ms): 321.4 | learning rate: 1.229561E-04 | global batch size:     8 | lm loss: 3.485697E+00 | loss scale: 262144.0 | grad norm: 0.663 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 15:20:52] iteration    95200/  500000 | consumed samples:       761600 | elapsed time per iteration (ms): 323.5 | learning rate: 1.229013E-04 | global batch size:     8 | lm loss: 3.526014E+00 | loss scale: 262144.0 | grad norm: 0.660 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 15:21:24] iteration    95300/  500000 | consumed samples:       762400 | elapsed time per iteration (ms): 323.3 | learning rate: 1.228464E-04 | global batch size:     8 | lm loss: 3.505456E+00 | loss scale: 262144.0 | grad norm: 0.676 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 15:21:56] iteration    95400/  500000 | consumed samples:       763200 | elapsed time per iteration (ms): 322.1 | learning rate: 1.227915E-04 | global batch size:     8 | lm loss: 3.503916E+00 | loss scale: 524288.0 | grad norm: 0.607 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 15:22:28] iteration    95500/  500000 | consumed samples:       764000 | elapsed time per iteration (ms): 320.5 | learning rate: 1.227371E-04 | global batch size:     8 | lm loss: 3.487498E+00 | loss scale: 524288.0 | grad norm: 0.629 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-21 15:23:00] iteration    95600/  500000 | consumed samples:       764800 | elapsed time per iteration (ms): 322.8 | learning rate: 1.226821E-04 | global batch size:     8 | lm loss: 3.493051E+00 | loss scale: 524288.0 | grad norm: 0.617 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 15:23:33] iteration    95700/  500000 | consumed samples:       765600 | elapsed time per iteration (ms): 322.9 | learning rate: 1.226271E-04 | global batch size:     8 | lm loss: 3.477561E+00 | loss scale: 524288.0 | grad norm: 0.645 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 15:24:05] iteration    95800/  500000 | consumed samples:       766400 | elapsed time per iteration (ms): 321.2 | learning rate: 1.225720E-04 | global batch size:     8 | lm loss: 3.463843E+00 | loss scale: 524288.0 | grad norm: 0.655 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 15:24:37] iteration    95900/  500000 | consumed samples:       767200 | elapsed time per iteration (ms): 321.7 | learning rate: 1.225174E-04 | global batch size:     8 | lm loss: 3.496424E+00 | loss scale: 262144.0 | grad norm: 0.628 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-21 15:25:09] iteration    96000/  500000 | consumed samples:       768000 | elapsed time per iteration (ms): 322.5 | learning rate: 1.224628E-04 | global batch size:     8 | lm loss: 3.463817E+00 | loss scale: 131072.0 | grad norm: 0.659 | number of skipped iterations:   1 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1069.69, 1069.69)
-------------------------------------------------------------------------------------------------
 validation loss at iteration 96000 | lm loss value: 3.881468E+00 | lm loss PPL: 4.849535E+01 | 
-------------------------------------------------------------------------------------------------
 [2024-06-21 15:25:42] iteration    96100/  500000 | consumed samples:       768800 | elapsed time per iteration (ms): 320.3 | learning rate: 1.224076E-04 | global batch size:     8 | lm loss: 3.476909E+00 | loss scale: 131072.0 | grad norm: 0.626 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 15:26:14] iteration    96200/  500000 | consumed samples:       769600 | elapsed time per iteration (ms): 319.7 | learning rate: 1.223529E-04 | global batch size:     8 | lm loss: 3.486606E+00 | loss scale: 65536.0 | grad norm: 0.658 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-21 15:26:46] iteration    96300/  500000 | consumed samples:       770400 | elapsed time per iteration (ms): 321.5 | learning rate: 1.222976E-04 | global batch size:     8 | lm loss: 3.500243E+00 | loss scale: 65536.0 | grad norm: 0.655 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 15:27:19] iteration    96400/  500000 | consumed samples:       771200 | elapsed time per iteration (ms): 321.9 | learning rate: 1.222423E-04 | global batch size:     8 | lm loss: 3.466082E+00 | loss scale: 65536.0 | grad norm: 0.632 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 15:27:51] iteration    96500/  500000 | consumed samples:       772000 | elapsed time per iteration (ms): 322.2 | learning rate: 1.221869E-04 | global batch size:     8 | lm loss: 3.461574E+00 | loss scale: 65536.0 | grad norm: 0.610 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 15:28:23] iteration    96600/  500000 | consumed samples:       772800 | elapsed time per iteration (ms): 321.1 | learning rate: 1.221315E-04 | global batch size:     8 | lm loss: 3.469701E+00 | loss scale: 65536.0 | grad norm: 0.609 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 15:28:55] iteration    96700/  500000 | consumed samples:       773600 | elapsed time per iteration (ms): 320.8 | learning rate: 1.220760E-04 | global batch size:     8 | lm loss: 3.500072E+00 | loss scale: 65536.0 | grad norm: 0.630 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 15:29:27] iteration    96800/  500000 | consumed samples:       774400 | elapsed time per iteration (ms): 321.7 | learning rate: 1.220205E-04 | global batch size:     8 | lm loss: 3.462411E+00 | loss scale: 65536.0 | grad norm: 0.642 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 15:30:00] iteration    96900/  500000 | consumed samples:       775200 | elapsed time per iteration (ms): 322.6 | learning rate: 1.219650E-04 | global batch size:     8 | lm loss: 3.464676E+00 | loss scale: 65536.0 | grad norm: 0.645 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 15:30:32] iteration    97000/  500000 | consumed samples:       776000 | elapsed time per iteration (ms): 321.1 | learning rate: 1.219094E-04 | global batch size:     8 | lm loss: 3.459225E+00 | loss scale: 65536.0 | grad norm: 0.630 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1065.44, 1065.44)
-------------------------------------------------------------------------------------------------
 validation loss at iteration 97000 | lm loss value: 3.673292E+00 | lm loss PPL: 3.938134E+01 | 
-------------------------------------------------------------------------------------------------
 [2024-06-21 15:31:05] iteration    97100/  500000 | consumed samples:       776800 | elapsed time per iteration (ms): 321.0 | learning rate: 1.218538E-04 | global batch size:     8 | lm loss: 3.504279E+00 | loss scale: 65536.0 | grad norm: 0.630 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 15:31:37] iteration    97200/  500000 | consumed samples:       777600 | elapsed time per iteration (ms): 322.9 | learning rate: 1.217981E-04 | global batch size:     8 | lm loss: 3.467556E+00 | loss scale: 131072.0 | grad norm: 0.659 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 15:32:09] iteration    97300/  500000 | consumed samples:       778400 | elapsed time per iteration (ms): 322.9 | learning rate: 1.217424E-04 | global batch size:     8 | lm loss: 3.501044E+00 | loss scale: 131072.0 | grad norm: 0.663 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 15:32:42] iteration    97400/  500000 | consumed samples:       779200 | elapsed time per iteration (ms): 323.8 | learning rate: 1.216867E-04 | global batch size:     8 | lm loss: 3.476452E+00 | loss scale: 131072.0 | grad norm: 0.635 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 15:33:14] iteration    97500/  500000 | consumed samples:       780000 | elapsed time per iteration (ms): 323.6 | learning rate: 1.216309E-04 | global batch size:     8 | lm loss: 3.458018E+00 | loss scale: 131072.0 | grad norm: 0.640 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 15:33:47] iteration    97600/  500000 | consumed samples:       780800 | elapsed time per iteration (ms): 324.4 | learning rate: 1.215751E-04 | global batch size:     8 | lm loss: 3.513541E+00 | loss scale: 131072.0 | grad norm: 0.674 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 15:34:19] iteration    97700/  500000 | consumed samples:       781600 | elapsed time per iteration (ms): 323.6 | learning rate: 1.215192E-04 | global batch size:     8 | lm loss: 3.501127E+00 | loss scale: 131072.0 | grad norm: 0.614 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 15:34:51] iteration    97800/  500000 | consumed samples:       782400 | elapsed time per iteration (ms): 323.8 | learning rate: 1.214633E-04 | global batch size:     8 | lm loss: 3.509459E+00 | loss scale: 131072.0 | grad norm: 0.683 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 15:35:24] iteration    97900/  500000 | consumed samples:       783200 | elapsed time per iteration (ms): 323.2 | learning rate: 1.214073E-04 | global batch size:     8 | lm loss: 3.501974E+00 | loss scale: 131072.0 | grad norm: 0.646 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 15:35:56] iteration    98000/  500000 | consumed samples:       784000 | elapsed time per iteration (ms): 322.8 | learning rate: 1.213514E-04 | global batch size:     8 | lm loss: 3.473671E+00 | loss scale: 131072.0 | grad norm: 0.653 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1062.52, 1062.52)
-------------------------------------------------------------------------------------------------
 validation loss at iteration 98000 | lm loss value: 3.658246E+00 | lm loss PPL: 3.879325E+01 | 
-------------------------------------------------------------------------------------------------
 [2024-06-21 15:36:29] iteration    98100/  500000 | consumed samples:       784800 | elapsed time per iteration (ms): 322.3 | learning rate: 1.212953E-04 | global batch size:     8 | lm loss: 3.441784E+00 | loss scale: 131072.0 | grad norm: 0.653 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 15:37:01] iteration    98200/  500000 | consumed samples:       785600 | elapsed time per iteration (ms): 322.0 | learning rate: 1.212393E-04 | global batch size:     8 | lm loss: 3.420534E+00 | loss scale: 262144.0 | grad norm: 0.672 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 15:37:34] iteration    98300/  500000 | consumed samples:       786400 | elapsed time per iteration (ms): 324.8 | learning rate: 1.211831E-04 | global batch size:     8 | lm loss: 3.502210E+00 | loss scale: 262144.0 | grad norm: 0.634 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 15:38:06] iteration    98400/  500000 | consumed samples:       787200 | elapsed time per iteration (ms): 320.5 | learning rate: 1.211270E-04 | global batch size:     8 | lm loss: 3.444643E+00 | loss scale: 262144.0 | grad norm: 0.630 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 15:38:38] iteration    98500/  500000 | consumed samples:       788000 | elapsed time per iteration (ms): 321.3 | learning rate: 1.210708E-04 | global batch size:     8 | lm loss: 3.469861E+00 | loss scale: 262144.0 | grad norm: 0.639 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 15:39:10] iteration    98600/  500000 | consumed samples:       788800 | elapsed time per iteration (ms): 320.4 | learning rate: 1.210146E-04 | global batch size:     8 | lm loss: 3.504126E+00 | loss scale: 262144.0 | grad norm: 0.634 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 15:39:42] iteration    98700/  500000 | consumed samples:       789600 | elapsed time per iteration (ms): 320.5 | learning rate: 1.209583E-04 | global batch size:     8 | lm loss: 3.443331E+00 | loss scale: 262144.0 | grad norm: 0.621 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 15:40:14] iteration    98800/  500000 | consumed samples:       790400 | elapsed time per iteration (ms): 322.8 | learning rate: 1.209020E-04 | global batch size:     8 | lm loss: 3.477431E+00 | loss scale: 262144.0 | grad norm: 0.637 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 15:40:47] iteration    98900/  500000 | consumed samples:       791200 | elapsed time per iteration (ms): 322.8 | learning rate: 1.208456E-04 | global batch size:     8 | lm loss: 3.471155E+00 | loss scale: 262144.0 | grad norm: 0.637 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 15:41:19] iteration    99000/  500000 | consumed samples:       792000 | elapsed time per iteration (ms): 318.5 | learning rate: 1.207892E-04 | global batch size:     8 | lm loss: 3.463296E+00 | loss scale: 262144.0 | grad norm: 0.628 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1064.52, 1064.52)
-------------------------------------------------------------------------------------------------
 validation loss at iteration 99000 | lm loss value: 3.860005E+00 | lm loss PPL: 4.746560E+01 | 
-------------------------------------------------------------------------------------------------
 [2024-06-21 15:41:52] iteration    99100/  500000 | consumed samples:       792800 | elapsed time per iteration (ms): 325.5 | learning rate: 1.207328E-04 | global batch size:     8 | lm loss: 3.466237E+00 | loss scale: 262144.0 | grad norm: 0.647 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 15:42:24] iteration    99200/  500000 | consumed samples:       793600 | elapsed time per iteration (ms): 322.3 | learning rate: 1.206763E-04 | global batch size:     8 | lm loss: 3.457948E+00 | loss scale: 524288.0 | grad norm: 0.649 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 15:42:57] iteration    99300/  500000 | consumed samples:       794400 | elapsed time per iteration (ms): 322.1 | learning rate: 1.206204E-04 | global batch size:     8 | lm loss: 3.516173E+00 | loss scale: 524288.0 | grad norm: 0.639 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-21 15:43:29] iteration    99400/  500000 | consumed samples:       795200 | elapsed time per iteration (ms): 324.5 | learning rate: 1.205638E-04 | global batch size:     8 | lm loss: 3.464817E+00 | loss scale: 524288.0 | grad norm: 0.655 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 15:44:01] iteration    99500/  500000 | consumed samples:       796000 | elapsed time per iteration (ms): 321.9 | learning rate: 1.205078E-04 | global batch size:     8 | lm loss: 3.469544E+00 | loss scale: 262144.0 | grad norm: 0.656 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-21 15:44:33] iteration    99600/  500000 | consumed samples:       796800 | elapsed time per iteration (ms): 321.2 | learning rate: 1.204512E-04 | global batch size:     8 | lm loss: 3.435313E+00 | loss scale: 262144.0 | grad norm: 0.665 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 15:45:06] iteration    99700/  500000 | consumed samples:       797600 | elapsed time per iteration (ms): 321.4 | learning rate: 1.203945E-04 | global batch size:     8 | lm loss: 3.432871E+00 | loss scale: 262144.0 | grad norm: 0.686 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 15:45:38] iteration    99800/  500000 | consumed samples:       798400 | elapsed time per iteration (ms): 320.3 | learning rate: 1.203378E-04 | global batch size:     8 | lm loss: 3.483964E+00 | loss scale: 262144.0 | grad norm: 0.638 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 15:46:10] iteration    99900/  500000 | consumed samples:       799200 | elapsed time per iteration (ms): 320.7 | learning rate: 1.202810E-04 | global batch size:     8 | lm loss: 3.445157E+00 | loss scale: 262144.0 | grad norm: 0.676 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 15:46:42] iteration   100000/  500000 | consumed samples:       800000 | elapsed time per iteration (ms): 321.5 | learning rate: 1.202242E-04 | global batch size:     8 | lm loss: 3.448856E+00 | loss scale: 262144.0 | grad norm: 0.637 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1063.71, 1063.71)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 100000 | lm loss value: 3.738895E+00 | lm loss PPL: 4.205151E+01 | 
--------------------------------------------------------------------------------------------------
saving checkpoint at iteration  100000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-max in torch format
  successfully saved checkpoint at iteration  100000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-max
(min, max) time across ranks (ms):
    save-checkpoint ................................: (5610.94, 5610.94)
 [2024-06-21 15:47:21] iteration   100100/  500000 | consumed samples:       800800 | elapsed time per iteration (ms): 320.9 | learning rate: 1.201674E-04 | global batch size:     8 | lm loss: 3.507271E+00 | loss scale: 262144.0 | grad norm: 0.652 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 15:47:53] iteration   100200/  500000 | consumed samples:       801600 | elapsed time per iteration (ms): 322.7 | learning rate: 1.201105E-04 | global batch size:     8 | lm loss: 3.464725E+00 | loss scale: 262144.0 | grad norm: 0.629 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 15:48:25] iteration   100300/  500000 | consumed samples:       802400 | elapsed time per iteration (ms): 321.6 | learning rate: 1.200536E-04 | global batch size:     8 | lm loss: 3.459185E+00 | loss scale: 262144.0 | grad norm: 0.672 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 15:48:57] iteration   100400/  500000 | consumed samples:       803200 | elapsed time per iteration (ms): 322.8 | learning rate: 1.199967E-04 | global batch size:     8 | lm loss: 3.448209E+00 | loss scale: 262144.0 | grad norm: 0.646 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 15:49:29] iteration   100500/  500000 | consumed samples:       804000 | elapsed time per iteration (ms): 321.1 | learning rate: 1.199397E-04 | global batch size:     8 | lm loss: 3.484734E+00 | loss scale: 524288.0 | grad norm: 0.635 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 15:50:01] iteration   100600/  500000 | consumed samples:       804800 | elapsed time per iteration (ms): 320.1 | learning rate: 1.198827E-04 | global batch size:     8 | lm loss: 3.497864E+00 | loss scale: 524288.0 | grad norm: 0.689 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 15:50:33] iteration   100700/  500000 | consumed samples:       805600 | elapsed time per iteration (ms): 320.4 | learning rate: 1.198262E-04 | global batch size:     8 | lm loss: 3.430885E+00 | loss scale: 524288.0 | grad norm: 0.624 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-21 15:51:06] iteration   100800/  500000 | consumed samples:       806400 | elapsed time per iteration (ms): 321.2 | learning rate: 1.197691E-04 | global batch size:     8 | lm loss: 3.484220E+00 | loss scale: 524288.0 | grad norm: 0.625 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 15:51:38] iteration   100900/  500000 | consumed samples:       807200 | elapsed time per iteration (ms): 322.7 | learning rate: 1.197119E-04 | global batch size:     8 | lm loss: 3.435973E+00 | loss scale: 524288.0 | grad norm: 0.650 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 15:52:10] iteration   101000/  500000 | consumed samples:       808000 | elapsed time per iteration (ms): 321.4 | learning rate: 1.196547E-04 | global batch size:     8 | lm loss: 3.465403E+00 | loss scale: 524288.0 | grad norm: 0.672 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1062.27, 1062.27)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 101000 | lm loss value: 3.696367E+00 | lm loss PPL: 4.030063E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-21 15:52:43] iteration   101100/  500000 | consumed samples:       808800 | elapsed time per iteration (ms): 321.3 | learning rate: 1.195975E-04 | global batch size:     8 | lm loss: 3.470519E+00 | loss scale: 524288.0 | grad norm: 0.631 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 15:53:15] iteration   101200/  500000 | consumed samples:       809600 | elapsed time per iteration (ms): 322.0 | learning rate: 1.195402E-04 | global batch size:     8 | lm loss: 3.460579E+00 | loss scale: 524288.0 | grad norm: 0.598 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 15:53:48] iteration   101300/  500000 | consumed samples:       810400 | elapsed time per iteration (ms): 323.8 | learning rate: 1.194829E-04 | global batch size:     8 | lm loss: 3.400791E+00 | loss scale: 524288.0 | grad norm: 0.627 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 15:54:20] iteration   101400/  500000 | consumed samples:       811200 | elapsed time per iteration (ms): 321.0 | learning rate: 1.194262E-04 | global batch size:     8 | lm loss: 3.491368E+00 | loss scale: 262144.0 | grad norm: 0.670 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-21 15:54:52] iteration   101500/  500000 | consumed samples:       812000 | elapsed time per iteration (ms): 322.3 | learning rate: 1.193688E-04 | global batch size:     8 | lm loss: 3.457002E+00 | loss scale: 262144.0 | grad norm: 0.679 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 15:55:24] iteration   101600/  500000 | consumed samples:       812800 | elapsed time per iteration (ms): 322.0 | learning rate: 1.193114E-04 | global batch size:     8 | lm loss: 3.452878E+00 | loss scale: 262144.0 | grad norm: 0.635 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 15:55:56] iteration   101700/  500000 | consumed samples:       813600 | elapsed time per iteration (ms): 321.6 | learning rate: 1.192539E-04 | global batch size:     8 | lm loss: 3.489219E+00 | loss scale: 262144.0 | grad norm: 0.618 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 15:56:29] iteration   101800/  500000 | consumed samples:       814400 | elapsed time per iteration (ms): 321.5 | learning rate: 1.191964E-04 | global batch size:     8 | lm loss: 3.428716E+00 | loss scale: 262144.0 | grad norm: 0.656 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 15:57:01] iteration   101900/  500000 | consumed samples:       815200 | elapsed time per iteration (ms): 323.5 | learning rate: 1.191389E-04 | global batch size:     8 | lm loss: 3.484560E+00 | loss scale: 262144.0 | grad norm: 0.639 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 15:57:33] iteration   102000/  500000 | consumed samples:       816000 | elapsed time per iteration (ms): 323.3 | learning rate: 1.190819E-04 | global batch size:     8 | lm loss: 3.417075E+00 | loss scale: 131072.0 | grad norm: 0.655 | number of skipped iterations:   1 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1066.80, 1066.80)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 102000 | lm loss value: 3.766861E+00 | lm loss PPL: 4.324411E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-21 15:58:06] iteration   102100/  500000 | consumed samples:       816800 | elapsed time per iteration (ms): 321.0 | learning rate: 1.190243E-04 | global batch size:     8 | lm loss: 3.433421E+00 | loss scale: 131072.0 | grad norm: 0.649 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 15:58:39] iteration   102200/  500000 | consumed samples:       817600 | elapsed time per iteration (ms): 322.8 | learning rate: 1.189666E-04 | global batch size:     8 | lm loss: 3.463304E+00 | loss scale: 131072.0 | grad norm: 0.647 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 15:59:11] iteration   102300/  500000 | consumed samples:       818400 | elapsed time per iteration (ms): 320.3 | learning rate: 1.189090E-04 | global batch size:     8 | lm loss: 3.477386E+00 | loss scale: 131072.0 | grad norm: 0.673 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 15:59:43] iteration   102400/  500000 | consumed samples:       819200 | elapsed time per iteration (ms): 320.2 | learning rate: 1.188512E-04 | global batch size:     8 | lm loss: 3.480296E+00 | loss scale: 131072.0 | grad norm: 0.668 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 16:00:15] iteration   102500/  500000 | consumed samples:       820000 | elapsed time per iteration (ms): 321.0 | learning rate: 1.187935E-04 | global batch size:     8 | lm loss: 3.467307E+00 | loss scale: 131072.0 | grad norm: 0.667 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 16:00:47] iteration   102600/  500000 | consumed samples:       820800 | elapsed time per iteration (ms): 323.2 | learning rate: 1.187357E-04 | global batch size:     8 | lm loss: 3.422075E+00 | loss scale: 131072.0 | grad norm: 0.668 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 16:01:19] iteration   102700/  500000 | consumed samples:       821600 | elapsed time per iteration (ms): 322.3 | learning rate: 1.186778E-04 | global batch size:     8 | lm loss: 3.486845E+00 | loss scale: 131072.0 | grad norm: 0.594 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 16:01:52] iteration   102800/  500000 | consumed samples:       822400 | elapsed time per iteration (ms): 322.0 | learning rate: 1.186200E-04 | global batch size:     8 | lm loss: 3.441716E+00 | loss scale: 131072.0 | grad norm: 0.639 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 16:02:24] iteration   102900/  500000 | consumed samples:       823200 | elapsed time per iteration (ms): 321.6 | learning rate: 1.185620E-04 | global batch size:     8 | lm loss: 3.471011E+00 | loss scale: 131072.0 | grad norm: 0.630 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 16:02:56] iteration   103000/  500000 | consumed samples:       824000 | elapsed time per iteration (ms): 326.0 | learning rate: 1.185041E-04 | global batch size:     8 | lm loss: 3.438771E+00 | loss scale: 262144.0 | grad norm: 0.648 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1062.76, 1062.76)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 103000 | lm loss value: 3.730152E+00 | lm loss PPL: 4.168544E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-21 16:03:30] iteration   103100/  500000 | consumed samples:       824800 | elapsed time per iteration (ms): 323.3 | learning rate: 1.184461E-04 | global batch size:     8 | lm loss: 3.464422E+00 | loss scale: 262144.0 | grad norm: 0.651 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 16:04:02] iteration   103200/  500000 | consumed samples:       825600 | elapsed time per iteration (ms): 320.7 | learning rate: 1.183881E-04 | global batch size:     8 | lm loss: 3.461978E+00 | loss scale: 262144.0 | grad norm: 0.658 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 16:04:34] iteration   103300/  500000 | consumed samples:       826400 | elapsed time per iteration (ms): 320.9 | learning rate: 1.183300E-04 | global batch size:     8 | lm loss: 3.447831E+00 | loss scale: 262144.0 | grad norm: 0.633 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 16:05:06] iteration   103400/  500000 | consumed samples:       827200 | elapsed time per iteration (ms): 322.6 | learning rate: 1.182719E-04 | global batch size:     8 | lm loss: 3.453101E+00 | loss scale: 262144.0 | grad norm: 0.654 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 16:05:38] iteration   103500/  500000 | consumed samples:       828000 | elapsed time per iteration (ms): 323.2 | learning rate: 1.182138E-04 | global batch size:     8 | lm loss: 3.426855E+00 | loss scale: 262144.0 | grad norm: 0.658 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 16:06:11] iteration   103600/  500000 | consumed samples:       828800 | elapsed time per iteration (ms): 320.7 | learning rate: 1.181556E-04 | global batch size:     8 | lm loss: 3.443798E+00 | loss scale: 262144.0 | grad norm: 0.687 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 16:06:43] iteration   103700/  500000 | consumed samples:       829600 | elapsed time per iteration (ms): 320.8 | learning rate: 1.180974E-04 | global batch size:     8 | lm loss: 3.485103E+00 | loss scale: 262144.0 | grad norm: 0.672 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 16:07:15] iteration   103800/  500000 | consumed samples:       830400 | elapsed time per iteration (ms): 320.9 | learning rate: 1.180391E-04 | global batch size:     8 | lm loss: 3.484621E+00 | loss scale: 262144.0 | grad norm: 0.640 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 16:07:47] iteration   103900/  500000 | consumed samples:       831200 | elapsed time per iteration (ms): 322.2 | learning rate: 1.179808E-04 | global batch size:     8 | lm loss: 3.421516E+00 | loss scale: 262144.0 | grad norm: 0.665 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 16:08:19] iteration   104000/  500000 | consumed samples:       832000 | elapsed time per iteration (ms): 321.6 | learning rate: 1.179225E-04 | global batch size:     8 | lm loss: 3.430670E+00 | loss scale: 524288.0 | grad norm: 0.667 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1071.21, 1071.21)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 104000 | lm loss value: 3.802668E+00 | lm loss PPL: 4.482059E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-21 16:08:53] iteration   104100/  500000 | consumed samples:       832800 | elapsed time per iteration (ms): 323.7 | learning rate: 1.178647E-04 | global batch size:     8 | lm loss: 3.468801E+00 | loss scale: 524288.0 | grad norm: 0.643 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-21 16:09:25] iteration   104200/  500000 | consumed samples:       833600 | elapsed time per iteration (ms): 321.1 | learning rate: 1.178063E-04 | global batch size:     8 | lm loss: 3.430327E+00 | loss scale: 524288.0 | grad norm: 0.662 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 16:09:57] iteration   104300/  500000 | consumed samples:       834400 | elapsed time per iteration (ms): 322.0 | learning rate: 1.177479E-04 | global batch size:     8 | lm loss: 3.449898E+00 | loss scale: 524288.0 | grad norm: 0.654 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 16:10:29] iteration   104400/  500000 | consumed samples:       835200 | elapsed time per iteration (ms): 321.0 | learning rate: 1.176894E-04 | global batch size:     8 | lm loss: 3.422298E+00 | loss scale: 524288.0 | grad norm: 0.638 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 16:11:01] iteration   104500/  500000 | consumed samples:       836000 | elapsed time per iteration (ms): 321.0 | learning rate: 1.176315E-04 | global batch size:     8 | lm loss: 3.441759E+00 | loss scale: 262144.0 | grad norm: 0.651 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-21 16:11:33] iteration   104600/  500000 | consumed samples:       836800 | elapsed time per iteration (ms): 322.6 | learning rate: 1.175729E-04 | global batch size:     8 | lm loss: 3.460736E+00 | loss scale: 262144.0 | grad norm: 0.706 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 16:12:05] iteration   104700/  500000 | consumed samples:       837600 | elapsed time per iteration (ms): 321.9 | learning rate: 1.175143E-04 | global batch size:     8 | lm loss: 3.427423E+00 | loss scale: 262144.0 | grad norm: 0.703 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 16:12:38] iteration   104800/  500000 | consumed samples:       838400 | elapsed time per iteration (ms): 321.6 | learning rate: 1.174557E-04 | global batch size:     8 | lm loss: 3.421608E+00 | loss scale: 262144.0 | grad norm: 0.689 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 16:13:10] iteration   104900/  500000 | consumed samples:       839200 | elapsed time per iteration (ms): 322.1 | learning rate: 1.173970E-04 | global batch size:     8 | lm loss: 3.416837E+00 | loss scale: 262144.0 | grad norm: 0.613 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 16:13:42] iteration   105000/  500000 | consumed samples:       840000 | elapsed time per iteration (ms): 322.3 | learning rate: 1.173383E-04 | global batch size:     8 | lm loss: 3.492667E+00 | loss scale: 262144.0 | grad norm: 0.734 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1076.14, 1076.14)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 105000 | lm loss value: 3.682478E+00 | lm loss PPL: 3.974476E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-21 16:14:15] iteration   105100/  500000 | consumed samples:       840800 | elapsed time per iteration (ms): 320.7 | learning rate: 1.172796E-04 | global batch size:     8 | lm loss: 3.440895E+00 | loss scale: 262144.0 | grad norm: 0.667 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 16:14:47] iteration   105200/  500000 | consumed samples:       841600 | elapsed time per iteration (ms): 321.9 | learning rate: 1.172208E-04 | global batch size:     8 | lm loss: 3.416883E+00 | loss scale: 262144.0 | grad norm: 0.651 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 16:15:20] iteration   105300/  500000 | consumed samples:       842400 | elapsed time per iteration (ms): 322.0 | learning rate: 1.171620E-04 | global batch size:     8 | lm loss: 3.446829E+00 | loss scale: 262144.0 | grad norm: 0.641 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 16:15:52] iteration   105400/  500000 | consumed samples:       843200 | elapsed time per iteration (ms): 321.2 | learning rate: 1.171032E-04 | global batch size:     8 | lm loss: 3.458097E+00 | loss scale: 262144.0 | grad norm: 0.706 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 16:16:24] iteration   105500/  500000 | consumed samples:       844000 | elapsed time per iteration (ms): 322.3 | learning rate: 1.170443E-04 | global batch size:     8 | lm loss: 3.437049E+00 | loss scale: 524288.0 | grad norm: 0.629 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 16:16:56] iteration   105600/  500000 | consumed samples:       844800 | elapsed time per iteration (ms): 323.5 | learning rate: 1.169854E-04 | global batch size:     8 | lm loss: 3.427635E+00 | loss scale: 524288.0 | grad norm: 0.684 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 16:17:29] iteration   105700/  500000 | consumed samples:       845600 | elapsed time per iteration (ms): 321.9 | learning rate: 1.169264E-04 | global batch size:     8 | lm loss: 3.470321E+00 | loss scale: 524288.0 | grad norm: 0.650 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 16:18:01] iteration   105800/  500000 | consumed samples:       846400 | elapsed time per iteration (ms): 322.3 | learning rate: 1.168674E-04 | global batch size:     8 | lm loss: 3.414636E+00 | loss scale: 524288.0 | grad norm: 0.659 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 16:18:33] iteration   105900/  500000 | consumed samples:       847200 | elapsed time per iteration (ms): 321.8 | learning rate: 1.168084E-04 | global batch size:     8 | lm loss: 3.449022E+00 | loss scale: 524288.0 | grad norm: 0.651 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 16:19:05] iteration   106000/  500000 | consumed samples:       848000 | elapsed time per iteration (ms): 321.0 | learning rate: 1.167499E-04 | global batch size:     8 | lm loss: 3.397501E+00 | loss scale: 524288.0 | grad norm: 0.668 | number of skipped iterations:   1 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1063.91, 1063.91)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 106000 | lm loss value: 3.681472E+00 | lm loss PPL: 3.970480E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-21 16:19:38] iteration   106100/  500000 | consumed samples:       848800 | elapsed time per iteration (ms): 322.3 | learning rate: 1.166908E-04 | global batch size:     8 | lm loss: 3.489914E+00 | loss scale: 524288.0 | grad norm: 0.693 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 16:20:10] iteration   106200/  500000 | consumed samples:       849600 | elapsed time per iteration (ms): 320.1 | learning rate: 1.166317E-04 | global batch size:     8 | lm loss: 3.421060E+00 | loss scale: 524288.0 | grad norm: 0.652 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 16:20:43] iteration   106300/  500000 | consumed samples:       850400 | elapsed time per iteration (ms): 322.7 | learning rate: 1.165725E-04 | global batch size:     8 | lm loss: 3.450494E+00 | loss scale: 524288.0 | grad norm: 0.620 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 16:21:15] iteration   106400/  500000 | consumed samples:       851200 | elapsed time per iteration (ms): 320.4 | learning rate: 1.165139E-04 | global batch size:     8 | lm loss: 3.455079E+00 | loss scale: 262144.0 | grad norm: 0.652 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-21 16:21:47] iteration   106500/  500000 | consumed samples:       852000 | elapsed time per iteration (ms): 318.9 | learning rate: 1.164547E-04 | global batch size:     8 | lm loss: 3.443275E+00 | loss scale: 262144.0 | grad norm: 0.668 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 16:22:19] iteration   106600/  500000 | consumed samples:       852800 | elapsed time per iteration (ms): 322.1 | learning rate: 1.163954E-04 | global batch size:     8 | lm loss: 3.406461E+00 | loss scale: 262144.0 | grad norm: 0.662 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 16:22:51] iteration   106700/  500000 | consumed samples:       853600 | elapsed time per iteration (ms): 322.6 | learning rate: 1.163361E-04 | global batch size:     8 | lm loss: 3.419339E+00 | loss scale: 262144.0 | grad norm: 0.648 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 16:23:23] iteration   106800/  500000 | consumed samples:       854400 | elapsed time per iteration (ms): 322.3 | learning rate: 1.162767E-04 | global batch size:     8 | lm loss: 3.475488E+00 | loss scale: 262144.0 | grad norm: 0.637 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 16:23:55] iteration   106900/  500000 | consumed samples:       855200 | elapsed time per iteration (ms): 322.4 | learning rate: 1.162173E-04 | global batch size:     8 | lm loss: 3.480618E+00 | loss scale: 262144.0 | grad norm: 0.636 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 16:24:28] iteration   107000/  500000 | consumed samples:       856000 | elapsed time per iteration (ms): 321.8 | learning rate: 1.161579E-04 | global batch size:     8 | lm loss: 3.427492E+00 | loss scale: 262144.0 | grad norm: 0.686 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1071.72, 1071.72)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 107000 | lm loss value: 3.823426E+00 | lm loss PPL: 4.576074E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-21 16:25:01] iteration   107100/  500000 | consumed samples:       856800 | elapsed time per iteration (ms): 322.1 | learning rate: 1.160985E-04 | global batch size:     8 | lm loss: 3.434716E+00 | loss scale: 262144.0 | grad norm: 0.650 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 16:25:33] iteration   107200/  500000 | consumed samples:       857600 | elapsed time per iteration (ms): 322.2 | learning rate: 1.160390E-04 | global batch size:     8 | lm loss: 3.434231E+00 | loss scale: 262144.0 | grad norm: 0.685 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 16:26:05] iteration   107300/  500000 | consumed samples:       858400 | elapsed time per iteration (ms): 320.7 | learning rate: 1.159795E-04 | global batch size:     8 | lm loss: 3.458749E+00 | loss scale: 262144.0 | grad norm: 0.625 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 16:26:37] iteration   107400/  500000 | consumed samples:       859200 | elapsed time per iteration (ms): 319.6 | learning rate: 1.159205E-04 | global batch size:     8 | lm loss: 3.425622E+00 | loss scale: 524288.0 | grad norm: 0.646 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-21 16:27:09] iteration   107500/  500000 | consumed samples:       860000 | elapsed time per iteration (ms): 321.5 | learning rate: 1.158609E-04 | global batch size:     8 | lm loss: 3.470546E+00 | loss scale: 524288.0 | grad norm: 0.673 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 16:27:42] iteration   107600/  500000 | consumed samples:       860800 | elapsed time per iteration (ms): 322.7 | learning rate: 1.158013E-04 | global batch size:     8 | lm loss: 3.417062E+00 | loss scale: 524288.0 | grad norm: 0.667 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 16:28:14] iteration   107700/  500000 | consumed samples:       861600 | elapsed time per iteration (ms): 322.2 | learning rate: 1.157416E-04 | global batch size:     8 | lm loss: 3.434023E+00 | loss scale: 524288.0 | grad norm: 0.636 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 16:28:46] iteration   107800/  500000 | consumed samples:       862400 | elapsed time per iteration (ms): 323.5 | learning rate: 1.156819E-04 | global batch size:     8 | lm loss: 3.475502E+00 | loss scale: 524288.0 | grad norm: 0.611 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 16:29:18] iteration   107900/  500000 | consumed samples:       863200 | elapsed time per iteration (ms): 318.1 | learning rate: 1.156221E-04 | global batch size:     8 | lm loss: 3.463427E+00 | loss scale: 524288.0 | grad norm: 0.654 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 16:29:50] iteration   108000/  500000 | consumed samples:       864000 | elapsed time per iteration (ms): 320.9 | learning rate: 1.155624E-04 | global batch size:     8 | lm loss: 3.419754E+00 | loss scale: 524288.0 | grad norm: 0.669 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1062.54, 1062.54)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 108000 | lm loss value: 3.613642E+00 | lm loss PPL: 3.710092E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-21 16:30:23] iteration   108100/  500000 | consumed samples:       864800 | elapsed time per iteration (ms): 322.7 | learning rate: 1.155032E-04 | global batch size:     8 | lm loss: 3.398550E+00 | loss scale: 262144.0 | grad norm: 0.680 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-21 16:30:56] iteration   108200/  500000 | consumed samples:       865600 | elapsed time per iteration (ms): 323.9 | learning rate: 1.154433E-04 | global batch size:     8 | lm loss: 3.465905E+00 | loss scale: 262144.0 | grad norm: 0.658 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 16:31:28] iteration   108300/  500000 | consumed samples:       866400 | elapsed time per iteration (ms): 322.3 | learning rate: 1.153834E-04 | global batch size:     8 | lm loss: 3.390498E+00 | loss scale: 262144.0 | grad norm: 0.693 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 16:32:00] iteration   108400/  500000 | consumed samples:       867200 | elapsed time per iteration (ms): 320.7 | learning rate: 1.153235E-04 | global batch size:     8 | lm loss: 3.374863E+00 | loss scale: 262144.0 | grad norm: 0.655 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 16:32:32] iteration   108500/  500000 | consumed samples:       868000 | elapsed time per iteration (ms): 321.5 | learning rate: 1.152636E-04 | global batch size:     8 | lm loss: 3.425505E+00 | loss scale: 262144.0 | grad norm: 0.710 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 16:33:04] iteration   108600/  500000 | consumed samples:       868800 | elapsed time per iteration (ms): 321.4 | learning rate: 1.152036E-04 | global batch size:     8 | lm loss: 3.443380E+00 | loss scale: 262144.0 | grad norm: 0.640 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 16:33:37] iteration   108700/  500000 | consumed samples:       869600 | elapsed time per iteration (ms): 322.3 | learning rate: 1.151436E-04 | global batch size:     8 | lm loss: 3.423947E+00 | loss scale: 262144.0 | grad norm: 0.698 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 16:34:09] iteration   108800/  500000 | consumed samples:       870400 | elapsed time per iteration (ms): 323.4 | learning rate: 1.150835E-04 | global batch size:     8 | lm loss: 3.382199E+00 | loss scale: 262144.0 | grad norm: 0.658 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 16:34:41] iteration   108900/  500000 | consumed samples:       871200 | elapsed time per iteration (ms): 321.4 | learning rate: 1.150240E-04 | global batch size:     8 | lm loss: 3.399059E+00 | loss scale: 131072.0 | grad norm: 0.643 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-21 16:35:13] iteration   109000/  500000 | consumed samples:       872000 | elapsed time per iteration (ms): 323.2 | learning rate: 1.149639E-04 | global batch size:     8 | lm loss: 3.381821E+00 | loss scale: 131072.0 | grad norm: 0.711 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1066.17, 1066.17)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 109000 | lm loss value: 3.777578E+00 | lm loss PPL: 4.371003E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-21 16:35:46] iteration   109100/  500000 | consumed samples:       872800 | elapsed time per iteration (ms): 319.6 | learning rate: 1.149038E-04 | global batch size:     8 | lm loss: 3.414091E+00 | loss scale: 131072.0 | grad norm: 0.670 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 16:36:18] iteration   109200/  500000 | consumed samples:       873600 | elapsed time per iteration (ms): 319.5 | learning rate: 1.148436E-04 | global batch size:     8 | lm loss: 3.440988E+00 | loss scale: 131072.0 | grad norm: 0.667 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 16:36:51] iteration   109300/  500000 | consumed samples:       874400 | elapsed time per iteration (ms): 323.4 | learning rate: 1.147834E-04 | global batch size:     8 | lm loss: 3.400894E+00 | loss scale: 131072.0 | grad norm: 0.673 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 16:37:23] iteration   109400/  500000 | consumed samples:       875200 | elapsed time per iteration (ms): 321.4 | learning rate: 1.147231E-04 | global batch size:     8 | lm loss: 3.437010E+00 | loss scale: 131072.0 | grad norm: 0.656 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 16:37:55] iteration   109500/  500000 | consumed samples:       876000 | elapsed time per iteration (ms): 323.1 | learning rate: 1.146628E-04 | global batch size:     8 | lm loss: 3.447243E+00 | loss scale: 131072.0 | grad norm: 0.634 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 16:38:28] iteration   109600/  500000 | consumed samples:       876800 | elapsed time per iteration (ms): 323.6 | learning rate: 1.146025E-04 | global batch size:     8 | lm loss: 3.418912E+00 | loss scale: 131072.0 | grad norm: 0.660 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 16:39:00] iteration   109700/  500000 | consumed samples:       877600 | elapsed time per iteration (ms): 322.4 | learning rate: 1.145421E-04 | global batch size:     8 | lm loss: 3.423022E+00 | loss scale: 131072.0 | grad norm: 0.929 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 16:39:32] iteration   109800/  500000 | consumed samples:       878400 | elapsed time per iteration (ms): 321.1 | learning rate: 1.144817E-04 | global batch size:     8 | lm loss: 3.476441E+00 | loss scale: 131072.0 | grad norm: 0.795 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 16:40:04] iteration   109900/  500000 | consumed samples:       879200 | elapsed time per iteration (ms): 322.7 | learning rate: 1.144213E-04 | global batch size:     8 | lm loss: 3.453206E+00 | loss scale: 262144.0 | grad norm: 0.710 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 16:40:36] iteration   110000/  500000 | consumed samples:       880000 | elapsed time per iteration (ms): 323.0 | learning rate: 1.143608E-04 | global batch size:     8 | lm loss: 3.421039E+00 | loss scale: 262144.0 | grad norm: 0.642 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1063.65, 1063.65)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 110000 | lm loss value: 3.795154E+00 | lm loss PPL: 4.448510E+01 | 
--------------------------------------------------------------------------------------------------
saving checkpoint at iteration  110000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-max in torch format
  successfully saved checkpoint at iteration  110000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-max
(min, max) time across ranks (ms):
    save-checkpoint ................................: (5668.37, 5668.37)
 [2024-06-21 16:41:15] iteration   110100/  500000 | consumed samples:       880800 | elapsed time per iteration (ms): 322.3 | learning rate: 1.143003E-04 | global batch size:     8 | lm loss: 3.408547E+00 | loss scale: 262144.0 | grad norm: 0.669 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 16:41:47] iteration   110200/  500000 | consumed samples:       881600 | elapsed time per iteration (ms): 320.4 | learning rate: 1.142398E-04 | global batch size:     8 | lm loss: 3.438908E+00 | loss scale: 262144.0 | grad norm: 0.680 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 16:42:20] iteration   110300/  500000 | consumed samples:       882400 | elapsed time per iteration (ms): 321.0 | learning rate: 1.141793E-04 | global batch size:     8 | lm loss: 3.436662E+00 | loss scale: 262144.0 | grad norm: 0.662 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 16:42:52] iteration   110400/  500000 | consumed samples:       883200 | elapsed time per iteration (ms): 319.7 | learning rate: 1.141187E-04 | global batch size:     8 | lm loss: 3.425743E+00 | loss scale: 262144.0 | grad norm: 0.678 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 16:43:24] iteration   110500/  500000 | consumed samples:       884000 | elapsed time per iteration (ms): 322.1 | learning rate: 1.140580E-04 | global batch size:     8 | lm loss: 3.446549E+00 | loss scale: 262144.0 | grad norm: 0.653 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 16:43:56] iteration   110600/  500000 | consumed samples:       884800 | elapsed time per iteration (ms): 320.8 | learning rate: 1.139974E-04 | global batch size:     8 | lm loss: 3.447333E+00 | loss scale: 262144.0 | grad norm: 0.704 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 16:44:28] iteration   110700/  500000 | consumed samples:       885600 | elapsed time per iteration (ms): 320.9 | learning rate: 1.139367E-04 | global batch size:     8 | lm loss: 3.427340E+00 | loss scale: 262144.0 | grad norm: 0.678 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 16:45:00] iteration   110800/  500000 | consumed samples:       886400 | elapsed time per iteration (ms): 320.4 | learning rate: 1.138759E-04 | global batch size:     8 | lm loss: 3.400229E+00 | loss scale: 262144.0 | grad norm: 0.647 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 16:45:32] iteration   110900/  500000 | consumed samples:       887200 | elapsed time per iteration (ms): 322.6 | learning rate: 1.138152E-04 | global batch size:     8 | lm loss: 3.410580E+00 | loss scale: 524288.0 | grad norm: 0.647 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 16:46:04] iteration   111000/  500000 | consumed samples:       888000 | elapsed time per iteration (ms): 321.9 | learning rate: 1.137550E-04 | global batch size:     8 | lm loss: 3.457171E+00 | loss scale: 524288.0 | grad norm: 0.676 | number of skipped iterations:   1 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1064.72, 1064.72)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 111000 | lm loss value: 3.781001E+00 | lm loss PPL: 4.385994E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-21 16:46:38] iteration   111100/  500000 | consumed samples:       888800 | elapsed time per iteration (ms): 323.1 | learning rate: 1.136942E-04 | global batch size:     8 | lm loss: 3.393456E+00 | loss scale: 524288.0 | grad norm: 0.644 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 16:47:10] iteration   111200/  500000 | consumed samples:       889600 | elapsed time per iteration (ms): 321.8 | learning rate: 1.136339E-04 | global batch size:     8 | lm loss: 3.404325E+00 | loss scale: 262144.0 | grad norm: 0.691 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-21 16:47:42] iteration   111300/  500000 | consumed samples:       890400 | elapsed time per iteration (ms): 321.9 | learning rate: 1.135730E-04 | global batch size:     8 | lm loss: 3.394074E+00 | loss scale: 262144.0 | grad norm: 0.644 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 16:48:15] iteration   111400/  500000 | consumed samples:       891200 | elapsed time per iteration (ms): 323.4 | learning rate: 1.135121E-04 | global batch size:     8 | lm loss: 3.446384E+00 | loss scale: 262144.0 | grad norm: 0.661 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 16:48:47] iteration   111500/  500000 | consumed samples:       892000 | elapsed time per iteration (ms): 321.0 | learning rate: 1.134511E-04 | global batch size:     8 | lm loss: 3.395002E+00 | loss scale: 262144.0 | grad norm: 0.691 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 16:49:19] iteration   111600/  500000 | consumed samples:       892800 | elapsed time per iteration (ms): 322.1 | learning rate: 1.133901E-04 | global batch size:     8 | lm loss: 3.405282E+00 | loss scale: 262144.0 | grad norm: 0.657 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 16:49:51] iteration   111700/  500000 | consumed samples:       893600 | elapsed time per iteration (ms): 321.6 | learning rate: 1.133291E-04 | global batch size:     8 | lm loss: 3.423542E+00 | loss scale: 262144.0 | grad norm: 0.684 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 16:50:23] iteration   111800/  500000 | consumed samples:       894400 | elapsed time per iteration (ms): 324.1 | learning rate: 1.132680E-04 | global batch size:     8 | lm loss: 3.436558E+00 | loss scale: 262144.0 | grad norm: 0.662 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 16:50:56] iteration   111900/  500000 | consumed samples:       895200 | elapsed time per iteration (ms): 322.0 | learning rate: 1.132070E-04 | global batch size:     8 | lm loss: 3.458920E+00 | loss scale: 262144.0 | grad norm: 0.750 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 16:51:28] iteration   112000/  500000 | consumed samples:       896000 | elapsed time per iteration (ms): 321.1 | learning rate: 1.131458E-04 | global batch size:     8 | lm loss: 3.426895E+00 | loss scale: 262144.0 | grad norm: 0.641 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1063.94, 1063.94)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 112000 | lm loss value: 3.743869E+00 | lm loss PPL: 4.226117E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-21 16:52:01] iteration   112100/  500000 | consumed samples:       896800 | elapsed time per iteration (ms): 322.6 | learning rate: 1.130847E-04 | global batch size:     8 | lm loss: 3.428935E+00 | loss scale: 262144.0 | grad norm: 0.692 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 16:52:33] iteration   112200/  500000 | consumed samples:       897600 | elapsed time per iteration (ms): 321.8 | learning rate: 1.130235E-04 | global batch size:     8 | lm loss: 3.424528E+00 | loss scale: 524288.0 | grad norm: 0.677 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 16:53:05] iteration   112300/  500000 | consumed samples:       898400 | elapsed time per iteration (ms): 321.3 | learning rate: 1.129629E-04 | global batch size:     8 | lm loss: 3.475353E+00 | loss scale: 524288.0 | grad norm: 0.699 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-21 16:53:38] iteration   112400/  500000 | consumed samples:       899200 | elapsed time per iteration (ms): 323.4 | learning rate: 1.129016E-04 | global batch size:     8 | lm loss: 3.398458E+00 | loss scale: 524288.0 | grad norm: 0.656 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 16:54:10] iteration   112500/  500000 | consumed samples:       900000 | elapsed time per iteration (ms): 321.9 | learning rate: 1.128403E-04 | global batch size:     8 | lm loss: 3.450930E+00 | loss scale: 524288.0 | grad norm: 0.688 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 16:54:42] iteration   112600/  500000 | consumed samples:       900800 | elapsed time per iteration (ms): 323.6 | learning rate: 1.127790E-04 | global batch size:     8 | lm loss: 3.427209E+00 | loss scale: 524288.0 | grad norm: 0.651 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 16:55:14] iteration   112700/  500000 | consumed samples:       901600 | elapsed time per iteration (ms): 320.3 | learning rate: 1.127177E-04 | global batch size:     8 | lm loss: 3.436667E+00 | loss scale: 524288.0 | grad norm: 0.655 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 16:55:47] iteration   112800/  500000 | consumed samples:       902400 | elapsed time per iteration (ms): 323.2 | learning rate: 1.126563E-04 | global batch size:     8 | lm loss: 3.406386E+00 | loss scale: 524288.0 | grad norm: 0.671 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 16:56:19] iteration   112900/  500000 | consumed samples:       903200 | elapsed time per iteration (ms): 321.9 | learning rate: 1.125949E-04 | global batch size:     8 | lm loss: 3.415618E+00 | loss scale: 524288.0 | grad norm: 0.650 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 16:56:51] iteration   113000/  500000 | consumed samples:       904000 | elapsed time per iteration (ms): 319.4 | learning rate: 1.125334E-04 | global batch size:     8 | lm loss: 3.390411E+00 | loss scale: 524288.0 | grad norm: 0.652 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1070.03, 1070.03)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 113000 | lm loss value: 3.600658E+00 | lm loss PPL: 3.662234E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-21 16:57:24] iteration   113100/  500000 | consumed samples:       904800 | elapsed time per iteration (ms): 323.1 | learning rate: 1.124725E-04 | global batch size:     8 | lm loss: 3.416098E+00 | loss scale: 262144.0 | grad norm: 0.675 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-21 16:57:56] iteration   113200/  500000 | consumed samples:       905600 | elapsed time per iteration (ms): 322.4 | learning rate: 1.124110E-04 | global batch size:     8 | lm loss: 3.403465E+00 | loss scale: 262144.0 | grad norm: 0.686 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 16:58:29] iteration   113300/  500000 | consumed samples:       906400 | elapsed time per iteration (ms): 321.6 | learning rate: 1.123495E-04 | global batch size:     8 | lm loss: 3.426741E+00 | loss scale: 262144.0 | grad norm: 0.660 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 16:59:01] iteration   113400/  500000 | consumed samples:       907200 | elapsed time per iteration (ms): 324.1 | learning rate: 1.122885E-04 | global batch size:     8 | lm loss: 3.377939E+00 | loss scale: 131072.0 | grad norm: 0.671 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-21 16:59:33] iteration   113500/  500000 | consumed samples:       908000 | elapsed time per iteration (ms): 324.4 | learning rate: 1.122269E-04 | global batch size:     8 | lm loss: 3.409427E+00 | loss scale: 131072.0 | grad norm: 0.679 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 17:00:05] iteration   113600/  500000 | consumed samples:       908800 | elapsed time per iteration (ms): 320.7 | learning rate: 1.121653E-04 | global batch size:     8 | lm loss: 3.398284E+00 | loss scale: 131072.0 | grad norm: 0.650 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 17:00:38] iteration   113700/  500000 | consumed samples:       909600 | elapsed time per iteration (ms): 320.6 | learning rate: 1.121036E-04 | global batch size:     8 | lm loss: 3.421414E+00 | loss scale: 131072.0 | grad norm: 0.633 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 17:01:10] iteration   113800/  500000 | consumed samples:       910400 | elapsed time per iteration (ms): 320.6 | learning rate: 1.120419E-04 | global batch size:     8 | lm loss: 3.453845E+00 | loss scale: 131072.0 | grad norm: 0.663 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 17:01:42] iteration   113900/  500000 | consumed samples:       911200 | elapsed time per iteration (ms): 323.3 | learning rate: 1.119802E-04 | global batch size:     8 | lm loss: 3.415400E+00 | loss scale: 131072.0 | grad norm: 0.664 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 17:02:14] iteration   114000/  500000 | consumed samples:       912000 | elapsed time per iteration (ms): 320.9 | learning rate: 1.119184E-04 | global batch size:     8 | lm loss: 3.409011E+00 | loss scale: 131072.0 | grad norm: 0.684 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1065.55, 1065.55)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 114000 | lm loss value: 3.665122E+00 | lm loss PPL: 3.906091E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-21 17:02:47] iteration   114100/  500000 | consumed samples:       912800 | elapsed time per iteration (ms): 321.7 | learning rate: 1.118566E-04 | global batch size:     8 | lm loss: 3.410689E+00 | loss scale: 131072.0 | grad norm: 0.753 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 17:03:19] iteration   114200/  500000 | consumed samples:       913600 | elapsed time per iteration (ms): 322.3 | learning rate: 1.117948E-04 | global batch size:     8 | lm loss: 3.390682E+00 | loss scale: 131072.0 | grad norm: 0.694 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 17:03:52] iteration   114300/  500000 | consumed samples:       914400 | elapsed time per iteration (ms): 321.0 | learning rate: 1.117329E-04 | global batch size:     8 | lm loss: 3.389095E+00 | loss scale: 131072.0 | grad norm: 0.661 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 17:04:24] iteration   114400/  500000 | consumed samples:       915200 | elapsed time per iteration (ms): 321.8 | learning rate: 1.116710E-04 | global batch size:     8 | lm loss: 3.390693E+00 | loss scale: 262144.0 | grad norm: 0.655 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 17:04:56] iteration   114500/  500000 | consumed samples:       916000 | elapsed time per iteration (ms): 322.3 | learning rate: 1.116091E-04 | global batch size:     8 | lm loss: 3.435231E+00 | loss scale: 262144.0 | grad norm: 0.663 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 17:05:28] iteration   114600/  500000 | consumed samples:       916800 | elapsed time per iteration (ms): 322.6 | learning rate: 1.115472E-04 | global batch size:     8 | lm loss: 3.395574E+00 | loss scale: 262144.0 | grad norm: 0.638 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 17:06:00] iteration   114700/  500000 | consumed samples:       917600 | elapsed time per iteration (ms): 322.0 | learning rate: 1.114858E-04 | global batch size:     8 | lm loss: 3.378161E+00 | loss scale: 262144.0 | grad norm: 0.666 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-21 17:06:32] iteration   114800/  500000 | consumed samples:       918400 | elapsed time per iteration (ms): 319.5 | learning rate: 1.114238E-04 | global batch size:     8 | lm loss: 3.418525E+00 | loss scale: 262144.0 | grad norm: 0.692 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 17:07:05] iteration   114900/  500000 | consumed samples:       919200 | elapsed time per iteration (ms): 322.1 | learning rate: 1.113618E-04 | global batch size:     8 | lm loss: 3.359294E+00 | loss scale: 262144.0 | grad norm: 0.696 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 17:07:37] iteration   115000/  500000 | consumed samples:       920000 | elapsed time per iteration (ms): 322.7 | learning rate: 1.112997E-04 | global batch size:     8 | lm loss: 3.436675E+00 | loss scale: 262144.0 | grad norm: 0.653 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1066.26, 1066.26)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 115000 | lm loss value: 3.603277E+00 | lm loss PPL: 3.671837E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-21 17:08:10] iteration   115100/  500000 | consumed samples:       920800 | elapsed time per iteration (ms): 320.9 | learning rate: 1.112376E-04 | global batch size:     8 | lm loss: 3.411645E+00 | loss scale: 262144.0 | grad norm: 0.684 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 17:08:42] iteration   115200/  500000 | consumed samples:       921600 | elapsed time per iteration (ms): 323.5 | learning rate: 1.111754E-04 | global batch size:     8 | lm loss: 3.403515E+00 | loss scale: 262144.0 | grad norm: 0.649 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 17:09:15] iteration   115300/  500000 | consumed samples:       922400 | elapsed time per iteration (ms): 322.5 | learning rate: 1.111133E-04 | global batch size:     8 | lm loss: 3.394975E+00 | loss scale: 262144.0 | grad norm: 0.690 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 17:09:47] iteration   115400/  500000 | consumed samples:       923200 | elapsed time per iteration (ms): 321.5 | learning rate: 1.110511E-04 | global batch size:     8 | lm loss: 3.403250E+00 | loss scale: 262144.0 | grad norm: 0.646 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 17:10:19] iteration   115500/  500000 | consumed samples:       924000 | elapsed time per iteration (ms): 320.6 | learning rate: 1.109888E-04 | global batch size:     8 | lm loss: 3.379633E+00 | loss scale: 262144.0 | grad norm: 0.649 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 17:10:51] iteration   115600/  500000 | consumed samples:       924800 | elapsed time per iteration (ms): 321.6 | learning rate: 1.109266E-04 | global batch size:     8 | lm loss: 3.406052E+00 | loss scale: 262144.0 | grad norm: 0.691 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 17:11:23] iteration   115700/  500000 | consumed samples:       925600 | elapsed time per iteration (ms): 321.3 | learning rate: 1.108643E-04 | global batch size:     8 | lm loss: 3.365807E+00 | loss scale: 524288.0 | grad norm: 0.637 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 17:11:55] iteration   115800/  500000 | consumed samples:       926400 | elapsed time per iteration (ms): 320.7 | learning rate: 1.108020E-04 | global batch size:     8 | lm loss: 3.404601E+00 | loss scale: 524288.0 | grad norm: 0.677 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 17:12:27] iteration   115900/  500000 | consumed samples:       927200 | elapsed time per iteration (ms): 320.0 | learning rate: 1.107396E-04 | global batch size:     8 | lm loss: 3.406103E+00 | loss scale: 524288.0 | grad norm: 0.659 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 17:12:59] iteration   116000/  500000 | consumed samples:       928000 | elapsed time per iteration (ms): 321.8 | learning rate: 1.106772E-04 | global batch size:     8 | lm loss: 3.341622E+00 | loss scale: 524288.0 | grad norm: 0.679 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1068.72, 1068.72)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 116000 | lm loss value: 3.618661E+00 | lm loss PPL: 3.728761E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-21 17:13:33] iteration   116100/  500000 | consumed samples:       928800 | elapsed time per iteration (ms): 322.9 | learning rate: 1.106148E-04 | global batch size:     8 | lm loss: 3.394607E+00 | loss scale: 524288.0 | grad norm: 0.708 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 17:14:05] iteration   116200/  500000 | consumed samples:       929600 | elapsed time per iteration (ms): 321.6 | learning rate: 1.105530E-04 | global batch size:     8 | lm loss: 3.427571E+00 | loss scale: 524288.0 | grad norm: 0.687 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-21 17:14:37] iteration   116300/  500000 | consumed samples:       930400 | elapsed time per iteration (ms): 320.9 | learning rate: 1.104905E-04 | global batch size:     8 | lm loss: 3.408885E+00 | loss scale: 524288.0 | grad norm: 0.708 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 17:15:09] iteration   116400/  500000 | consumed samples:       931200 | elapsed time per iteration (ms): 322.0 | learning rate: 1.104280E-04 | global batch size:     8 | lm loss: 3.382290E+00 | loss scale: 524288.0 | grad norm: 0.673 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 17:15:41] iteration   116500/  500000 | consumed samples:       932000 | elapsed time per iteration (ms): 321.2 | learning rate: 1.103655E-04 | global batch size:     8 | lm loss: 3.371362E+00 | loss scale: 524288.0 | grad norm: 0.688 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 17:16:13] iteration   116600/  500000 | consumed samples:       932800 | elapsed time per iteration (ms): 321.2 | learning rate: 1.103030E-04 | global batch size:     8 | lm loss: 3.396667E+00 | loss scale: 524288.0 | grad norm: 0.698 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 17:16:46] iteration   116700/  500000 | consumed samples:       933600 | elapsed time per iteration (ms): 323.4 | learning rate: 1.102410E-04 | global batch size:     8 | lm loss: 3.396903E+00 | loss scale: 262144.0 | grad norm: 0.675 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-21 17:17:18] iteration   116800/  500000 | consumed samples:       934400 | elapsed time per iteration (ms): 321.9 | learning rate: 1.101784E-04 | global batch size:     8 | lm loss: 3.363782E+00 | loss scale: 262144.0 | grad norm: 0.661 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 17:17:50] iteration   116900/  500000 | consumed samples:       935200 | elapsed time per iteration (ms): 323.0 | learning rate: 1.101157E-04 | global batch size:     8 | lm loss: 3.399668E+00 | loss scale: 262144.0 | grad norm: 0.688 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 17:18:22] iteration   117000/  500000 | consumed samples:       936000 | elapsed time per iteration (ms): 322.0 | learning rate: 1.100530E-04 | global batch size:     8 | lm loss: 3.389315E+00 | loss scale: 262144.0 | grad norm: 0.677 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1070.54, 1070.54)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 117000 | lm loss value: 3.835995E+00 | lm loss PPL: 4.633950E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-21 17:18:56] iteration   117100/  500000 | consumed samples:       936800 | elapsed time per iteration (ms): 321.1 | learning rate: 1.099903E-04 | global batch size:     8 | lm loss: 3.421534E+00 | loss scale: 262144.0 | grad norm: 0.662 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 17:19:28] iteration   117200/  500000 | consumed samples:       937600 | elapsed time per iteration (ms): 322.9 | learning rate: 1.099276E-04 | global batch size:     8 | lm loss: 3.396800E+00 | loss scale: 262144.0 | grad norm: 0.733 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 17:20:00] iteration   117300/  500000 | consumed samples:       938400 | elapsed time per iteration (ms): 321.4 | learning rate: 1.098648E-04 | global batch size:     8 | lm loss: 3.429036E+00 | loss scale: 262144.0 | grad norm: 0.655 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 17:20:32] iteration   117400/  500000 | consumed samples:       939200 | elapsed time per iteration (ms): 320.9 | learning rate: 1.098020E-04 | global batch size:     8 | lm loss: 3.372861E+00 | loss scale: 262144.0 | grad norm: 0.674 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 17:21:05] iteration   117500/  500000 | consumed samples:       940000 | elapsed time per iteration (ms): 323.6 | learning rate: 1.097392E-04 | global batch size:     8 | lm loss: 3.408908E+00 | loss scale: 262144.0 | grad norm: 0.685 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 17:21:37] iteration   117600/  500000 | consumed samples:       940800 | elapsed time per iteration (ms): 320.8 | learning rate: 1.096764E-04 | global batch size:     8 | lm loss: 3.417912E+00 | loss scale: 262144.0 | grad norm: 0.677 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 17:22:09] iteration   117700/  500000 | consumed samples:       941600 | elapsed time per iteration (ms): 320.7 | learning rate: 1.096135E-04 | global batch size:     8 | lm loss: 3.373940E+00 | loss scale: 524288.0 | grad norm: 0.656 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 17:22:41] iteration   117800/  500000 | consumed samples:       942400 | elapsed time per iteration (ms): 323.0 | learning rate: 1.095506E-04 | global batch size:     8 | lm loss: 3.379680E+00 | loss scale: 524288.0 | grad norm: 0.695 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 17:23:13] iteration   117900/  500000 | consumed samples:       943200 | elapsed time per iteration (ms): 323.4 | learning rate: 1.094876E-04 | global batch size:     8 | lm loss: 3.403123E+00 | loss scale: 524288.0 | grad norm: 0.661 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 17:23:45] iteration   118000/  500000 | consumed samples:       944000 | elapsed time per iteration (ms): 321.7 | learning rate: 1.094246E-04 | global batch size:     8 | lm loss: 3.396820E+00 | loss scale: 524288.0 | grad norm: 0.647 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1062.58, 1062.58)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 118000 | lm loss value: 3.774040E+00 | lm loss PPL: 4.355565E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-21 17:24:19] iteration   118100/  500000 | consumed samples:       944800 | elapsed time per iteration (ms): 322.3 | learning rate: 1.093623E-04 | global batch size:     8 | lm loss: 3.374001E+00 | loss scale: 524288.0 | grad norm: 0.669 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-21 17:24:51] iteration   118200/  500000 | consumed samples:       945600 | elapsed time per iteration (ms): 324.1 | learning rate: 1.092992E-04 | global batch size:     8 | lm loss: 3.363639E+00 | loss scale: 524288.0 | grad norm: 0.675 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 17:25:23] iteration   118300/  500000 | consumed samples:       946400 | elapsed time per iteration (ms): 321.1 | learning rate: 1.092362E-04 | global batch size:     8 | lm loss: 3.387942E+00 | loss scale: 524288.0 | grad norm: 0.656 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 17:25:56] iteration   118400/  500000 | consumed samples:       947200 | elapsed time per iteration (ms): 322.5 | learning rate: 1.091737E-04 | global batch size:     8 | lm loss: 3.421813E+00 | loss scale: 262144.0 | grad norm: 0.691 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-21 17:26:28] iteration   118500/  500000 | consumed samples:       948000 | elapsed time per iteration (ms): 322.8 | learning rate: 1.091106E-04 | global batch size:     8 | lm loss: 3.395670E+00 | loss scale: 262144.0 | grad norm: 0.656 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 17:27:00] iteration   118600/  500000 | consumed samples:       948800 | elapsed time per iteration (ms): 324.2 | learning rate: 1.090475E-04 | global batch size:     8 | lm loss: 3.399078E+00 | loss scale: 262144.0 | grad norm: 0.622 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 17:27:32] iteration   118700/  500000 | consumed samples:       949600 | elapsed time per iteration (ms): 321.0 | learning rate: 1.089843E-04 | global batch size:     8 | lm loss: 3.384875E+00 | loss scale: 262144.0 | grad norm: 0.745 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 17:28:04] iteration   118800/  500000 | consumed samples:       950400 | elapsed time per iteration (ms): 321.2 | learning rate: 1.089211E-04 | global batch size:     8 | lm loss: 3.415635E+00 | loss scale: 262144.0 | grad norm: 0.638 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 17:28:37] iteration   118900/  500000 | consumed samples:       951200 | elapsed time per iteration (ms): 323.3 | learning rate: 1.088579E-04 | global batch size:     8 | lm loss: 3.392709E+00 | loss scale: 262144.0 | grad norm: 0.652 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 17:29:09] iteration   119000/  500000 | consumed samples:       952000 | elapsed time per iteration (ms): 323.6 | learning rate: 1.087946E-04 | global batch size:     8 | lm loss: 3.398430E+00 | loss scale: 262144.0 | grad norm: 0.681 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1064.78, 1064.78)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 119000 | lm loss value: 3.689579E+00 | lm loss PPL: 4.002799E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-21 17:29:42] iteration   119100/  500000 | consumed samples:       952800 | elapsed time per iteration (ms): 322.5 | learning rate: 1.087313E-04 | global batch size:     8 | lm loss: 3.376429E+00 | loss scale: 262144.0 | grad norm: 0.681 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 17:30:15] iteration   119200/  500000 | consumed samples:       953600 | elapsed time per iteration (ms): 321.4 | learning rate: 1.086680E-04 | global batch size:     8 | lm loss: 3.347112E+00 | loss scale: 262144.0 | grad norm: 0.692 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 17:30:47] iteration   119300/  500000 | consumed samples:       954400 | elapsed time per iteration (ms): 321.1 | learning rate: 1.086047E-04 | global batch size:     8 | lm loss: 3.340718E+00 | loss scale: 262144.0 | grad norm: 0.643 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 17:31:19] iteration   119400/  500000 | consumed samples:       955200 | elapsed time per iteration (ms): 320.9 | learning rate: 1.085413E-04 | global batch size:     8 | lm loss: 3.408843E+00 | loss scale: 524288.0 | grad norm: 0.715 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 17:31:51] iteration   119500/  500000 | consumed samples:       956000 | elapsed time per iteration (ms): 323.1 | learning rate: 1.084779E-04 | global batch size:     8 | lm loss: 3.413468E+00 | loss scale: 524288.0 | grad norm: 0.620 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 17:32:23] iteration   119600/  500000 | consumed samples:       956800 | elapsed time per iteration (ms): 321.9 | learning rate: 1.084145E-04 | global batch size:     8 | lm loss: 3.378394E+00 | loss scale: 524288.0 | grad norm: 0.732 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 17:32:56] iteration   119700/  500000 | consumed samples:       957600 | elapsed time per iteration (ms): 322.7 | learning rate: 1.083510E-04 | global batch size:     8 | lm loss: 3.441554E+00 | loss scale: 524288.0 | grad norm: 0.680 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 17:33:28] iteration   119800/  500000 | consumed samples:       958400 | elapsed time per iteration (ms): 323.2 | learning rate: 1.082875E-04 | global batch size:     8 | lm loss: 3.396047E+00 | loss scale: 524288.0 | grad norm: 0.674 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 17:34:00] iteration   119900/  500000 | consumed samples:       959200 | elapsed time per iteration (ms): 322.2 | learning rate: 1.082240E-04 | global batch size:     8 | lm loss: 3.396848E+00 | loss scale: 524288.0 | grad norm: 0.681 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 17:34:32] iteration   120000/  500000 | consumed samples:       960000 | elapsed time per iteration (ms): 320.6 | learning rate: 1.081605E-04 | global batch size:     8 | lm loss: 3.406916E+00 | loss scale: 524288.0 | grad norm: 0.700 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1064.77, 1064.77)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 120000 | lm loss value: 3.671242E+00 | lm loss PPL: 3.930071E+01 | 
--------------------------------------------------------------------------------------------------
saving checkpoint at iteration  120000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-max in torch format
  successfully saved checkpoint at iteration  120000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-max
(min, max) time across ranks (ms):
    save-checkpoint ................................: (5742.51, 5742.51)
 [2024-06-21 17:35:11] iteration   120100/  500000 | consumed samples:       960800 | elapsed time per iteration (ms): 321.5 | learning rate: 1.080976E-04 | global batch size:     8 | lm loss: 3.399401E+00 | loss scale: 524288.0 | grad norm: 0.664 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-21 17:35:43] iteration   120200/  500000 | consumed samples:       961600 | elapsed time per iteration (ms): 323.3 | learning rate: 1.080346E-04 | global batch size:     8 | lm loss: 3.368688E+00 | loss scale: 262144.0 | grad norm: 0.685 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-21 17:36:16] iteration   120300/  500000 | consumed samples:       962400 | elapsed time per iteration (ms): 322.3 | learning rate: 1.079710E-04 | global batch size:     8 | lm loss: 3.401270E+00 | loss scale: 262144.0 | grad norm: 0.673 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 17:36:48] iteration   120400/  500000 | consumed samples:       963200 | elapsed time per iteration (ms): 324.8 | learning rate: 1.079073E-04 | global batch size:     8 | lm loss: 3.372915E+00 | loss scale: 262144.0 | grad norm: 0.712 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 17:37:20] iteration   120500/  500000 | consumed samples:       964000 | elapsed time per iteration (ms): 322.5 | learning rate: 1.078437E-04 | global batch size:     8 | lm loss: 3.404524E+00 | loss scale: 262144.0 | grad norm: 0.693 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 17:37:53] iteration   120600/  500000 | consumed samples:       964800 | elapsed time per iteration (ms): 321.8 | learning rate: 1.077800E-04 | global batch size:     8 | lm loss: 3.371344E+00 | loss scale: 262144.0 | grad norm: 0.664 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 17:38:25] iteration   120700/  500000 | consumed samples:       965600 | elapsed time per iteration (ms): 322.4 | learning rate: 1.077162E-04 | global batch size:     8 | lm loss: 3.385337E+00 | loss scale: 262144.0 | grad norm: 0.712 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 17:38:57] iteration   120800/  500000 | consumed samples:       966400 | elapsed time per iteration (ms): 321.2 | learning rate: 1.076525E-04 | global batch size:     8 | lm loss: 3.364326E+00 | loss scale: 262144.0 | grad norm: 0.687 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 17:39:29] iteration   120900/  500000 | consumed samples:       967200 | elapsed time per iteration (ms): 320.9 | learning rate: 1.075887E-04 | global batch size:     8 | lm loss: 3.352131E+00 | loss scale: 262144.0 | grad norm: 0.656 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 17:40:01] iteration   121000/  500000 | consumed samples:       968000 | elapsed time per iteration (ms): 320.4 | learning rate: 1.075249E-04 | global batch size:     8 | lm loss: 3.344201E+00 | loss scale: 262144.0 | grad norm: 0.698 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1063.71, 1063.71)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 121000 | lm loss value: 3.860550E+00 | lm loss PPL: 4.749148E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-21 17:40:34] iteration   121100/  500000 | consumed samples:       968800 | elapsed time per iteration (ms): 321.6 | learning rate: 1.074610E-04 | global batch size:     8 | lm loss: 3.399833E+00 | loss scale: 262144.0 | grad norm: 0.650 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 17:41:06] iteration   121200/  500000 | consumed samples:       969600 | elapsed time per iteration (ms): 321.6 | learning rate: 1.073972E-04 | global batch size:     8 | lm loss: 3.395193E+00 | loss scale: 524288.0 | grad norm: 0.681 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 17:41:39] iteration   121300/  500000 | consumed samples:       970400 | elapsed time per iteration (ms): 323.8 | learning rate: 1.073333E-04 | global batch size:     8 | lm loss: 3.393195E+00 | loss scale: 524288.0 | grad norm: 0.730 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 17:42:11] iteration   121400/  500000 | consumed samples:       971200 | elapsed time per iteration (ms): 323.7 | learning rate: 1.072694E-04 | global batch size:     8 | lm loss: 3.341840E+00 | loss scale: 524288.0 | grad norm: 0.680 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 17:42:43] iteration   121500/  500000 | consumed samples:       972000 | elapsed time per iteration (ms): 320.2 | learning rate: 1.072061E-04 | global batch size:     8 | lm loss: 3.392365E+00 | loss scale: 524288.0 | grad norm: 0.663 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-21 17:43:15] iteration   121600/  500000 | consumed samples:       972800 | elapsed time per iteration (ms): 322.1 | learning rate: 1.071421E-04 | global batch size:     8 | lm loss: 3.407466E+00 | loss scale: 524288.0 | grad norm: 0.671 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 17:43:48] iteration   121700/  500000 | consumed samples:       973600 | elapsed time per iteration (ms): 322.3 | learning rate: 1.070781E-04 | global batch size:     8 | lm loss: 3.359949E+00 | loss scale: 524288.0 | grad norm: 0.691 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 17:44:20] iteration   121800/  500000 | consumed samples:       974400 | elapsed time per iteration (ms): 320.8 | learning rate: 1.070141E-04 | global batch size:     8 | lm loss: 3.370607E+00 | loss scale: 524288.0 | grad norm: 0.697 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 17:44:52] iteration   121900/  500000 | consumed samples:       975200 | elapsed time per iteration (ms): 322.3 | learning rate: 1.069500E-04 | global batch size:     8 | lm loss: 3.383555E+00 | loss scale: 524288.0 | grad norm: 0.665 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 17:45:24] iteration   122000/  500000 | consumed samples:       976000 | elapsed time per iteration (ms): 321.5 | learning rate: 1.068866E-04 | global batch size:     8 | lm loss: 3.392002E+00 | loss scale: 262144.0 | grad norm: 0.700 | number of skipped iterations:   1 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1063.52, 1063.52)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 122000 | lm loss value: 3.625565E+00 | lm loss PPL: 3.754593E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-21 17:45:58] iteration   122100/  500000 | consumed samples:       976800 | elapsed time per iteration (ms): 323.5 | learning rate: 1.068225E-04 | global batch size:     8 | lm loss: 3.409531E+00 | loss scale: 262144.0 | grad norm: 0.690 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 17:46:30] iteration   122200/  500000 | consumed samples:       977600 | elapsed time per iteration (ms): 322.9 | learning rate: 1.067583E-04 | global batch size:     8 | lm loss: 3.387622E+00 | loss scale: 262144.0 | grad norm: 0.628 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 17:47:02] iteration   122300/  500000 | consumed samples:       978400 | elapsed time per iteration (ms): 323.3 | learning rate: 1.066942E-04 | global batch size:     8 | lm loss: 3.360233E+00 | loss scale: 262144.0 | grad norm: 0.703 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 17:47:34] iteration   122400/  500000 | consumed samples:       979200 | elapsed time per iteration (ms): 321.8 | learning rate: 1.066300E-04 | global batch size:     8 | lm loss: 3.385914E+00 | loss scale: 262144.0 | grad norm: 0.682 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 17:48:06] iteration   122500/  500000 | consumed samples:       980000 | elapsed time per iteration (ms): 321.2 | learning rate: 1.065658E-04 | global batch size:     8 | lm loss: 3.354391E+00 | loss scale: 262144.0 | grad norm: 0.655 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 17:48:39] iteration   122600/  500000 | consumed samples:       980800 | elapsed time per iteration (ms): 323.3 | learning rate: 1.065015E-04 | global batch size:     8 | lm loss: 3.351764E+00 | loss scale: 262144.0 | grad norm: 0.676 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 17:49:11] iteration   122700/  500000 | consumed samples:       981600 | elapsed time per iteration (ms): 322.8 | learning rate: 1.064373E-04 | global batch size:     8 | lm loss: 3.425665E+00 | loss scale: 262144.0 | grad norm: 0.691 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 17:49:43] iteration   122800/  500000 | consumed samples:       982400 | elapsed time per iteration (ms): 323.2 | learning rate: 1.063730E-04 | global batch size:     8 | lm loss: 3.391881E+00 | loss scale: 262144.0 | grad norm: 0.688 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 17:50:16] iteration   122900/  500000 | consumed samples:       983200 | elapsed time per iteration (ms): 321.3 | learning rate: 1.063087E-04 | global batch size:     8 | lm loss: 3.347364E+00 | loss scale: 262144.0 | grad norm: 0.671 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 17:50:48] iteration   123000/  500000 | consumed samples:       984000 | elapsed time per iteration (ms): 322.8 | learning rate: 1.062443E-04 | global batch size:     8 | lm loss: 3.421096E+00 | loss scale: 524288.0 | grad norm: 0.686 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1062.19, 1062.19)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 123000 | lm loss value: 3.885529E+00 | lm loss PPL: 4.869267E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-21 17:51:21] iteration   123100/  500000 | consumed samples:       984800 | elapsed time per iteration (ms): 322.0 | learning rate: 1.061800E-04 | global batch size:     8 | lm loss: 3.389821E+00 | loss scale: 524288.0 | grad norm: 0.682 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 17:51:53] iteration   123200/  500000 | consumed samples:       985600 | elapsed time per iteration (ms): 322.6 | learning rate: 1.061156E-04 | global batch size:     8 | lm loss: 3.358407E+00 | loss scale: 524288.0 | grad norm: 0.658 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 17:52:26] iteration   123300/  500000 | consumed samples:       986400 | elapsed time per iteration (ms): 321.5 | learning rate: 1.060512E-04 | global batch size:     8 | lm loss: 3.352675E+00 | loss scale: 524288.0 | grad norm: 0.651 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 17:52:58] iteration   123400/  500000 | consumed samples:       987200 | elapsed time per iteration (ms): 320.8 | learning rate: 1.059874E-04 | global batch size:     8 | lm loss: 3.378653E+00 | loss scale: 524288.0 | grad norm: 0.669 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-21 17:53:30] iteration   123500/  500000 | consumed samples:       988000 | elapsed time per iteration (ms): 320.4 | learning rate: 1.059229E-04 | global batch size:     8 | lm loss: 3.395906E+00 | loss scale: 524288.0 | grad norm: 0.689 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 17:54:02] iteration   123600/  500000 | consumed samples:       988800 | elapsed time per iteration (ms): 322.0 | learning rate: 1.058584E-04 | global batch size:     8 | lm loss: 3.388331E+00 | loss scale: 524288.0 | grad norm: 0.659 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 17:54:34] iteration   123700/  500000 | consumed samples:       989600 | elapsed time per iteration (ms): 323.2 | learning rate: 1.057939E-04 | global batch size:     8 | lm loss: 3.386996E+00 | loss scale: 524288.0 | grad norm: 0.721 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 17:55:06] iteration   123800/  500000 | consumed samples:       990400 | elapsed time per iteration (ms): 321.2 | learning rate: 1.057293E-04 | global batch size:     8 | lm loss: 3.404055E+00 | loss scale: 524288.0 | grad norm: 0.684 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 17:55:38] iteration   123900/  500000 | consumed samples:       991200 | elapsed time per iteration (ms): 321.1 | learning rate: 1.056648E-04 | global batch size:     8 | lm loss: 3.368320E+00 | loss scale: 524288.0 | grad norm: 0.654 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 17:56:11] iteration   124000/  500000 | consumed samples:       992000 | elapsed time per iteration (ms): 321.8 | learning rate: 1.056002E-04 | global batch size:     8 | lm loss: 3.389255E+00 | loss scale: 524288.0 | grad norm: 0.700 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1062.83, 1062.83)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 124000 | lm loss value: 3.860806E+00 | lm loss PPL: 4.750362E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-21 17:56:44] iteration   124100/  500000 | consumed samples:       992800 | elapsed time per iteration (ms): 322.4 | learning rate: 1.055356E-04 | global batch size:     8 | lm loss: 3.381701E+00 | loss scale: 524288.0 | grad norm: 0.694 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 17:57:16] iteration   124200/  500000 | consumed samples:       993600 | elapsed time per iteration (ms): 322.6 | learning rate: 1.054709E-04 | global batch size:     8 | lm loss: 3.330454E+00 | loss scale: 524288.0 | grad norm: 0.682 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 17:57:49] iteration   124300/  500000 | consumed samples:       994400 | elapsed time per iteration (ms): 324.2 | learning rate: 1.054062E-04 | global batch size:     8 | lm loss: 3.376758E+00 | loss scale: 524288.0 | grad norm: 0.676 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 17:58:21] iteration   124400/  500000 | consumed samples:       995200 | elapsed time per iteration (ms): 320.2 | learning rate: 1.053428E-04 | global batch size:     8 | lm loss: 3.336200E+00 | loss scale: 524288.0 | grad norm: 0.676 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-21 17:58:53] iteration   124500/  500000 | consumed samples:       996000 | elapsed time per iteration (ms): 321.4 | learning rate: 1.052781E-04 | global batch size:     8 | lm loss: 3.358790E+00 | loss scale: 524288.0 | grad norm: 0.659 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 17:59:25] iteration   124600/  500000 | consumed samples:       996800 | elapsed time per iteration (ms): 323.4 | learning rate: 1.052140E-04 | global batch size:     8 | lm loss: 3.403486E+00 | loss scale: 262144.0 | grad norm: 0.721 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-21 17:59:57] iteration   124700/  500000 | consumed samples:       997600 | elapsed time per iteration (ms): 322.4 | learning rate: 1.051493E-04 | global batch size:     8 | lm loss: 3.400190E+00 | loss scale: 262144.0 | grad norm: 0.673 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 18:00:30] iteration   124800/  500000 | consumed samples:       998400 | elapsed time per iteration (ms): 322.8 | learning rate: 1.050845E-04 | global batch size:     8 | lm loss: 3.345143E+00 | loss scale: 262144.0 | grad norm: 0.800 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 18:01:02] iteration   124900/  500000 | consumed samples:       999200 | elapsed time per iteration (ms): 323.9 | learning rate: 1.050196E-04 | global batch size:     8 | lm loss: 3.392173E+00 | loss scale: 262144.0 | grad norm: 0.699 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 18:01:34] iteration   125000/  500000 | consumed samples:      1000000 | elapsed time per iteration (ms): 322.3 | learning rate: 1.049548E-04 | global batch size:     8 | lm loss: 3.352125E+00 | loss scale: 262144.0 | grad norm: 0.655 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1063.27, 1063.27)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 125000 | lm loss value: 3.831590E+00 | lm loss PPL: 4.613586E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-21 18:02:07] iteration   125100/  500000 | consumed samples:      1000800 | elapsed time per iteration (ms): 319.2 | learning rate: 1.048899E-04 | global batch size:     8 | lm loss: 3.354464E+00 | loss scale: 262144.0 | grad norm: 0.686 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 18:02:39] iteration   125200/  500000 | consumed samples:      1001600 | elapsed time per iteration (ms): 322.1 | learning rate: 1.048250E-04 | global batch size:     8 | lm loss: 3.359915E+00 | loss scale: 262144.0 | grad norm: 0.679 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 18:03:11] iteration   125300/  500000 | consumed samples:      1002400 | elapsed time per iteration (ms): 319.6 | learning rate: 1.047601E-04 | global batch size:     8 | lm loss: 3.376189E+00 | loss scale: 262144.0 | grad norm: 0.679 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 18:03:44] iteration   125400/  500000 | consumed samples:      1003200 | elapsed time per iteration (ms): 321.6 | learning rate: 1.046952E-04 | global batch size:     8 | lm loss: 3.375301E+00 | loss scale: 262144.0 | grad norm: 0.729 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 18:04:16] iteration   125500/  500000 | consumed samples:      1004000 | elapsed time per iteration (ms): 320.5 | learning rate: 1.046302E-04 | global batch size:     8 | lm loss: 3.390795E+00 | loss scale: 262144.0 | grad norm: 0.720 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 18:04:48] iteration   125600/  500000 | consumed samples:      1004800 | elapsed time per iteration (ms): 321.5 | learning rate: 1.045652E-04 | global batch size:     8 | lm loss: 3.330796E+00 | loss scale: 524288.0 | grad norm: 0.659 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 18:05:20] iteration   125700/  500000 | consumed samples:      1005600 | elapsed time per iteration (ms): 321.0 | learning rate: 1.045009E-04 | global batch size:     8 | lm loss: 3.373271E+00 | loss scale: 524288.0 | grad norm: 0.706 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-21 18:05:52] iteration   125800/  500000 | consumed samples:      1006400 | elapsed time per iteration (ms): 323.1 | learning rate: 1.044358E-04 | global batch size:     8 | lm loss: 3.328832E+00 | loss scale: 524288.0 | grad norm: 0.692 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 18:06:24] iteration   125900/  500000 | consumed samples:      1007200 | elapsed time per iteration (ms): 321.4 | learning rate: 1.043708E-04 | global batch size:     8 | lm loss: 3.338090E+00 | loss scale: 524288.0 | grad norm: 0.682 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 18:06:56] iteration   126000/  500000 | consumed samples:      1008000 | elapsed time per iteration (ms): 321.5 | learning rate: 1.043057E-04 | global batch size:     8 | lm loss: 3.395563E+00 | loss scale: 524288.0 | grad norm: 0.705 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1064.31, 1064.31)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 126000 | lm loss value: 3.725008E+00 | lm loss PPL: 4.147158E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-21 18:07:30] iteration   126100/  500000 | consumed samples:      1008800 | elapsed time per iteration (ms): 321.2 | learning rate: 1.042412E-04 | global batch size:     8 | lm loss: 3.347288E+00 | loss scale: 262144.0 | grad norm: 0.685 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-21 18:08:02] iteration   126200/  500000 | consumed samples:      1009600 | elapsed time per iteration (ms): 321.9 | learning rate: 1.041761E-04 | global batch size:     8 | lm loss: 3.401953E+00 | loss scale: 262144.0 | grad norm: 0.701 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 18:08:34] iteration   126300/  500000 | consumed samples:      1010400 | elapsed time per iteration (ms): 322.8 | learning rate: 1.041109E-04 | global batch size:     8 | lm loss: 3.366180E+00 | loss scale: 262144.0 | grad norm: 0.665 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 18:09:06] iteration   126400/  500000 | consumed samples:      1011200 | elapsed time per iteration (ms): 322.3 | learning rate: 1.040457E-04 | global batch size:     8 | lm loss: 3.382896E+00 | loss scale: 262144.0 | grad norm: 0.695 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 18:09:38] iteration   126500/  500000 | consumed samples:      1012000 | elapsed time per iteration (ms): 319.8 | learning rate: 1.039805E-04 | global batch size:     8 | lm loss: 3.352225E+00 | loss scale: 262144.0 | grad norm: 0.725 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 18:10:10] iteration   126600/  500000 | consumed samples:      1012800 | elapsed time per iteration (ms): 321.7 | learning rate: 1.039153E-04 | global batch size:     8 | lm loss: 3.331841E+00 | loss scale: 262144.0 | grad norm: 0.698 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 18:10:42] iteration   126700/  500000 | consumed samples:      1013600 | elapsed time per iteration (ms): 320.0 | learning rate: 1.038501E-04 | global batch size:     8 | lm loss: 3.349119E+00 | loss scale: 262144.0 | grad norm: 0.702 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 18:11:15] iteration   126800/  500000 | consumed samples:      1014400 | elapsed time per iteration (ms): 323.2 | learning rate: 1.037848E-04 | global batch size:     8 | lm loss: 3.367512E+00 | loss scale: 262144.0 | grad norm: 0.665 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 18:11:47] iteration   126900/  500000 | consumed samples:      1015200 | elapsed time per iteration (ms): 324.4 | learning rate: 1.037195E-04 | global batch size:     8 | lm loss: 3.343735E+00 | loss scale: 262144.0 | grad norm: 0.784 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 18:12:19] iteration   127000/  500000 | consumed samples:      1016000 | elapsed time per iteration (ms): 322.4 | learning rate: 1.036542E-04 | global batch size:     8 | lm loss: 3.338671E+00 | loss scale: 262144.0 | grad norm: 0.672 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1067.09, 1067.09)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 127000 | lm loss value: 3.643681E+00 | lm loss PPL: 3.823229E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-21 18:12:53] iteration   127100/  500000 | consumed samples:      1016800 | elapsed time per iteration (ms): 323.7 | learning rate: 1.035888E-04 | global batch size:     8 | lm loss: 3.375254E+00 | loss scale: 524288.0 | grad norm: 0.671 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 18:13:25] iteration   127200/  500000 | consumed samples:      1017600 | elapsed time per iteration (ms): 322.9 | learning rate: 1.035235E-04 | global batch size:     8 | lm loss: 3.353248E+00 | loss scale: 524288.0 | grad norm: 0.697 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 18:13:57] iteration   127300/  500000 | consumed samples:      1018400 | elapsed time per iteration (ms): 320.3 | learning rate: 1.034581E-04 | global batch size:     8 | lm loss: 3.319229E+00 | loss scale: 524288.0 | grad norm: 0.668 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 18:14:29] iteration   127400/  500000 | consumed samples:      1019200 | elapsed time per iteration (ms): 321.4 | learning rate: 1.033927E-04 | global batch size:     8 | lm loss: 3.353755E+00 | loss scale: 524288.0 | grad norm: 0.692 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 18:15:02] iteration   127500/  500000 | consumed samples:      1020000 | elapsed time per iteration (ms): 321.8 | learning rate: 1.033279E-04 | global batch size:     8 | lm loss: 3.323385E+00 | loss scale: 524288.0 | grad norm: 0.646 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-21 18:15:34] iteration   127600/  500000 | consumed samples:      1020800 | elapsed time per iteration (ms): 321.2 | learning rate: 1.032624E-04 | global batch size:     8 | lm loss: 3.380047E+00 | loss scale: 524288.0 | grad norm: 0.651 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 18:16:06] iteration   127700/  500000 | consumed samples:      1021600 | elapsed time per iteration (ms): 321.4 | learning rate: 1.031976E-04 | global batch size:     8 | lm loss: 3.304974E+00 | loss scale: 262144.0 | grad norm: 0.696 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-21 18:16:38] iteration   127800/  500000 | consumed samples:      1022400 | elapsed time per iteration (ms): 323.2 | learning rate: 1.031321E-04 | global batch size:     8 | lm loss: 3.323442E+00 | loss scale: 262144.0 | grad norm: 0.725 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 18:17:10] iteration   127900/  500000 | consumed samples:      1023200 | elapsed time per iteration (ms): 322.6 | learning rate: 1.030665E-04 | global batch size:     8 | lm loss: 3.344038E+00 | loss scale: 262144.0 | grad norm: 0.670 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 18:17:42] iteration   128000/  500000 | consumed samples:      1024000 | elapsed time per iteration (ms): 319.1 | learning rate: 1.030010E-04 | global batch size:     8 | lm loss: 3.368911E+00 | loss scale: 262144.0 | grad norm: 0.667 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1068.99, 1068.99)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 128000 | lm loss value: 3.707034E+00 | lm loss PPL: 4.073280E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-21 18:18:15] iteration   128100/  500000 | consumed samples:      1024800 | elapsed time per iteration (ms): 320.8 | learning rate: 1.029361E-04 | global batch size:     8 | lm loss: 3.361222E+00 | loss scale: 131072.0 | grad norm: 0.733 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-21 18:18:48] iteration   128200/  500000 | consumed samples:      1025600 | elapsed time per iteration (ms): 322.9 | learning rate: 1.028705E-04 | global batch size:     8 | lm loss: 3.343945E+00 | loss scale: 131072.0 | grad norm: 0.659 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 18:19:20] iteration   128300/  500000 | consumed samples:      1026400 | elapsed time per iteration (ms): 319.6 | learning rate: 1.028049E-04 | global batch size:     8 | lm loss: 3.364278E+00 | loss scale: 131072.0 | grad norm: 0.669 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 18:19:52] iteration   128400/  500000 | consumed samples:      1027200 | elapsed time per iteration (ms): 321.5 | learning rate: 1.027392E-04 | global batch size:     8 | lm loss: 3.339334E+00 | loss scale: 131072.0 | grad norm: 0.771 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 18:20:24] iteration   128500/  500000 | consumed samples:      1028000 | elapsed time per iteration (ms): 320.2 | learning rate: 1.026736E-04 | global batch size:     8 | lm loss: 3.320449E+00 | loss scale: 131072.0 | grad norm: 0.664 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 18:20:56] iteration   128600/  500000 | consumed samples:      1028800 | elapsed time per iteration (ms): 320.6 | learning rate: 1.026079E-04 | global batch size:     8 | lm loss: 3.317064E+00 | loss scale: 131072.0 | grad norm: 0.694 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 18:21:28] iteration   128700/  500000 | consumed samples:      1029600 | elapsed time per iteration (ms): 320.9 | learning rate: 1.025422E-04 | global batch size:     8 | lm loss: 3.354553E+00 | loss scale: 131072.0 | grad norm: 0.685 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 18:22:00] iteration   128800/  500000 | consumed samples:      1030400 | elapsed time per iteration (ms): 321.9 | learning rate: 1.024764E-04 | global batch size:     8 | lm loss: 3.357579E+00 | loss scale: 131072.0 | grad norm: 0.679 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 18:22:32] iteration   128900/  500000 | consumed samples:      1031200 | elapsed time per iteration (ms): 320.4 | learning rate: 1.024107E-04 | global batch size:     8 | lm loss: 3.340556E+00 | loss scale: 131072.0 | grad norm: 0.689 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 18:23:05] iteration   129000/  500000 | consumed samples:      1032000 | elapsed time per iteration (ms): 323.8 | learning rate: 1.023449E-04 | global batch size:     8 | lm loss: 3.387007E+00 | loss scale: 131072.0 | grad norm: 0.721 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1063.52, 1063.52)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 129000 | lm loss value: 3.729601E+00 | lm loss PPL: 4.166250E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-21 18:23:38] iteration   129100/  500000 | consumed samples:      1032800 | elapsed time per iteration (ms): 319.8 | learning rate: 1.022791E-04 | global batch size:     8 | lm loss: 3.351493E+00 | loss scale: 262144.0 | grad norm: 0.675 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 18:24:10] iteration   129200/  500000 | consumed samples:      1033600 | elapsed time per iteration (ms): 319.6 | learning rate: 1.022133E-04 | global batch size:     8 | lm loss: 3.332291E+00 | loss scale: 262144.0 | grad norm: 0.723 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 18:24:42] iteration   129300/  500000 | consumed samples:      1034400 | elapsed time per iteration (ms): 322.0 | learning rate: 1.021475E-04 | global batch size:     8 | lm loss: 3.346674E+00 | loss scale: 262144.0 | grad norm: 0.689 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 18:25:14] iteration   129400/  500000 | consumed samples:      1035200 | elapsed time per iteration (ms): 321.5 | learning rate: 1.020816E-04 | global batch size:     8 | lm loss: 3.350852E+00 | loss scale: 262144.0 | grad norm: 0.649 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 18:25:46] iteration   129500/  500000 | consumed samples:      1036000 | elapsed time per iteration (ms): 325.1 | learning rate: 1.020157E-04 | global batch size:     8 | lm loss: 3.351810E+00 | loss scale: 262144.0 | grad norm: 0.693 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 18:26:18] iteration   129600/  500000 | consumed samples:      1036800 | elapsed time per iteration (ms): 320.3 | learning rate: 1.019498E-04 | global batch size:     8 | lm loss: 3.344031E+00 | loss scale: 262144.0 | grad norm: 0.716 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 18:26:51] iteration   129700/  500000 | consumed samples:      1037600 | elapsed time per iteration (ms): 322.1 | learning rate: 1.018839E-04 | global batch size:     8 | lm loss: 3.389999E+00 | loss scale: 262144.0 | grad norm: 0.663 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 18:27:23] iteration   129800/  500000 | consumed samples:      1038400 | elapsed time per iteration (ms): 323.1 | learning rate: 1.018179E-04 | global batch size:     8 | lm loss: 3.357596E+00 | loss scale: 262144.0 | grad norm: 0.669 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 18:27:55] iteration   129900/  500000 | consumed samples:      1039200 | elapsed time per iteration (ms): 322.8 | learning rate: 1.017520E-04 | global batch size:     8 | lm loss: 3.350532E+00 | loss scale: 262144.0 | grad norm: 0.686 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 18:28:28] iteration   130000/  500000 | consumed samples:      1040000 | elapsed time per iteration (ms): 322.4 | learning rate: 1.016860E-04 | global batch size:     8 | lm loss: 3.348072E+00 | loss scale: 262144.0 | grad norm: 0.692 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1064.48, 1064.48)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 130000 | lm loss value: 3.753080E+00 | lm loss PPL: 4.265226E+01 | 
--------------------------------------------------------------------------------------------------
saving checkpoint at iteration  130000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-max in torch format
  successfully saved checkpoint at iteration  130000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-max
(min, max) time across ranks (ms):
    save-checkpoint ................................: (5647.79, 5647.79)
 [2024-06-21 18:29:06] iteration   130100/  500000 | consumed samples:      1040800 | elapsed time per iteration (ms): 318.9 | learning rate: 1.016200E-04 | global batch size:     8 | lm loss: 3.367125E+00 | loss scale: 524288.0 | grad norm: 0.666 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 18:29:38] iteration   130200/  500000 | consumed samples:      1041600 | elapsed time per iteration (ms): 320.8 | learning rate: 1.015539E-04 | global batch size:     8 | lm loss: 3.352203E+00 | loss scale: 524288.0 | grad norm: 0.685 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 18:30:10] iteration   130300/  500000 | consumed samples:      1042400 | elapsed time per iteration (ms): 321.6 | learning rate: 1.014885E-04 | global batch size:     8 | lm loss: 3.366111E+00 | loss scale: 524288.0 | grad norm: 0.663 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-21 18:30:43] iteration   130400/  500000 | consumed samples:      1043200 | elapsed time per iteration (ms): 324.2 | learning rate: 1.014225E-04 | global batch size:     8 | lm loss: 3.302106E+00 | loss scale: 524288.0 | grad norm: 0.686 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 18:31:15] iteration   130500/  500000 | consumed samples:      1044000 | elapsed time per iteration (ms): 321.2 | learning rate: 1.013564E-04 | global batch size:     8 | lm loss: 3.326197E+00 | loss scale: 524288.0 | grad norm: 0.711 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 18:31:47] iteration   130600/  500000 | consumed samples:      1044800 | elapsed time per iteration (ms): 321.4 | learning rate: 1.012902E-04 | global batch size:     8 | lm loss: 3.310960E+00 | loss scale: 524288.0 | grad norm: 0.682 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 18:32:19] iteration   130700/  500000 | consumed samples:      1045600 | elapsed time per iteration (ms): 320.7 | learning rate: 1.012241E-04 | global batch size:     8 | lm loss: 3.355570E+00 | loss scale: 524288.0 | grad norm: 0.676 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 18:32:51] iteration   130800/  500000 | consumed samples:      1046400 | elapsed time per iteration (ms): 322.1 | learning rate: 1.011580E-04 | global batch size:     8 | lm loss: 3.312924E+00 | loss scale: 524288.0 | grad norm: 0.669 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 18:33:24] iteration   130900/  500000 | consumed samples:      1047200 | elapsed time per iteration (ms): 321.8 | learning rate: 1.010918E-04 | global batch size:     8 | lm loss: 3.347437E+00 | loss scale: 524288.0 | grad norm: 0.719 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 18:33:56] iteration   131000/  500000 | consumed samples:      1048000 | elapsed time per iteration (ms): 322.7 | learning rate: 1.010256E-04 | global batch size:     8 | lm loss: 3.391736E+00 | loss scale: 524288.0 | grad norm: 0.717 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1065.55, 1065.55)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 131000 | lm loss value: 3.665199E+00 | lm loss PPL: 3.906389E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-21 18:34:29] iteration   131100/  500000 | consumed samples:      1048800 | elapsed time per iteration (ms): 322.2 | learning rate: 1.009593E-04 | global batch size:     8 | lm loss: 3.366646E+00 | loss scale: 524288.0 | grad norm: 0.688 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 18:35:01] iteration   131200/  500000 | consumed samples:      1049600 | elapsed time per iteration (ms): 322.2 | learning rate: 1.008931E-04 | global batch size:     8 | lm loss: 3.331721E+00 | loss scale: 524288.0 | grad norm: 0.683 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 18:35:33] iteration   131300/  500000 | consumed samples:      1050400 | elapsed time per iteration (ms): 321.2 | learning rate: 1.008275E-04 | global batch size:     8 | lm loss: 3.356754E+00 | loss scale: 1048576.0 | grad norm: 0.664 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-21 18:36:05] iteration   131400/  500000 | consumed samples:      1051200 | elapsed time per iteration (ms): 319.5 | learning rate: 1.007626E-04 | global batch size:     8 | lm loss: 3.399817E+00 | loss scale: 262144.0 | grad norm: 0.688 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-21 18:36:38] iteration   131500/  500000 | consumed samples:      1052000 | elapsed time per iteration (ms): 322.4 | learning rate: 1.006962E-04 | global batch size:     8 | lm loss: 3.384672E+00 | loss scale: 262144.0 | grad norm: 0.666 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 18:37:10] iteration   131600/  500000 | consumed samples:      1052800 | elapsed time per iteration (ms): 324.0 | learning rate: 1.006299E-04 | global batch size:     8 | lm loss: 3.383724E+00 | loss scale: 262144.0 | grad norm: 0.700 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 18:37:42] iteration   131700/  500000 | consumed samples:      1053600 | elapsed time per iteration (ms): 320.7 | learning rate: 1.005636E-04 | global batch size:     8 | lm loss: 3.382741E+00 | loss scale: 262144.0 | grad norm: 0.674 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 18:38:14] iteration   131800/  500000 | consumed samples:      1054400 | elapsed time per iteration (ms): 321.0 | learning rate: 1.004979E-04 | global batch size:     8 | lm loss: 3.382597E+00 | loss scale: 131072.0 | grad norm: 0.686 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-21 18:38:47] iteration   131900/  500000 | consumed samples:      1055200 | elapsed time per iteration (ms): 323.4 | learning rate: 1.004315E-04 | global batch size:     8 | lm loss: 3.338788E+00 | loss scale: 131072.0 | grad norm: 0.685 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 18:39:19] iteration   132000/  500000 | consumed samples:      1056000 | elapsed time per iteration (ms): 321.2 | learning rate: 1.003664E-04 | global batch size:     8 | lm loss: 3.303026E+00 | loss scale: 32768.0 | grad norm: 0.713 | number of skipped iterations:   2 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1065.72, 1065.72)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 132000 | lm loss value: 3.632464E+00 | lm loss PPL: 3.780585E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-21 18:39:52] iteration   132100/  500000 | consumed samples:      1056800 | elapsed time per iteration (ms): 320.7 | learning rate: 1.003000E-04 | global batch size:     8 | lm loss: 3.298657E+00 | loss scale: 32768.0 | grad norm: 0.673 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 18:40:24] iteration   132200/  500000 | consumed samples:      1057600 | elapsed time per iteration (ms): 322.2 | learning rate: 1.002336E-04 | global batch size:     8 | lm loss: 3.353375E+00 | loss scale: 32768.0 | grad norm: 0.705 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 18:40:56] iteration   132300/  500000 | consumed samples:      1058400 | elapsed time per iteration (ms): 322.9 | learning rate: 1.001671E-04 | global batch size:     8 | lm loss: 3.299934E+00 | loss scale: 32768.0 | grad norm: 0.763 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 18:41:29] iteration   132400/  500000 | consumed samples:      1059200 | elapsed time per iteration (ms): 324.1 | learning rate: 1.001006E-04 | global batch size:     8 | lm loss: 3.356604E+00 | loss scale: 32768.0 | grad norm: 0.663 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 18:42:01] iteration   132500/  500000 | consumed samples:      1060000 | elapsed time per iteration (ms): 321.7 | learning rate: 1.000341E-04 | global batch size:     8 | lm loss: 3.335842E+00 | loss scale: 32768.0 | grad norm: 0.662 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 18:42:33] iteration   132600/  500000 | consumed samples:      1060800 | elapsed time per iteration (ms): 325.4 | learning rate: 9.996758E-05 | global batch size:     8 | lm loss: 3.316278E+00 | loss scale: 32768.0 | grad norm: 0.682 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 18:43:06] iteration   132700/  500000 | consumed samples:      1061600 | elapsed time per iteration (ms): 321.1 | learning rate: 9.990104E-05 | global batch size:     8 | lm loss: 3.341449E+00 | loss scale: 32768.0 | grad norm: 0.607 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 18:43:38] iteration   132800/  500000 | consumed samples:      1062400 | elapsed time per iteration (ms): 323.5 | learning rate: 9.983448E-05 | global batch size:     8 | lm loss: 3.356661E+00 | loss scale: 32768.0 | grad norm: 0.668 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 18:44:10] iteration   132900/  500000 | consumed samples:      1063200 | elapsed time per iteration (ms): 323.3 | learning rate: 9.976790E-05 | global batch size:     8 | lm loss: 3.317706E+00 | loss scale: 32768.0 | grad norm: 0.716 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 18:44:43] iteration   133000/  500000 | consumed samples:      1064000 | elapsed time per iteration (ms): 324.0 | learning rate: 9.970130E-05 | global batch size:     8 | lm loss: 3.321627E+00 | loss scale: 65536.0 | grad norm: 0.675 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1067.69, 1067.69)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 133000 | lm loss value: 3.667314E+00 | lm loss PPL: 3.914663E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-21 18:45:16] iteration   133100/  500000 | consumed samples:      1064800 | elapsed time per iteration (ms): 321.9 | learning rate: 9.963468E-05 | global batch size:     8 | lm loss: 3.354601E+00 | loss scale: 65536.0 | grad norm: 0.718 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 18:45:48] iteration   133200/  500000 | consumed samples:      1065600 | elapsed time per iteration (ms): 324.7 | learning rate: 9.956804E-05 | global batch size:     8 | lm loss: 3.334081E+00 | loss scale: 65536.0 | grad norm: 0.753 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 18:46:20] iteration   133300/  500000 | consumed samples:      1066400 | elapsed time per iteration (ms): 321.0 | learning rate: 9.950138E-05 | global batch size:     8 | lm loss: 3.342936E+00 | loss scale: 65536.0 | grad norm: 0.673 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 18:46:53] iteration   133400/  500000 | consumed samples:      1067200 | elapsed time per iteration (ms): 323.7 | learning rate: 9.943470E-05 | global batch size:     8 | lm loss: 3.372529E+00 | loss scale: 65536.0 | grad norm: 0.674 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 18:47:25] iteration   133500/  500000 | consumed samples:      1068000 | elapsed time per iteration (ms): 322.0 | learning rate: 9.936800E-05 | global batch size:     8 | lm loss: 3.364820E+00 | loss scale: 65536.0 | grad norm: 0.688 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 18:47:57] iteration   133600/  500000 | consumed samples:      1068800 | elapsed time per iteration (ms): 320.7 | learning rate: 9.930129E-05 | global batch size:     8 | lm loss: 3.352191E+00 | loss scale: 65536.0 | grad norm: 0.693 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 18:48:29] iteration   133700/  500000 | consumed samples:      1069600 | elapsed time per iteration (ms): 321.9 | learning rate: 9.923455E-05 | global batch size:     8 | lm loss: 3.363312E+00 | loss scale: 65536.0 | grad norm: 0.708 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 18:49:02] iteration   133800/  500000 | consumed samples:      1070400 | elapsed time per iteration (ms): 322.9 | learning rate: 9.916780E-05 | global batch size:     8 | lm loss: 3.346475E+00 | loss scale: 65536.0 | grad norm: 0.715 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 18:49:34] iteration   133900/  500000 | consumed samples:      1071200 | elapsed time per iteration (ms): 321.4 | learning rate: 9.910169E-05 | global batch size:     8 | lm loss: 3.339945E+00 | loss scale: 65536.0 | grad norm: 0.707 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-21 18:50:06] iteration   134000/  500000 | consumed samples:      1072000 | elapsed time per iteration (ms): 322.1 | learning rate: 9.903490E-05 | global batch size:     8 | lm loss: 3.348318E+00 | loss scale: 65536.0 | grad norm: 0.680 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1067.25, 1067.25)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 134000 | lm loss value: 3.736826E+00 | lm loss PPL: 4.196460E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-21 18:50:39] iteration   134100/  500000 | consumed samples:      1072800 | elapsed time per iteration (ms): 322.7 | learning rate: 9.896809E-05 | global batch size:     8 | lm loss: 3.384559E+00 | loss scale: 65536.0 | grad norm: 0.651 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 18:51:11] iteration   134200/  500000 | consumed samples:      1073600 | elapsed time per iteration (ms): 322.5 | learning rate: 9.890126E-05 | global batch size:     8 | lm loss: 3.361599E+00 | loss scale: 65536.0 | grad norm: 0.682 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 18:51:44] iteration   134300/  500000 | consumed samples:      1074400 | elapsed time per iteration (ms): 322.3 | learning rate: 9.883442E-05 | global batch size:     8 | lm loss: 3.331606E+00 | loss scale: 65536.0 | grad norm: 0.723 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 18:52:16] iteration   134400/  500000 | consumed samples:      1075200 | elapsed time per iteration (ms): 322.1 | learning rate: 9.876755E-05 | global batch size:     8 | lm loss: 3.319554E+00 | loss scale: 65536.0 | grad norm: 0.648 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 18:52:48] iteration   134500/  500000 | consumed samples:      1076000 | elapsed time per iteration (ms): 324.4 | learning rate: 9.870067E-05 | global batch size:     8 | lm loss: 3.401411E+00 | loss scale: 65536.0 | grad norm: 0.694 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 18:53:20] iteration   134600/  500000 | consumed samples:      1076800 | elapsed time per iteration (ms): 320.6 | learning rate: 9.863376E-05 | global batch size:     8 | lm loss: 3.345685E+00 | loss scale: 65536.0 | grad norm: 0.701 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 18:53:52] iteration   134700/  500000 | consumed samples:      1077600 | elapsed time per iteration (ms): 319.5 | learning rate: 9.856684E-05 | global batch size:     8 | lm loss: 3.382729E+00 | loss scale: 65536.0 | grad norm: 0.726 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 18:54:25] iteration   134800/  500000 | consumed samples:      1078400 | elapsed time per iteration (ms): 321.4 | learning rate: 9.849990E-05 | global batch size:     8 | lm loss: 3.346689E+00 | loss scale: 65536.0 | grad norm: 0.686 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 18:54:57] iteration   134900/  500000 | consumed samples:      1079200 | elapsed time per iteration (ms): 323.3 | learning rate: 9.843295E-05 | global batch size:     8 | lm loss: 3.327019E+00 | loss scale: 131072.0 | grad norm: 0.668 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 18:55:29] iteration   135000/  500000 | consumed samples:      1080000 | elapsed time per iteration (ms): 323.3 | learning rate: 9.836597E-05 | global batch size:     8 | lm loss: 3.331368E+00 | loss scale: 131072.0 | grad norm: 0.720 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1065.31, 1065.31)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 135000 | lm loss value: 3.750701E+00 | lm loss PPL: 4.255091E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-21 18:56:03] iteration   135100/  500000 | consumed samples:      1080800 | elapsed time per iteration (ms): 323.9 | learning rate: 9.829898E-05 | global batch size:     8 | lm loss: 3.303466E+00 | loss scale: 131072.0 | grad norm: 0.666 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 18:56:35] iteration   135200/  500000 | consumed samples:      1081600 | elapsed time per iteration (ms): 322.4 | learning rate: 9.823196E-05 | global batch size:     8 | lm loss: 3.340661E+00 | loss scale: 131072.0 | grad norm: 0.664 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 18:57:07] iteration   135300/  500000 | consumed samples:      1082400 | elapsed time per iteration (ms): 321.5 | learning rate: 9.816494E-05 | global batch size:     8 | lm loss: 3.346770E+00 | loss scale: 131072.0 | grad norm: 0.722 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 18:57:39] iteration   135400/  500000 | consumed samples:      1083200 | elapsed time per iteration (ms): 321.4 | learning rate: 9.809789E-05 | global batch size:     8 | lm loss: 3.329575E+00 | loss scale: 131072.0 | grad norm: 0.673 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 18:58:11] iteration   135500/  500000 | consumed samples:      1084000 | elapsed time per iteration (ms): 321.1 | learning rate: 9.803082E-05 | global batch size:     8 | lm loss: 3.358750E+00 | loss scale: 131072.0 | grad norm: 0.739 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 18:58:43] iteration   135600/  500000 | consumed samples:      1084800 | elapsed time per iteration (ms): 321.6 | learning rate: 9.796374E-05 | global batch size:     8 | lm loss: 3.311576E+00 | loss scale: 131072.0 | grad norm: 0.662 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 18:59:16] iteration   135700/  500000 | consumed samples:      1085600 | elapsed time per iteration (ms): 321.1 | learning rate: 9.789664E-05 | global batch size:     8 | lm loss: 3.368384E+00 | loss scale: 131072.0 | grad norm: 0.722 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 18:59:48] iteration   135800/  500000 | consumed samples:      1086400 | elapsed time per iteration (ms): 323.7 | learning rate: 9.782952E-05 | global batch size:     8 | lm loss: 3.340224E+00 | loss scale: 131072.0 | grad norm: 0.719 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 19:00:20] iteration   135900/  500000 | consumed samples:      1087200 | elapsed time per iteration (ms): 321.0 | learning rate: 9.776238E-05 | global batch size:     8 | lm loss: 3.331897E+00 | loss scale: 262144.0 | grad norm: 0.664 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 19:00:52] iteration   136000/  500000 | consumed samples:      1088000 | elapsed time per iteration (ms): 320.7 | learning rate: 9.769523E-05 | global batch size:     8 | lm loss: 3.362748E+00 | loss scale: 262144.0 | grad norm: 0.734 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1065.64, 1065.64)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 136000 | lm loss value: 3.566854E+00 | lm loss PPL: 3.540505E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-21 19:01:25] iteration   136100/  500000 | consumed samples:      1088800 | elapsed time per iteration (ms): 321.8 | learning rate: 9.762806E-05 | global batch size:     8 | lm loss: 3.345949E+00 | loss scale: 262144.0 | grad norm: 0.723 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 19:01:58] iteration   136200/  500000 | consumed samples:      1089600 | elapsed time per iteration (ms): 322.5 | learning rate: 9.756087E-05 | global batch size:     8 | lm loss: 3.316884E+00 | loss scale: 262144.0 | grad norm: 0.696 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 19:02:30] iteration   136300/  500000 | consumed samples:      1090400 | elapsed time per iteration (ms): 321.2 | learning rate: 9.749367E-05 | global batch size:     8 | lm loss: 3.306198E+00 | loss scale: 262144.0 | grad norm: 0.716 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 19:03:02] iteration   136400/  500000 | consumed samples:      1091200 | elapsed time per iteration (ms): 321.1 | learning rate: 9.742645E-05 | global batch size:     8 | lm loss: 3.337704E+00 | loss scale: 262144.0 | grad norm: 0.700 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 19:03:34] iteration   136500/  500000 | consumed samples:      1092000 | elapsed time per iteration (ms): 318.7 | learning rate: 9.735921E-05 | global batch size:     8 | lm loss: 3.334829E+00 | loss scale: 262144.0 | grad norm: 0.688 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 19:04:06] iteration   136600/  500000 | consumed samples:      1092800 | elapsed time per iteration (ms): 322.2 | learning rate: 9.729195E-05 | global batch size:     8 | lm loss: 3.354617E+00 | loss scale: 262144.0 | grad norm: 0.695 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 19:04:38] iteration   136700/  500000 | consumed samples:      1093600 | elapsed time per iteration (ms): 324.0 | learning rate: 9.722468E-05 | global batch size:     8 | lm loss: 3.393596E+00 | loss scale: 262144.0 | grad norm: 0.660 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 19:05:10] iteration   136800/  500000 | consumed samples:      1094400 | elapsed time per iteration (ms): 320.4 | learning rate: 9.715738E-05 | global batch size:     8 | lm loss: 3.303674E+00 | loss scale: 262144.0 | grad norm: 0.721 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 19:05:42] iteration   136900/  500000 | consumed samples:      1095200 | elapsed time per iteration (ms): 319.8 | learning rate: 9.709008E-05 | global batch size:     8 | lm loss: 3.289145E+00 | loss scale: 524288.0 | grad norm: 0.651 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 19:06:14] iteration   137000/  500000 | consumed samples:      1096000 | elapsed time per iteration (ms): 321.2 | learning rate: 9.702275E-05 | global batch size:     8 | lm loss: 3.315451E+00 | loss scale: 524288.0 | grad norm: 0.703 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1068.09, 1068.09)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 137000 | lm loss value: 3.776898E+00 | lm loss PPL: 4.368034E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-21 19:06:48] iteration   137100/  500000 | consumed samples:      1096800 | elapsed time per iteration (ms): 320.9 | learning rate: 9.695541E-05 | global batch size:     8 | lm loss: 3.365309E+00 | loss scale: 524288.0 | grad norm: 0.702 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 19:07:20] iteration   137200/  500000 | consumed samples:      1097600 | elapsed time per iteration (ms): 322.6 | learning rate: 9.688805E-05 | global batch size:     8 | lm loss: 3.357035E+00 | loss scale: 524288.0 | grad norm: 0.677 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 19:07:52] iteration   137300/  500000 | consumed samples:      1098400 | elapsed time per iteration (ms): 321.0 | learning rate: 9.682068E-05 | global batch size:     8 | lm loss: 3.325876E+00 | loss scale: 524288.0 | grad norm: 0.698 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 19:08:24] iteration   137400/  500000 | consumed samples:      1099200 | elapsed time per iteration (ms): 322.4 | learning rate: 9.675329E-05 | global batch size:     8 | lm loss: 3.335409E+00 | loss scale: 524288.0 | grad norm: 0.692 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 19:08:56] iteration   137500/  500000 | consumed samples:      1100000 | elapsed time per iteration (ms): 321.2 | learning rate: 9.668588E-05 | global batch size:     8 | lm loss: 3.361753E+00 | loss scale: 524288.0 | grad norm: 0.721 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 19:09:29] iteration   137600/  500000 | consumed samples:      1100800 | elapsed time per iteration (ms): 322.4 | learning rate: 9.661981E-05 | global batch size:     8 | lm loss: 3.320918E+00 | loss scale: 262144.0 | grad norm: 0.674 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-21 19:10:01] iteration   137700/  500000 | consumed samples:      1101600 | elapsed time per iteration (ms): 322.1 | learning rate: 9.655237E-05 | global batch size:     8 | lm loss: 3.298259E+00 | loss scale: 262144.0 | grad norm: 0.670 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 19:10:33] iteration   137800/  500000 | consumed samples:      1102400 | elapsed time per iteration (ms): 323.3 | learning rate: 9.648491E-05 | global batch size:     8 | lm loss: 3.342195E+00 | loss scale: 262144.0 | grad norm: 0.683 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 19:11:05] iteration   137900/  500000 | consumed samples:      1103200 | elapsed time per iteration (ms): 321.0 | learning rate: 9.641744E-05 | global batch size:     8 | lm loss: 3.339734E+00 | loss scale: 262144.0 | grad norm: 0.675 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 19:11:37] iteration   138000/  500000 | consumed samples:      1104000 | elapsed time per iteration (ms): 320.6 | learning rate: 9.634995E-05 | global batch size:     8 | lm loss: 3.275688E+00 | loss scale: 262144.0 | grad norm: 0.698 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1064.94, 1064.94)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 138000 | lm loss value: 3.694548E+00 | lm loss PPL: 4.022739E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-21 19:12:10] iteration   138100/  500000 | consumed samples:      1104800 | elapsed time per iteration (ms): 319.2 | learning rate: 9.628245E-05 | global batch size:     8 | lm loss: 3.297954E+00 | loss scale: 262144.0 | grad norm: 0.755 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 19:12:42] iteration   138200/  500000 | consumed samples:      1105600 | elapsed time per iteration (ms): 320.8 | learning rate: 9.621493E-05 | global batch size:     8 | lm loss: 3.319870E+00 | loss scale: 262144.0 | grad norm: 0.679 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 19:13:15] iteration   138300/  500000 | consumed samples:      1106400 | elapsed time per iteration (ms): 323.6 | learning rate: 9.614739E-05 | global batch size:     8 | lm loss: 3.346002E+00 | loss scale: 262144.0 | grad norm: 0.680 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 19:13:47] iteration   138400/  500000 | consumed samples:      1107200 | elapsed time per iteration (ms): 320.3 | learning rate: 9.607984E-05 | global batch size:     8 | lm loss: 3.314694E+00 | loss scale: 262144.0 | grad norm: 0.703 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 19:14:19] iteration   138500/  500000 | consumed samples:      1108000 | elapsed time per iteration (ms): 320.3 | learning rate: 9.601227E-05 | global batch size:     8 | lm loss: 3.296241E+00 | loss scale: 262144.0 | grad norm: 0.736 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 19:14:51] iteration   138600/  500000 | consumed samples:      1108800 | elapsed time per iteration (ms): 322.6 | learning rate: 9.594468E-05 | global batch size:     8 | lm loss: 3.302801E+00 | loss scale: 524288.0 | grad norm: 0.692 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 19:15:23] iteration   138700/  500000 | consumed samples:      1109600 | elapsed time per iteration (ms): 322.5 | learning rate: 9.587708E-05 | global batch size:     8 | lm loss: 3.296934E+00 | loss scale: 524288.0 | grad norm: 0.711 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 19:15:55] iteration   138800/  500000 | consumed samples:      1110400 | elapsed time per iteration (ms): 321.4 | learning rate: 9.580947E-05 | global batch size:     8 | lm loss: 3.338092E+00 | loss scale: 524288.0 | grad norm: 0.738 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 19:16:27] iteration   138900/  500000 | consumed samples:      1111200 | elapsed time per iteration (ms): 320.7 | learning rate: 9.574184E-05 | global batch size:     8 | lm loss: 3.346735E+00 | loss scale: 524288.0 | grad norm: 0.725 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 19:17:00] iteration   139000/  500000 | consumed samples:      1112000 | elapsed time per iteration (ms): 321.2 | learning rate: 9.567419E-05 | global batch size:     8 | lm loss: 3.323348E+00 | loss scale: 524288.0 | grad norm: 0.650 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1066.40, 1066.40)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 139000 | lm loss value: 3.684397E+00 | lm loss PPL: 3.982109E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-21 19:17:33] iteration   139100/  500000 | consumed samples:      1112800 | elapsed time per iteration (ms): 321.3 | learning rate: 9.560653E-05 | global batch size:     8 | lm loss: 3.360291E+00 | loss scale: 524288.0 | grad norm: 0.647 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 19:18:05] iteration   139200/  500000 | consumed samples:      1113600 | elapsed time per iteration (ms): 323.6 | learning rate: 9.553885E-05 | global batch size:     8 | lm loss: 3.282633E+00 | loss scale: 524288.0 | grad norm: 0.681 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 19:18:37] iteration   139300/  500000 | consumed samples:      1114400 | elapsed time per iteration (ms): 322.3 | learning rate: 9.547116E-05 | global batch size:     8 | lm loss: 3.343514E+00 | loss scale: 524288.0 | grad norm: 0.659 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 19:19:10] iteration   139400/  500000 | consumed samples:      1115200 | elapsed time per iteration (ms): 322.0 | learning rate: 9.540413E-05 | global batch size:     8 | lm loss: 3.324525E+00 | loss scale: 524288.0 | grad norm: 0.689 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-21 19:19:42] iteration   139500/  500000 | consumed samples:      1116000 | elapsed time per iteration (ms): 322.6 | learning rate: 9.533641E-05 | global batch size:     8 | lm loss: 3.353588E+00 | loss scale: 524288.0 | grad norm: 0.697 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 19:20:14] iteration   139600/  500000 | consumed samples:      1116800 | elapsed time per iteration (ms): 323.2 | learning rate: 9.526867E-05 | global batch size:     8 | lm loss: 3.322251E+00 | loss scale: 524288.0 | grad norm: 0.748 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 19:20:46] iteration   139700/  500000 | consumed samples:      1117600 | elapsed time per iteration (ms): 322.2 | learning rate: 9.520092E-05 | global batch size:     8 | lm loss: 3.303046E+00 | loss scale: 524288.0 | grad norm: 0.709 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 19:21:19] iteration   139800/  500000 | consumed samples:      1118400 | elapsed time per iteration (ms): 322.5 | learning rate: 9.513315E-05 | global batch size:     8 | lm loss: 3.330677E+00 | loss scale: 524288.0 | grad norm: 0.708 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 19:21:51] iteration   139900/  500000 | consumed samples:      1119200 | elapsed time per iteration (ms): 325.2 | learning rate: 9.506537E-05 | global batch size:     8 | lm loss: 3.332281E+00 | loss scale: 524288.0 | grad norm: 0.718 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 19:22:23] iteration   140000/  500000 | consumed samples:      1120000 | elapsed time per iteration (ms): 320.5 | learning rate: 9.499757E-05 | global batch size:     8 | lm loss: 3.342018E+00 | loss scale: 524288.0 | grad norm: 0.722 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1064.30, 1064.30)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 140000 | lm loss value: 3.757562E+00 | lm loss PPL: 4.284386E+01 | 
--------------------------------------------------------------------------------------------------
saving checkpoint at iteration  140000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-max in torch format
  successfully saved checkpoint at iteration  140000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-max
(min, max) time across ranks (ms):
    save-checkpoint ................................: (5761.13, 5761.13)
 [2024-06-21 19:23:02] iteration   140100/  500000 | consumed samples:      1120800 | elapsed time per iteration (ms): 319.5 | learning rate: 9.492976E-05 | global batch size:     8 | lm loss: 3.298813E+00 | loss scale: 524288.0 | grad norm: 0.713 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 19:23:34] iteration   140200/  500000 | consumed samples:      1121600 | elapsed time per iteration (ms): 318.4 | learning rate: 9.486193E-05 | global batch size:     8 | lm loss: 3.332246E+00 | loss scale: 524288.0 | grad norm: 0.707 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 19:24:06] iteration   140300/  500000 | consumed samples:      1122400 | elapsed time per iteration (ms): 318.9 | learning rate: 9.479409E-05 | global batch size:     8 | lm loss: 3.312739E+00 | loss scale: 524288.0 | grad norm: 0.693 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 19:24:38] iteration   140400/  500000 | consumed samples:      1123200 | elapsed time per iteration (ms): 322.2 | learning rate: 9.472759E-05 | global batch size:     8 | lm loss: 3.309576E+00 | loss scale: 524288.0 | grad norm: 0.693 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-21 19:25:10] iteration   140500/  500000 | consumed samples:      1124000 | elapsed time per iteration (ms): 320.9 | learning rate: 9.465972E-05 | global batch size:     8 | lm loss: 3.261600E+00 | loss scale: 524288.0 | grad norm: 0.716 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 19:25:42] iteration   140600/  500000 | consumed samples:      1124800 | elapsed time per iteration (ms): 318.8 | learning rate: 9.459252E-05 | global batch size:     8 | lm loss: 3.288685E+00 | loss scale: 262144.0 | grad norm: 0.729 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-21 19:26:14] iteration   140700/  500000 | consumed samples:      1125600 | elapsed time per iteration (ms): 319.7 | learning rate: 9.452462E-05 | global batch size:     8 | lm loss: 3.314772E+00 | loss scale: 262144.0 | grad norm: 0.731 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 19:26:46] iteration   140800/  500000 | consumed samples:      1126400 | elapsed time per iteration (ms): 323.8 | learning rate: 9.445671E-05 | global batch size:     8 | lm loss: 3.309831E+00 | loss scale: 262144.0 | grad norm: 0.695 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 19:27:18] iteration   140900/  500000 | consumed samples:      1127200 | elapsed time per iteration (ms): 320.8 | learning rate: 9.438878E-05 | global batch size:     8 | lm loss: 3.340580E+00 | loss scale: 262144.0 | grad norm: 0.750 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 19:27:51] iteration   141000/  500000 | consumed samples:      1128000 | elapsed time per iteration (ms): 321.7 | learning rate: 9.432084E-05 | global batch size:     8 | lm loss: 3.324065E+00 | loss scale: 262144.0 | grad norm: 0.712 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1065.72, 1065.72)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 141000 | lm loss value: 3.664986E+00 | lm loss PPL: 3.905558E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-21 19:28:24] iteration   141100/  500000 | consumed samples:      1128800 | elapsed time per iteration (ms): 321.2 | learning rate: 9.425288E-05 | global batch size:     8 | lm loss: 3.326318E+00 | loss scale: 262144.0 | grad norm: 0.706 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 19:28:56] iteration   141200/  500000 | consumed samples:      1129600 | elapsed time per iteration (ms): 320.1 | learning rate: 9.418491E-05 | global batch size:     8 | lm loss: 3.324952E+00 | loss scale: 262144.0 | grad norm: 0.706 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 19:29:28] iteration   141300/  500000 | consumed samples:      1130400 | elapsed time per iteration (ms): 321.7 | learning rate: 9.411693E-05 | global batch size:     8 | lm loss: 3.345617E+00 | loss scale: 262144.0 | grad norm: 0.724 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 19:30:00] iteration   141400/  500000 | consumed samples:      1131200 | elapsed time per iteration (ms): 321.0 | learning rate: 9.404893E-05 | global batch size:     8 | lm loss: 3.319499E+00 | loss scale: 262144.0 | grad norm: 0.655 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 19:30:32] iteration   141500/  500000 | consumed samples:      1132000 | elapsed time per iteration (ms): 322.6 | learning rate: 9.398092E-05 | global batch size:     8 | lm loss: 3.309498E+00 | loss scale: 262144.0 | grad norm: 0.672 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 19:31:04] iteration   141600/  500000 | consumed samples:      1132800 | elapsed time per iteration (ms): 321.7 | learning rate: 9.391290E-05 | global batch size:     8 | lm loss: 3.329958E+00 | loss scale: 524288.0 | grad norm: 0.691 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 19:31:37] iteration   141700/  500000 | consumed samples:      1133600 | elapsed time per iteration (ms): 322.1 | learning rate: 9.384554E-05 | global batch size:     8 | lm loss: 3.299454E+00 | loss scale: 524288.0 | grad norm: 0.679 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-21 19:32:09] iteration   141800/  500000 | consumed samples:      1134400 | elapsed time per iteration (ms): 321.0 | learning rate: 9.377749E-05 | global batch size:     8 | lm loss: 3.321658E+00 | loss scale: 524288.0 | grad norm: 0.721 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 19:32:41] iteration   141900/  500000 | consumed samples:      1135200 | elapsed time per iteration (ms): 322.0 | learning rate: 9.370942E-05 | global batch size:     8 | lm loss: 3.290644E+00 | loss scale: 524288.0 | grad norm: 0.732 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 19:33:13] iteration   142000/  500000 | consumed samples:      1136000 | elapsed time per iteration (ms): 322.2 | learning rate: 9.364134E-05 | global batch size:     8 | lm loss: 3.309406E+00 | loss scale: 524288.0 | grad norm: 0.756 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1063.06, 1063.06)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 142000 | lm loss value: 3.730306E+00 | lm loss PPL: 4.169188E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-21 19:33:47] iteration   142100/  500000 | consumed samples:      1136800 | elapsed time per iteration (ms): 324.7 | learning rate: 9.357325E-05 | global batch size:     8 | lm loss: 3.299879E+00 | loss scale: 524288.0 | grad norm: 0.695 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 19:34:19] iteration   142200/  500000 | consumed samples:      1137600 | elapsed time per iteration (ms): 321.2 | learning rate: 9.350515E-05 | global batch size:     8 | lm loss: 3.331364E+00 | loss scale: 524288.0 | grad norm: 0.705 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 19:34:51] iteration   142300/  500000 | consumed samples:      1138400 | elapsed time per iteration (ms): 322.0 | learning rate: 9.343703E-05 | global batch size:     8 | lm loss: 3.326010E+00 | loss scale: 524288.0 | grad norm: 0.688 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 19:35:23] iteration   142400/  500000 | consumed samples:      1139200 | elapsed time per iteration (ms): 320.3 | learning rate: 9.336889E-05 | global batch size:     8 | lm loss: 3.302263E+00 | loss scale: 524288.0 | grad norm: 0.707 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 19:35:55] iteration   142500/  500000 | consumed samples:      1140000 | elapsed time per iteration (ms): 321.5 | learning rate: 9.330075E-05 | global batch size:     8 | lm loss: 3.329990E+00 | loss scale: 524288.0 | grad norm: 0.710 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 19:36:27] iteration   142600/  500000 | consumed samples:      1140800 | elapsed time per iteration (ms): 321.4 | learning rate: 9.323327E-05 | global batch size:     8 | lm loss: 3.350195E+00 | loss scale: 262144.0 | grad norm: 0.713 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-21 19:36:59] iteration   142700/  500000 | consumed samples:      1141600 | elapsed time per iteration (ms): 322.1 | learning rate: 9.316510E-05 | global batch size:     8 | lm loss: 3.286977E+00 | loss scale: 262144.0 | grad norm: 0.705 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 19:37:32] iteration   142800/  500000 | consumed samples:      1142400 | elapsed time per iteration (ms): 321.5 | learning rate: 9.309692E-05 | global batch size:     8 | lm loss: 3.291607E+00 | loss scale: 262144.0 | grad norm: 0.734 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 19:38:04] iteration   142900/  500000 | consumed samples:      1143200 | elapsed time per iteration (ms): 321.1 | learning rate: 9.302872E-05 | global batch size:     8 | lm loss: 3.298491E+00 | loss scale: 262144.0 | grad norm: 0.734 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 19:38:36] iteration   143000/  500000 | consumed samples:      1144000 | elapsed time per iteration (ms): 321.4 | learning rate: 9.296051E-05 | global batch size:     8 | lm loss: 3.339370E+00 | loss scale: 262144.0 | grad norm: 0.746 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1066.07, 1066.07)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 143000 | lm loss value: 3.721684E+00 | lm loss PPL: 4.133392E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-21 19:39:09] iteration   143100/  500000 | consumed samples:      1144800 | elapsed time per iteration (ms): 322.4 | learning rate: 9.289229E-05 | global batch size:     8 | lm loss: 3.292860E+00 | loss scale: 262144.0 | grad norm: 0.706 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 19:39:41] iteration   143200/  500000 | consumed samples:      1145600 | elapsed time per iteration (ms): 321.3 | learning rate: 9.282405E-05 | global batch size:     8 | lm loss: 3.309202E+00 | loss scale: 262144.0 | grad norm: 0.720 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 19:40:13] iteration   143300/  500000 | consumed samples:      1146400 | elapsed time per iteration (ms): 320.6 | learning rate: 9.275580E-05 | global batch size:     8 | lm loss: 3.331643E+00 | loss scale: 262144.0 | grad norm: 0.720 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 19:40:46] iteration   143400/  500000 | consumed samples:      1147200 | elapsed time per iteration (ms): 322.2 | learning rate: 9.268754E-05 | global batch size:     8 | lm loss: 3.340207E+00 | loss scale: 262144.0 | grad norm: 0.683 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 19:41:18] iteration   143500/  500000 | consumed samples:      1148000 | elapsed time per iteration (ms): 321.7 | learning rate: 9.261927E-05 | global batch size:     8 | lm loss: 3.322757E+00 | loss scale: 262144.0 | grad norm: 0.693 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 19:41:50] iteration   143600/  500000 | consumed samples:      1148800 | elapsed time per iteration (ms): 323.6 | learning rate: 9.255167E-05 | global batch size:     8 | lm loss: 3.310285E+00 | loss scale: 524288.0 | grad norm: 0.664 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-21 19:42:22] iteration   143700/  500000 | consumed samples:      1149600 | elapsed time per iteration (ms): 322.7 | learning rate: 9.248337E-05 | global batch size:     8 | lm loss: 3.289593E+00 | loss scale: 524288.0 | grad norm: 0.678 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 19:42:55] iteration   143800/  500000 | consumed samples:      1150400 | elapsed time per iteration (ms): 322.3 | learning rate: 9.241574E-05 | global batch size:     8 | lm loss: 3.320927E+00 | loss scale: 262144.0 | grad norm: 0.685 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-21 19:43:27] iteration   143900/  500000 | consumed samples:      1151200 | elapsed time per iteration (ms): 321.0 | learning rate: 9.234742E-05 | global batch size:     8 | lm loss: 3.320249E+00 | loss scale: 262144.0 | grad norm: 0.689 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 19:43:59] iteration   144000/  500000 | consumed samples:      1152000 | elapsed time per iteration (ms): 323.9 | learning rate: 9.227909E-05 | global batch size:     8 | lm loss: 3.324385E+00 | loss scale: 262144.0 | grad norm: 0.729 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1066.75, 1066.75)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 144000 | lm loss value: 3.775083E+00 | lm loss PPL: 4.360112E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-21 19:44:32] iteration   144100/  500000 | consumed samples:      1152800 | elapsed time per iteration (ms): 320.8 | learning rate: 9.221074E-05 | global batch size:     8 | lm loss: 3.322289E+00 | loss scale: 262144.0 | grad norm: 0.725 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 19:45:04] iteration   144200/  500000 | consumed samples:      1153600 | elapsed time per iteration (ms): 321.7 | learning rate: 9.214238E-05 | global batch size:     8 | lm loss: 3.306953E+00 | loss scale: 262144.0 | grad norm: 0.684 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 19:45:37] iteration   144300/  500000 | consumed samples:      1154400 | elapsed time per iteration (ms): 321.5 | learning rate: 9.207401E-05 | global batch size:     8 | lm loss: 3.323750E+00 | loss scale: 262144.0 | grad norm: 0.711 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 19:46:09] iteration   144400/  500000 | consumed samples:      1155200 | elapsed time per iteration (ms): 322.3 | learning rate: 9.200563E-05 | global batch size:     8 | lm loss: 3.323037E+00 | loss scale: 262144.0 | grad norm: 0.712 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 19:46:41] iteration   144500/  500000 | consumed samples:      1156000 | elapsed time per iteration (ms): 323.1 | learning rate: 9.193792E-05 | global batch size:     8 | lm loss: 3.297177E+00 | loss scale: 131072.0 | grad norm: 0.695 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-21 19:47:13] iteration   144600/  500000 | consumed samples:      1156800 | elapsed time per iteration (ms): 320.9 | learning rate: 9.186952E-05 | global batch size:     8 | lm loss: 3.238164E+00 | loss scale: 131072.0 | grad norm: 0.726 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 19:47:45] iteration   144700/  500000 | consumed samples:      1157600 | elapsed time per iteration (ms): 322.7 | learning rate: 9.180110E-05 | global batch size:     8 | lm loss: 3.330979E+00 | loss scale: 131072.0 | grad norm: 0.672 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 19:48:18] iteration   144800/  500000 | consumed samples:      1158400 | elapsed time per iteration (ms): 323.1 | learning rate: 9.173267E-05 | global batch size:     8 | lm loss: 3.332813E+00 | loss scale: 131072.0 | grad norm: 0.719 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 19:48:50] iteration   144900/  500000 | consumed samples:      1159200 | elapsed time per iteration (ms): 321.3 | learning rate: 9.166423E-05 | global batch size:     8 | lm loss: 3.281748E+00 | loss scale: 131072.0 | grad norm: 0.718 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 19:49:22] iteration   145000/  500000 | consumed samples:      1160000 | elapsed time per iteration (ms): 320.8 | learning rate: 9.159578E-05 | global batch size:     8 | lm loss: 3.263587E+00 | loss scale: 131072.0 | grad norm: 0.728 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1064.21, 1064.21)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 145000 | lm loss value: 3.675191E+00 | lm loss PPL: 3.945620E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-21 19:49:55] iteration   145100/  500000 | consumed samples:      1160800 | elapsed time per iteration (ms): 322.4 | learning rate: 9.152732E-05 | global batch size:     8 | lm loss: 3.326548E+00 | loss scale: 131072.0 | grad norm: 0.738 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 19:50:28] iteration   145200/  500000 | consumed samples:      1161600 | elapsed time per iteration (ms): 322.7 | learning rate: 9.145884E-05 | global batch size:     8 | lm loss: 3.300465E+00 | loss scale: 131072.0 | grad norm: 0.724 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 19:51:00] iteration   145300/  500000 | consumed samples:      1162400 | elapsed time per iteration (ms): 321.9 | learning rate: 9.139035E-05 | global batch size:     8 | lm loss: 3.310977E+00 | loss scale: 131072.0 | grad norm: 0.686 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 19:51:32] iteration   145400/  500000 | consumed samples:      1163200 | elapsed time per iteration (ms): 321.7 | learning rate: 9.132186E-05 | global batch size:     8 | lm loss: 3.304378E+00 | loss scale: 131072.0 | grad norm: 0.810 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 19:52:04] iteration   145500/  500000 | consumed samples:      1164000 | elapsed time per iteration (ms): 323.6 | learning rate: 9.125335E-05 | global batch size:     8 | lm loss: 3.318896E+00 | loss scale: 262144.0 | grad norm: 0.729 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 19:52:37] iteration   145600/  500000 | consumed samples:      1164800 | elapsed time per iteration (ms): 322.9 | learning rate: 9.118483E-05 | global batch size:     8 | lm loss: 3.270259E+00 | loss scale: 262144.0 | grad norm: 0.697 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 19:53:09] iteration   145700/  500000 | consumed samples:      1165600 | elapsed time per iteration (ms): 322.2 | learning rate: 9.111630E-05 | global batch size:     8 | lm loss: 3.308432E+00 | loss scale: 262144.0 | grad norm: 0.718 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 19:53:41] iteration   145800/  500000 | consumed samples:      1166400 | elapsed time per iteration (ms): 324.5 | learning rate: 9.104776E-05 | global batch size:     8 | lm loss: 3.256266E+00 | loss scale: 262144.0 | grad norm: 0.778 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 19:54:13] iteration   145900/  500000 | consumed samples:      1167200 | elapsed time per iteration (ms): 320.6 | learning rate: 9.097921E-05 | global batch size:     8 | lm loss: 3.308227E+00 | loss scale: 262144.0 | grad norm: 0.688 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 19:54:46] iteration   146000/  500000 | consumed samples:      1168000 | elapsed time per iteration (ms): 322.8 | learning rate: 9.091064E-05 | global batch size:     8 | lm loss: 3.318906E+00 | loss scale: 262144.0 | grad norm: 0.692 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1063.53, 1063.53)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 146000 | lm loss value: 3.473619E+00 | lm loss PPL: 3.225325E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-21 19:55:19] iteration   146100/  500000 | consumed samples:      1168800 | elapsed time per iteration (ms): 322.3 | learning rate: 9.084207E-05 | global batch size:     8 | lm loss: 3.306143E+00 | loss scale: 262144.0 | grad norm: 0.685 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 19:55:51] iteration   146200/  500000 | consumed samples:      1169600 | elapsed time per iteration (ms): 323.6 | learning rate: 9.077349E-05 | global batch size:     8 | lm loss: 3.280771E+00 | loss scale: 262144.0 | grad norm: 0.722 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 19:56:24] iteration   146300/  500000 | consumed samples:      1170400 | elapsed time per iteration (ms): 323.7 | learning rate: 9.070489E-05 | global batch size:     8 | lm loss: 3.281277E+00 | loss scale: 262144.0 | grad norm: 0.710 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 19:56:56] iteration   146400/  500000 | consumed samples:      1171200 | elapsed time per iteration (ms): 321.6 | learning rate: 9.063629E-05 | global batch size:     8 | lm loss: 3.265589E+00 | loss scale: 262144.0 | grad norm: 0.735 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 19:57:28] iteration   146500/  500000 | consumed samples:      1172000 | elapsed time per iteration (ms): 322.8 | learning rate: 9.056767E-05 | global batch size:     8 | lm loss: 3.331605E+00 | loss scale: 524288.0 | grad norm: 0.711 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 19:58:00] iteration   146600/  500000 | consumed samples:      1172800 | elapsed time per iteration (ms): 322.7 | learning rate: 9.049905E-05 | global batch size:     8 | lm loss: 3.282764E+00 | loss scale: 524288.0 | grad norm: 0.695 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 19:58:33] iteration   146700/  500000 | consumed samples:      1173600 | elapsed time per iteration (ms): 324.0 | learning rate: 9.043041E-05 | global batch size:     8 | lm loss: 3.292011E+00 | loss scale: 524288.0 | grad norm: 0.720 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 19:59:05] iteration   146800/  500000 | consumed samples:      1174400 | elapsed time per iteration (ms): 323.7 | learning rate: 9.036176E-05 | global batch size:     8 | lm loss: 3.273641E+00 | loss scale: 524288.0 | grad norm: 0.698 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 19:59:37] iteration   146900/  500000 | consumed samples:      1175200 | elapsed time per iteration (ms): 322.8 | learning rate: 9.029311E-05 | global batch size:     8 | lm loss: 3.303379E+00 | loss scale: 524288.0 | grad norm: 0.700 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 20:00:10] iteration   147000/  500000 | consumed samples:      1176000 | elapsed time per iteration (ms): 324.7 | learning rate: 9.022444E-05 | global batch size:     8 | lm loss: 3.297121E+00 | loss scale: 524288.0 | grad norm: 0.742 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1064.62, 1064.62)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 147000 | lm loss value: 3.646861E+00 | lm loss PPL: 3.835408E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-21 20:00:43] iteration   147100/  500000 | consumed samples:      1176800 | elapsed time per iteration (ms): 321.5 | learning rate: 9.015645E-05 | global batch size:     8 | lm loss: 3.299807E+00 | loss scale: 524288.0 | grad norm: 0.761 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-21 20:01:15] iteration   147200/  500000 | consumed samples:      1177600 | elapsed time per iteration (ms): 321.3 | learning rate: 9.008776E-05 | global batch size:     8 | lm loss: 3.329778E+00 | loss scale: 524288.0 | grad norm: 0.695 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 20:01:47] iteration   147300/  500000 | consumed samples:      1178400 | elapsed time per iteration (ms): 322.4 | learning rate: 9.001906E-05 | global batch size:     8 | lm loss: 3.293563E+00 | loss scale: 524288.0 | grad norm: 0.757 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 20:02:20] iteration   147400/  500000 | consumed samples:      1179200 | elapsed time per iteration (ms): 322.5 | learning rate: 8.995104E-05 | global batch size:     8 | lm loss: 3.253821E+00 | loss scale: 262144.0 | grad norm: 0.704 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-21 20:02:52] iteration   147500/  500000 | consumed samples:      1180000 | elapsed time per iteration (ms): 321.4 | learning rate: 8.988233E-05 | global batch size:     8 | lm loss: 3.267846E+00 | loss scale: 262144.0 | grad norm: 0.749 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 20:03:24] iteration   147600/  500000 | consumed samples:      1180800 | elapsed time per iteration (ms): 324.1 | learning rate: 8.981360E-05 | global batch size:     8 | lm loss: 3.324493E+00 | loss scale: 262144.0 | grad norm: 0.718 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 20:03:57] iteration   147700/  500000 | consumed samples:      1181600 | elapsed time per iteration (ms): 324.1 | learning rate: 8.974487E-05 | global batch size:     8 | lm loss: 3.342770E+00 | loss scale: 262144.0 | grad norm: 0.688 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 20:04:29] iteration   147800/  500000 | consumed samples:      1182400 | elapsed time per iteration (ms): 319.4 | learning rate: 8.967612E-05 | global batch size:     8 | lm loss: 3.320548E+00 | loss scale: 262144.0 | grad norm: 0.714 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 20:05:01] iteration   147900/  500000 | consumed samples:      1183200 | elapsed time per iteration (ms): 323.0 | learning rate: 8.960737E-05 | global batch size:     8 | lm loss: 3.278362E+00 | loss scale: 262144.0 | grad norm: 0.722 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 20:05:33] iteration   148000/  500000 | consumed samples:      1184000 | elapsed time per iteration (ms): 321.7 | learning rate: 8.953860E-05 | global batch size:     8 | lm loss: 3.249980E+00 | loss scale: 262144.0 | grad norm: 0.681 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1063.99, 1063.99)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 148000 | lm loss value: 3.696714E+00 | lm loss PPL: 4.031463E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-21 20:06:06] iteration   148100/  500000 | consumed samples:      1184800 | elapsed time per iteration (ms): 322.9 | learning rate: 8.946983E-05 | global batch size:     8 | lm loss: 3.294828E+00 | loss scale: 262144.0 | grad norm: 0.797 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 20:06:39] iteration   148200/  500000 | consumed samples:      1185600 | elapsed time per iteration (ms): 323.1 | learning rate: 8.940105E-05 | global batch size:     8 | lm loss: 3.292756E+00 | loss scale: 262144.0 | grad norm: 0.647 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 20:07:11] iteration   148300/  500000 | consumed samples:      1186400 | elapsed time per iteration (ms): 319.8 | learning rate: 8.933225E-05 | global batch size:     8 | lm loss: 3.281956E+00 | loss scale: 262144.0 | grad norm: 0.718 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 20:07:43] iteration   148400/  500000 | consumed samples:      1187200 | elapsed time per iteration (ms): 320.7 | learning rate: 8.926414E-05 | global batch size:     8 | lm loss: 3.305499E+00 | loss scale: 524288.0 | grad norm: 0.688 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-21 20:08:15] iteration   148500/  500000 | consumed samples:      1188000 | elapsed time per iteration (ms): 321.3 | learning rate: 8.919533E-05 | global batch size:     8 | lm loss: 3.319986E+00 | loss scale: 524288.0 | grad norm: 0.729 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 20:08:47] iteration   148600/  500000 | consumed samples:      1188800 | elapsed time per iteration (ms): 320.4 | learning rate: 8.912651E-05 | global batch size:     8 | lm loss: 3.294131E+00 | loss scale: 524288.0 | grad norm: 0.705 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 20:09:19] iteration   148700/  500000 | consumed samples:      1189600 | elapsed time per iteration (ms): 319.1 | learning rate: 8.905837E-05 | global batch size:     8 | lm loss: 3.291151E+00 | loss scale: 262144.0 | grad norm: 0.700 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-21 20:09:51] iteration   148800/  500000 | consumed samples:      1190400 | elapsed time per iteration (ms): 320.6 | learning rate: 8.898953E-05 | global batch size:     8 | lm loss: 3.245661E+00 | loss scale: 262144.0 | grad norm: 0.696 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 20:10:23] iteration   148900/  500000 | consumed samples:      1191200 | elapsed time per iteration (ms): 323.6 | learning rate: 8.892069E-05 | global batch size:     8 | lm loss: 3.307731E+00 | loss scale: 262144.0 | grad norm: 0.699 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 20:10:56] iteration   149000/  500000 | consumed samples:      1192000 | elapsed time per iteration (ms): 323.9 | learning rate: 8.885183E-05 | global batch size:     8 | lm loss: 3.307805E+00 | loss scale: 262144.0 | grad norm: 0.740 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1063.58, 1063.58)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 149000 | lm loss value: 3.581691E+00 | lm loss PPL: 3.593426E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-21 20:11:29] iteration   149100/  500000 | consumed samples:      1192800 | elapsed time per iteration (ms): 319.4 | learning rate: 8.878297E-05 | global batch size:     8 | lm loss: 3.315696E+00 | loss scale: 262144.0 | grad norm: 0.736 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 20:12:01] iteration   149200/  500000 | consumed samples:      1193600 | elapsed time per iteration (ms): 322.6 | learning rate: 8.871410E-05 | global batch size:     8 | lm loss: 3.264182E+00 | loss scale: 262144.0 | grad norm: 0.703 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 20:12:33] iteration   149300/  500000 | consumed samples:      1194400 | elapsed time per iteration (ms): 321.8 | learning rate: 8.864521E-05 | global batch size:     8 | lm loss: 3.279595E+00 | loss scale: 262144.0 | grad norm: 0.677 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 20:13:05] iteration   149400/  500000 | consumed samples:      1195200 | elapsed time per iteration (ms): 322.6 | learning rate: 8.857633E-05 | global batch size:     8 | lm loss: 3.270251E+00 | loss scale: 262144.0 | grad norm: 0.669 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 20:13:38] iteration   149500/  500000 | consumed samples:      1196000 | elapsed time per iteration (ms): 322.4 | learning rate: 8.850812E-05 | global batch size:     8 | lm loss: 3.268266E+00 | loss scale: 131072.0 | grad norm: 0.687 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-21 20:14:10] iteration   149600/  500000 | consumed samples:      1196800 | elapsed time per iteration (ms): 321.1 | learning rate: 8.843921E-05 | global batch size:     8 | lm loss: 3.274568E+00 | loss scale: 131072.0 | grad norm: 0.738 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 20:14:42] iteration   149700/  500000 | consumed samples:      1197600 | elapsed time per iteration (ms): 322.7 | learning rate: 8.837030E-05 | global batch size:     8 | lm loss: 3.303102E+00 | loss scale: 131072.0 | grad norm: 0.664 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 20:15:14] iteration   149800/  500000 | consumed samples:      1198400 | elapsed time per iteration (ms): 320.6 | learning rate: 8.830137E-05 | global batch size:     8 | lm loss: 3.274297E+00 | loss scale: 131072.0 | grad norm: 0.713 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 20:15:46] iteration   149900/  500000 | consumed samples:      1199200 | elapsed time per iteration (ms): 321.3 | learning rate: 8.823244E-05 | global batch size:     8 | lm loss: 3.280815E+00 | loss scale: 131072.0 | grad norm: 0.697 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 20:16:18] iteration   150000/  500000 | consumed samples:      1200000 | elapsed time per iteration (ms): 322.8 | learning rate: 8.816350E-05 | global batch size:     8 | lm loss: 3.272950E+00 | loss scale: 131072.0 | grad norm: 0.663 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1064.20, 1064.20)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 150000 | lm loss value: 3.690906E+00 | lm loss PPL: 4.008114E+01 | 
--------------------------------------------------------------------------------------------------
saving checkpoint at iteration  150000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-max in torch format
  successfully saved checkpoint at iteration  150000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-max
(min, max) time across ranks (ms):
    save-checkpoint ................................: (5719.33, 5719.33)
 [2024-06-21 20:16:57] iteration   150100/  500000 | consumed samples:      1200800 | elapsed time per iteration (ms): 320.4 | learning rate: 8.809456E-05 | global batch size:     8 | lm loss: 3.322143E+00 | loss scale: 131072.0 | grad norm: 0.693 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 20:17:29] iteration   150200/  500000 | consumed samples:      1201600 | elapsed time per iteration (ms): 320.5 | learning rate: 8.802560E-05 | global batch size:     8 | lm loss: 3.259930E+00 | loss scale: 131072.0 | grad norm: 0.739 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 20:18:01] iteration   150300/  500000 | consumed samples:      1202400 | elapsed time per iteration (ms): 321.6 | learning rate: 8.795664E-05 | global batch size:     8 | lm loss: 3.287709E+00 | loss scale: 131072.0 | grad norm: 0.765 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 20:18:34] iteration   150400/  500000 | consumed samples:      1203200 | elapsed time per iteration (ms): 321.3 | learning rate: 8.788767E-05 | global batch size:     8 | lm loss: 3.300829E+00 | loss scale: 131072.0 | grad norm: 0.647 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 20:19:06] iteration   150500/  500000 | consumed samples:      1204000 | elapsed time per iteration (ms): 320.0 | learning rate: 8.781869E-05 | global batch size:     8 | lm loss: 3.294312E+00 | loss scale: 262144.0 | grad norm: 0.715 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 20:19:38] iteration   150600/  500000 | consumed samples:      1204800 | elapsed time per iteration (ms): 323.4 | learning rate: 8.775109E-05 | global batch size:     8 | lm loss: 3.280320E+00 | loss scale: 131072.0 | grad norm: 0.680 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-21 20:20:10] iteration   150700/  500000 | consumed samples:      1205600 | elapsed time per iteration (ms): 322.3 | learning rate: 8.768209E-05 | global batch size:     8 | lm loss: 3.267789E+00 | loss scale: 131072.0 | grad norm: 0.724 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 20:20:42] iteration   150800/  500000 | consumed samples:      1206400 | elapsed time per iteration (ms): 322.1 | learning rate: 8.761309E-05 | global batch size:     8 | lm loss: 3.253526E+00 | loss scale: 131072.0 | grad norm: 0.734 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 20:21:15] iteration   150900/  500000 | consumed samples:      1207200 | elapsed time per iteration (ms): 322.0 | learning rate: 8.754408E-05 | global batch size:     8 | lm loss: 3.270195E+00 | loss scale: 131072.0 | grad norm: 0.717 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 20:21:47] iteration   151000/  500000 | consumed samples:      1208000 | elapsed time per iteration (ms): 323.2 | learning rate: 8.747507E-05 | global batch size:     8 | lm loss: 3.280217E+00 | loss scale: 131072.0 | grad norm: 0.726 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1067.37, 1067.37)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 151000 | lm loss value: 3.732702E+00 | lm loss PPL: 4.179186E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-21 20:22:20] iteration   151100/  500000 | consumed samples:      1208800 | elapsed time per iteration (ms): 322.0 | learning rate: 8.740604E-05 | global batch size:     8 | lm loss: 3.319434E+00 | loss scale: 131072.0 | grad norm: 0.736 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 20:22:52] iteration   151200/  500000 | consumed samples:      1209600 | elapsed time per iteration (ms): 322.3 | learning rate: 8.733701E-05 | global batch size:     8 | lm loss: 3.299535E+00 | loss scale: 131072.0 | grad norm: 0.729 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 20:23:25] iteration   151300/  500000 | consumed samples:      1210400 | elapsed time per iteration (ms): 321.7 | learning rate: 8.726797E-05 | global batch size:     8 | lm loss: 3.275350E+00 | loss scale: 131072.0 | grad norm: 0.719 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 20:23:57] iteration   151400/  500000 | consumed samples:      1211200 | elapsed time per iteration (ms): 322.1 | learning rate: 8.719893E-05 | global batch size:     8 | lm loss: 3.310414E+00 | loss scale: 131072.0 | grad norm: 0.681 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 20:24:29] iteration   151500/  500000 | consumed samples:      1212000 | elapsed time per iteration (ms): 324.5 | learning rate: 8.712988E-05 | global batch size:     8 | lm loss: 3.315601E+00 | loss scale: 131072.0 | grad norm: 0.734 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 20:25:01] iteration   151600/  500000 | consumed samples:      1212800 | elapsed time per iteration (ms): 321.5 | learning rate: 8.706082E-05 | global batch size:     8 | lm loss: 3.250202E+00 | loss scale: 262144.0 | grad norm: 0.725 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 20:25:34] iteration   151700/  500000 | consumed samples:      1213600 | elapsed time per iteration (ms): 321.9 | learning rate: 8.699175E-05 | global batch size:     8 | lm loss: 3.295944E+00 | loss scale: 262144.0 | grad norm: 0.742 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 20:26:06] iteration   151800/  500000 | consumed samples:      1214400 | elapsed time per iteration (ms): 322.7 | learning rate: 8.692268E-05 | global batch size:     8 | lm loss: 3.276054E+00 | loss scale: 262144.0 | grad norm: 0.724 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 20:26:38] iteration   151900/  500000 | consumed samples:      1215200 | elapsed time per iteration (ms): 323.9 | learning rate: 8.685360E-05 | global batch size:     8 | lm loss: 3.264802E+00 | loss scale: 262144.0 | grad norm: 0.722 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 20:27:10] iteration   152000/  500000 | consumed samples:      1216000 | elapsed time per iteration (ms): 320.2 | learning rate: 8.678521E-05 | global batch size:     8 | lm loss: 3.225960E+00 | loss scale: 262144.0 | grad norm: 0.704 | number of skipped iterations:   1 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1063.45, 1063.45)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 152000 | lm loss value: 3.724419E+00 | lm loss PPL: 4.144713E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-21 20:27:43] iteration   152100/  500000 | consumed samples:      1216800 | elapsed time per iteration (ms): 320.7 | learning rate: 8.671611E-05 | global batch size:     8 | lm loss: 3.269225E+00 | loss scale: 262144.0 | grad norm: 0.660 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 20:28:16] iteration   152200/  500000 | consumed samples:      1217600 | elapsed time per iteration (ms): 322.6 | learning rate: 8.664701E-05 | global batch size:     8 | lm loss: 3.296819E+00 | loss scale: 262144.0 | grad norm: 0.725 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 20:28:48] iteration   152300/  500000 | consumed samples:      1218400 | elapsed time per iteration (ms): 324.9 | learning rate: 8.657791E-05 | global batch size:     8 | lm loss: 3.300252E+00 | loss scale: 262144.0 | grad norm: 0.724 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 20:29:20] iteration   152400/  500000 | consumed samples:      1219200 | elapsed time per iteration (ms): 322.7 | learning rate: 8.650879E-05 | global batch size:     8 | lm loss: 3.283379E+00 | loss scale: 262144.0 | grad norm: 0.731 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 20:29:53] iteration   152500/  500000 | consumed samples:      1220000 | elapsed time per iteration (ms): 321.9 | learning rate: 8.643968E-05 | global batch size:     8 | lm loss: 3.303648E+00 | loss scale: 262144.0 | grad norm: 0.748 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 20:30:25] iteration   152600/  500000 | consumed samples:      1220800 | elapsed time per iteration (ms): 321.6 | learning rate: 8.637055E-05 | global batch size:     8 | lm loss: 3.265378E+00 | loss scale: 262144.0 | grad norm: 0.679 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 20:30:57] iteration   152700/  500000 | consumed samples:      1221600 | elapsed time per iteration (ms): 322.5 | learning rate: 8.630142E-05 | global batch size:     8 | lm loss: 3.264597E+00 | loss scale: 262144.0 | grad norm: 0.702 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 20:31:29] iteration   152800/  500000 | consumed samples:      1222400 | elapsed time per iteration (ms): 322.9 | learning rate: 8.623228E-05 | global batch size:     8 | lm loss: 3.285168E+00 | loss scale: 262144.0 | grad norm: 0.704 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 20:32:01] iteration   152900/  500000 | consumed samples:      1223200 | elapsed time per iteration (ms): 321.9 | learning rate: 8.616314E-05 | global batch size:     8 | lm loss: 3.270019E+00 | loss scale: 262144.0 | grad norm: 0.756 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 20:32:34] iteration   153000/  500000 | consumed samples:      1224000 | elapsed time per iteration (ms): 323.3 | learning rate: 8.609399E-05 | global batch size:     8 | lm loss: 3.243409E+00 | loss scale: 524288.0 | grad norm: 0.727 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1063.36, 1063.36)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 153000 | lm loss value: 3.790531E+00 | lm loss PPL: 4.427991E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-21 20:33:07] iteration   153100/  500000 | consumed samples:      1224800 | elapsed time per iteration (ms): 323.4 | learning rate: 8.602552E-05 | global batch size:     8 | lm loss: 3.255936E+00 | loss scale: 524288.0 | grad norm: 0.701 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-21 20:33:39] iteration   153200/  500000 | consumed samples:      1225600 | elapsed time per iteration (ms): 318.5 | learning rate: 8.595636E-05 | global batch size:     8 | lm loss: 3.287032E+00 | loss scale: 524288.0 | grad norm: 0.704 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 20:34:11] iteration   153300/  500000 | consumed samples:      1226400 | elapsed time per iteration (ms): 320.9 | learning rate: 8.588788E-05 | global batch size:     8 | lm loss: 3.285937E+00 | loss scale: 262144.0 | grad norm: 0.716 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-21 20:34:43] iteration   153400/  500000 | consumed samples:      1227200 | elapsed time per iteration (ms): 322.2 | learning rate: 8.581940E-05 | global batch size:     8 | lm loss: 3.289017E+00 | loss scale: 131072.0 | grad norm: 0.716 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-21 20:35:16] iteration   153500/  500000 | consumed samples:      1228000 | elapsed time per iteration (ms): 322.6 | learning rate: 8.575022E-05 | global batch size:     8 | lm loss: 3.290312E+00 | loss scale: 131072.0 | grad norm: 0.679 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 20:35:48] iteration   153600/  500000 | consumed samples:      1228800 | elapsed time per iteration (ms): 322.6 | learning rate: 8.568104E-05 | global batch size:     8 | lm loss: 3.263608E+00 | loss scale: 131072.0 | grad norm: 0.729 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 20:36:20] iteration   153700/  500000 | consumed samples:      1229600 | elapsed time per iteration (ms): 321.5 | learning rate: 8.561185E-05 | global batch size:     8 | lm loss: 3.287426E+00 | loss scale: 131072.0 | grad norm: 0.707 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 20:36:52] iteration   153800/  500000 | consumed samples:      1230400 | elapsed time per iteration (ms): 323.1 | learning rate: 8.554265E-05 | global batch size:     8 | lm loss: 3.278880E+00 | loss scale: 131072.0 | grad norm: 0.701 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 20:37:25] iteration   153900/  500000 | consumed samples:      1231200 | elapsed time per iteration (ms): 322.1 | learning rate: 8.547345E-05 | global batch size:     8 | lm loss: 3.290688E+00 | loss scale: 131072.0 | grad norm: 0.754 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 20:37:57] iteration   154000/  500000 | consumed samples:      1232000 | elapsed time per iteration (ms): 321.9 | learning rate: 8.540425E-05 | global batch size:     8 | lm loss: 3.276684E+00 | loss scale: 131072.0 | grad norm: 0.710 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1063.66, 1063.66)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 154000 | lm loss value: 3.674466E+00 | lm loss PPL: 3.942759E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-21 20:38:30] iteration   154100/  500000 | consumed samples:      1232800 | elapsed time per iteration (ms): 322.1 | learning rate: 8.533503E-05 | global batch size:     8 | lm loss: 3.296554E+00 | loss scale: 131072.0 | grad norm: 0.710 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 20:39:02] iteration   154200/  500000 | consumed samples:      1233600 | elapsed time per iteration (ms): 321.6 | learning rate: 8.526582E-05 | global batch size:     8 | lm loss: 3.269213E+00 | loss scale: 131072.0 | grad norm: 0.752 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 20:39:34] iteration   154300/  500000 | consumed samples:      1234400 | elapsed time per iteration (ms): 321.1 | learning rate: 8.519659E-05 | global batch size:     8 | lm loss: 3.257514E+00 | loss scale: 131072.0 | grad norm: 0.709 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 20:40:07] iteration   154400/  500000 | consumed samples:      1235200 | elapsed time per iteration (ms): 322.4 | learning rate: 8.512737E-05 | global batch size:     8 | lm loss: 3.290148E+00 | loss scale: 262144.0 | grad norm: 0.735 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 20:40:39] iteration   154500/  500000 | consumed samples:      1236000 | elapsed time per iteration (ms): 320.6 | learning rate: 8.505813E-05 | global batch size:     8 | lm loss: 3.268991E+00 | loss scale: 262144.0 | grad norm: 0.700 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 20:41:11] iteration   154600/  500000 | consumed samples:      1236800 | elapsed time per iteration (ms): 319.9 | learning rate: 8.498890E-05 | global batch size:     8 | lm loss: 3.295439E+00 | loss scale: 262144.0 | grad norm: 0.716 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 20:41:43] iteration   154700/  500000 | consumed samples:      1237600 | elapsed time per iteration (ms): 323.6 | learning rate: 8.491965E-05 | global batch size:     8 | lm loss: 3.289677E+00 | loss scale: 262144.0 | grad norm: 0.708 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 20:42:15] iteration   154800/  500000 | consumed samples:      1238400 | elapsed time per iteration (ms): 322.5 | learning rate: 8.485041E-05 | global batch size:     8 | lm loss: 3.240302E+00 | loss scale: 262144.0 | grad norm: 0.728 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 20:42:47] iteration   154900/  500000 | consumed samples:      1239200 | elapsed time per iteration (ms): 322.2 | learning rate: 8.478115E-05 | global batch size:     8 | lm loss: 3.257658E+00 | loss scale: 262144.0 | grad norm: 0.739 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 20:43:20] iteration   155000/  500000 | consumed samples:      1240000 | elapsed time per iteration (ms): 322.9 | learning rate: 8.471190E-05 | global batch size:     8 | lm loss: 3.295524E+00 | loss scale: 262144.0 | grad norm: 0.739 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1065.12, 1065.12)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 155000 | lm loss value: 3.587533E+00 | lm loss PPL: 3.614481E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-21 20:43:53] iteration   155100/  500000 | consumed samples:      1240800 | elapsed time per iteration (ms): 323.2 | learning rate: 8.464264E-05 | global batch size:     8 | lm loss: 3.234459E+00 | loss scale: 262144.0 | grad norm: 0.703 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 20:44:25] iteration   155200/  500000 | consumed samples:      1241600 | elapsed time per iteration (ms): 323.7 | learning rate: 8.457337E-05 | global batch size:     8 | lm loss: 3.284434E+00 | loss scale: 262144.0 | grad norm: 0.691 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 20:44:58] iteration   155300/  500000 | consumed samples:      1242400 | elapsed time per iteration (ms): 323.5 | learning rate: 8.450410E-05 | global batch size:     8 | lm loss: 3.247541E+00 | loss scale: 262144.0 | grad norm: 0.716 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 20:45:30] iteration   155400/  500000 | consumed samples:      1243200 | elapsed time per iteration (ms): 319.7 | learning rate: 8.443552E-05 | global batch size:     8 | lm loss: 3.231060E+00 | loss scale: 524288.0 | grad norm: 0.717 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-21 20:46:02] iteration   155500/  500000 | consumed samples:      1244000 | elapsed time per iteration (ms): 322.0 | learning rate: 8.436624E-05 | global batch size:     8 | lm loss: 3.246926E+00 | loss scale: 524288.0 | grad norm: 0.708 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 20:46:34] iteration   155600/  500000 | consumed samples:      1244800 | elapsed time per iteration (ms): 323.1 | learning rate: 8.429696E-05 | global batch size:     8 | lm loss: 3.229255E+00 | loss scale: 524288.0 | grad norm: 0.710 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 20:47:06] iteration   155700/  500000 | consumed samples:      1245600 | elapsed time per iteration (ms): 319.6 | learning rate: 8.422767E-05 | global batch size:     8 | lm loss: 3.250160E+00 | loss scale: 524288.0 | grad norm: 0.719 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 20:47:39] iteration   155800/  500000 | consumed samples:      1246400 | elapsed time per iteration (ms): 323.1 | learning rate: 8.415907E-05 | global batch size:     8 | lm loss: 3.259236E+00 | loss scale: 262144.0 | grad norm: 0.737 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-21 20:48:11] iteration   155900/  500000 | consumed samples:      1247200 | elapsed time per iteration (ms): 323.5 | learning rate: 8.409047E-05 | global batch size:     8 | lm loss: 3.292766E+00 | loss scale: 131072.0 | grad norm: 0.721 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-21 20:48:43] iteration   156000/  500000 | consumed samples:      1248000 | elapsed time per iteration (ms): 323.9 | learning rate: 8.402117E-05 | global batch size:     8 | lm loss: 3.291892E+00 | loss scale: 131072.0 | grad norm: 0.785 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1063.22, 1063.22)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 156000 | lm loss value: 3.655572E+00 | lm loss PPL: 3.868963E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-21 20:49:16] iteration   156100/  500000 | consumed samples:      1248800 | elapsed time per iteration (ms): 320.4 | learning rate: 8.395186E-05 | global batch size:     8 | lm loss: 3.292470E+00 | loss scale: 131072.0 | grad norm: 0.698 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 20:49:49] iteration   156200/  500000 | consumed samples:      1249600 | elapsed time per iteration (ms): 324.8 | learning rate: 8.388255E-05 | global batch size:     8 | lm loss: 3.258022E+00 | loss scale: 131072.0 | grad norm: 0.710 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 20:50:21] iteration   156300/  500000 | consumed samples:      1250400 | elapsed time per iteration (ms): 321.7 | learning rate: 8.381324E-05 | global batch size:     8 | lm loss: 3.296626E+00 | loss scale: 131072.0 | grad norm: 0.755 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 20:50:53] iteration   156400/  500000 | consumed samples:      1251200 | elapsed time per iteration (ms): 323.2 | learning rate: 8.374393E-05 | global batch size:     8 | lm loss: 3.272193E+00 | loss scale: 131072.0 | grad norm: 0.775 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 20:51:26] iteration   156500/  500000 | consumed samples:      1252000 | elapsed time per iteration (ms): 323.3 | learning rate: 8.367530E-05 | global batch size:     8 | lm loss: 3.255484E+00 | loss scale: 65536.0 | grad norm: 0.708 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-21 20:51:58] iteration   156600/  500000 | consumed samples:      1252800 | elapsed time per iteration (ms): 322.1 | learning rate: 8.360598E-05 | global batch size:     8 | lm loss: 3.263429E+00 | loss scale: 65536.0 | grad norm: 0.786 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 20:52:30] iteration   156700/  500000 | consumed samples:      1253600 | elapsed time per iteration (ms): 321.5 | learning rate: 8.353665E-05 | global batch size:     8 | lm loss: 3.246513E+00 | loss scale: 65536.0 | grad norm: 0.719 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 20:53:02] iteration   156800/  500000 | consumed samples:      1254400 | elapsed time per iteration (ms): 322.9 | learning rate: 8.346732E-05 | global batch size:     8 | lm loss: 3.232174E+00 | loss scale: 65536.0 | grad norm: 0.738 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 20:53:35] iteration   156900/  500000 | consumed samples:      1255200 | elapsed time per iteration (ms): 321.6 | learning rate: 8.339799E-05 | global batch size:     8 | lm loss: 3.281763E+00 | loss scale: 65536.0 | grad norm: 0.733 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 20:54:07] iteration   157000/  500000 | consumed samples:      1256000 | elapsed time per iteration (ms): 321.9 | learning rate: 8.332865E-05 | global batch size:     8 | lm loss: 3.278348E+00 | loss scale: 65536.0 | grad norm: 0.726 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1065.37, 1065.37)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 157000 | lm loss value: 3.693356E+00 | lm loss PPL: 4.017947E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-21 20:54:40] iteration   157100/  500000 | consumed samples:      1256800 | elapsed time per iteration (ms): 320.2 | learning rate: 8.325931E-05 | global batch size:     8 | lm loss: 3.320110E+00 | loss scale: 65536.0 | grad norm: 0.720 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 20:55:12] iteration   157200/  500000 | consumed samples:      1257600 | elapsed time per iteration (ms): 322.2 | learning rate: 8.318997E-05 | global batch size:     8 | lm loss: 3.256609E+00 | loss scale: 65536.0 | grad norm: 0.718 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 20:55:44] iteration   157300/  500000 | consumed samples:      1258400 | elapsed time per iteration (ms): 321.2 | learning rate: 8.312063E-05 | global batch size:     8 | lm loss: 3.247427E+00 | loss scale: 65536.0 | grad norm: 0.761 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 20:56:16] iteration   157400/  500000 | consumed samples:      1259200 | elapsed time per iteration (ms): 320.8 | learning rate: 8.305128E-05 | global batch size:     8 | lm loss: 3.249298E+00 | loss scale: 65536.0 | grad norm: 0.710 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 20:56:49] iteration   157500/  500000 | consumed samples:      1260000 | elapsed time per iteration (ms): 323.4 | learning rate: 8.298192E-05 | global batch size:     8 | lm loss: 3.260218E+00 | loss scale: 131072.0 | grad norm: 0.734 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 20:57:21] iteration   157600/  500000 | consumed samples:      1260800 | elapsed time per iteration (ms): 321.0 | learning rate: 8.291257E-05 | global batch size:     8 | lm loss: 3.293056E+00 | loss scale: 131072.0 | grad norm: 0.712 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 20:57:53] iteration   157700/  500000 | consumed samples:      1261600 | elapsed time per iteration (ms): 322.5 | learning rate: 8.284321E-05 | global batch size:     8 | lm loss: 3.297820E+00 | loss scale: 131072.0 | grad norm: 0.716 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 20:58:25] iteration   157800/  500000 | consumed samples:      1262400 | elapsed time per iteration (ms): 321.6 | learning rate: 8.277385E-05 | global batch size:     8 | lm loss: 3.229439E+00 | loss scale: 131072.0 | grad norm: 0.713 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 20:58:57] iteration   157900/  500000 | consumed samples:      1263200 | elapsed time per iteration (ms): 322.5 | learning rate: 8.270449E-05 | global batch size:     8 | lm loss: 3.261949E+00 | loss scale: 131072.0 | grad norm: 0.690 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 20:59:29] iteration   158000/  500000 | consumed samples:      1264000 | elapsed time per iteration (ms): 320.8 | learning rate: 8.263582E-05 | global batch size:     8 | lm loss: 3.285501E+00 | loss scale: 131072.0 | grad norm: 0.754 | number of skipped iterations:   1 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1065.93, 1065.93)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 158000 | lm loss value: 3.715979E+00 | lm loss PPL: 4.109882E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-21 21:00:03] iteration   158100/  500000 | consumed samples:      1264800 | elapsed time per iteration (ms): 321.5 | learning rate: 8.256645E-05 | global batch size:     8 | lm loss: 3.243869E+00 | loss scale: 131072.0 | grad norm: 0.756 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 21:00:35] iteration   158200/  500000 | consumed samples:      1265600 | elapsed time per iteration (ms): 321.4 | learning rate: 8.249708E-05 | global batch size:     8 | lm loss: 3.231199E+00 | loss scale: 131072.0 | grad norm: 0.727 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 21:01:07] iteration   158300/  500000 | consumed samples:      1266400 | elapsed time per iteration (ms): 324.6 | learning rate: 8.242770E-05 | global batch size:     8 | lm loss: 3.302831E+00 | loss scale: 131072.0 | grad norm: 0.730 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 21:01:39] iteration   158400/  500000 | consumed samples:      1267200 | elapsed time per iteration (ms): 321.1 | learning rate: 8.235833E-05 | global batch size:     8 | lm loss: 3.290395E+00 | loss scale: 131072.0 | grad norm: 0.749 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 21:02:11] iteration   158500/  500000 | consumed samples:      1268000 | elapsed time per iteration (ms): 319.9 | learning rate: 8.228895E-05 | global batch size:     8 | lm loss: 3.226546E+00 | loss scale: 131072.0 | grad norm: 0.777 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 21:02:44] iteration   158600/  500000 | consumed samples:      1268800 | elapsed time per iteration (ms): 322.0 | learning rate: 8.221957E-05 | global batch size:     8 | lm loss: 3.315995E+00 | loss scale: 131072.0 | grad norm: 0.737 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 21:03:16] iteration   158700/  500000 | consumed samples:      1269600 | elapsed time per iteration (ms): 321.0 | learning rate: 8.215019E-05 | global batch size:     8 | lm loss: 3.271058E+00 | loss scale: 131072.0 | grad norm: 0.724 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 21:03:48] iteration   158800/  500000 | consumed samples:      1270400 | elapsed time per iteration (ms): 322.2 | learning rate: 8.208080E-05 | global batch size:     8 | lm loss: 3.279869E+00 | loss scale: 131072.0 | grad norm: 0.725 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 21:04:20] iteration   158900/  500000 | consumed samples:      1271200 | elapsed time per iteration (ms): 320.2 | learning rate: 8.201141E-05 | global batch size:     8 | lm loss: 3.213936E+00 | loss scale: 131072.0 | grad norm: 0.724 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 21:04:52] iteration   159000/  500000 | consumed samples:      1272000 | elapsed time per iteration (ms): 320.7 | learning rate: 8.194202E-05 | global batch size:     8 | lm loss: 3.305515E+00 | loss scale: 262144.0 | grad norm: 0.759 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1064.89, 1064.89)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 159000 | lm loss value: 3.571210E+00 | lm loss PPL: 3.555958E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-21 21:05:25] iteration   159100/  500000 | consumed samples:      1272800 | elapsed time per iteration (ms): 321.1 | learning rate: 8.187333E-05 | global batch size:     8 | lm loss: 3.239581E+00 | loss scale: 262144.0 | grad norm: 0.742 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-21 21:05:57] iteration   159200/  500000 | consumed samples:      1273600 | elapsed time per iteration (ms): 323.4 | learning rate: 8.180394E-05 | global batch size:     8 | lm loss: 3.258373E+00 | loss scale: 262144.0 | grad norm: 0.706 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 21:06:30] iteration   159300/  500000 | consumed samples:      1274400 | elapsed time per iteration (ms): 323.6 | learning rate: 8.173454E-05 | global batch size:     8 | lm loss: 3.286357E+00 | loss scale: 262144.0 | grad norm: 0.713 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 21:07:02] iteration   159400/  500000 | consumed samples:      1275200 | elapsed time per iteration (ms): 324.2 | learning rate: 8.166514E-05 | global batch size:     8 | lm loss: 3.221500E+00 | loss scale: 262144.0 | grad norm: 0.757 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 21:07:35] iteration   159500/  500000 | consumed samples:      1276000 | elapsed time per iteration (ms): 322.7 | learning rate: 8.159575E-05 | global batch size:     8 | lm loss: 3.227232E+00 | loss scale: 262144.0 | grad norm: 0.812 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 21:08:07] iteration   159600/  500000 | consumed samples:      1276800 | elapsed time per iteration (ms): 321.0 | learning rate: 8.152704E-05 | global batch size:     8 | lm loss: 3.301694E+00 | loss scale: 131072.0 | grad norm: 0.705 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-21 21:08:39] iteration   159700/  500000 | consumed samples:      1277600 | elapsed time per iteration (ms): 324.6 | learning rate: 8.145764E-05 | global batch size:     8 | lm loss: 3.244269E+00 | loss scale: 131072.0 | grad norm: 0.746 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 21:09:11] iteration   159800/  500000 | consumed samples:      1278400 | elapsed time per iteration (ms): 322.1 | learning rate: 8.138824E-05 | global batch size:     8 | lm loss: 3.261637E+00 | loss scale: 131072.0 | grad norm: 0.719 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 21:09:44] iteration   159900/  500000 | consumed samples:      1279200 | elapsed time per iteration (ms): 323.2 | learning rate: 8.131884E-05 | global batch size:     8 | lm loss: 3.195660E+00 | loss scale: 131072.0 | grad norm: 0.691 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 21:10:16] iteration   160000/  500000 | consumed samples:      1280000 | elapsed time per iteration (ms): 323.7 | learning rate: 8.124943E-05 | global batch size:     8 | lm loss: 3.253007E+00 | loss scale: 131072.0 | grad norm: 0.784 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1065.23, 1065.23)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 160000 | lm loss value: 3.734634E+00 | lm loss PPL: 4.187270E+01 | 
--------------------------------------------------------------------------------------------------
saving checkpoint at iteration  160000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-max in torch format
  successfully saved checkpoint at iteration  160000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-max
(min, max) time across ranks (ms):
    save-checkpoint ................................: (5793.16, 5793.16)
 [2024-06-21 21:10:55] iteration   160100/  500000 | consumed samples:      1280800 | elapsed time per iteration (ms): 321.3 | learning rate: 8.118002E-05 | global batch size:     8 | lm loss: 3.227036E+00 | loss scale: 131072.0 | grad norm: 0.754 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 21:11:27] iteration   160200/  500000 | consumed samples:      1281600 | elapsed time per iteration (ms): 322.7 | learning rate: 8.111062E-05 | global batch size:     8 | lm loss: 3.285930E+00 | loss scale: 131072.0 | grad norm: 0.738 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 21:11:59] iteration   160300/  500000 | consumed samples:      1282400 | elapsed time per iteration (ms): 322.3 | learning rate: 8.104121E-05 | global batch size:     8 | lm loss: 3.269489E+00 | loss scale: 131072.0 | grad norm: 0.782 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 21:12:32] iteration   160400/  500000 | consumed samples:      1283200 | elapsed time per iteration (ms): 325.3 | learning rate: 8.097180E-05 | global batch size:     8 | lm loss: 3.227033E+00 | loss scale: 131072.0 | grad norm: 0.717 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 21:13:04] iteration   160500/  500000 | consumed samples:      1284000 | elapsed time per iteration (ms): 322.0 | learning rate: 8.090239E-05 | global batch size:     8 | lm loss: 3.237401E+00 | loss scale: 131072.0 | grad norm: 0.750 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 21:13:36] iteration   160600/  500000 | consumed samples:      1284800 | elapsed time per iteration (ms): 322.1 | learning rate: 8.083298E-05 | global batch size:     8 | lm loss: 3.266829E+00 | loss scale: 262144.0 | grad norm: 0.717 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 21:14:09] iteration   160700/  500000 | consumed samples:      1285600 | elapsed time per iteration (ms): 321.6 | learning rate: 8.076357E-05 | global batch size:     8 | lm loss: 3.276396E+00 | loss scale: 262144.0 | grad norm: 0.714 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 21:14:41] iteration   160800/  500000 | consumed samples:      1286400 | elapsed time per iteration (ms): 321.1 | learning rate: 8.069415E-05 | global batch size:     8 | lm loss: 3.237601E+00 | loss scale: 262144.0 | grad norm: 0.746 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 21:15:13] iteration   160900/  500000 | consumed samples:      1287200 | elapsed time per iteration (ms): 324.2 | learning rate: 8.062474E-05 | global batch size:     8 | lm loss: 3.216736E+00 | loss scale: 262144.0 | grad norm: 0.756 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 21:15:46] iteration   161000/  500000 | consumed samples:      1288000 | elapsed time per iteration (ms): 325.2 | learning rate: 8.055533E-05 | global batch size:     8 | lm loss: 3.265594E+00 | loss scale: 262144.0 | grad norm: 0.746 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1063.01, 1063.01)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 161000 | lm loss value: 3.668955E+00 | lm loss PPL: 3.921092E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-21 21:16:19] iteration   161100/  500000 | consumed samples:      1288800 | elapsed time per iteration (ms): 323.5 | learning rate: 8.048591E-05 | global batch size:     8 | lm loss: 3.243913E+00 | loss scale: 262144.0 | grad norm: 0.722 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 21:16:51] iteration   161200/  500000 | consumed samples:      1289600 | elapsed time per iteration (ms): 324.1 | learning rate: 8.041650E-05 | global batch size:     8 | lm loss: 3.293188E+00 | loss scale: 262144.0 | grad norm: 0.734 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 21:17:24] iteration   161300/  500000 | consumed samples:      1290400 | elapsed time per iteration (ms): 322.9 | learning rate: 8.034708E-05 | global batch size:     8 | lm loss: 3.237769E+00 | loss scale: 262144.0 | grad norm: 0.750 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 21:17:56] iteration   161400/  500000 | consumed samples:      1291200 | elapsed time per iteration (ms): 320.3 | learning rate: 8.027767E-05 | global batch size:     8 | lm loss: 3.272779E+00 | loss scale: 262144.0 | grad norm: 0.736 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 21:18:28] iteration   161500/  500000 | consumed samples:      1292000 | elapsed time per iteration (ms): 325.0 | learning rate: 8.020825E-05 | global batch size:     8 | lm loss: 3.235847E+00 | loss scale: 262144.0 | grad norm: 0.702 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 21:19:00] iteration   161600/  500000 | consumed samples:      1292800 | elapsed time per iteration (ms): 321.5 | learning rate: 8.013883E-05 | global batch size:     8 | lm loss: 3.290241E+00 | loss scale: 524288.0 | grad norm: 0.700 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 21:19:33] iteration   161700/  500000 | consumed samples:      1293600 | elapsed time per iteration (ms): 324.1 | learning rate: 8.006942E-05 | global batch size:     8 | lm loss: 3.254466E+00 | loss scale: 524288.0 | grad norm: 0.709 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 21:20:05] iteration   161800/  500000 | consumed samples:      1294400 | elapsed time per iteration (ms): 322.7 | learning rate: 8.000000E-05 | global batch size:     8 | lm loss: 3.258351E+00 | loss scale: 524288.0 | grad norm: 0.697 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 21:20:37] iteration   161900/  500000 | consumed samples:      1295200 | elapsed time per iteration (ms): 322.4 | learning rate: 7.993058E-05 | global batch size:     8 | lm loss: 3.279642E+00 | loss scale: 524288.0 | grad norm: 0.744 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 21:21:10] iteration   162000/  500000 | consumed samples:      1296000 | elapsed time per iteration (ms): 324.0 | learning rate: 7.986117E-05 | global batch size:     8 | lm loss: 3.211653E+00 | loss scale: 524288.0 | grad norm: 0.727 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1064.38, 1064.38)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 162000 | lm loss value: 3.684280E+00 | lm loss PPL: 3.981643E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-21 21:21:43] iteration   162100/  500000 | consumed samples:      1296800 | elapsed time per iteration (ms): 320.8 | learning rate: 7.979175E-05 | global batch size:     8 | lm loss: 3.237188E+00 | loss scale: 524288.0 | grad norm: 0.727 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 21:22:15] iteration   162200/  500000 | consumed samples:      1297600 | elapsed time per iteration (ms): 320.9 | learning rate: 7.972233E-05 | global batch size:     8 | lm loss: 3.241794E+00 | loss scale: 524288.0 | grad norm: 0.732 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 21:22:47] iteration   162300/  500000 | consumed samples:      1298400 | elapsed time per iteration (ms): 324.5 | learning rate: 7.965292E-05 | global batch size:     8 | lm loss: 3.230346E+00 | loss scale: 524288.0 | grad norm: 0.725 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 21:23:20] iteration   162400/  500000 | consumed samples:      1299200 | elapsed time per iteration (ms): 321.0 | learning rate: 7.958350E-05 | global batch size:     8 | lm loss: 3.226695E+00 | loss scale: 524288.0 | grad norm: 0.766 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 21:23:52] iteration   162500/  500000 | consumed samples:      1300000 | elapsed time per iteration (ms): 322.4 | learning rate: 7.951409E-05 | global batch size:     8 | lm loss: 3.248781E+00 | loss scale: 524288.0 | grad norm: 0.740 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 21:24:24] iteration   162600/  500000 | consumed samples:      1300800 | elapsed time per iteration (ms): 323.0 | learning rate: 7.944467E-05 | global batch size:     8 | lm loss: 3.260955E+00 | loss scale: 1048576.0 | grad norm: 0.709 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 21:24:56] iteration   162700/  500000 | consumed samples:      1301600 | elapsed time per iteration (ms): 322.5 | learning rate: 7.937665E-05 | global batch size:     8 | lm loss: 3.294249E+00 | loss scale: 524288.0 | grad norm: 0.740 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-21 21:25:29] iteration   162800/  500000 | consumed samples:      1302400 | elapsed time per iteration (ms): 322.6 | learning rate: 7.930723E-05 | global batch size:     8 | lm loss: 3.245126E+00 | loss scale: 524288.0 | grad norm: 0.739 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 21:26:01] iteration   162900/  500000 | consumed samples:      1303200 | elapsed time per iteration (ms): 321.7 | learning rate: 7.923782E-05 | global batch size:     8 | lm loss: 3.245181E+00 | loss scale: 524288.0 | grad norm: 0.740 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 21:26:33] iteration   163000/  500000 | consumed samples:      1304000 | elapsed time per iteration (ms): 322.6 | learning rate: 7.916841E-05 | global batch size:     8 | lm loss: 3.230386E+00 | loss scale: 524288.0 | grad norm: 0.784 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1065.04, 1065.04)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 163000 | lm loss value: 3.779563E+00 | lm loss PPL: 4.379689E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-21 21:27:06] iteration   163100/  500000 | consumed samples:      1304800 | elapsed time per iteration (ms): 323.0 | learning rate: 7.909900E-05 | global batch size:     8 | lm loss: 3.228679E+00 | loss scale: 524288.0 | grad norm: 0.751 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 21:27:39] iteration   163200/  500000 | consumed samples:      1305600 | elapsed time per iteration (ms): 323.2 | learning rate: 7.902959E-05 | global batch size:     8 | lm loss: 3.273410E+00 | loss scale: 524288.0 | grad norm: 0.703 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 21:28:11] iteration   163300/  500000 | consumed samples:      1306400 | elapsed time per iteration (ms): 322.0 | learning rate: 7.896018E-05 | global batch size:     8 | lm loss: 3.270457E+00 | loss scale: 524288.0 | grad norm: 0.733 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 21:28:43] iteration   163400/  500000 | consumed samples:      1307200 | elapsed time per iteration (ms): 322.4 | learning rate: 7.889077E-05 | global batch size:     8 | lm loss: 3.254837E+00 | loss scale: 524288.0 | grad norm: 0.746 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 21:29:15] iteration   163500/  500000 | consumed samples:      1308000 | elapsed time per iteration (ms): 319.1 | learning rate: 7.882206E-05 | global batch size:     8 | lm loss: 3.297475E+00 | loss scale: 262144.0 | grad norm: 0.727 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-21 21:29:47] iteration   163600/  500000 | consumed samples:      1308800 | elapsed time per iteration (ms): 323.2 | learning rate: 7.875265E-05 | global batch size:     8 | lm loss: 3.231552E+00 | loss scale: 262144.0 | grad norm: 0.757 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 21:30:20] iteration   163700/  500000 | consumed samples:      1309600 | elapsed time per iteration (ms): 323.9 | learning rate: 7.868325E-05 | global batch size:     8 | lm loss: 3.229192E+00 | loss scale: 262144.0 | grad norm: 0.735 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 21:30:52] iteration   163800/  500000 | consumed samples:      1310400 | elapsed time per iteration (ms): 320.6 | learning rate: 7.861384E-05 | global batch size:     8 | lm loss: 3.287607E+00 | loss scale: 262144.0 | grad norm: 0.746 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 21:31:24] iteration   163900/  500000 | consumed samples:      1311200 | elapsed time per iteration (ms): 324.4 | learning rate: 7.854444E-05 | global batch size:     8 | lm loss: 3.249391E+00 | loss scale: 262144.0 | grad norm: 0.738 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 21:31:56] iteration   164000/  500000 | consumed samples:      1312000 | elapsed time per iteration (ms): 321.5 | learning rate: 7.847504E-05 | global batch size:     8 | lm loss: 3.241181E+00 | loss scale: 262144.0 | grad norm: 0.773 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1065.18, 1065.18)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 164000 | lm loss value: 3.698607E+00 | lm loss PPL: 4.039101E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-21 21:32:30] iteration   164100/  500000 | consumed samples:      1312800 | elapsed time per iteration (ms): 321.1 | learning rate: 7.840564E-05 | global batch size:     8 | lm loss: 3.176900E+00 | loss scale: 262144.0 | grad norm: 0.732 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 21:33:02] iteration   164200/  500000 | consumed samples:      1313600 | elapsed time per iteration (ms): 323.4 | learning rate: 7.833624E-05 | global batch size:     8 | lm loss: 3.233311E+00 | loss scale: 262144.0 | grad norm: 0.728 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 21:33:34] iteration   164300/  500000 | consumed samples:      1314400 | elapsed time per iteration (ms): 322.5 | learning rate: 7.826685E-05 | global batch size:     8 | lm loss: 3.282850E+00 | loss scale: 262144.0 | grad norm: 0.750 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 21:34:07] iteration   164400/  500000 | consumed samples:      1315200 | elapsed time per iteration (ms): 323.3 | learning rate: 7.819745E-05 | global batch size:     8 | lm loss: 3.295966E+00 | loss scale: 262144.0 | grad norm: 0.706 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 21:34:39] iteration   164500/  500000 | consumed samples:      1316000 | elapsed time per iteration (ms): 323.8 | learning rate: 7.812806E-05 | global batch size:     8 | lm loss: 3.201539E+00 | loss scale: 524288.0 | grad norm: 0.751 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 21:35:11] iteration   164600/  500000 | consumed samples:      1316800 | elapsed time per iteration (ms): 320.9 | learning rate: 7.806006E-05 | global batch size:     8 | lm loss: 3.248869E+00 | loss scale: 262144.0 | grad norm: 0.727 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-21 21:35:43] iteration   164700/  500000 | consumed samples:      1317600 | elapsed time per iteration (ms): 323.0 | learning rate: 7.799067E-05 | global batch size:     8 | lm loss: 3.194072E+00 | loss scale: 262144.0 | grad norm: 0.717 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 21:36:16] iteration   164800/  500000 | consumed samples:      1318400 | elapsed time per iteration (ms): 322.6 | learning rate: 7.792128E-05 | global batch size:     8 | lm loss: 3.239121E+00 | loss scale: 262144.0 | grad norm: 0.761 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 21:36:48] iteration   164900/  500000 | consumed samples:      1319200 | elapsed time per iteration (ms): 323.8 | learning rate: 7.785190E-05 | global batch size:     8 | lm loss: 3.274346E+00 | loss scale: 262144.0 | grad norm: 0.770 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 21:37:20] iteration   165000/  500000 | consumed samples:      1320000 | elapsed time per iteration (ms): 324.0 | learning rate: 7.778251E-05 | global batch size:     8 | lm loss: 3.275716E+00 | loss scale: 262144.0 | grad norm: 0.704 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1064.23, 1064.23)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 165000 | lm loss value: 3.698538E+00 | lm loss PPL: 4.038820E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-21 21:37:54] iteration   165100/  500000 | consumed samples:      1320800 | elapsed time per iteration (ms): 323.2 | learning rate: 7.771313E-05 | global batch size:     8 | lm loss: 3.256004E+00 | loss scale: 262144.0 | grad norm: 0.772 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 21:38:26] iteration   165200/  500000 | consumed samples:      1321600 | elapsed time per iteration (ms): 322.8 | learning rate: 7.764445E-05 | global batch size:     8 | lm loss: 3.244953E+00 | loss scale: 131072.0 | grad norm: 0.770 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-21 21:38:58] iteration   165300/  500000 | consumed samples:      1322400 | elapsed time per iteration (ms): 323.3 | learning rate: 7.757507E-05 | global batch size:     8 | lm loss: 3.243780E+00 | loss scale: 131072.0 | grad norm: 0.741 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 21:39:31] iteration   165400/  500000 | consumed samples:      1323200 | elapsed time per iteration (ms): 323.1 | learning rate: 7.750570E-05 | global batch size:     8 | lm loss: 3.272492E+00 | loss scale: 131072.0 | grad norm: 0.699 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 21:40:03] iteration   165500/  500000 | consumed samples:      1324000 | elapsed time per iteration (ms): 322.0 | learning rate: 7.743633E-05 | global batch size:     8 | lm loss: 3.248896E+00 | loss scale: 131072.0 | grad norm: 0.787 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 21:40:35] iteration   165600/  500000 | consumed samples:      1324800 | elapsed time per iteration (ms): 321.6 | learning rate: 7.736696E-05 | global batch size:     8 | lm loss: 3.239569E+00 | loss scale: 131072.0 | grad norm: 0.703 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 21:41:07] iteration   165700/  500000 | consumed samples:      1325600 | elapsed time per iteration (ms): 322.0 | learning rate: 7.729759E-05 | global batch size:     8 | lm loss: 3.185748E+00 | loss scale: 131072.0 | grad norm: 0.703 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 21:41:39] iteration   165800/  500000 | consumed samples:      1326400 | elapsed time per iteration (ms): 321.1 | learning rate: 7.722823E-05 | global batch size:     8 | lm loss: 3.223260E+00 | loss scale: 131072.0 | grad norm: 0.746 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 21:42:12] iteration   165900/  500000 | consumed samples:      1327200 | elapsed time per iteration (ms): 324.0 | learning rate: 7.715887E-05 | global batch size:     8 | lm loss: 3.211963E+00 | loss scale: 131072.0 | grad norm: 0.766 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 21:42:44] iteration   166000/  500000 | consumed samples:      1328000 | elapsed time per iteration (ms): 321.3 | learning rate: 7.708951E-05 | global batch size:     8 | lm loss: 3.232379E+00 | loss scale: 131072.0 | grad norm: 0.851 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1063.92, 1063.92)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 166000 | lm loss value: 3.668926E+00 | lm loss PPL: 3.920975E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-21 21:43:17] iteration   166100/  500000 | consumed samples:      1328800 | elapsed time per iteration (ms): 323.0 | learning rate: 7.702016E-05 | global batch size:     8 | lm loss: 3.288571E+00 | loss scale: 131072.0 | grad norm: 0.704 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 21:43:49] iteration   166200/  500000 | consumed samples:      1329600 | elapsed time per iteration (ms): 321.9 | learning rate: 7.695080E-05 | global batch size:     8 | lm loss: 3.233156E+00 | loss scale: 262144.0 | grad norm: 0.715 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 21:44:21] iteration   166300/  500000 | consumed samples:      1330400 | elapsed time per iteration (ms): 319.4 | learning rate: 7.688145E-05 | global batch size:     8 | lm loss: 3.258925E+00 | loss scale: 262144.0 | grad norm: 0.798 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 21:44:53] iteration   166400/  500000 | consumed samples:      1331200 | elapsed time per iteration (ms): 321.2 | learning rate: 7.681211E-05 | global batch size:     8 | lm loss: 3.215607E+00 | loss scale: 262144.0 | grad norm: 0.737 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 21:45:26] iteration   166500/  500000 | consumed samples:      1332000 | elapsed time per iteration (ms): 324.4 | learning rate: 7.674277E-05 | global batch size:     8 | lm loss: 3.246098E+00 | loss scale: 262144.0 | grad norm: 0.726 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 21:45:58] iteration   166600/  500000 | consumed samples:      1332800 | elapsed time per iteration (ms): 323.3 | learning rate: 7.667343E-05 | global batch size:     8 | lm loss: 3.257509E+00 | loss scale: 262144.0 | grad norm: 0.778 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 21:46:30] iteration   166700/  500000 | consumed samples:      1333600 | elapsed time per iteration (ms): 322.8 | learning rate: 7.660409E-05 | global batch size:     8 | lm loss: 3.248026E+00 | loss scale: 262144.0 | grad norm: 0.750 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 21:47:03] iteration   166800/  500000 | consumed samples:      1334400 | elapsed time per iteration (ms): 321.1 | learning rate: 7.653476E-05 | global batch size:     8 | lm loss: 3.250010E+00 | loss scale: 262144.0 | grad norm: 0.668 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 21:47:35] iteration   166900/  500000 | consumed samples:      1335200 | elapsed time per iteration (ms): 321.8 | learning rate: 7.646543E-05 | global batch size:     8 | lm loss: 3.228603E+00 | loss scale: 262144.0 | grad norm: 0.735 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 21:48:07] iteration   167000/  500000 | consumed samples:      1336000 | elapsed time per iteration (ms): 323.3 | learning rate: 7.639610E-05 | global batch size:     8 | lm loss: 3.262568E+00 | loss scale: 262144.0 | grad norm: 0.742 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1067.89, 1067.89)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 167000 | lm loss value: 3.585521E+00 | lm loss PPL: 3.607216E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-21 21:48:41] iteration   167100/  500000 | consumed samples:      1336800 | elapsed time per iteration (ms): 323.6 | learning rate: 7.632678E-05 | global batch size:     8 | lm loss: 3.195403E+00 | loss scale: 262144.0 | grad norm: 0.744 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 21:49:13] iteration   167200/  500000 | consumed samples:      1337600 | elapsed time per iteration (ms): 321.1 | learning rate: 7.625746E-05 | global batch size:     8 | lm loss: 3.258710E+00 | loss scale: 524288.0 | grad norm: 0.731 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 21:49:45] iteration   167300/  500000 | consumed samples:      1338400 | elapsed time per iteration (ms): 322.9 | learning rate: 7.618814E-05 | global batch size:     8 | lm loss: 3.258303E+00 | loss scale: 524288.0 | grad norm: 0.750 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 21:50:17] iteration   167400/  500000 | consumed samples:      1339200 | elapsed time per iteration (ms): 322.5 | learning rate: 7.611883E-05 | global batch size:     8 | lm loss: 3.244121E+00 | loss scale: 524288.0 | grad norm: 0.704 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 21:50:50] iteration   167500/  500000 | consumed samples:      1340000 | elapsed time per iteration (ms): 323.3 | learning rate: 7.605022E-05 | global batch size:     8 | lm loss: 3.216531E+00 | loss scale: 524288.0 | grad norm: 0.761 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-21 21:51:21] iteration   167600/  500000 | consumed samples:      1340800 | elapsed time per iteration (ms): 319.3 | learning rate: 7.598161E-05 | global batch size:     8 | lm loss: 3.286788E+00 | loss scale: 262144.0 | grad norm: 0.735 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-21 21:51:54] iteration   167700/  500000 | consumed samples:      1341600 | elapsed time per iteration (ms): 323.8 | learning rate: 7.591231E-05 | global batch size:     8 | lm loss: 3.176589E+00 | loss scale: 262144.0 | grad norm: 0.733 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 21:52:26] iteration   167800/  500000 | consumed samples:      1342400 | elapsed time per iteration (ms): 320.5 | learning rate: 7.584301E-05 | global batch size:     8 | lm loss: 3.205385E+00 | loss scale: 262144.0 | grad norm: 0.760 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 21:52:58] iteration   167900/  500000 | consumed samples:      1343200 | elapsed time per iteration (ms): 320.0 | learning rate: 7.577372E-05 | global batch size:     8 | lm loss: 3.224601E+00 | loss scale: 262144.0 | grad norm: 0.713 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 21:53:30] iteration   168000/  500000 | consumed samples:      1344000 | elapsed time per iteration (ms): 320.6 | learning rate: 7.570512E-05 | global batch size:     8 | lm loss: 3.221324E+00 | loss scale: 131072.0 | grad norm: 0.716 | number of skipped iterations:   1 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1063.18, 1063.18)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 168000 | lm loss value: 3.775080E+00 | lm loss PPL: 4.360101E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-21 21:54:03] iteration   168100/  500000 | consumed samples:      1344800 | elapsed time per iteration (ms): 323.5 | learning rate: 7.563584E-05 | global batch size:     8 | lm loss: 3.210768E+00 | loss scale: 131072.0 | grad norm: 0.753 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 21:54:36] iteration   168200/  500000 | consumed samples:      1345600 | elapsed time per iteration (ms): 322.2 | learning rate: 7.556656E-05 | global batch size:     8 | lm loss: 3.254361E+00 | loss scale: 131072.0 | grad norm: 0.754 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 21:55:08] iteration   168300/  500000 | consumed samples:      1346400 | elapsed time per iteration (ms): 323.3 | learning rate: 7.549729E-05 | global batch size:     8 | lm loss: 3.245161E+00 | loss scale: 131072.0 | grad norm: 0.769 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 21:55:40] iteration   168400/  500000 | consumed samples:      1347200 | elapsed time per iteration (ms): 321.9 | learning rate: 7.542802E-05 | global batch size:     8 | lm loss: 3.228421E+00 | loss scale: 131072.0 | grad norm: 0.756 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 21:56:12] iteration   168500/  500000 | consumed samples:      1348000 | elapsed time per iteration (ms): 323.6 | learning rate: 7.535875E-05 | global batch size:     8 | lm loss: 3.213808E+00 | loss scale: 131072.0 | grad norm: 0.766 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 21:56:45] iteration   168600/  500000 | consumed samples:      1348800 | elapsed time per iteration (ms): 324.1 | learning rate: 7.528949E-05 | global batch size:     8 | lm loss: 3.219946E+00 | loss scale: 131072.0 | grad norm: 0.729 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 21:57:17] iteration   168700/  500000 | consumed samples:      1349600 | elapsed time per iteration (ms): 320.9 | learning rate: 7.522023E-05 | global batch size:     8 | lm loss: 3.231120E+00 | loss scale: 131072.0 | grad norm: 0.794 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 21:57:49] iteration   168800/  500000 | consumed samples:      1350400 | elapsed time per iteration (ms): 322.5 | learning rate: 7.515098E-05 | global batch size:     8 | lm loss: 3.224971E+00 | loss scale: 131072.0 | grad norm: 0.802 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 21:58:21] iteration   168900/  500000 | consumed samples:      1351200 | elapsed time per iteration (ms): 321.3 | learning rate: 7.508173E-05 | global batch size:     8 | lm loss: 3.219752E+00 | loss scale: 131072.0 | grad norm: 0.752 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 21:58:54] iteration   169000/  500000 | consumed samples:      1352000 | elapsed time per iteration (ms): 322.8 | learning rate: 7.501249E-05 | global batch size:     8 | lm loss: 3.218520E+00 | loss scale: 262144.0 | grad norm: 0.703 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1063.89, 1063.89)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 169000 | lm loss value: 3.687958E+00 | lm loss PPL: 3.996317E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-21 21:59:27] iteration   169100/  500000 | consumed samples:      1352800 | elapsed time per iteration (ms): 320.6 | learning rate: 7.494394E-05 | global batch size:     8 | lm loss: 3.185101E+00 | loss scale: 262144.0 | grad norm: 0.749 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-21 21:59:59] iteration   169200/  500000 | consumed samples:      1353600 | elapsed time per iteration (ms): 321.9 | learning rate: 7.487471E-05 | global batch size:     8 | lm loss: 3.212589E+00 | loss scale: 262144.0 | grad norm: 0.738 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 22:00:31] iteration   169300/  500000 | consumed samples:      1354400 | elapsed time per iteration (ms): 320.1 | learning rate: 7.480548E-05 | global batch size:     8 | lm loss: 3.218175E+00 | loss scale: 262144.0 | grad norm: 0.734 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 22:01:03] iteration   169400/  500000 | consumed samples:      1355200 | elapsed time per iteration (ms): 323.8 | learning rate: 7.473626E-05 | global batch size:     8 | lm loss: 3.232878E+00 | loss scale: 262144.0 | grad norm: 0.728 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 22:01:35] iteration   169500/  500000 | consumed samples:      1356000 | elapsed time per iteration (ms): 321.3 | learning rate: 7.466704E-05 | global batch size:     8 | lm loss: 3.196542E+00 | loss scale: 262144.0 | grad norm: 0.735 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 22:02:08] iteration   169600/  500000 | consumed samples:      1356800 | elapsed time per iteration (ms): 321.3 | learning rate: 7.459783E-05 | global batch size:     8 | lm loss: 3.234474E+00 | loss scale: 262144.0 | grad norm: 0.784 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 22:02:40] iteration   169700/  500000 | consumed samples:      1357600 | elapsed time per iteration (ms): 320.9 | learning rate: 7.452862E-05 | global batch size:     8 | lm loss: 3.259004E+00 | loss scale: 262144.0 | grad norm: 0.739 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 22:03:12] iteration   169800/  500000 | consumed samples:      1358400 | elapsed time per iteration (ms): 322.6 | learning rate: 7.445942E-05 | global batch size:     8 | lm loss: 3.226827E+00 | loss scale: 262144.0 | grad norm: 0.736 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 22:03:44] iteration   169900/  500000 | consumed samples:      1359200 | elapsed time per iteration (ms): 323.0 | learning rate: 7.439023E-05 | global batch size:     8 | lm loss: 3.262305E+00 | loss scale: 262144.0 | grad norm: 0.731 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 22:04:16] iteration   170000/  500000 | consumed samples:      1360000 | elapsed time per iteration (ms): 322.7 | learning rate: 7.432104E-05 | global batch size:     8 | lm loss: 3.213599E+00 | loss scale: 262144.0 | grad norm: 0.777 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1064.26, 1064.26)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 170000 | lm loss value: 3.714435E+00 | lm loss PPL: 4.103539E+01 | 
--------------------------------------------------------------------------------------------------
saving checkpoint at iteration  170000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-max in torch format
  successfully saved checkpoint at iteration  170000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-max
(min, max) time across ranks (ms):
    save-checkpoint ................................: (5898.10, 5898.10)
 [2024-06-21 22:04:56] iteration   170100/  500000 | consumed samples:      1360800 | elapsed time per iteration (ms): 321.5 | learning rate: 7.425185E-05 | global batch size:     8 | lm loss: 3.235229E+00 | loss scale: 524288.0 | grad norm: 0.821 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 22:05:28] iteration   170200/  500000 | consumed samples:      1361600 | elapsed time per iteration (ms): 322.2 | learning rate: 7.418267E-05 | global batch size:     8 | lm loss: 3.204672E+00 | loss scale: 524288.0 | grad norm: 0.745 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 22:06:00] iteration   170300/  500000 | consumed samples:      1362400 | elapsed time per iteration (ms): 321.7 | learning rate: 7.411350E-05 | global batch size:     8 | lm loss: 3.180357E+00 | loss scale: 524288.0 | grad norm: 0.773 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 22:06:32] iteration   170400/  500000 | consumed samples:      1363200 | elapsed time per iteration (ms): 322.2 | learning rate: 7.404433E-05 | global batch size:     8 | lm loss: 3.202990E+00 | loss scale: 524288.0 | grad norm: 0.715 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 22:07:04] iteration   170500/  500000 | consumed samples:      1364000 | elapsed time per iteration (ms): 321.0 | learning rate: 7.397517E-05 | global batch size:     8 | lm loss: 3.240550E+00 | loss scale: 524288.0 | grad norm: 0.731 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 22:07:37] iteration   170600/  500000 | consumed samples:      1364800 | elapsed time per iteration (ms): 323.1 | learning rate: 7.390601E-05 | global batch size:     8 | lm loss: 3.206469E+00 | loss scale: 524288.0 | grad norm: 0.770 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 22:08:09] iteration   170700/  500000 | consumed samples:      1365600 | elapsed time per iteration (ms): 321.9 | learning rate: 7.383686E-05 | global batch size:     8 | lm loss: 3.180253E+00 | loss scale: 524288.0 | grad norm: 0.743 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 22:08:41] iteration   170800/  500000 | consumed samples:      1366400 | elapsed time per iteration (ms): 322.6 | learning rate: 7.376772E-05 | global batch size:     8 | lm loss: 3.219141E+00 | loss scale: 524288.0 | grad norm: 0.787 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 22:09:13] iteration   170900/  500000 | consumed samples:      1367200 | elapsed time per iteration (ms): 322.5 | learning rate: 7.369858E-05 | global batch size:     8 | lm loss: 3.223463E+00 | loss scale: 524288.0 | grad norm: 0.777 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 22:09:45] iteration   171000/  500000 | consumed samples:      1368000 | elapsed time per iteration (ms): 321.1 | learning rate: 7.362945E-05 | global batch size:     8 | lm loss: 3.169212E+00 | loss scale: 524288.0 | grad norm: 0.753 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1063.58, 1063.58)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 171000 | lm loss value: 3.607239E+00 | lm loss PPL: 3.686415E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-21 22:10:18] iteration   171100/  500000 | consumed samples:      1368800 | elapsed time per iteration (ms): 319.8 | learning rate: 7.356171E-05 | global batch size:     8 | lm loss: 3.222169E+00 | loss scale: 524288.0 | grad norm: 0.764 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-21 22:10:51] iteration   171200/  500000 | consumed samples:      1369600 | elapsed time per iteration (ms): 322.4 | learning rate: 7.349328E-05 | global batch size:     8 | lm loss: 3.218597E+00 | loss scale: 262144.0 | grad norm: 0.746 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-21 22:11:23] iteration   171300/  500000 | consumed samples:      1370400 | elapsed time per iteration (ms): 322.1 | learning rate: 7.342417E-05 | global batch size:     8 | lm loss: 3.200168E+00 | loss scale: 262144.0 | grad norm: 0.722 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 22:11:55] iteration   171400/  500000 | consumed samples:      1371200 | elapsed time per iteration (ms): 321.4 | learning rate: 7.335506E-05 | global batch size:     8 | lm loss: 3.200390E+00 | loss scale: 262144.0 | grad norm: 0.728 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 22:12:27] iteration   171500/  500000 | consumed samples:      1372000 | elapsed time per iteration (ms): 322.5 | learning rate: 7.328596E-05 | global batch size:     8 | lm loss: 3.230509E+00 | loss scale: 262144.0 | grad norm: 0.734 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 22:13:00] iteration   171600/  500000 | consumed samples:      1372800 | elapsed time per iteration (ms): 324.3 | learning rate: 7.321687E-05 | global batch size:     8 | lm loss: 3.271006E+00 | loss scale: 262144.0 | grad norm: 0.749 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 22:13:32] iteration   171700/  500000 | consumed samples:      1373600 | elapsed time per iteration (ms): 322.7 | learning rate: 7.314778E-05 | global batch size:     8 | lm loss: 3.248592E+00 | loss scale: 262144.0 | grad norm: 0.756 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 22:14:04] iteration   171800/  500000 | consumed samples:      1374400 | elapsed time per iteration (ms): 323.2 | learning rate: 7.307870E-05 | global batch size:     8 | lm loss: 3.206802E+00 | loss scale: 262144.0 | grad norm: 0.728 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 22:14:37] iteration   171900/  500000 | consumed samples:      1375200 | elapsed time per iteration (ms): 324.7 | learning rate: 7.300963E-05 | global batch size:     8 | lm loss: 3.235894E+00 | loss scale: 262144.0 | grad norm: 0.718 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 22:15:09] iteration   172000/  500000 | consumed samples:      1376000 | elapsed time per iteration (ms): 322.2 | learning rate: 7.294056E-05 | global batch size:     8 | lm loss: 3.214978E+00 | loss scale: 262144.0 | grad norm: 0.764 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1066.42, 1066.42)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 172000 | lm loss value: 3.775591E+00 | lm loss PPL: 4.362327E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-21 22:15:43] iteration   172100/  500000 | consumed samples:      1376800 | elapsed time per iteration (ms): 324.0 | learning rate: 7.287150E-05 | global batch size:     8 | lm loss: 3.226667E+00 | loss scale: 262144.0 | grad norm: 0.734 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 22:16:15] iteration   172200/  500000 | consumed samples:      1377600 | elapsed time per iteration (ms): 321.6 | learning rate: 7.280314E-05 | global batch size:     8 | lm loss: 3.202187E+00 | loss scale: 524288.0 | grad norm: 0.757 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-21 22:16:47] iteration   172300/  500000 | consumed samples:      1378400 | elapsed time per iteration (ms): 322.2 | learning rate: 7.273410E-05 | global batch size:     8 | lm loss: 3.220659E+00 | loss scale: 524288.0 | grad norm: 0.754 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 22:17:19] iteration   172400/  500000 | consumed samples:      1379200 | elapsed time per iteration (ms): 322.5 | learning rate: 7.266506E-05 | global batch size:     8 | lm loss: 3.205807E+00 | loss scale: 524288.0 | grad norm: 0.717 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 22:17:52] iteration   172500/  500000 | consumed samples:      1380000 | elapsed time per iteration (ms): 323.9 | learning rate: 7.259603E-05 | global batch size:     8 | lm loss: 3.222483E+00 | loss scale: 524288.0 | grad norm: 0.728 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 22:18:24] iteration   172600/  500000 | consumed samples:      1380800 | elapsed time per iteration (ms): 322.7 | learning rate: 7.252700E-05 | global batch size:     8 | lm loss: 3.217416E+00 | loss scale: 524288.0 | grad norm: 0.753 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 22:18:56] iteration   172700/  500000 | consumed samples:      1381600 | elapsed time per iteration (ms): 323.2 | learning rate: 7.245799E-05 | global batch size:     8 | lm loss: 3.201118E+00 | loss scale: 524288.0 | grad norm: 0.774 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 22:19:28] iteration   172800/  500000 | consumed samples:      1382400 | elapsed time per iteration (ms): 322.4 | learning rate: 7.238967E-05 | global batch size:     8 | lm loss: 3.197268E+00 | loss scale: 262144.0 | grad norm: 0.743 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-21 22:20:01] iteration   172900/  500000 | consumed samples:      1383200 | elapsed time per iteration (ms): 323.1 | learning rate: 7.232067E-05 | global batch size:     8 | lm loss: 3.242742E+00 | loss scale: 262144.0 | grad norm: 0.740 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 22:20:33] iteration   173000/  500000 | consumed samples:      1384000 | elapsed time per iteration (ms): 322.3 | learning rate: 7.225167E-05 | global batch size:     8 | lm loss: 3.220800E+00 | loss scale: 262144.0 | grad norm: 0.699 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1068.96, 1068.96)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 173000 | lm loss value: 3.705867E+00 | lm loss PPL: 4.068531E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-21 22:21:06] iteration   173100/  500000 | consumed samples:      1384800 | elapsed time per iteration (ms): 321.3 | learning rate: 7.218269E-05 | global batch size:     8 | lm loss: 3.193507E+00 | loss scale: 262144.0 | grad norm: 0.729 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 22:21:39] iteration   173200/  500000 | consumed samples:      1385600 | elapsed time per iteration (ms): 324.7 | learning rate: 7.211371E-05 | global batch size:     8 | lm loss: 3.215216E+00 | loss scale: 262144.0 | grad norm: 0.793 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 22:22:11] iteration   173300/  500000 | consumed samples:      1386400 | elapsed time per iteration (ms): 320.4 | learning rate: 7.204474E-05 | global batch size:     8 | lm loss: 3.238622E+00 | loss scale: 262144.0 | grad norm: 0.705 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 22:22:43] iteration   173400/  500000 | consumed samples:      1387200 | elapsed time per iteration (ms): 323.3 | learning rate: 7.197578E-05 | global batch size:     8 | lm loss: 3.200656E+00 | loss scale: 262144.0 | grad norm: 0.734 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 22:23:15] iteration   173500/  500000 | consumed samples:      1388000 | elapsed time per iteration (ms): 322.1 | learning rate: 7.190682E-05 | global batch size:     8 | lm loss: 3.232278E+00 | loss scale: 262144.0 | grad norm: 0.730 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 22:23:47] iteration   173600/  500000 | consumed samples:      1388800 | elapsed time per iteration (ms): 322.6 | learning rate: 7.183787E-05 | global batch size:     8 | lm loss: 3.234184E+00 | loss scale: 262144.0 | grad norm: 0.804 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 22:24:20] iteration   173700/  500000 | consumed samples:      1389600 | elapsed time per iteration (ms): 321.0 | learning rate: 7.176894E-05 | global batch size:     8 | lm loss: 3.174383E+00 | loss scale: 262144.0 | grad norm: 0.740 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 22:24:52] iteration   173800/  500000 | consumed samples:      1390400 | elapsed time per iteration (ms): 325.7 | learning rate: 7.170069E-05 | global batch size:     8 | lm loss: 3.259121E+00 | loss scale: 524288.0 | grad norm: 0.805 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-21 22:25:24] iteration   173900/  500000 | consumed samples:      1391200 | elapsed time per iteration (ms): 322.5 | learning rate: 7.163246E-05 | global batch size:     8 | lm loss: 3.210845E+00 | loss scale: 262144.0 | grad norm: 0.801 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-21 22:25:56] iteration   174000/  500000 | consumed samples:      1392000 | elapsed time per iteration (ms): 320.1 | learning rate: 7.156355E-05 | global batch size:     8 | lm loss: 3.203713E+00 | loss scale: 262144.0 | grad norm: 0.735 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1064.02, 1064.02)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 174000 | lm loss value: 3.686687E+00 | lm loss PPL: 3.991239E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-21 22:26:30] iteration   174100/  500000 | consumed samples:      1392800 | elapsed time per iteration (ms): 322.7 | learning rate: 7.149464E-05 | global batch size:     8 | lm loss: 3.231049E+00 | loss scale: 262144.0 | grad norm: 0.777 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 22:27:02] iteration   174200/  500000 | consumed samples:      1393600 | elapsed time per iteration (ms): 322.2 | learning rate: 7.142574E-05 | global batch size:     8 | lm loss: 3.188496E+00 | loss scale: 262144.0 | grad norm: 0.717 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 22:27:34] iteration   174300/  500000 | consumed samples:      1394400 | elapsed time per iteration (ms): 323.4 | learning rate: 7.135685E-05 | global batch size:     8 | lm loss: 3.246219E+00 | loss scale: 262144.0 | grad norm: 0.745 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 22:28:06] iteration   174400/  500000 | consumed samples:      1395200 | elapsed time per iteration (ms): 322.2 | learning rate: 7.128797E-05 | global batch size:     8 | lm loss: 3.209065E+00 | loss scale: 262144.0 | grad norm: 0.755 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 22:28:39] iteration   174500/  500000 | consumed samples:      1396000 | elapsed time per iteration (ms): 323.8 | learning rate: 7.121910E-05 | global batch size:     8 | lm loss: 3.197886E+00 | loss scale: 262144.0 | grad norm: 0.735 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 22:29:11] iteration   174600/  500000 | consumed samples:      1396800 | elapsed time per iteration (ms): 323.7 | learning rate: 7.115023E-05 | global batch size:     8 | lm loss: 3.201110E+00 | loss scale: 262144.0 | grad norm: 0.788 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 22:29:44] iteration   174700/  500000 | consumed samples:      1397600 | elapsed time per iteration (ms): 323.9 | learning rate: 7.108138E-05 | global batch size:     8 | lm loss: 3.167035E+00 | loss scale: 262144.0 | grad norm: 0.755 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 22:30:16] iteration   174800/  500000 | consumed samples:      1398400 | elapsed time per iteration (ms): 322.8 | learning rate: 7.101253E-05 | global batch size:     8 | lm loss: 3.193661E+00 | loss scale: 262144.0 | grad norm: 0.757 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 22:30:48] iteration   174900/  500000 | consumed samples:      1399200 | elapsed time per iteration (ms): 322.6 | learning rate: 7.094370E-05 | global batch size:     8 | lm loss: 3.231578E+00 | loss scale: 524288.0 | grad norm: 0.730 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 22:31:20] iteration   175000/  500000 | consumed samples:      1400000 | elapsed time per iteration (ms): 321.6 | learning rate: 7.087487E-05 | global batch size:     8 | lm loss: 3.175249E+00 | loss scale: 524288.0 | grad norm: 0.773 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1064.50, 1064.50)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 175000 | lm loss value: 3.680450E+00 | lm loss PPL: 3.966423E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-21 22:31:54] iteration   175100/  500000 | consumed samples:      1400800 | elapsed time per iteration (ms): 321.9 | learning rate: 7.080674E-05 | global batch size:     8 | lm loss: 3.225200E+00 | loss scale: 524288.0 | grad norm: 0.752 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-21 22:32:26] iteration   175200/  500000 | consumed samples:      1401600 | elapsed time per iteration (ms): 322.7 | learning rate: 7.073792E-05 | global batch size:     8 | lm loss: 3.209122E+00 | loss scale: 524288.0 | grad norm: 0.768 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 22:32:58] iteration   175300/  500000 | consumed samples:      1402400 | elapsed time per iteration (ms): 320.2 | learning rate: 7.066912E-05 | global batch size:     8 | lm loss: 3.218943E+00 | loss scale: 524288.0 | grad norm: 0.705 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 22:33:30] iteration   175400/  500000 | consumed samples:      1403200 | elapsed time per iteration (ms): 322.0 | learning rate: 7.060102E-05 | global batch size:     8 | lm loss: 3.227786E+00 | loss scale: 262144.0 | grad norm: 0.750 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-21 22:34:02] iteration   175500/  500000 | consumed samples:      1404000 | elapsed time per iteration (ms): 321.3 | learning rate: 7.053223E-05 | global batch size:     8 | lm loss: 3.253984E+00 | loss scale: 262144.0 | grad norm: 0.721 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 22:34:34] iteration   175600/  500000 | consumed samples:      1404800 | elapsed time per iteration (ms): 322.7 | learning rate: 7.046346E-05 | global batch size:     8 | lm loss: 3.185504E+00 | loss scale: 262144.0 | grad norm: 0.751 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 22:35:07] iteration   175700/  500000 | consumed samples:      1405600 | elapsed time per iteration (ms): 323.7 | learning rate: 7.039470E-05 | global batch size:     8 | lm loss: 3.218589E+00 | loss scale: 262144.0 | grad norm: 0.777 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 22:35:39] iteration   175800/  500000 | consumed samples:      1406400 | elapsed time per iteration (ms): 322.3 | learning rate: 7.032594E-05 | global batch size:     8 | lm loss: 3.183010E+00 | loss scale: 262144.0 | grad norm: 0.767 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 22:36:11] iteration   175900/  500000 | consumed samples:      1407200 | elapsed time per iteration (ms): 323.1 | learning rate: 7.025720E-05 | global batch size:     8 | lm loss: 3.187796E+00 | loss scale: 262144.0 | grad norm: 0.747 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 22:36:44] iteration   176000/  500000 | consumed samples:      1408000 | elapsed time per iteration (ms): 321.9 | learning rate: 7.018846E-05 | global batch size:     8 | lm loss: 3.243051E+00 | loss scale: 262144.0 | grad norm: 0.772 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1063.40, 1063.40)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 176000 | lm loss value: 3.610664E+00 | lm loss PPL: 3.699059E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-21 22:37:17] iteration   176100/  500000 | consumed samples:      1408800 | elapsed time per iteration (ms): 321.6 | learning rate: 7.011973E-05 | global batch size:     8 | lm loss: 3.242407E+00 | loss scale: 262144.0 | grad norm: 0.721 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 22:37:49] iteration   176200/  500000 | consumed samples:      1409600 | elapsed time per iteration (ms): 322.7 | learning rate: 7.005102E-05 | global batch size:     8 | lm loss: 3.195675E+00 | loss scale: 262144.0 | grad norm: 0.786 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 22:38:21] iteration   176300/  500000 | consumed samples:      1410400 | elapsed time per iteration (ms): 321.5 | learning rate: 6.998231E-05 | global batch size:     8 | lm loss: 3.223082E+00 | loss scale: 262144.0 | grad norm: 0.749 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 22:38:53] iteration   176400/  500000 | consumed samples:      1411200 | elapsed time per iteration (ms): 322.3 | learning rate: 6.991361E-05 | global batch size:     8 | lm loss: 3.198382E+00 | loss scale: 524288.0 | grad norm: 0.760 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 22:39:25] iteration   176500/  500000 | consumed samples:      1412000 | elapsed time per iteration (ms): 320.4 | learning rate: 6.984493E-05 | global batch size:     8 | lm loss: 3.208849E+00 | loss scale: 524288.0 | grad norm: 0.735 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 22:39:58] iteration   176600/  500000 | consumed samples:      1412800 | elapsed time per iteration (ms): 323.0 | learning rate: 6.977625E-05 | global batch size:     8 | lm loss: 3.231981E+00 | loss scale: 524288.0 | grad norm: 0.754 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 22:40:30] iteration   176700/  500000 | consumed samples:      1413600 | elapsed time per iteration (ms): 321.4 | learning rate: 6.970827E-05 | global batch size:     8 | lm loss: 3.183017E+00 | loss scale: 524288.0 | grad norm: 0.760 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-21 22:41:02] iteration   176800/  500000 | consumed samples:      1414400 | elapsed time per iteration (ms): 321.9 | learning rate: 6.963961E-05 | global batch size:     8 | lm loss: 3.216683E+00 | loss scale: 524288.0 | grad norm: 0.786 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 22:41:34] iteration   176900/  500000 | consumed samples:      1415200 | elapsed time per iteration (ms): 321.4 | learning rate: 6.957096E-05 | global batch size:     8 | lm loss: 3.213957E+00 | loss scale: 524288.0 | grad norm: 0.782 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 22:42:07] iteration   177000/  500000 | consumed samples:      1416000 | elapsed time per iteration (ms): 322.9 | learning rate: 6.950233E-05 | global batch size:     8 | lm loss: 3.249868E+00 | loss scale: 524288.0 | grad norm: 0.708 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1068.24, 1068.24)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 177000 | lm loss value: 3.749389E+00 | lm loss PPL: 4.249511E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-21 22:42:40] iteration   177100/  500000 | consumed samples:      1416800 | elapsed time per iteration (ms): 322.1 | learning rate: 6.943370E-05 | global batch size:     8 | lm loss: 3.250224E+00 | loss scale: 524288.0 | grad norm: 0.774 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 22:43:12] iteration   177200/  500000 | consumed samples:      1417600 | elapsed time per iteration (ms): 321.1 | learning rate: 6.936508E-05 | global batch size:     8 | lm loss: 3.162893E+00 | loss scale: 524288.0 | grad norm: 0.773 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 22:43:44] iteration   177300/  500000 | consumed samples:      1418400 | elapsed time per iteration (ms): 322.4 | learning rate: 6.929648E-05 | global batch size:     8 | lm loss: 3.232606E+00 | loss scale: 524288.0 | grad norm: 0.774 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 22:44:16] iteration   177400/  500000 | consumed samples:      1419200 | elapsed time per iteration (ms): 321.5 | learning rate: 6.922788E-05 | global batch size:     8 | lm loss: 3.169327E+00 | loss scale: 524288.0 | grad norm: 0.795 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 22:44:49] iteration   177500/  500000 | consumed samples:      1420000 | elapsed time per iteration (ms): 323.3 | learning rate: 6.915999E-05 | global batch size:     8 | lm loss: 3.246047E+00 | loss scale: 262144.0 | grad norm: 0.790 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-21 22:45:21] iteration   177600/  500000 | consumed samples:      1420800 | elapsed time per iteration (ms): 320.8 | learning rate: 6.909141E-05 | global batch size:     8 | lm loss: 3.228709E+00 | loss scale: 262144.0 | grad norm: 0.761 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 22:45:53] iteration   177700/  500000 | consumed samples:      1421600 | elapsed time per iteration (ms): 323.7 | learning rate: 6.902285E-05 | global batch size:     8 | lm loss: 3.271698E+00 | loss scale: 262144.0 | grad norm: 0.794 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 22:46:25] iteration   177800/  500000 | consumed samples:      1422400 | elapsed time per iteration (ms): 322.2 | learning rate: 6.895430E-05 | global batch size:     8 | lm loss: 3.216877E+00 | loss scale: 262144.0 | grad norm: 0.777 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 22:46:58] iteration   177900/  500000 | consumed samples:      1423200 | elapsed time per iteration (ms): 323.1 | learning rate: 6.888576E-05 | global batch size:     8 | lm loss: 3.209442E+00 | loss scale: 262144.0 | grad norm: 0.750 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 22:47:30] iteration   178000/  500000 | consumed samples:      1424000 | elapsed time per iteration (ms): 323.0 | learning rate: 6.881723E-05 | global batch size:     8 | lm loss: 3.225902E+00 | loss scale: 262144.0 | grad norm: 0.765 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1063.28, 1063.28)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 178000 | lm loss value: 3.764756E+00 | lm loss PPL: 4.315317E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-21 22:48:03] iteration   178100/  500000 | consumed samples:      1424800 | elapsed time per iteration (ms): 322.1 | learning rate: 6.874871E-05 | global batch size:     8 | lm loss: 3.163889E+00 | loss scale: 262144.0 | grad norm: 0.772 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 22:48:36] iteration   178200/  500000 | consumed samples:      1425600 | elapsed time per iteration (ms): 325.0 | learning rate: 6.868020E-05 | global batch size:     8 | lm loss: 3.168497E+00 | loss scale: 262144.0 | grad norm: 0.773 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 22:49:08] iteration   178300/  500000 | consumed samples:      1426400 | elapsed time per iteration (ms): 321.3 | learning rate: 6.861170E-05 | global batch size:     8 | lm loss: 3.149958E+00 | loss scale: 262144.0 | grad norm: 0.753 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 22:49:40] iteration   178400/  500000 | consumed samples:      1427200 | elapsed time per iteration (ms): 322.2 | learning rate: 6.854321E-05 | global batch size:     8 | lm loss: 3.226186E+00 | loss scale: 262144.0 | grad norm: 0.777 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 22:50:12] iteration   178500/  500000 | consumed samples:      1428000 | elapsed time per iteration (ms): 322.5 | learning rate: 6.847474E-05 | global batch size:     8 | lm loss: 3.231457E+00 | loss scale: 524288.0 | grad norm: 0.765 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 22:50:45] iteration   178600/  500000 | consumed samples:      1428800 | elapsed time per iteration (ms): 323.0 | learning rate: 6.840628E-05 | global batch size:     8 | lm loss: 3.242867E+00 | loss scale: 524288.0 | grad norm: 0.705 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 22:51:17] iteration   178700/  500000 | consumed samples:      1429600 | elapsed time per iteration (ms): 321.9 | learning rate: 6.833782E-05 | global batch size:     8 | lm loss: 3.225042E+00 | loss scale: 524288.0 | grad norm: 0.787 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 22:51:49] iteration   178800/  500000 | consumed samples:      1430400 | elapsed time per iteration (ms): 324.3 | learning rate: 6.826938E-05 | global batch size:     8 | lm loss: 3.182667E+00 | loss scale: 524288.0 | grad norm: 0.758 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 22:52:22] iteration   178900/  500000 | consumed samples:      1431200 | elapsed time per iteration (ms): 323.4 | learning rate: 6.820095E-05 | global batch size:     8 | lm loss: 3.177399E+00 | loss scale: 524288.0 | grad norm: 0.757 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 22:52:54] iteration   179000/  500000 | consumed samples:      1432000 | elapsed time per iteration (ms): 321.7 | learning rate: 6.813390E-05 | global batch size:     8 | lm loss: 3.195144E+00 | loss scale: 262144.0 | grad norm: 0.754 | number of skipped iterations:   2 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1063.45, 1063.45)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 179000 | lm loss value: 3.614647E+00 | lm loss PPL: 3.713823E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-21 22:53:27] iteration   179100/  500000 | consumed samples:      1432800 | elapsed time per iteration (ms): 321.3 | learning rate: 6.806550E-05 | global batch size:     8 | lm loss: 3.245732E+00 | loss scale: 262144.0 | grad norm: 0.706 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 22:53:59] iteration   179200/  500000 | consumed samples:      1433600 | elapsed time per iteration (ms): 322.3 | learning rate: 6.799710E-05 | global batch size:     8 | lm loss: 3.221454E+00 | loss scale: 262144.0 | grad norm: 0.741 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 22:54:31] iteration   179300/  500000 | consumed samples:      1434400 | elapsed time per iteration (ms): 321.6 | learning rate: 6.792872E-05 | global batch size:     8 | lm loss: 3.207215E+00 | loss scale: 262144.0 | grad norm: 0.735 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 22:55:04] iteration   179400/  500000 | consumed samples:      1435200 | elapsed time per iteration (ms): 322.7 | learning rate: 6.786035E-05 | global batch size:     8 | lm loss: 3.208453E+00 | loss scale: 262144.0 | grad norm: 0.722 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 22:55:36] iteration   179500/  500000 | consumed samples:      1436000 | elapsed time per iteration (ms): 322.0 | learning rate: 6.779199E-05 | global batch size:     8 | lm loss: 3.227956E+00 | loss scale: 262144.0 | grad norm: 0.752 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 22:56:08] iteration   179600/  500000 | consumed samples:      1436800 | elapsed time per iteration (ms): 322.1 | learning rate: 6.772433E-05 | global batch size:     8 | lm loss: 3.204732E+00 | loss scale: 131072.0 | grad norm: 0.727 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-21 22:56:40] iteration   179700/  500000 | consumed samples:      1437600 | elapsed time per iteration (ms): 322.9 | learning rate: 6.765599E-05 | global batch size:     8 | lm loss: 3.153716E+00 | loss scale: 131072.0 | grad norm: 0.717 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 22:57:12] iteration   179800/  500000 | consumed samples:      1438400 | elapsed time per iteration (ms): 321.3 | learning rate: 6.758767E-05 | global batch size:     8 | lm loss: 3.182041E+00 | loss scale: 131072.0 | grad norm: 0.762 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 22:57:45] iteration   179900/  500000 | consumed samples:      1439200 | elapsed time per iteration (ms): 322.1 | learning rate: 6.751936E-05 | global batch size:     8 | lm loss: 3.184149E+00 | loss scale: 131072.0 | grad norm: 0.741 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 22:58:17] iteration   180000/  500000 | consumed samples:      1440000 | elapsed time per iteration (ms): 322.8 | learning rate: 6.745106E-05 | global batch size:     8 | lm loss: 3.209273E+00 | loss scale: 131072.0 | grad norm: 0.764 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1066.23, 1066.23)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 180000 | lm loss value: 3.586012E+00 | lm loss PPL: 3.608986E+01 | 
--------------------------------------------------------------------------------------------------
saving checkpoint at iteration  180000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-max in torch format
  successfully saved checkpoint at iteration  180000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-max
(min, max) time across ranks (ms):
    save-checkpoint ................................: (5733.66, 5733.66)
 [2024-06-21 22:58:56] iteration   180100/  500000 | consumed samples:      1440800 | elapsed time per iteration (ms): 321.3 | learning rate: 6.738278E-05 | global batch size:     8 | lm loss: 3.146462E+00 | loss scale: 131072.0 | grad norm: 0.723 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 22:59:28] iteration   180200/  500000 | consumed samples:      1441600 | elapsed time per iteration (ms): 320.8 | learning rate: 6.731450E-05 | global batch size:     8 | lm loss: 3.189507E+00 | loss scale: 131072.0 | grad norm: 0.758 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 23:00:00] iteration   180300/  500000 | consumed samples:      1442400 | elapsed time per iteration (ms): 322.5 | learning rate: 6.724624E-05 | global batch size:     8 | lm loss: 3.200375E+00 | loss scale: 131072.0 | grad norm: 0.766 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 23:00:32] iteration   180400/  500000 | consumed samples:      1443200 | elapsed time per iteration (ms): 321.6 | learning rate: 6.717800E-05 | global batch size:     8 | lm loss: 3.212578E+00 | loss scale: 131072.0 | grad norm: 0.764 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 23:01:04] iteration   180500/  500000 | consumed samples:      1444000 | elapsed time per iteration (ms): 320.0 | learning rate: 6.710976E-05 | global batch size:     8 | lm loss: 3.174323E+00 | loss scale: 131072.0 | grad norm: 0.773 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 23:01:37] iteration   180600/  500000 | consumed samples:      1444800 | elapsed time per iteration (ms): 324.5 | learning rate: 6.704154E-05 | global batch size:     8 | lm loss: 3.201226E+00 | loss scale: 262144.0 | grad norm: 0.819 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 23:02:09] iteration   180700/  500000 | consumed samples:      1445600 | elapsed time per iteration (ms): 320.5 | learning rate: 6.697333E-05 | global batch size:     8 | lm loss: 3.193637E+00 | loss scale: 262144.0 | grad norm: 0.761 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 23:02:41] iteration   180800/  500000 | consumed samples:      1446400 | elapsed time per iteration (ms): 321.4 | learning rate: 6.690513E-05 | global batch size:     8 | lm loss: 3.190157E+00 | loss scale: 262144.0 | grad norm: 0.793 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 23:03:13] iteration   180900/  500000 | consumed samples:      1447200 | elapsed time per iteration (ms): 323.8 | learning rate: 6.683694E-05 | global batch size:     8 | lm loss: 3.221179E+00 | loss scale: 262144.0 | grad norm: 0.791 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 23:03:46] iteration   181000/  500000 | consumed samples:      1448000 | elapsed time per iteration (ms): 322.8 | learning rate: 6.676877E-05 | global batch size:     8 | lm loss: 3.198488E+00 | loss scale: 262144.0 | grad norm: 0.745 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1063.29, 1063.29)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 181000 | lm loss value: 3.668283E+00 | lm loss PPL: 3.918456E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-21 23:04:19] iteration   181100/  500000 | consumed samples:      1448800 | elapsed time per iteration (ms): 322.9 | learning rate: 6.670061E-05 | global batch size:     8 | lm loss: 3.203636E+00 | loss scale: 262144.0 | grad norm: 0.741 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 23:04:51] iteration   181200/  500000 | consumed samples:      1449600 | elapsed time per iteration (ms): 322.4 | learning rate: 6.663247E-05 | global batch size:     8 | lm loss: 3.185142E+00 | loss scale: 262144.0 | grad norm: 0.756 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 23:05:23] iteration   181300/  500000 | consumed samples:      1450400 | elapsed time per iteration (ms): 321.8 | learning rate: 6.656434E-05 | global batch size:     8 | lm loss: 3.205770E+00 | loss scale: 262144.0 | grad norm: 0.787 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 23:05:56] iteration   181400/  500000 | consumed samples:      1451200 | elapsed time per iteration (ms): 322.6 | learning rate: 6.649622E-05 | global batch size:     8 | lm loss: 3.187576E+00 | loss scale: 262144.0 | grad norm: 0.738 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 23:06:28] iteration   181500/  500000 | consumed samples:      1452000 | elapsed time per iteration (ms): 322.7 | learning rate: 6.642811E-05 | global batch size:     8 | lm loss: 3.172539E+00 | loss scale: 262144.0 | grad norm: 0.830 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 23:07:00] iteration   181600/  500000 | consumed samples:      1452800 | elapsed time per iteration (ms): 322.4 | learning rate: 6.636002E-05 | global batch size:     8 | lm loss: 3.193637E+00 | loss scale: 524288.0 | grad norm: 0.753 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 23:07:32] iteration   181700/  500000 | consumed samples:      1453600 | elapsed time per iteration (ms): 321.8 | learning rate: 6.629262E-05 | global batch size:     8 | lm loss: 3.171200E+00 | loss scale: 524288.0 | grad norm: 0.734 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-21 23:08:05] iteration   181800/  500000 | consumed samples:      1454400 | elapsed time per iteration (ms): 322.3 | learning rate: 6.622455E-05 | global batch size:     8 | lm loss: 3.160601E+00 | loss scale: 524288.0 | grad norm: 0.751 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 23:08:37] iteration   181900/  500000 | consumed samples:      1455200 | elapsed time per iteration (ms): 322.8 | learning rate: 6.615650E-05 | global batch size:     8 | lm loss: 3.125583E+00 | loss scale: 524288.0 | grad norm: 0.745 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 23:09:09] iteration   182000/  500000 | consumed samples:      1456000 | elapsed time per iteration (ms): 322.9 | learning rate: 6.608846E-05 | global batch size:     8 | lm loss: 3.193930E+00 | loss scale: 524288.0 | grad norm: 0.738 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1066.36, 1066.36)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 182000 | lm loss value: 3.695425E+00 | lm loss PPL: 4.026268E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-21 23:09:42] iteration   182100/  500000 | consumed samples:      1456800 | elapsed time per iteration (ms): 322.1 | learning rate: 6.602044E-05 | global batch size:     8 | lm loss: 3.209773E+00 | loss scale: 524288.0 | grad norm: 0.748 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 23:10:15] iteration   182200/  500000 | consumed samples:      1457600 | elapsed time per iteration (ms): 322.7 | learning rate: 6.595243E-05 | global batch size:     8 | lm loss: 3.223244E+00 | loss scale: 524288.0 | grad norm: 0.767 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 23:10:47] iteration   182300/  500000 | consumed samples:      1458400 | elapsed time per iteration (ms): 321.7 | learning rate: 6.588443E-05 | global batch size:     8 | lm loss: 3.176683E+00 | loss scale: 524288.0 | grad norm: 0.745 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 23:11:19] iteration   182400/  500000 | consumed samples:      1459200 | elapsed time per iteration (ms): 323.3 | learning rate: 6.581645E-05 | global batch size:     8 | lm loss: 3.191276E+00 | loss scale: 524288.0 | grad norm: 0.756 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 23:11:51] iteration   182500/  500000 | consumed samples:      1460000 | elapsed time per iteration (ms): 322.2 | learning rate: 6.574848E-05 | global batch size:     8 | lm loss: 3.185675E+00 | loss scale: 524288.0 | grad norm: 0.726 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 23:12:24] iteration   182600/  500000 | consumed samples:      1460800 | elapsed time per iteration (ms): 321.3 | learning rate: 6.568052E-05 | global batch size:     8 | lm loss: 3.205818E+00 | loss scale: 524288.0 | grad norm: 0.770 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 23:12:56] iteration   182700/  500000 | consumed samples:      1461600 | elapsed time per iteration (ms): 322.6 | learning rate: 6.561394E-05 | global batch size:     8 | lm loss: 3.200441E+00 | loss scale: 524288.0 | grad norm: 0.762 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-21 23:13:28] iteration   182800/  500000 | consumed samples:      1462400 | elapsed time per iteration (ms): 320.4 | learning rate: 6.554601E-05 | global batch size:     8 | lm loss: 3.212111E+00 | loss scale: 524288.0 | grad norm: 0.747 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 23:14:00] iteration   182900/  500000 | consumed samples:      1463200 | elapsed time per iteration (ms): 322.7 | learning rate: 6.547878E-05 | global batch size:     8 | lm loss: 3.156407E+00 | loss scale: 262144.0 | grad norm: 0.748 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-21 23:14:32] iteration   183000/  500000 | consumed samples:      1464000 | elapsed time per iteration (ms): 321.6 | learning rate: 6.541088E-05 | global batch size:     8 | lm loss: 3.180594E+00 | loss scale: 262144.0 | grad norm: 0.808 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1066.03, 1066.03)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 183000 | lm loss value: 3.614877E+00 | lm loss PPL: 3.714679E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-21 23:15:05] iteration   183100/  500000 | consumed samples:      1464800 | elapsed time per iteration (ms): 321.0 | learning rate: 6.534299E-05 | global batch size:     8 | lm loss: 3.213770E+00 | loss scale: 262144.0 | grad norm: 0.738 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 23:15:38] iteration   183200/  500000 | consumed samples:      1465600 | elapsed time per iteration (ms): 323.2 | learning rate: 6.527512E-05 | global batch size:     8 | lm loss: 3.169402E+00 | loss scale: 262144.0 | grad norm: 0.770 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 23:16:10] iteration   183300/  500000 | consumed samples:      1466400 | elapsed time per iteration (ms): 323.4 | learning rate: 6.520726E-05 | global batch size:     8 | lm loss: 3.223387E+00 | loss scale: 262144.0 | grad norm: 0.770 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 23:16:42] iteration   183400/  500000 | consumed samples:      1467200 | elapsed time per iteration (ms): 322.0 | learning rate: 6.513942E-05 | global batch size:     8 | lm loss: 3.188574E+00 | loss scale: 262144.0 | grad norm: 0.721 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 23:17:15] iteration   183500/  500000 | consumed samples:      1468000 | elapsed time per iteration (ms): 323.2 | learning rate: 6.507160E-05 | global batch size:     8 | lm loss: 3.185939E+00 | loss scale: 262144.0 | grad norm: 0.775 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 23:17:47] iteration   183600/  500000 | consumed samples:      1468800 | elapsed time per iteration (ms): 323.9 | learning rate: 6.500378E-05 | global batch size:     8 | lm loss: 3.191100E+00 | loss scale: 262144.0 | grad norm: 0.744 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 23:18:19] iteration   183700/  500000 | consumed samples:      1469600 | elapsed time per iteration (ms): 321.5 | learning rate: 6.493599E-05 | global batch size:     8 | lm loss: 3.192126E+00 | loss scale: 262144.0 | grad norm: 0.755 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 23:18:52] iteration   183800/  500000 | consumed samples:      1470400 | elapsed time per iteration (ms): 323.9 | learning rate: 6.486820E-05 | global batch size:     8 | lm loss: 3.218090E+00 | loss scale: 262144.0 | grad norm: 0.757 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 23:19:24] iteration   183900/  500000 | consumed samples:      1471200 | elapsed time per iteration (ms): 322.7 | learning rate: 6.480044E-05 | global batch size:     8 | lm loss: 3.168516E+00 | loss scale: 524288.0 | grad norm: 0.748 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 23:19:56] iteration   184000/  500000 | consumed samples:      1472000 | elapsed time per iteration (ms): 325.2 | learning rate: 6.473268E-05 | global batch size:     8 | lm loss: 3.173445E+00 | loss scale: 524288.0 | grad norm: 0.751 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1065.62, 1065.62)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 184000 | lm loss value: 3.526722E+00 | lm loss PPL: 3.401231E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-21 23:20:29] iteration   184100/  500000 | consumed samples:      1472800 | elapsed time per iteration (ms): 320.4 | learning rate: 6.466495E-05 | global batch size:     8 | lm loss: 3.174904E+00 | loss scale: 524288.0 | grad norm: 0.787 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 23:21:02] iteration   184200/  500000 | consumed samples:      1473600 | elapsed time per iteration (ms): 322.0 | learning rate: 6.459790E-05 | global batch size:     8 | lm loss: 3.231366E+00 | loss scale: 524288.0 | grad norm: 0.735 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-21 23:21:34] iteration   184300/  500000 | consumed samples:      1474400 | elapsed time per iteration (ms): 319.3 | learning rate: 6.453019E-05 | global batch size:     8 | lm loss: 3.164909E+00 | loss scale: 524288.0 | grad norm: 0.769 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 23:22:06] iteration   184400/  500000 | consumed samples:      1475200 | elapsed time per iteration (ms): 321.8 | learning rate: 6.446318E-05 | global batch size:     8 | lm loss: 3.177367E+00 | loss scale: 262144.0 | grad norm: 0.774 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-21 23:22:38] iteration   184500/  500000 | consumed samples:      1476000 | elapsed time per iteration (ms): 323.7 | learning rate: 6.439550E-05 | global batch size:     8 | lm loss: 3.199407E+00 | loss scale: 262144.0 | grad norm: 0.767 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 23:23:11] iteration   184600/  500000 | consumed samples:      1476800 | elapsed time per iteration (ms): 324.0 | learning rate: 6.432784E-05 | global batch size:     8 | lm loss: 3.185476E+00 | loss scale: 262144.0 | grad norm: 0.767 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 23:23:43] iteration   184700/  500000 | consumed samples:      1477600 | elapsed time per iteration (ms): 321.5 | learning rate: 6.426019E-05 | global batch size:     8 | lm loss: 3.160905E+00 | loss scale: 262144.0 | grad norm: 0.785 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 23:24:15] iteration   184800/  500000 | consumed samples:      1478400 | elapsed time per iteration (ms): 320.2 | learning rate: 6.419256E-05 | global batch size:     8 | lm loss: 3.198779E+00 | loss scale: 262144.0 | grad norm: 0.765 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 23:24:47] iteration   184900/  500000 | consumed samples:      1479200 | elapsed time per iteration (ms): 324.2 | learning rate: 6.412494E-05 | global batch size:     8 | lm loss: 3.161308E+00 | loss scale: 262144.0 | grad norm: 0.761 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 23:25:19] iteration   185000/  500000 | consumed samples:      1480000 | elapsed time per iteration (ms): 322.1 | learning rate: 6.405734E-05 | global batch size:     8 | lm loss: 3.171663E+00 | loss scale: 262144.0 | grad norm: 0.740 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1063.87, 1063.87)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 185000 | lm loss value: 3.602298E+00 | lm loss PPL: 3.668245E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-21 23:25:52] iteration   185100/  500000 | consumed samples:      1480800 | elapsed time per iteration (ms): 320.1 | learning rate: 6.398976E-05 | global batch size:     8 | lm loss: 3.173145E+00 | loss scale: 262144.0 | grad norm: 0.743 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 23:26:25] iteration   185200/  500000 | consumed samples:      1481600 | elapsed time per iteration (ms): 320.7 | learning rate: 6.392219E-05 | global batch size:     8 | lm loss: 3.182668E+00 | loss scale: 262144.0 | grad norm: 0.758 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 23:26:57] iteration   185300/  500000 | consumed samples:      1482400 | elapsed time per iteration (ms): 320.2 | learning rate: 6.385464E-05 | global batch size:     8 | lm loss: 3.212160E+00 | loss scale: 262144.0 | grad norm: 0.746 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 23:27:29] iteration   185400/  500000 | consumed samples:      1483200 | elapsed time per iteration (ms): 320.5 | learning rate: 6.378710E-05 | global batch size:     8 | lm loss: 3.190495E+00 | loss scale: 524288.0 | grad norm: 0.758 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 23:28:01] iteration   185500/  500000 | consumed samples:      1484000 | elapsed time per iteration (ms): 320.3 | learning rate: 6.372025E-05 | global batch size:     8 | lm loss: 3.151395E+00 | loss scale: 524288.0 | grad norm: 0.784 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-21 23:28:33] iteration   185600/  500000 | consumed samples:      1484800 | elapsed time per iteration (ms): 319.3 | learning rate: 6.365275E-05 | global batch size:     8 | lm loss: 3.179641E+00 | loss scale: 524288.0 | grad norm: 0.795 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 23:29:04] iteration   185700/  500000 | consumed samples:      1485600 | elapsed time per iteration (ms): 318.6 | learning rate: 6.358526E-05 | global batch size:     8 | lm loss: 3.174460E+00 | loss scale: 524288.0 | grad norm: 0.774 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 23:29:37] iteration   185800/  500000 | consumed samples:      1486400 | elapsed time per iteration (ms): 321.8 | learning rate: 6.351779E-05 | global batch size:     8 | lm loss: 3.198760E+00 | loss scale: 524288.0 | grad norm: 0.763 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 23:30:09] iteration   185900/  500000 | consumed samples:      1487200 | elapsed time per iteration (ms): 320.4 | learning rate: 6.345033E-05 | global batch size:     8 | lm loss: 3.156797E+00 | loss scale: 524288.0 | grad norm: 0.770 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 23:30:41] iteration   186000/  500000 | consumed samples:      1488000 | elapsed time per iteration (ms): 323.4 | learning rate: 6.338289E-05 | global batch size:     8 | lm loss: 3.224420E+00 | loss scale: 524288.0 | grad norm: 0.772 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1066.77, 1066.77)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 186000 | lm loss value: 3.648034E+00 | lm loss PPL: 3.839909E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-21 23:31:14] iteration   186100/  500000 | consumed samples:      1488800 | elapsed time per iteration (ms): 322.1 | learning rate: 6.331547E-05 | global batch size:     8 | lm loss: 3.181634E+00 | loss scale: 524288.0 | grad norm: 0.761 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 23:31:46] iteration   186200/  500000 | consumed samples:      1489600 | elapsed time per iteration (ms): 321.8 | learning rate: 6.324806E-05 | global batch size:     8 | lm loss: 3.147229E+00 | loss scale: 524288.0 | grad norm: 0.771 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 23:32:19] iteration   186300/  500000 | consumed samples:      1490400 | elapsed time per iteration (ms): 321.8 | learning rate: 6.318067E-05 | global batch size:     8 | lm loss: 3.133911E+00 | loss scale: 524288.0 | grad norm: 0.768 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 23:32:51] iteration   186400/  500000 | consumed samples:      1491200 | elapsed time per iteration (ms): 321.1 | learning rate: 6.311329E-05 | global batch size:     8 | lm loss: 3.169535E+00 | loss scale: 524288.0 | grad norm: 0.738 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 23:33:23] iteration   186500/  500000 | consumed samples:      1492000 | elapsed time per iteration (ms): 321.8 | learning rate: 6.304728E-05 | global batch size:     8 | lm loss: 3.156897E+00 | loss scale: 524288.0 | grad norm: 0.780 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-21 23:33:55] iteration   186600/  500000 | consumed samples:      1492800 | elapsed time per iteration (ms): 322.7 | learning rate: 6.297994E-05 | global batch size:     8 | lm loss: 3.176282E+00 | loss scale: 524288.0 | grad norm: 0.725 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 23:34:27] iteration   186700/  500000 | consumed samples:      1493600 | elapsed time per iteration (ms): 323.2 | learning rate: 6.291262E-05 | global batch size:     8 | lm loss: 3.167289E+00 | loss scale: 524288.0 | grad norm: 0.776 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 23:35:00] iteration   186800/  500000 | consumed samples:      1494400 | elapsed time per iteration (ms): 323.5 | learning rate: 6.284531E-05 | global batch size:     8 | lm loss: 3.160818E+00 | loss scale: 524288.0 | grad norm: 0.784 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 23:35:32] iteration   186900/  500000 | consumed samples:      1495200 | elapsed time per iteration (ms): 321.2 | learning rate: 6.277802E-05 | global batch size:     8 | lm loss: 3.165479E+00 | loss scale: 524288.0 | grad norm: 0.775 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 23:36:04] iteration   187000/  500000 | consumed samples:      1496000 | elapsed time per iteration (ms): 321.1 | learning rate: 6.271074E-05 | global batch size:     8 | lm loss: 3.169976E+00 | loss scale: 524288.0 | grad norm: 0.748 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1065.42, 1065.42)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 187000 | lm loss value: 3.656893E+00 | lm loss PPL: 3.874080E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-21 23:36:37] iteration   187100/  500000 | consumed samples:      1496800 | elapsed time per iteration (ms): 323.3 | learning rate: 6.264348E-05 | global batch size:     8 | lm loss: 3.194149E+00 | loss scale: 524288.0 | grad norm: 0.769 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 23:37:10] iteration   187200/  500000 | consumed samples:      1497600 | elapsed time per iteration (ms): 322.9 | learning rate: 6.257624E-05 | global batch size:     8 | lm loss: 3.179965E+00 | loss scale: 524288.0 | grad norm: 0.752 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 23:37:42] iteration   187300/  500000 | consumed samples:      1498400 | elapsed time per iteration (ms): 323.2 | learning rate: 6.250902E-05 | global batch size:     8 | lm loss: 3.147090E+00 | loss scale: 524288.0 | grad norm: 0.811 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 23:38:14] iteration   187400/  500000 | consumed samples:      1499200 | elapsed time per iteration (ms): 321.4 | learning rate: 6.244182E-05 | global batch size:     8 | lm loss: 3.161510E+00 | loss scale: 524288.0 | grad norm: 0.755 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 23:38:47] iteration   187500/  500000 | consumed samples:      1500000 | elapsed time per iteration (ms): 323.1 | learning rate: 6.237530E-05 | global batch size:     8 | lm loss: 3.155395E+00 | loss scale: 262144.0 | grad norm: 0.794 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-21 23:39:19] iteration   187600/  500000 | consumed samples:      1500800 | elapsed time per iteration (ms): 323.5 | learning rate: 6.230813E-05 | global batch size:     8 | lm loss: 3.171638E+00 | loss scale: 262144.0 | grad norm: 0.795 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 23:39:51] iteration   187700/  500000 | consumed samples:      1501600 | elapsed time per iteration (ms): 324.7 | learning rate: 6.224097E-05 | global batch size:     8 | lm loss: 3.210176E+00 | loss scale: 262144.0 | grad norm: 0.727 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 23:40:24] iteration   187800/  500000 | consumed samples:      1502400 | elapsed time per iteration (ms): 322.0 | learning rate: 6.217384E-05 | global batch size:     8 | lm loss: 3.209940E+00 | loss scale: 262144.0 | grad norm: 0.749 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 23:40:56] iteration   187900/  500000 | consumed samples:      1503200 | elapsed time per iteration (ms): 321.8 | learning rate: 6.210672E-05 | global batch size:     8 | lm loss: 3.158871E+00 | loss scale: 262144.0 | grad norm: 0.754 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 23:41:28] iteration   188000/  500000 | consumed samples:      1504000 | elapsed time per iteration (ms): 321.2 | learning rate: 6.203962E-05 | global batch size:     8 | lm loss: 3.199031E+00 | loss scale: 262144.0 | grad norm: 0.774 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1063.42, 1063.42)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 188000 | lm loss value: 3.646822E+00 | lm loss PPL: 3.835258E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-21 23:42:01] iteration   188100/  500000 | consumed samples:      1504800 | elapsed time per iteration (ms): 321.8 | learning rate: 6.197253E-05 | global batch size:     8 | lm loss: 3.179930E+00 | loss scale: 262144.0 | grad norm: 0.743 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 23:42:33] iteration   188200/  500000 | consumed samples:      1505600 | elapsed time per iteration (ms): 321.7 | learning rate: 6.190547E-05 | global batch size:     8 | lm loss: 3.193210E+00 | loss scale: 262144.0 | grad norm: 0.784 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 23:43:05] iteration   188300/  500000 | consumed samples:      1506400 | elapsed time per iteration (ms): 318.8 | learning rate: 6.183842E-05 | global batch size:     8 | lm loss: 3.144076E+00 | loss scale: 262144.0 | grad norm: 0.787 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 23:43:37] iteration   188400/  500000 | consumed samples:      1507200 | elapsed time per iteration (ms): 322.3 | learning rate: 6.177139E-05 | global batch size:     8 | lm loss: 3.169066E+00 | loss scale: 262144.0 | grad norm: 0.737 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 23:44:10] iteration   188500/  500000 | consumed samples:      1508000 | elapsed time per iteration (ms): 322.9 | learning rate: 6.170437E-05 | global batch size:     8 | lm loss: 3.146214E+00 | loss scale: 524288.0 | grad norm: 0.758 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 23:44:42] iteration   188600/  500000 | consumed samples:      1508800 | elapsed time per iteration (ms): 320.2 | learning rate: 6.163738E-05 | global batch size:     8 | lm loss: 3.173040E+00 | loss scale: 524288.0 | grad norm: 0.757 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 23:45:14] iteration   188700/  500000 | consumed samples:      1509600 | elapsed time per iteration (ms): 319.5 | learning rate: 6.157040E-05 | global batch size:     8 | lm loss: 3.164858E+00 | loss scale: 524288.0 | grad norm: 0.813 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 23:45:46] iteration   188800/  500000 | consumed samples:      1510400 | elapsed time per iteration (ms): 321.2 | learning rate: 6.150344E-05 | global batch size:     8 | lm loss: 3.142318E+00 | loss scale: 524288.0 | grad norm: 0.885 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 23:46:18] iteration   188900/  500000 | consumed samples:      1511200 | elapsed time per iteration (ms): 323.2 | learning rate: 6.143650E-05 | global batch size:     8 | lm loss: 3.197858E+00 | loss scale: 524288.0 | grad norm: 0.757 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 23:46:50] iteration   189000/  500000 | consumed samples:      1512000 | elapsed time per iteration (ms): 322.3 | learning rate: 6.137025E-05 | global batch size:     8 | lm loss: 3.146405E+00 | loss scale: 524288.0 | grad norm: 0.789 | number of skipped iterations:   1 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1064.90, 1064.90)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 189000 | lm loss value: 3.614880E+00 | lm loss PPL: 3.714690E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-21 23:47:24] iteration   189100/  500000 | consumed samples:      1512800 | elapsed time per iteration (ms): 321.8 | learning rate: 6.130335E-05 | global batch size:     8 | lm loss: 3.200834E+00 | loss scale: 524288.0 | grad norm: 0.802 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 23:47:56] iteration   189200/  500000 | consumed samples:      1513600 | elapsed time per iteration (ms): 323.1 | learning rate: 6.123646E-05 | global batch size:     8 | lm loss: 3.174044E+00 | loss scale: 524288.0 | grad norm: 0.734 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 23:48:28] iteration   189300/  500000 | consumed samples:      1514400 | elapsed time per iteration (ms): 322.6 | learning rate: 6.116960E-05 | global batch size:     8 | lm loss: 3.172382E+00 | loss scale: 524288.0 | grad norm: 0.773 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 23:49:00] iteration   189400/  500000 | consumed samples:      1515200 | elapsed time per iteration (ms): 321.0 | learning rate: 6.110275E-05 | global batch size:     8 | lm loss: 3.197429E+00 | loss scale: 524288.0 | grad norm: 0.780 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 23:49:32] iteration   189500/  500000 | consumed samples:      1516000 | elapsed time per iteration (ms): 320.6 | learning rate: 6.103592E-05 | global batch size:     8 | lm loss: 3.205874E+00 | loss scale: 524288.0 | grad norm: 0.760 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 23:50:04] iteration   189600/  500000 | consumed samples:      1516800 | elapsed time per iteration (ms): 321.9 | learning rate: 6.096911E-05 | global batch size:     8 | lm loss: 3.142146E+00 | loss scale: 524288.0 | grad norm: 0.813 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 23:50:37] iteration   189700/  500000 | consumed samples:      1517600 | elapsed time per iteration (ms): 323.7 | learning rate: 6.090231E-05 | global batch size:     8 | lm loss: 3.141623E+00 | loss scale: 524288.0 | grad norm: 0.769 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 23:51:09] iteration   189800/  500000 | consumed samples:      1518400 | elapsed time per iteration (ms): 323.0 | learning rate: 6.083554E-05 | global batch size:     8 | lm loss: 3.152167E+00 | loss scale: 524288.0 | grad norm: 0.791 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 23:51:41] iteration   189900/  500000 | consumed samples:      1519200 | elapsed time per iteration (ms): 321.6 | learning rate: 6.076878E-05 | global batch size:     8 | lm loss: 3.179025E+00 | loss scale: 524288.0 | grad norm: 0.774 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 23:52:14] iteration   190000/  500000 | consumed samples:      1520000 | elapsed time per iteration (ms): 323.7 | learning rate: 6.070338E-05 | global batch size:     8 | lm loss: 3.168153E+00 | loss scale: 524288.0 | grad norm: 0.748 | number of skipped iterations:   2 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1065.67, 1065.67)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 190000 | lm loss value: 3.664412E+00 | lm loss PPL: 3.903318E+01 | 
--------------------------------------------------------------------------------------------------
saving checkpoint at iteration  190000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-max in torch format
  successfully saved checkpoint at iteration  190000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-max
(min, max) time across ranks (ms):
    save-checkpoint ................................: (5777.80, 5777.80)
 [2024-06-21 23:52:53] iteration   190100/  500000 | consumed samples:      1520800 | elapsed time per iteration (ms): 322.7 | learning rate: 6.063667E-05 | global batch size:     8 | lm loss: 3.182551E+00 | loss scale: 524288.0 | grad norm: 0.749 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 23:53:25] iteration   190200/  500000 | consumed samples:      1521600 | elapsed time per iteration (ms): 320.4 | learning rate: 6.056997E-05 | global batch size:     8 | lm loss: 3.178087E+00 | loss scale: 524288.0 | grad norm: 0.784 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 23:53:57] iteration   190300/  500000 | consumed samples:      1522400 | elapsed time per iteration (ms): 322.4 | learning rate: 6.050329E-05 | global batch size:     8 | lm loss: 3.165448E+00 | loss scale: 524288.0 | grad norm: 0.766 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 23:54:29] iteration   190400/  500000 | consumed samples:      1523200 | elapsed time per iteration (ms): 322.1 | learning rate: 6.043663E-05 | global batch size:     8 | lm loss: 3.163823E+00 | loss scale: 524288.0 | grad norm: 0.805 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 23:55:02] iteration   190500/  500000 | consumed samples:      1524000 | elapsed time per iteration (ms): 323.7 | learning rate: 6.036999E-05 | global batch size:     8 | lm loss: 3.182422E+00 | loss scale: 524288.0 | grad norm: 0.758 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 23:55:34] iteration   190600/  500000 | consumed samples:      1524800 | elapsed time per iteration (ms): 323.3 | learning rate: 6.030337E-05 | global batch size:     8 | lm loss: 3.206813E+00 | loss scale: 524288.0 | grad norm: 0.806 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 23:56:06] iteration   190700/  500000 | consumed samples:      1525600 | elapsed time per iteration (ms): 321.3 | learning rate: 6.023676E-05 | global batch size:     8 | lm loss: 3.152191E+00 | loss scale: 524288.0 | grad norm: 0.804 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 23:56:39] iteration   190800/  500000 | consumed samples:      1526400 | elapsed time per iteration (ms): 324.9 | learning rate: 6.017085E-05 | global batch size:     8 | lm loss: 3.165841E+00 | loss scale: 262144.0 | grad norm: 0.770 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-21 23:57:11] iteration   190900/  500000 | consumed samples:      1527200 | elapsed time per iteration (ms): 322.7 | learning rate: 6.010428E-05 | global batch size:     8 | lm loss: 3.174491E+00 | loss scale: 262144.0 | grad norm: 0.766 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 23:57:43] iteration   191000/  500000 | consumed samples:      1528000 | elapsed time per iteration (ms): 323.7 | learning rate: 6.003774E-05 | global batch size:     8 | lm loss: 3.222910E+00 | loss scale: 262144.0 | grad norm: 0.726 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1065.49, 1065.49)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 191000 | lm loss value: 3.735037E+00 | lm loss PPL: 4.188957E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-21 23:58:17] iteration   191100/  500000 | consumed samples:      1528800 | elapsed time per iteration (ms): 323.3 | learning rate: 5.997122E-05 | global batch size:     8 | lm loss: 3.174814E+00 | loss scale: 262144.0 | grad norm: 0.761 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 23:58:49] iteration   191200/  500000 | consumed samples:      1529600 | elapsed time per iteration (ms): 322.7 | learning rate: 5.990471E-05 | global batch size:     8 | lm loss: 3.195352E+00 | loss scale: 262144.0 | grad norm: 0.786 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 23:59:21] iteration   191300/  500000 | consumed samples:      1530400 | elapsed time per iteration (ms): 322.1 | learning rate: 5.983823E-05 | global batch size:     8 | lm loss: 3.144521E+00 | loss scale: 262144.0 | grad norm: 0.769 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-21 23:59:53] iteration   191400/  500000 | consumed samples:      1531200 | elapsed time per iteration (ms): 323.6 | learning rate: 5.977176E-05 | global batch size:     8 | lm loss: 3.197753E+00 | loss scale: 262144.0 | grad norm: 0.760 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 00:00:26] iteration   191500/  500000 | consumed samples:      1532000 | elapsed time per iteration (ms): 323.5 | learning rate: 5.970532E-05 | global batch size:     8 | lm loss: 3.113984E+00 | loss scale: 262144.0 | grad norm: 0.770 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 00:00:58] iteration   191600/  500000 | consumed samples:      1532800 | elapsed time per iteration (ms): 319.1 | learning rate: 5.963889E-05 | global batch size:     8 | lm loss: 3.144106E+00 | loss scale: 262144.0 | grad norm: 0.804 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 00:01:30] iteration   191700/  500000 | consumed samples:      1533600 | elapsed time per iteration (ms): 322.4 | learning rate: 5.957249E-05 | global batch size:     8 | lm loss: 3.202973E+00 | loss scale: 262144.0 | grad norm: 0.771 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 00:02:02] iteration   191800/  500000 | consumed samples:      1534400 | elapsed time per iteration (ms): 323.5 | learning rate: 5.950610E-05 | global batch size:     8 | lm loss: 3.135907E+00 | loss scale: 524288.0 | grad norm: 0.783 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 00:02:35] iteration   191900/  500000 | consumed samples:      1535200 | elapsed time per iteration (ms): 322.8 | learning rate: 5.943974E-05 | global batch size:     8 | lm loss: 3.137656E+00 | loss scale: 524288.0 | grad norm: 0.773 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 00:03:07] iteration   192000/  500000 | consumed samples:      1536000 | elapsed time per iteration (ms): 321.1 | learning rate: 5.937339E-05 | global batch size:     8 | lm loss: 3.197060E+00 | loss scale: 524288.0 | grad norm: 0.793 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1065.10, 1065.10)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 192000 | lm loss value: 3.644212E+00 | lm loss PPL: 3.825262E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 00:03:40] iteration   192100/  500000 | consumed samples:      1536800 | elapsed time per iteration (ms): 322.9 | learning rate: 5.930707E-05 | global batch size:     8 | lm loss: 3.173972E+00 | loss scale: 524288.0 | grad norm: 0.747 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 00:04:12] iteration   192200/  500000 | consumed samples:      1537600 | elapsed time per iteration (ms): 322.9 | learning rate: 5.924076E-05 | global batch size:     8 | lm loss: 3.174632E+00 | loss scale: 524288.0 | grad norm: 0.751 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 00:04:45] iteration   192300/  500000 | consumed samples:      1538400 | elapsed time per iteration (ms): 324.7 | learning rate: 5.917448E-05 | global batch size:     8 | lm loss: 3.197166E+00 | loss scale: 524288.0 | grad norm: 0.751 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 00:05:17] iteration   192400/  500000 | consumed samples:      1539200 | elapsed time per iteration (ms): 321.4 | learning rate: 5.910888E-05 | global batch size:     8 | lm loss: 3.144857E+00 | loss scale: 524288.0 | grad norm: 0.784 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-22 00:05:49] iteration   192500/  500000 | consumed samples:      1540000 | elapsed time per iteration (ms): 320.3 | learning rate: 5.904264E-05 | global batch size:     8 | lm loss: 3.185092E+00 | loss scale: 524288.0 | grad norm: 0.778 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 00:06:21] iteration   192600/  500000 | consumed samples:      1540800 | elapsed time per iteration (ms): 319.5 | learning rate: 5.897642E-05 | global batch size:     8 | lm loss: 3.207653E+00 | loss scale: 524288.0 | grad norm: 0.834 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 00:06:53] iteration   192700/  500000 | consumed samples:      1541600 | elapsed time per iteration (ms): 322.6 | learning rate: 5.891021E-05 | global batch size:     8 | lm loss: 3.166843E+00 | loss scale: 524288.0 | grad norm: 0.753 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 00:07:25] iteration   192800/  500000 | consumed samples:      1542400 | elapsed time per iteration (ms): 320.9 | learning rate: 5.884403E-05 | global batch size:     8 | lm loss: 3.173651E+00 | loss scale: 524288.0 | grad norm: 0.772 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 00:07:58] iteration   192900/  500000 | consumed samples:      1543200 | elapsed time per iteration (ms): 322.4 | learning rate: 5.877787E-05 | global batch size:     8 | lm loss: 3.147510E+00 | loss scale: 524288.0 | grad norm: 0.803 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 00:08:30] iteration   193000/  500000 | consumed samples:      1544000 | elapsed time per iteration (ms): 320.2 | learning rate: 5.871173E-05 | global batch size:     8 | lm loss: 3.153741E+00 | loss scale: 524288.0 | grad norm: 0.801 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1067.07, 1067.07)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 193000 | lm loss value: 3.740392E+00 | lm loss PPL: 4.211449E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 00:09:03] iteration   193100/  500000 | consumed samples:      1544800 | elapsed time per iteration (ms): 321.2 | learning rate: 5.864562E-05 | global batch size:     8 | lm loss: 3.169946E+00 | loss scale: 524288.0 | grad norm: 0.817 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 00:09:35] iteration   193200/  500000 | consumed samples:      1545600 | elapsed time per iteration (ms): 320.3 | learning rate: 5.857952E-05 | global batch size:     8 | lm loss: 3.184655E+00 | loss scale: 524288.0 | grad norm: 0.788 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 00:10:07] iteration   193300/  500000 | consumed samples:      1546400 | elapsed time per iteration (ms): 321.0 | learning rate: 5.851344E-05 | global batch size:     8 | lm loss: 3.220575E+00 | loss scale: 524288.0 | grad norm: 0.765 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 00:10:39] iteration   193400/  500000 | consumed samples:      1547200 | elapsed time per iteration (ms): 321.2 | learning rate: 5.844805E-05 | global batch size:     8 | lm loss: 3.208180E+00 | loss scale: 262144.0 | grad norm: 0.784 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-22 00:11:11] iteration   193500/  500000 | consumed samples:      1548000 | elapsed time per iteration (ms): 319.5 | learning rate: 5.838201E-05 | global batch size:     8 | lm loss: 3.187961E+00 | loss scale: 262144.0 | grad norm: 0.827 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 00:11:43] iteration   193600/  500000 | consumed samples:      1548800 | elapsed time per iteration (ms): 323.6 | learning rate: 5.831600E-05 | global batch size:     8 | lm loss: 3.125643E+00 | loss scale: 262144.0 | grad norm: 0.778 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 00:12:15] iteration   193700/  500000 | consumed samples:      1549600 | elapsed time per iteration (ms): 321.3 | learning rate: 5.825001E-05 | global batch size:     8 | lm loss: 3.209698E+00 | loss scale: 262144.0 | grad norm: 0.769 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 00:12:47] iteration   193800/  500000 | consumed samples:      1550400 | elapsed time per iteration (ms): 320.4 | learning rate: 5.818404E-05 | global batch size:     8 | lm loss: 3.164406E+00 | loss scale: 262144.0 | grad norm: 0.761 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 00:13:19] iteration   193900/  500000 | consumed samples:      1551200 | elapsed time per iteration (ms): 319.8 | learning rate: 5.811809E-05 | global batch size:     8 | lm loss: 3.178140E+00 | loss scale: 262144.0 | grad norm: 0.758 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 00:13:52] iteration   194000/  500000 | consumed samples:      1552000 | elapsed time per iteration (ms): 321.2 | learning rate: 5.805217E-05 | global batch size:     8 | lm loss: 3.172503E+00 | loss scale: 262144.0 | grad norm: 0.788 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1071.36, 1071.36)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 194000 | lm loss value: 3.641503E+00 | lm loss PPL: 3.814913E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 00:14:25] iteration   194100/  500000 | consumed samples:      1552800 | elapsed time per iteration (ms): 320.3 | learning rate: 5.798626E-05 | global batch size:     8 | lm loss: 3.113763E+00 | loss scale: 262144.0 | grad norm: 0.778 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 00:14:57] iteration   194200/  500000 | consumed samples:      1553600 | elapsed time per iteration (ms): 322.0 | learning rate: 5.792038E-05 | global batch size:     8 | lm loss: 3.185208E+00 | loss scale: 262144.0 | grad norm: 0.760 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 00:15:29] iteration   194300/  500000 | consumed samples:      1554400 | elapsed time per iteration (ms): 322.6 | learning rate: 5.785451E-05 | global batch size:     8 | lm loss: 3.182665E+00 | loss scale: 262144.0 | grad norm: 0.781 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 00:16:01] iteration   194400/  500000 | consumed samples:      1555200 | elapsed time per iteration (ms): 320.5 | learning rate: 5.778867E-05 | global batch size:     8 | lm loss: 3.167173E+00 | loss scale: 524288.0 | grad norm: 0.745 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 00:16:33] iteration   194500/  500000 | consumed samples:      1556000 | elapsed time per iteration (ms): 319.2 | learning rate: 5.772286E-05 | global batch size:     8 | lm loss: 3.155921E+00 | loss scale: 524288.0 | grad norm: 0.803 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 00:17:05] iteration   194600/  500000 | consumed samples:      1556800 | elapsed time per iteration (ms): 321.7 | learning rate: 5.765706E-05 | global batch size:     8 | lm loss: 3.124935E+00 | loss scale: 524288.0 | grad norm: 0.837 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 00:17:37] iteration   194700/  500000 | consumed samples:      1557600 | elapsed time per iteration (ms): 321.1 | learning rate: 5.759128E-05 | global batch size:     8 | lm loss: 3.162249E+00 | loss scale: 524288.0 | grad norm: 0.760 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 00:18:10] iteration   194800/  500000 | consumed samples:      1558400 | elapsed time per iteration (ms): 323.3 | learning rate: 5.752619E-05 | global batch size:     8 | lm loss: 3.142873E+00 | loss scale: 524288.0 | grad norm: 0.777 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-22 00:18:42] iteration   194900/  500000 | consumed samples:      1559200 | elapsed time per iteration (ms): 322.7 | learning rate: 5.746046E-05 | global batch size:     8 | lm loss: 3.129031E+00 | loss scale: 524288.0 | grad norm: 0.793 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 00:19:14] iteration   195000/  500000 | consumed samples:      1560000 | elapsed time per iteration (ms): 322.6 | learning rate: 5.739541E-05 | global batch size:     8 | lm loss: 3.173736E+00 | loss scale: 262144.0 | grad norm: 0.791 | number of skipped iterations:   1 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1064.88, 1064.88)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 195000 | lm loss value: 3.612524E+00 | lm loss PPL: 3.705947E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 00:19:48] iteration   195100/  500000 | consumed samples:      1560800 | elapsed time per iteration (ms): 322.4 | learning rate: 5.732972E-05 | global batch size:     8 | lm loss: 3.131767E+00 | loss scale: 262144.0 | grad norm: 0.795 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 00:20:20] iteration   195200/  500000 | consumed samples:      1561600 | elapsed time per iteration (ms): 322.0 | learning rate: 5.726406E-05 | global batch size:     8 | lm loss: 3.118955E+00 | loss scale: 262144.0 | grad norm: 0.767 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 00:20:52] iteration   195300/  500000 | consumed samples:      1562400 | elapsed time per iteration (ms): 322.8 | learning rate: 5.719842E-05 | global batch size:     8 | lm loss: 3.188654E+00 | loss scale: 262144.0 | grad norm: 0.778 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 00:21:24] iteration   195400/  500000 | consumed samples:      1563200 | elapsed time per iteration (ms): 322.5 | learning rate: 5.713280E-05 | global batch size:     8 | lm loss: 3.138586E+00 | loss scale: 262144.0 | grad norm: 0.779 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 00:21:57] iteration   195500/  500000 | consumed samples:      1564000 | elapsed time per iteration (ms): 323.6 | learning rate: 5.706720E-05 | global batch size:     8 | lm loss: 3.151310E+00 | loss scale: 262144.0 | grad norm: 0.736 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 00:22:29] iteration   195600/  500000 | consumed samples:      1564800 | elapsed time per iteration (ms): 324.1 | learning rate: 5.700162E-05 | global batch size:     8 | lm loss: 3.154757E+00 | loss scale: 262144.0 | grad norm: 0.778 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 00:23:01] iteration   195700/  500000 | consumed samples:      1565600 | elapsed time per iteration (ms): 323.1 | learning rate: 5.693607E-05 | global batch size:     8 | lm loss: 3.168669E+00 | loss scale: 262144.0 | grad norm: 0.770 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 00:23:34] iteration   195800/  500000 | consumed samples:      1566400 | elapsed time per iteration (ms): 322.2 | learning rate: 5.687054E-05 | global batch size:     8 | lm loss: 3.205087E+00 | loss scale: 262144.0 | grad norm: 0.757 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 00:24:06] iteration   195900/  500000 | consumed samples:      1567200 | elapsed time per iteration (ms): 321.4 | learning rate: 5.680504E-05 | global batch size:     8 | lm loss: 3.150927E+00 | loss scale: 262144.0 | grad norm: 0.785 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 00:24:38] iteration   196000/  500000 | consumed samples:      1568000 | elapsed time per iteration (ms): 322.9 | learning rate: 5.673955E-05 | global batch size:     8 | lm loss: 3.144631E+00 | loss scale: 524288.0 | grad norm: 0.795 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1064.44, 1064.44)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 196000 | lm loss value: 3.646471E+00 | lm loss PPL: 3.833913E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 00:25:11] iteration   196100/  500000 | consumed samples:      1568800 | elapsed time per iteration (ms): 323.1 | learning rate: 5.667409E-05 | global batch size:     8 | lm loss: 3.147187E+00 | loss scale: 524288.0 | grad norm: 0.811 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 00:25:43] iteration   196200/  500000 | consumed samples:      1569600 | elapsed time per iteration (ms): 321.1 | learning rate: 5.660866E-05 | global batch size:     8 | lm loss: 3.129143E+00 | loss scale: 524288.0 | grad norm: 0.787 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 00:26:16] iteration   196300/  500000 | consumed samples:      1570400 | elapsed time per iteration (ms): 322.1 | learning rate: 5.654324E-05 | global batch size:     8 | lm loss: 3.179985E+00 | loss scale: 524288.0 | grad norm: 0.810 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 00:26:48] iteration   196400/  500000 | consumed samples:      1571200 | elapsed time per iteration (ms): 320.8 | learning rate: 5.647785E-05 | global batch size:     8 | lm loss: 3.150003E+00 | loss scale: 524288.0 | grad norm: 0.858 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 00:27:20] iteration   196500/  500000 | consumed samples:      1572000 | elapsed time per iteration (ms): 318.3 | learning rate: 5.641314E-05 | global batch size:     8 | lm loss: 3.135678E+00 | loss scale: 524288.0 | grad norm: 0.752 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-22 00:27:52] iteration   196600/  500000 | consumed samples:      1572800 | elapsed time per iteration (ms): 321.3 | learning rate: 5.634844E-05 | global batch size:     8 | lm loss: 3.170090E+00 | loss scale: 262144.0 | grad norm: 0.806 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-22 00:28:24] iteration   196700/  500000 | consumed samples:      1573600 | elapsed time per iteration (ms): 322.0 | learning rate: 5.628312E-05 | global batch size:     8 | lm loss: 3.135524E+00 | loss scale: 262144.0 | grad norm: 0.802 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 00:28:56] iteration   196800/  500000 | consumed samples:      1574400 | elapsed time per iteration (ms): 320.0 | learning rate: 5.621782E-05 | global batch size:     8 | lm loss: 3.162832E+00 | loss scale: 262144.0 | grad norm: 0.741 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 00:29:28] iteration   196900/  500000 | consumed samples:      1575200 | elapsed time per iteration (ms): 319.8 | learning rate: 5.615255E-05 | global batch size:     8 | lm loss: 3.159130E+00 | loss scale: 262144.0 | grad norm: 0.786 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 00:30:00] iteration   197000/  500000 | consumed samples:      1576000 | elapsed time per iteration (ms): 322.9 | learning rate: 5.608729E-05 | global batch size:     8 | lm loss: 3.143590E+00 | loss scale: 262144.0 | grad norm: 0.771 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1064.67, 1064.67)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 197000 | lm loss value: 3.647417E+00 | lm loss PPL: 3.837542E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 00:30:33] iteration   197100/  500000 | consumed samples:      1576800 | elapsed time per iteration (ms): 321.4 | learning rate: 5.602206E-05 | global batch size:     8 | lm loss: 3.181841E+00 | loss scale: 262144.0 | grad norm: 0.809 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 00:31:05] iteration   197200/  500000 | consumed samples:      1577600 | elapsed time per iteration (ms): 319.9 | learning rate: 5.595751E-05 | global batch size:     8 | lm loss: 3.104454E+00 | loss scale: 131072.0 | grad norm: 0.743 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-22 00:31:38] iteration   197300/  500000 | consumed samples:      1578400 | elapsed time per iteration (ms): 321.8 | learning rate: 5.589233E-05 | global batch size:     8 | lm loss: 3.142186E+00 | loss scale: 131072.0 | grad norm: 0.767 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 00:32:10] iteration   197400/  500000 | consumed samples:      1579200 | elapsed time per iteration (ms): 322.1 | learning rate: 5.582717E-05 | global batch size:     8 | lm loss: 3.139931E+00 | loss scale: 131072.0 | grad norm: 0.802 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 00:32:42] iteration   197500/  500000 | consumed samples:      1580000 | elapsed time per iteration (ms): 321.4 | learning rate: 5.576204E-05 | global batch size:     8 | lm loss: 3.163231E+00 | loss scale: 131072.0 | grad norm: 0.761 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 00:33:14] iteration   197600/  500000 | consumed samples:      1580800 | elapsed time per iteration (ms): 320.8 | learning rate: 5.569693E-05 | global batch size:     8 | lm loss: 3.129364E+00 | loss scale: 131072.0 | grad norm: 0.758 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 00:33:46] iteration   197700/  500000 | consumed samples:      1581600 | elapsed time per iteration (ms): 323.0 | learning rate: 5.563184E-05 | global batch size:     8 | lm loss: 3.125578E+00 | loss scale: 131072.0 | grad norm: 0.817 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 00:34:18] iteration   197800/  500000 | consumed samples:      1582400 | elapsed time per iteration (ms): 321.6 | learning rate: 5.556678E-05 | global batch size:     8 | lm loss: 3.175333E+00 | loss scale: 131072.0 | grad norm: 0.788 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 00:34:51] iteration   197900/  500000 | consumed samples:      1583200 | elapsed time per iteration (ms): 322.9 | learning rate: 5.550174E-05 | global batch size:     8 | lm loss: 3.177037E+00 | loss scale: 131072.0 | grad norm: 0.797 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 00:35:23] iteration   198000/  500000 | consumed samples:      1584000 | elapsed time per iteration (ms): 323.1 | learning rate: 5.543672E-05 | global batch size:     8 | lm loss: 3.167829E+00 | loss scale: 131072.0 | grad norm: 0.764 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1063.76, 1063.76)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 198000 | lm loss value: 3.746621E+00 | lm loss PPL: 4.237763E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 00:35:56] iteration   198100/  500000 | consumed samples:      1584800 | elapsed time per iteration (ms): 320.8 | learning rate: 5.537173E-05 | global batch size:     8 | lm loss: 3.168343E+00 | loss scale: 131072.0 | grad norm: 0.821 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 00:36:28] iteration   198200/  500000 | consumed samples:      1585600 | elapsed time per iteration (ms): 321.1 | learning rate: 5.530677E-05 | global batch size:     8 | lm loss: 3.155104E+00 | loss scale: 262144.0 | grad norm: 0.797 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 00:37:01] iteration   198300/  500000 | consumed samples:      1586400 | elapsed time per iteration (ms): 322.2 | learning rate: 5.524183E-05 | global batch size:     8 | lm loss: 3.132214E+00 | loss scale: 262144.0 | grad norm: 0.846 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 00:37:32] iteration   198400/  500000 | consumed samples:      1587200 | elapsed time per iteration (ms): 318.4 | learning rate: 5.517691E-05 | global batch size:     8 | lm loss: 3.144943E+00 | loss scale: 262144.0 | grad norm: 0.833 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 00:38:05] iteration   198500/  500000 | consumed samples:      1588000 | elapsed time per iteration (ms): 321.5 | learning rate: 5.511202E-05 | global batch size:     8 | lm loss: 3.151483E+00 | loss scale: 262144.0 | grad norm: 0.774 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 00:38:37] iteration   198600/  500000 | consumed samples:      1588800 | elapsed time per iteration (ms): 321.4 | learning rate: 5.504715E-05 | global batch size:     8 | lm loss: 3.166220E+00 | loss scale: 262144.0 | grad norm: 0.824 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 00:39:09] iteration   198700/  500000 | consumed samples:      1589600 | elapsed time per iteration (ms): 322.0 | learning rate: 5.498230E-05 | global batch size:     8 | lm loss: 3.175736E+00 | loss scale: 262144.0 | grad norm: 0.823 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 00:39:41] iteration   198800/  500000 | consumed samples:      1590400 | elapsed time per iteration (ms): 321.0 | learning rate: 5.491748E-05 | global batch size:     8 | lm loss: 3.138384E+00 | loss scale: 262144.0 | grad norm: 0.795 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 00:40:13] iteration   198900/  500000 | consumed samples:      1591200 | elapsed time per iteration (ms): 320.1 | learning rate: 5.485269E-05 | global batch size:     8 | lm loss: 3.098428E+00 | loss scale: 262144.0 | grad norm: 0.754 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 00:40:45] iteration   199000/  500000 | consumed samples:      1592000 | elapsed time per iteration (ms): 321.1 | learning rate: 5.478792E-05 | global batch size:     8 | lm loss: 3.124173E+00 | loss scale: 262144.0 | grad norm: 0.782 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1064.02, 1064.02)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 199000 | lm loss value: 3.617563E+00 | lm loss PPL: 3.724667E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 00:41:18] iteration   199100/  500000 | consumed samples:      1592800 | elapsed time per iteration (ms): 318.9 | learning rate: 5.472317E-05 | global batch size:     8 | lm loss: 3.139015E+00 | loss scale: 262144.0 | grad norm: 0.793 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 00:41:50] iteration   199200/  500000 | consumed samples:      1593600 | elapsed time per iteration (ms): 321.0 | learning rate: 5.465845E-05 | global batch size:     8 | lm loss: 3.136809E+00 | loss scale: 524288.0 | grad norm: 0.930 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 00:42:22] iteration   199300/  500000 | consumed samples:      1594400 | elapsed time per iteration (ms): 321.2 | learning rate: 5.459376E-05 | global batch size:     8 | lm loss: 3.132985E+00 | loss scale: 524288.0 | grad norm: 0.748 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 00:42:55] iteration   199400/  500000 | consumed samples:      1595200 | elapsed time per iteration (ms): 323.3 | learning rate: 5.452909E-05 | global batch size:     8 | lm loss: 3.155817E+00 | loss scale: 524288.0 | grad norm: 0.809 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 00:43:27] iteration   199500/  500000 | consumed samples:      1596000 | elapsed time per iteration (ms): 319.9 | learning rate: 5.446444E-05 | global batch size:     8 | lm loss: 3.144590E+00 | loss scale: 524288.0 | grad norm: 0.812 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 00:43:59] iteration   199600/  500000 | consumed samples:      1596800 | elapsed time per iteration (ms): 321.2 | learning rate: 5.439982E-05 | global batch size:     8 | lm loss: 3.149523E+00 | loss scale: 524288.0 | grad norm: 0.794 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 00:44:31] iteration   199700/  500000 | consumed samples:      1597600 | elapsed time per iteration (ms): 322.5 | learning rate: 5.433523E-05 | global batch size:     8 | lm loss: 3.140347E+00 | loss scale: 524288.0 | grad norm: 0.786 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 00:45:03] iteration   199800/  500000 | consumed samples:      1598400 | elapsed time per iteration (ms): 322.2 | learning rate: 5.427066E-05 | global batch size:     8 | lm loss: 3.195150E+00 | loss scale: 524288.0 | grad norm: 0.738 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 00:45:35] iteration   199900/  500000 | consumed samples:      1599200 | elapsed time per iteration (ms): 320.4 | learning rate: 5.420611E-05 | global batch size:     8 | lm loss: 3.166250E+00 | loss scale: 524288.0 | grad norm: 0.875 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 00:46:07] iteration   200000/  500000 | consumed samples:      1600000 | elapsed time per iteration (ms): 321.3 | learning rate: 5.414159E-05 | global batch size:     8 | lm loss: 3.152502E+00 | loss scale: 524288.0 | grad norm: 0.751 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1063.64, 1063.64)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 200000 | lm loss value: 3.794755E+00 | lm loss PPL: 4.446735E+01 | 
--------------------------------------------------------------------------------------------------
saving checkpoint at iteration  200000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-max in torch format
  successfully saved checkpoint at iteration  200000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-max
(min, max) time across ranks (ms):
    save-checkpoint ................................: (5723.39, 5723.39)
 [2024-06-22 00:46:46] iteration   200100/  500000 | consumed samples:      1600800 | elapsed time per iteration (ms): 322.6 | learning rate: 5.407710E-05 | global batch size:     8 | lm loss: 3.177440E+00 | loss scale: 524288.0 | grad norm: 0.804 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 00:47:19] iteration   200200/  500000 | consumed samples:      1601600 | elapsed time per iteration (ms): 323.1 | learning rate: 5.401328E-05 | global batch size:     8 | lm loss: 3.145313E+00 | loss scale: 1048576.0 | grad norm: 0.813 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-22 00:47:51] iteration   200300/  500000 | consumed samples:      1602400 | elapsed time per iteration (ms): 321.8 | learning rate: 5.395012E-05 | global batch size:     8 | lm loss: 3.182363E+00 | loss scale: 262144.0 | grad norm: 0.793 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-22 00:48:23] iteration   200400/  500000 | consumed samples:      1603200 | elapsed time per iteration (ms): 321.4 | learning rate: 5.388570E-05 | global batch size:     8 | lm loss: 3.143611E+00 | loss scale: 262144.0 | grad norm: 0.811 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 00:48:55] iteration   200500/  500000 | consumed samples:      1604000 | elapsed time per iteration (ms): 321.4 | learning rate: 5.382131E-05 | global batch size:     8 | lm loss: 3.139894E+00 | loss scale: 262144.0 | grad norm: 0.780 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 00:49:27] iteration   200600/  500000 | consumed samples:      1604800 | elapsed time per iteration (ms): 322.6 | learning rate: 5.375759E-05 | global batch size:     8 | lm loss: 3.103856E+00 | loss scale: 131072.0 | grad norm: 0.830 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-22 00:50:00] iteration   200700/  500000 | consumed samples:      1605600 | elapsed time per iteration (ms): 322.8 | learning rate: 5.369325E-05 | global batch size:     8 | lm loss: 3.112418E+00 | loss scale: 131072.0 | grad norm: 0.773 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 00:50:32] iteration   200800/  500000 | consumed samples:      1606400 | elapsed time per iteration (ms): 321.8 | learning rate: 5.362893E-05 | global batch size:     8 | lm loss: 3.123708E+00 | loss scale: 131072.0 | grad norm: 0.781 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 00:51:04] iteration   200900/  500000 | consumed samples:      1607200 | elapsed time per iteration (ms): 322.9 | learning rate: 5.356464E-05 | global batch size:     8 | lm loss: 3.142469E+00 | loss scale: 131072.0 | grad norm: 0.791 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 00:51:37] iteration   201000/  500000 | consumed samples:      1608000 | elapsed time per iteration (ms): 323.5 | learning rate: 5.350038E-05 | global batch size:     8 | lm loss: 3.154240E+00 | loss scale: 131072.0 | grad norm: 0.810 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1064.49, 1064.49)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 201000 | lm loss value: 3.661651E+00 | lm loss PPL: 3.892555E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 00:52:10] iteration   201100/  500000 | consumed samples:      1608800 | elapsed time per iteration (ms): 321.9 | learning rate: 5.343614E-05 | global batch size:     8 | lm loss: 3.139112E+00 | loss scale: 131072.0 | grad norm: 0.805 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 00:52:42] iteration   201200/  500000 | consumed samples:      1609600 | elapsed time per iteration (ms): 323.6 | learning rate: 5.337193E-05 | global batch size:     8 | lm loss: 3.144294E+00 | loss scale: 131072.0 | grad norm: 0.778 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 00:53:15] iteration   201300/  500000 | consumed samples:      1610400 | elapsed time per iteration (ms): 324.1 | learning rate: 5.330775E-05 | global batch size:     8 | lm loss: 3.103391E+00 | loss scale: 131072.0 | grad norm: 0.781 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 00:53:47] iteration   201400/  500000 | consumed samples:      1611200 | elapsed time per iteration (ms): 324.2 | learning rate: 5.324359E-05 | global batch size:     8 | lm loss: 3.148557E+00 | loss scale: 131072.0 | grad norm: 0.791 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 00:54:19] iteration   201500/  500000 | consumed samples:      1612000 | elapsed time per iteration (ms): 320.9 | learning rate: 5.317946E-05 | global batch size:     8 | lm loss: 3.150702E+00 | loss scale: 131072.0 | grad norm: 0.788 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 00:54:51] iteration   201600/  500000 | consumed samples:      1612800 | elapsed time per iteration (ms): 320.9 | learning rate: 5.311535E-05 | global batch size:     8 | lm loss: 3.109201E+00 | loss scale: 262144.0 | grad norm: 0.791 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 00:55:23] iteration   201700/  500000 | consumed samples:      1613600 | elapsed time per iteration (ms): 320.7 | learning rate: 5.305127E-05 | global batch size:     8 | lm loss: 3.162110E+00 | loss scale: 262144.0 | grad norm: 0.798 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 00:55:55] iteration   201800/  500000 | consumed samples:      1614400 | elapsed time per iteration (ms): 321.4 | learning rate: 5.298786E-05 | global batch size:     8 | lm loss: 3.129572E+00 | loss scale: 262144.0 | grad norm: 0.769 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-22 00:56:28] iteration   201900/  500000 | consumed samples:      1615200 | elapsed time per iteration (ms): 322.0 | learning rate: 5.292383E-05 | global batch size:     8 | lm loss: 3.114739E+00 | loss scale: 262144.0 | grad norm: 0.789 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 00:57:00] iteration   202000/  500000 | consumed samples:      1616000 | elapsed time per iteration (ms): 321.3 | learning rate: 5.285983E-05 | global batch size:     8 | lm loss: 3.136917E+00 | loss scale: 262144.0 | grad norm: 0.761 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1065.19, 1065.19)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 202000 | lm loss value: 3.530809E+00 | lm loss PPL: 3.415159E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 00:57:33] iteration   202100/  500000 | consumed samples:      1616800 | elapsed time per iteration (ms): 323.9 | learning rate: 5.279586E-05 | global batch size:     8 | lm loss: 3.120154E+00 | loss scale: 262144.0 | grad norm: 0.775 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 00:58:05] iteration   202200/  500000 | consumed samples:      1617600 | elapsed time per iteration (ms): 323.2 | learning rate: 5.273191E-05 | global batch size:     8 | lm loss: 3.117664E+00 | loss scale: 262144.0 | grad norm: 0.802 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 00:58:38] iteration   202300/  500000 | consumed samples:      1618400 | elapsed time per iteration (ms): 324.5 | learning rate: 5.266799E-05 | global batch size:     8 | lm loss: 3.143407E+00 | loss scale: 262144.0 | grad norm: 0.794 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 00:59:10] iteration   202400/  500000 | consumed samples:      1619200 | elapsed time per iteration (ms): 323.0 | learning rate: 5.260474E-05 | global batch size:     8 | lm loss: 3.166386E+00 | loss scale: 131072.0 | grad norm: 0.771 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-22 00:59:42] iteration   202500/  500000 | consumed samples:      1620000 | elapsed time per iteration (ms): 320.8 | learning rate: 5.254087E-05 | global batch size:     8 | lm loss: 3.145791E+00 | loss scale: 131072.0 | grad norm: 0.765 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 01:00:15] iteration   202600/  500000 | consumed samples:      1620800 | elapsed time per iteration (ms): 323.3 | learning rate: 5.247703E-05 | global batch size:     8 | lm loss: 3.163667E+00 | loss scale: 131072.0 | grad norm: 0.807 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 01:00:47] iteration   202700/  500000 | consumed samples:      1621600 | elapsed time per iteration (ms): 323.5 | learning rate: 5.241322E-05 | global batch size:     8 | lm loss: 3.147545E+00 | loss scale: 131072.0 | grad norm: 0.816 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 01:01:19] iteration   202800/  500000 | consumed samples:      1622400 | elapsed time per iteration (ms): 322.3 | learning rate: 5.234944E-05 | global batch size:     8 | lm loss: 3.126492E+00 | loss scale: 131072.0 | grad norm: 0.796 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 01:01:51] iteration   202900/  500000 | consumed samples:      1623200 | elapsed time per iteration (ms): 319.8 | learning rate: 5.228568E-05 | global batch size:     8 | lm loss: 3.138911E+00 | loss scale: 131072.0 | grad norm: 0.805 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 01:02:23] iteration   203000/  500000 | consumed samples:      1624000 | elapsed time per iteration (ms): 320.9 | learning rate: 5.222195E-05 | global batch size:     8 | lm loss: 3.133259E+00 | loss scale: 131072.0 | grad norm: 0.808 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1064.34, 1064.34)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 203000 | lm loss value: 3.671076E+00 | lm loss PPL: 3.929416E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 01:02:56] iteration   203100/  500000 | consumed samples:      1624800 | elapsed time per iteration (ms): 321.2 | learning rate: 5.215824E-05 | global batch size:     8 | lm loss: 3.149710E+00 | loss scale: 131072.0 | grad norm: 0.772 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 01:03:29] iteration   203200/  500000 | consumed samples:      1625600 | elapsed time per iteration (ms): 324.4 | learning rate: 5.209457E-05 | global batch size:     8 | lm loss: 3.134543E+00 | loss scale: 131072.0 | grad norm: 0.789 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 01:04:01] iteration   203300/  500000 | consumed samples:      1626400 | elapsed time per iteration (ms): 322.4 | learning rate: 5.203092E-05 | global batch size:     8 | lm loss: 3.140271E+00 | loss scale: 131072.0 | grad norm: 0.820 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 01:04:33] iteration   203400/  500000 | consumed samples:      1627200 | elapsed time per iteration (ms): 318.2 | learning rate: 5.196730E-05 | global batch size:     8 | lm loss: 3.138984E+00 | loss scale: 262144.0 | grad norm: 0.794 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 01:05:05] iteration   203500/  500000 | consumed samples:      1628000 | elapsed time per iteration (ms): 321.1 | learning rate: 5.190371E-05 | global batch size:     8 | lm loss: 3.147799E+00 | loss scale: 262144.0 | grad norm: 0.776 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 01:05:37] iteration   203600/  500000 | consumed samples:      1628800 | elapsed time per iteration (ms): 321.3 | learning rate: 5.184014E-05 | global batch size:     8 | lm loss: 3.118244E+00 | loss scale: 262144.0 | grad norm: 0.812 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 01:06:09] iteration   203700/  500000 | consumed samples:      1629600 | elapsed time per iteration (ms): 322.8 | learning rate: 5.177660E-05 | global batch size:     8 | lm loss: 3.145853E+00 | loss scale: 262144.0 | grad norm: 0.768 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 01:06:42] iteration   203800/  500000 | consumed samples:      1630400 | elapsed time per iteration (ms): 322.4 | learning rate: 5.171309E-05 | global batch size:     8 | lm loss: 3.133517E+00 | loss scale: 262144.0 | grad norm: 0.791 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 01:07:14] iteration   203900/  500000 | consumed samples:      1631200 | elapsed time per iteration (ms): 322.0 | learning rate: 5.164961E-05 | global batch size:     8 | lm loss: 3.170833E+00 | loss scale: 262144.0 | grad norm: 0.767 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 01:07:46] iteration   204000/  500000 | consumed samples:      1632000 | elapsed time per iteration (ms): 323.9 | learning rate: 5.158615E-05 | global batch size:     8 | lm loss: 3.104365E+00 | loss scale: 262144.0 | grad norm: 0.809 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1065.36, 1065.36)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 204000 | lm loss value: 3.760403E+00 | lm loss PPL: 4.296575E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 01:08:19] iteration   204100/  500000 | consumed samples:      1632800 | elapsed time per iteration (ms): 320.6 | learning rate: 5.152273E-05 | global batch size:     8 | lm loss: 3.117210E+00 | loss scale: 262144.0 | grad norm: 0.857 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 01:08:51] iteration   204200/  500000 | consumed samples:      1633600 | elapsed time per iteration (ms): 320.6 | learning rate: 5.145933E-05 | global batch size:     8 | lm loss: 3.164523E+00 | loss scale: 262144.0 | grad norm: 0.806 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 01:09:24] iteration   204300/  500000 | consumed samples:      1634400 | elapsed time per iteration (ms): 321.9 | learning rate: 5.139596E-05 | global batch size:     8 | lm loss: 3.105768E+00 | loss scale: 262144.0 | grad norm: 0.789 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 01:09:56] iteration   204400/  500000 | consumed samples:      1635200 | elapsed time per iteration (ms): 323.2 | learning rate: 5.133262E-05 | global batch size:     8 | lm loss: 3.102677E+00 | loss scale: 524288.0 | grad norm: 0.780 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 01:10:28] iteration   204500/  500000 | consumed samples:      1636000 | elapsed time per iteration (ms): 324.1 | learning rate: 5.126993E-05 | global batch size:     8 | lm loss: 3.093856E+00 | loss scale: 524288.0 | grad norm: 0.806 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-22 01:11:01] iteration   204600/  500000 | consumed samples:      1636800 | elapsed time per iteration (ms): 320.9 | learning rate: 5.120728E-05 | global batch size:     8 | lm loss: 3.158856E+00 | loss scale: 262144.0 | grad norm: 0.829 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-22 01:11:33] iteration   204700/  500000 | consumed samples:      1637600 | elapsed time per iteration (ms): 322.0 | learning rate: 5.114402E-05 | global batch size:     8 | lm loss: 3.151999E+00 | loss scale: 262144.0 | grad norm: 0.840 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 01:12:05] iteration   204800/  500000 | consumed samples:      1638400 | elapsed time per iteration (ms): 322.6 | learning rate: 5.108079E-05 | global batch size:     8 | lm loss: 3.107999E+00 | loss scale: 262144.0 | grad norm: 0.805 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 01:12:37] iteration   204900/  500000 | consumed samples:      1639200 | elapsed time per iteration (ms): 324.2 | learning rate: 5.101822E-05 | global batch size:     8 | lm loss: 3.126730E+00 | loss scale: 131072.0 | grad norm: 0.861 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-22 01:13:10] iteration   205000/  500000 | consumed samples:      1640000 | elapsed time per iteration (ms): 322.4 | learning rate: 5.095505E-05 | global batch size:     8 | lm loss: 3.141342E+00 | loss scale: 131072.0 | grad norm: 0.791 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1064.89, 1064.89)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 205000 | lm loss value: 3.618166E+00 | lm loss PPL: 3.726915E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 01:13:43] iteration   205100/  500000 | consumed samples:      1640800 | elapsed time per iteration (ms): 323.7 | learning rate: 5.089191E-05 | global batch size:     8 | lm loss: 3.116539E+00 | loss scale: 131072.0 | grad norm: 0.796 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 01:14:15] iteration   205200/  500000 | consumed samples:      1641600 | elapsed time per iteration (ms): 322.3 | learning rate: 5.082879E-05 | global batch size:     8 | lm loss: 3.147621E+00 | loss scale: 131072.0 | grad norm: 0.821 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 01:14:48] iteration   205300/  500000 | consumed samples:      1642400 | elapsed time per iteration (ms): 322.6 | learning rate: 5.076570E-05 | global batch size:     8 | lm loss: 3.144148E+00 | loss scale: 131072.0 | grad norm: 0.782 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 01:15:20] iteration   205400/  500000 | consumed samples:      1643200 | elapsed time per iteration (ms): 322.0 | learning rate: 5.070264E-05 | global batch size:     8 | lm loss: 3.115405E+00 | loss scale: 131072.0 | grad norm: 0.854 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 01:15:52] iteration   205500/  500000 | consumed samples:      1644000 | elapsed time per iteration (ms): 323.5 | learning rate: 5.063961E-05 | global batch size:     8 | lm loss: 3.155700E+00 | loss scale: 131072.0 | grad norm: 0.805 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 01:16:24] iteration   205600/  500000 | consumed samples:      1644800 | elapsed time per iteration (ms): 323.6 | learning rate: 5.057661E-05 | global batch size:     8 | lm loss: 3.147180E+00 | loss scale: 131072.0 | grad norm: 0.849 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 01:16:57] iteration   205700/  500000 | consumed samples:      1645600 | elapsed time per iteration (ms): 323.5 | learning rate: 5.051364E-05 | global batch size:     8 | lm loss: 3.131389E+00 | loss scale: 131072.0 | grad norm: 0.787 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 01:17:29] iteration   205800/  500000 | consumed samples:      1646400 | elapsed time per iteration (ms): 322.4 | learning rate: 5.045070E-05 | global batch size:     8 | lm loss: 3.109215E+00 | loss scale: 131072.0 | grad norm: 1.471 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 01:18:01] iteration   205900/  500000 | consumed samples:      1647200 | elapsed time per iteration (ms): 322.4 | learning rate: 5.038778E-05 | global batch size:     8 | lm loss: 3.145606E+00 | loss scale: 262144.0 | grad norm: 0.839 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 01:18:33] iteration   206000/  500000 | consumed samples:      1648000 | elapsed time per iteration (ms): 321.9 | learning rate: 5.032490E-05 | global batch size:     8 | lm loss: 3.130329E+00 | loss scale: 262144.0 | grad norm: 0.791 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1066.04, 1066.04)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 206000 | lm loss value: 3.708835E+00 | lm loss PPL: 4.080625E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 01:19:07] iteration   206100/  500000 | consumed samples:      1648800 | elapsed time per iteration (ms): 324.0 | learning rate: 5.026204E-05 | global batch size:     8 | lm loss: 3.126340E+00 | loss scale: 262144.0 | grad norm: 0.843 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 01:19:39] iteration   206200/  500000 | consumed samples:      1649600 | elapsed time per iteration (ms): 321.6 | learning rate: 5.019922E-05 | global batch size:     8 | lm loss: 3.130334E+00 | loss scale: 262144.0 | grad norm: 0.788 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 01:20:11] iteration   206300/  500000 | consumed samples:      1650400 | elapsed time per iteration (ms): 323.2 | learning rate: 5.013642E-05 | global batch size:     8 | lm loss: 3.107223E+00 | loss scale: 262144.0 | grad norm: 0.803 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 01:20:43] iteration   206400/  500000 | consumed samples:      1651200 | elapsed time per iteration (ms): 320.4 | learning rate: 5.007365E-05 | global batch size:     8 | lm loss: 3.155221E+00 | loss scale: 262144.0 | grad norm: 0.765 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 01:21:16] iteration   206500/  500000 | consumed samples:      1652000 | elapsed time per iteration (ms): 321.4 | learning rate: 5.001092E-05 | global batch size:     8 | lm loss: 3.103471E+00 | loss scale: 262144.0 | grad norm: 0.875 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 01:21:48] iteration   206600/  500000 | consumed samples:      1652800 | elapsed time per iteration (ms): 321.3 | learning rate: 4.994821E-05 | global batch size:     8 | lm loss: 3.096237E+00 | loss scale: 262144.0 | grad norm: 0.752 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 01:22:20] iteration   206700/  500000 | consumed samples:      1653600 | elapsed time per iteration (ms): 322.5 | learning rate: 4.988553E-05 | global batch size:     8 | lm loss: 3.115991E+00 | loss scale: 262144.0 | grad norm: 0.786 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 01:22:52] iteration   206800/  500000 | consumed samples:      1654400 | elapsed time per iteration (ms): 320.2 | learning rate: 4.982288E-05 | global batch size:     8 | lm loss: 3.101300E+00 | loss scale: 262144.0 | grad norm: 0.812 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 01:23:24] iteration   206900/  500000 | consumed samples:      1655200 | elapsed time per iteration (ms): 324.3 | learning rate: 4.976088E-05 | global batch size:     8 | lm loss: 3.142754E+00 | loss scale: 524288.0 | grad norm: 0.804 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-22 01:23:57] iteration   207000/  500000 | consumed samples:      1656000 | elapsed time per iteration (ms): 324.7 | learning rate: 4.969829E-05 | global batch size:     8 | lm loss: 3.100949E+00 | loss scale: 524288.0 | grad norm: 0.794 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1068.28, 1068.28)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 207000 | lm loss value: 3.592712E+00 | lm loss PPL: 3.633246E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 01:24:30] iteration   207100/  500000 | consumed samples:      1656800 | elapsed time per iteration (ms): 321.3 | learning rate: 4.963573E-05 | global batch size:     8 | lm loss: 3.124659E+00 | loss scale: 524288.0 | grad norm: 0.809 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 01:25:02] iteration   207200/  500000 | consumed samples:      1657600 | elapsed time per iteration (ms): 322.2 | learning rate: 4.957320E-05 | global batch size:     8 | lm loss: 3.124035E+00 | loss scale: 524288.0 | grad norm: 0.826 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 01:25:34] iteration   207300/  500000 | consumed samples:      1658400 | elapsed time per iteration (ms): 321.6 | learning rate: 4.951133E-05 | global batch size:     8 | lm loss: 3.111411E+00 | loss scale: 262144.0 | grad norm: 0.812 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-22 01:26:07] iteration   207400/  500000 | consumed samples:      1659200 | elapsed time per iteration (ms): 321.7 | learning rate: 4.944948E-05 | global batch size:     8 | lm loss: 3.143737E+00 | loss scale: 131072.0 | grad norm: 0.782 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-22 01:26:39] iteration   207500/  500000 | consumed samples:      1660000 | elapsed time per iteration (ms): 322.4 | learning rate: 4.938704E-05 | global batch size:     8 | lm loss: 3.112688E+00 | loss scale: 131072.0 | grad norm: 0.787 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 01:27:11] iteration   207600/  500000 | consumed samples:      1660800 | elapsed time per iteration (ms): 320.5 | learning rate: 4.932463E-05 | global batch size:     8 | lm loss: 3.127549E+00 | loss scale: 131072.0 | grad norm: 0.830 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 01:27:43] iteration   207700/  500000 | consumed samples:      1661600 | elapsed time per iteration (ms): 324.3 | learning rate: 4.926225E-05 | global batch size:     8 | lm loss: 3.100117E+00 | loss scale: 131072.0 | grad norm: 0.834 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 01:28:16] iteration   207800/  500000 | consumed samples:      1662400 | elapsed time per iteration (ms): 322.7 | learning rate: 4.919989E-05 | global batch size:     8 | lm loss: 3.070159E+00 | loss scale: 131072.0 | grad norm: 0.787 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 01:28:48] iteration   207900/  500000 | consumed samples:      1663200 | elapsed time per iteration (ms): 324.4 | learning rate: 4.913757E-05 | global batch size:     8 | lm loss: 3.115100E+00 | loss scale: 131072.0 | grad norm: 0.824 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 01:29:20] iteration   208000/  500000 | consumed samples:      1664000 | elapsed time per iteration (ms): 322.0 | learning rate: 4.907528E-05 | global batch size:     8 | lm loss: 3.131524E+00 | loss scale: 131072.0 | grad norm: 0.807 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1063.75, 1063.75)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 208000 | lm loss value: 3.679619E+00 | lm loss PPL: 3.963129E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 01:29:53] iteration   208100/  500000 | consumed samples:      1664800 | elapsed time per iteration (ms): 321.6 | learning rate: 4.901302E-05 | global batch size:     8 | lm loss: 3.105398E+00 | loss scale: 131072.0 | grad norm: 0.762 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 01:30:26] iteration   208200/  500000 | consumed samples:      1665600 | elapsed time per iteration (ms): 324.4 | learning rate: 4.895079E-05 | global batch size:     8 | lm loss: 3.124368E+00 | loss scale: 131072.0 | grad norm: 0.858 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 01:30:58] iteration   208300/  500000 | consumed samples:      1666400 | elapsed time per iteration (ms): 323.7 | learning rate: 4.888860E-05 | global batch size:     8 | lm loss: 3.143794E+00 | loss scale: 131072.0 | grad norm: 0.814 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 01:31:31] iteration   208400/  500000 | consumed samples:      1667200 | elapsed time per iteration (ms): 322.9 | learning rate: 4.882643E-05 | global batch size:     8 | lm loss: 3.123940E+00 | loss scale: 262144.0 | grad norm: 0.790 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 01:32:03] iteration   208500/  500000 | consumed samples:      1668000 | elapsed time per iteration (ms): 322.3 | learning rate: 4.876429E-05 | global batch size:     8 | lm loss: 3.112198E+00 | loss scale: 262144.0 | grad norm: 0.814 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 01:32:35] iteration   208600/  500000 | consumed samples:      1668800 | elapsed time per iteration (ms): 320.7 | learning rate: 4.870280E-05 | global batch size:     8 | lm loss: 3.142768E+00 | loss scale: 262144.0 | grad norm: 0.829 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-22 01:33:07] iteration   208700/  500000 | consumed samples:      1669600 | elapsed time per iteration (ms): 323.1 | learning rate: 4.864073E-05 | global batch size:     8 | lm loss: 3.125457E+00 | loss scale: 262144.0 | grad norm: 0.794 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 01:33:39] iteration   208800/  500000 | consumed samples:      1670400 | elapsed time per iteration (ms): 322.8 | learning rate: 4.857868E-05 | global batch size:     8 | lm loss: 3.114573E+00 | loss scale: 262144.0 | grad norm: 0.821 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 01:34:12] iteration   208900/  500000 | consumed samples:      1671200 | elapsed time per iteration (ms): 321.5 | learning rate: 4.851729E-05 | global batch size:     8 | lm loss: 3.110119E+00 | loss scale: 131072.0 | grad norm: 0.797 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-22 01:34:44] iteration   209000/  500000 | consumed samples:      1672000 | elapsed time per iteration (ms): 322.5 | learning rate: 4.845530E-05 | global batch size:     8 | lm loss: 3.127213E+00 | loss scale: 131072.0 | grad norm: 0.820 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1063.60, 1063.60)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 209000 | lm loss value: 3.570338E+00 | lm loss PPL: 3.552859E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 01:35:17] iteration   209100/  500000 | consumed samples:      1672800 | elapsed time per iteration (ms): 320.9 | learning rate: 4.839335E-05 | global batch size:     8 | lm loss: 3.114036E+00 | loss scale: 131072.0 | grad norm: 0.825 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 01:35:49] iteration   209200/  500000 | consumed samples:      1673600 | elapsed time per iteration (ms): 322.7 | learning rate: 4.833143E-05 | global batch size:     8 | lm loss: 3.109765E+00 | loss scale: 131072.0 | grad norm: 1.041 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 01:36:21] iteration   209300/  500000 | consumed samples:      1674400 | elapsed time per iteration (ms): 321.1 | learning rate: 4.826954E-05 | global batch size:     8 | lm loss: 3.123839E+00 | loss scale: 131072.0 | grad norm: 0.763 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 01:36:54] iteration   209400/  500000 | consumed samples:      1675200 | elapsed time per iteration (ms): 322.2 | learning rate: 4.820768E-05 | global batch size:     8 | lm loss: 3.105424E+00 | loss scale: 131072.0 | grad norm: 0.849 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 01:37:26] iteration   209500/  500000 | consumed samples:      1676000 | elapsed time per iteration (ms): 321.2 | learning rate: 4.814585E-05 | global batch size:     8 | lm loss: 3.135101E+00 | loss scale: 131072.0 | grad norm: 0.815 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 01:37:58] iteration   209600/  500000 | consumed samples:      1676800 | elapsed time per iteration (ms): 323.7 | learning rate: 4.808405E-05 | global batch size:     8 | lm loss: 3.149302E+00 | loss scale: 131072.0 | grad norm: 0.822 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 01:38:30] iteration   209700/  500000 | consumed samples:      1677600 | elapsed time per iteration (ms): 321.4 | learning rate: 4.802229E-05 | global batch size:     8 | lm loss: 3.146584E+00 | loss scale: 131072.0 | grad norm: 0.760 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 01:39:03] iteration   209800/  500000 | consumed samples:      1678400 | elapsed time per iteration (ms): 323.9 | learning rate: 4.796055E-05 | global batch size:     8 | lm loss: 3.145934E+00 | loss scale: 131072.0 | grad norm: 0.802 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 01:39:35] iteration   209900/  500000 | consumed samples:      1679200 | elapsed time per iteration (ms): 323.0 | learning rate: 4.789885E-05 | global batch size:     8 | lm loss: 3.133167E+00 | loss scale: 262144.0 | grad norm: 0.839 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 01:40:07] iteration   210000/  500000 | consumed samples:      1680000 | elapsed time per iteration (ms): 320.9 | learning rate: 4.783718E-05 | global batch size:     8 | lm loss: 3.157672E+00 | loss scale: 262144.0 | grad norm: 0.881 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1063.98, 1063.98)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 210000 | lm loss value: 3.782001E+00 | lm loss PPL: 4.390382E+01 | 
--------------------------------------------------------------------------------------------------
saving checkpoint at iteration  210000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-max in torch format
  successfully saved checkpoint at iteration  210000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-max
(min, max) time across ranks (ms):
    save-checkpoint ................................: (5606.23, 5606.23)
 [2024-06-22 01:40:46] iteration   210100/  500000 | consumed samples:      1680800 | elapsed time per iteration (ms): 320.3 | learning rate: 4.777554E-05 | global batch size:     8 | lm loss: 3.143669E+00 | loss scale: 262144.0 | grad norm: 0.802 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 01:41:18] iteration   210200/  500000 | consumed samples:      1681600 | elapsed time per iteration (ms): 322.1 | learning rate: 4.771393E-05 | global batch size:     8 | lm loss: 3.122536E+00 | loss scale: 262144.0 | grad norm: 0.821 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 01:41:50] iteration   210300/  500000 | consumed samples:      1682400 | elapsed time per iteration (ms): 323.9 | learning rate: 4.765235E-05 | global batch size:     8 | lm loss: 3.131873E+00 | loss scale: 262144.0 | grad norm: 0.787 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 01:42:22] iteration   210400/  500000 | consumed samples:      1683200 | elapsed time per iteration (ms): 320.4 | learning rate: 4.759081E-05 | global batch size:     8 | lm loss: 3.103711E+00 | loss scale: 262144.0 | grad norm: 0.830 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 01:42:55] iteration   210500/  500000 | consumed samples:      1684000 | elapsed time per iteration (ms): 324.3 | learning rate: 4.752930E-05 | global batch size:     8 | lm loss: 3.137659E+00 | loss scale: 262144.0 | grad norm: 0.806 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 01:43:27] iteration   210600/  500000 | consumed samples:      1684800 | elapsed time per iteration (ms): 323.3 | learning rate: 4.746782E-05 | global batch size:     8 | lm loss: 3.094040E+00 | loss scale: 262144.0 | grad norm: 0.821 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 01:43:59] iteration   210700/  500000 | consumed samples:      1685600 | elapsed time per iteration (ms): 323.0 | learning rate: 4.740637E-05 | global batch size:     8 | lm loss: 3.107070E+00 | loss scale: 262144.0 | grad norm: 0.809 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 01:44:32] iteration   210800/  500000 | consumed samples:      1686400 | elapsed time per iteration (ms): 321.9 | learning rate: 4.734495E-05 | global batch size:     8 | lm loss: 3.158117E+00 | loss scale: 262144.0 | grad norm: 0.811 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 01:45:04] iteration   210900/  500000 | consumed samples:      1687200 | elapsed time per iteration (ms): 321.2 | learning rate: 4.728357E-05 | global batch size:     8 | lm loss: 3.117914E+00 | loss scale: 524288.0 | grad norm: 0.800 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 01:45:36] iteration   211000/  500000 | consumed samples:      1688000 | elapsed time per iteration (ms): 320.1 | learning rate: 4.722222E-05 | global batch size:     8 | lm loss: 3.132845E+00 | loss scale: 524288.0 | grad norm: 0.819 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1062.50, 1062.50)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 211000 | lm loss value: 3.673390E+00 | lm loss PPL: 3.938519E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 01:46:09] iteration   211100/  500000 | consumed samples:      1688800 | elapsed time per iteration (ms): 321.1 | learning rate: 4.716151E-05 | global batch size:     8 | lm loss: 3.132784E+00 | loss scale: 524288.0 | grad norm: 0.806 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-22 01:46:41] iteration   211200/  500000 | consumed samples:      1689600 | elapsed time per iteration (ms): 320.7 | learning rate: 4.710022E-05 | global batch size:     8 | lm loss: 3.103005E+00 | loss scale: 524288.0 | grad norm: 0.836 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 01:47:13] iteration   211300/  500000 | consumed samples:      1690400 | elapsed time per iteration (ms): 321.0 | learning rate: 4.703897E-05 | global batch size:     8 | lm loss: 3.114623E+00 | loss scale: 524288.0 | grad norm: 0.807 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 01:47:45] iteration   211400/  500000 | consumed samples:      1691200 | elapsed time per iteration (ms): 322.6 | learning rate: 4.697774E-05 | global batch size:     8 | lm loss: 3.094260E+00 | loss scale: 524288.0 | grad norm: 0.812 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 01:48:17] iteration   211500/  500000 | consumed samples:      1692000 | elapsed time per iteration (ms): 320.2 | learning rate: 4.691655E-05 | global batch size:     8 | lm loss: 3.091087E+00 | loss scale: 524288.0 | grad norm: 0.820 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 01:48:49] iteration   211600/  500000 | consumed samples:      1692800 | elapsed time per iteration (ms): 319.9 | learning rate: 4.685539E-05 | global batch size:     8 | lm loss: 3.126661E+00 | loss scale: 524288.0 | grad norm: 0.739 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 01:49:21] iteration   211700/  500000 | consumed samples:      1693600 | elapsed time per iteration (ms): 319.7 | learning rate: 4.679427E-05 | global batch size:     8 | lm loss: 3.155562E+00 | loss scale: 524288.0 | grad norm: 0.837 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 01:49:53] iteration   211800/  500000 | consumed samples:      1694400 | elapsed time per iteration (ms): 321.8 | learning rate: 4.673318E-05 | global batch size:     8 | lm loss: 3.142823E+00 | loss scale: 524288.0 | grad norm: 0.813 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 01:50:26] iteration   211900/  500000 | consumed samples:      1695200 | elapsed time per iteration (ms): 321.7 | learning rate: 4.667212E-05 | global batch size:     8 | lm loss: 3.145219E+00 | loss scale: 524288.0 | grad norm: 0.831 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 01:50:58] iteration   212000/  500000 | consumed samples:      1696000 | elapsed time per iteration (ms): 322.5 | learning rate: 4.661109E-05 | global batch size:     8 | lm loss: 3.106739E+00 | loss scale: 524288.0 | grad norm: 0.796 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1063.38, 1063.38)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 212000 | lm loss value: 3.645911E+00 | lm loss PPL: 3.831765E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 01:51:31] iteration   212100/  500000 | consumed samples:      1696800 | elapsed time per iteration (ms): 319.7 | learning rate: 4.655131E-05 | global batch size:     8 | lm loss: 3.103511E+00 | loss scale: 524288.0 | grad norm: 0.843 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-22 01:52:03] iteration   212200/  500000 | consumed samples:      1697600 | elapsed time per iteration (ms): 319.1 | learning rate: 4.649035E-05 | global batch size:     8 | lm loss: 3.106137E+00 | loss scale: 524288.0 | grad norm: 0.813 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 01:52:35] iteration   212300/  500000 | consumed samples:      1698400 | elapsed time per iteration (ms): 319.3 | learning rate: 4.643003E-05 | global batch size:     8 | lm loss: 3.132856E+00 | loss scale: 262144.0 | grad norm: 0.822 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-22 01:53:07] iteration   212400/  500000 | consumed samples:      1699200 | elapsed time per iteration (ms): 320.8 | learning rate: 4.636974E-05 | global batch size:     8 | lm loss: 3.106941E+00 | loss scale: 131072.0 | grad norm: 0.785 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-22 01:53:39] iteration   212500/  500000 | consumed samples:      1700000 | elapsed time per iteration (ms): 319.8 | learning rate: 4.630888E-05 | global batch size:     8 | lm loss: 3.121677E+00 | loss scale: 131072.0 | grad norm: 0.814 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 01:54:11] iteration   212600/  500000 | consumed samples:      1700800 | elapsed time per iteration (ms): 319.4 | learning rate: 4.624805E-05 | global batch size:     8 | lm loss: 3.143183E+00 | loss scale: 131072.0 | grad norm: 0.822 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 01:54:43] iteration   212700/  500000 | consumed samples:      1701600 | elapsed time per iteration (ms): 318.9 | learning rate: 4.618725E-05 | global batch size:     8 | lm loss: 3.103026E+00 | loss scale: 131072.0 | grad norm: 0.862 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 01:55:15] iteration   212800/  500000 | consumed samples:      1702400 | elapsed time per iteration (ms): 321.8 | learning rate: 4.612649E-05 | global batch size:     8 | lm loss: 3.110872E+00 | loss scale: 131072.0 | grad norm: 0.801 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 01:55:47] iteration   212900/  500000 | consumed samples:      1703200 | elapsed time per iteration (ms): 321.0 | learning rate: 4.606576E-05 | global batch size:     8 | lm loss: 3.074165E+00 | loss scale: 131072.0 | grad norm: 0.798 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 01:56:19] iteration   213000/  500000 | consumed samples:      1704000 | elapsed time per iteration (ms): 321.9 | learning rate: 4.600506E-05 | global batch size:     8 | lm loss: 3.145420E+00 | loss scale: 131072.0 | grad norm: 0.818 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1065.84, 1065.84)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 213000 | lm loss value: 3.664230E+00 | lm loss PPL: 3.902608E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 01:56:53] iteration   213100/  500000 | consumed samples:      1704800 | elapsed time per iteration (ms): 323.2 | learning rate: 4.594439E-05 | global batch size:     8 | lm loss: 3.129924E+00 | loss scale: 131072.0 | grad norm: 0.807 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 01:57:25] iteration   213200/  500000 | consumed samples:      1705600 | elapsed time per iteration (ms): 320.9 | learning rate: 4.588376E-05 | global batch size:     8 | lm loss: 3.088782E+00 | loss scale: 131072.0 | grad norm: 0.822 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 01:57:57] iteration   213300/  500000 | consumed samples:      1706400 | elapsed time per iteration (ms): 323.3 | learning rate: 4.582317E-05 | global batch size:     8 | lm loss: 3.163432E+00 | loss scale: 131072.0 | grad norm: 0.802 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 01:58:29] iteration   213400/  500000 | consumed samples:      1707200 | elapsed time per iteration (ms): 323.5 | learning rate: 4.576260E-05 | global batch size:     8 | lm loss: 3.077032E+00 | loss scale: 262144.0 | grad norm: 0.800 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 01:59:01] iteration   213500/  500000 | consumed samples:      1708000 | elapsed time per iteration (ms): 321.6 | learning rate: 4.570207E-05 | global batch size:     8 | lm loss: 3.105376E+00 | loss scale: 262144.0 | grad norm: 0.793 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 01:59:34] iteration   213600/  500000 | consumed samples:      1708800 | elapsed time per iteration (ms): 322.4 | learning rate: 4.564158E-05 | global batch size:     8 | lm loss: 3.124739E+00 | loss scale: 262144.0 | grad norm: 0.821 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 02:00:06] iteration   213700/  500000 | consumed samples:      1709600 | elapsed time per iteration (ms): 322.0 | learning rate: 4.558111E-05 | global batch size:     8 | lm loss: 3.113419E+00 | loss scale: 262144.0 | grad norm: 0.839 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 02:00:38] iteration   213800/  500000 | consumed samples:      1710400 | elapsed time per iteration (ms): 323.7 | learning rate: 4.552068E-05 | global batch size:     8 | lm loss: 3.139572E+00 | loss scale: 262144.0 | grad norm: 0.785 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 02:01:11] iteration   213900/  500000 | consumed samples:      1711200 | elapsed time per iteration (ms): 322.4 | learning rate: 4.546029E-05 | global batch size:     8 | lm loss: 3.118728E+00 | loss scale: 262144.0 | grad norm: 0.819 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 02:01:43] iteration   214000/  500000 | consumed samples:      1712000 | elapsed time per iteration (ms): 323.7 | learning rate: 4.539993E-05 | global batch size:     8 | lm loss: 3.104266E+00 | loss scale: 262144.0 | grad norm: 0.795 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1064.13, 1064.13)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 214000 | lm loss value: 3.643476E+00 | lm loss PPL: 3.822447E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 02:02:16] iteration   214100/  500000 | consumed samples:      1712800 | elapsed time per iteration (ms): 321.1 | learning rate: 4.533960E-05 | global batch size:     8 | lm loss: 3.116059E+00 | loss scale: 262144.0 | grad norm: 0.830 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 02:02:48] iteration   214200/  500000 | consumed samples:      1713600 | elapsed time per iteration (ms): 322.7 | learning rate: 4.527931E-05 | global batch size:     8 | lm loss: 3.115881E+00 | loss scale: 262144.0 | grad norm: 0.817 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 02:03:20] iteration   214300/  500000 | consumed samples:      1714400 | elapsed time per iteration (ms): 320.7 | learning rate: 4.521905E-05 | global batch size:     8 | lm loss: 3.140415E+00 | loss scale: 262144.0 | grad norm: 0.823 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 02:03:52] iteration   214400/  500000 | consumed samples:      1715200 | elapsed time per iteration (ms): 320.2 | learning rate: 4.515883E-05 | global batch size:     8 | lm loss: 3.086409E+00 | loss scale: 524288.0 | grad norm: 0.779 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 02:04:24] iteration   214500/  500000 | consumed samples:      1716000 | elapsed time per iteration (ms): 319.7 | learning rate: 4.509864E-05 | global batch size:     8 | lm loss: 3.105370E+00 | loss scale: 524288.0 | grad norm: 0.799 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 02:04:57] iteration   214600/  500000 | consumed samples:      1716800 | elapsed time per iteration (ms): 322.7 | learning rate: 4.503848E-05 | global batch size:     8 | lm loss: 3.095071E+00 | loss scale: 524288.0 | grad norm: 0.901 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 02:05:29] iteration   214700/  500000 | consumed samples:      1717600 | elapsed time per iteration (ms): 324.6 | learning rate: 4.497836E-05 | global batch size:     8 | lm loss: 3.120541E+00 | loss scale: 524288.0 | grad norm: 0.840 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 02:06:01] iteration   214800/  500000 | consumed samples:      1718400 | elapsed time per iteration (ms): 321.8 | learning rate: 4.491827E-05 | global batch size:     8 | lm loss: 3.127170E+00 | loss scale: 524288.0 | grad norm: 0.850 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 02:06:33] iteration   214900/  500000 | consumed samples:      1719200 | elapsed time per iteration (ms): 321.5 | learning rate: 4.485822E-05 | global batch size:     8 | lm loss: 3.079496E+00 | loss scale: 524288.0 | grad norm: 0.794 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 02:07:06] iteration   215000/  500000 | consumed samples:      1720000 | elapsed time per iteration (ms): 322.5 | learning rate: 4.479820E-05 | global batch size:     8 | lm loss: 3.125445E+00 | loss scale: 524288.0 | grad norm: 0.802 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1068.83, 1068.83)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 215000 | lm loss value: 3.692240E+00 | lm loss PPL: 4.013466E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 02:07:39] iteration   215100/  500000 | consumed samples:      1720800 | elapsed time per iteration (ms): 323.3 | learning rate: 4.473822E-05 | global batch size:     8 | lm loss: 3.105996E+00 | loss scale: 524288.0 | grad norm: 0.862 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 02:08:12] iteration   215200/  500000 | consumed samples:      1721600 | elapsed time per iteration (ms): 324.0 | learning rate: 4.467827E-05 | global batch size:     8 | lm loss: 3.080610E+00 | loss scale: 524288.0 | grad norm: 0.830 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 02:08:44] iteration   215300/  500000 | consumed samples:      1722400 | elapsed time per iteration (ms): 323.8 | learning rate: 4.461836E-05 | global batch size:     8 | lm loss: 3.083565E+00 | loss scale: 524288.0 | grad norm: 0.772 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 02:09:16] iteration   215400/  500000 | consumed samples:      1723200 | elapsed time per iteration (ms): 323.0 | learning rate: 4.455968E-05 | global batch size:     8 | lm loss: 3.122900E+00 | loss scale: 524288.0 | grad norm: 0.856 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-22 02:09:49] iteration   215500/  500000 | consumed samples:      1724000 | elapsed time per iteration (ms): 323.7 | learning rate: 4.449983E-05 | global batch size:     8 | lm loss: 3.088160E+00 | loss scale: 524288.0 | grad norm: 0.777 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 02:10:21] iteration   215600/  500000 | consumed samples:      1724800 | elapsed time per iteration (ms): 323.8 | learning rate: 4.444002E-05 | global batch size:     8 | lm loss: 3.142755E+00 | loss scale: 524288.0 | grad norm: 0.776 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 02:10:53] iteration   215700/  500000 | consumed samples:      1725600 | elapsed time per iteration (ms): 323.6 | learning rate: 4.438025E-05 | global batch size:     8 | lm loss: 3.127624E+00 | loss scale: 524288.0 | grad norm: 0.819 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 02:11:25] iteration   215800/  500000 | consumed samples:      1726400 | elapsed time per iteration (ms): 321.5 | learning rate: 4.432051E-05 | global batch size:     8 | lm loss: 3.127288E+00 | loss scale: 524288.0 | grad norm: 0.825 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 02:11:57] iteration   215900/  500000 | consumed samples:      1727200 | elapsed time per iteration (ms): 320.2 | learning rate: 4.426140E-05 | global batch size:     8 | lm loss: 3.107136E+00 | loss scale: 262144.0 | grad norm: 0.785 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-22 02:12:30] iteration   216000/  500000 | consumed samples:      1728000 | elapsed time per iteration (ms): 321.8 | learning rate: 4.420173E-05 | global batch size:     8 | lm loss: 3.103819E+00 | loss scale: 262144.0 | grad norm: 0.833 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1064.07, 1064.07)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 216000 | lm loss value: 3.635060E+00 | lm loss PPL: 3.790413E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 02:13:03] iteration   216100/  500000 | consumed samples:      1728800 | elapsed time per iteration (ms): 322.1 | learning rate: 4.414209E-05 | global batch size:     8 | lm loss: 3.098829E+00 | loss scale: 262144.0 | grad norm: 0.834 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 02:13:35] iteration   216200/  500000 | consumed samples:      1729600 | elapsed time per iteration (ms): 321.4 | learning rate: 4.408249E-05 | global batch size:     8 | lm loss: 3.062774E+00 | loss scale: 262144.0 | grad norm: 0.813 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 02:14:07] iteration   216300/  500000 | consumed samples:      1730400 | elapsed time per iteration (ms): 320.4 | learning rate: 4.402293E-05 | global batch size:     8 | lm loss: 3.120650E+00 | loss scale: 262144.0 | grad norm: 0.799 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 02:14:39] iteration   216400/  500000 | consumed samples:      1731200 | elapsed time per iteration (ms): 319.6 | learning rate: 4.396340E-05 | global batch size:     8 | lm loss: 3.101114E+00 | loss scale: 262144.0 | grad norm: 0.805 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 02:15:11] iteration   216500/  500000 | consumed samples:      1732000 | elapsed time per iteration (ms): 319.1 | learning rate: 4.390391E-05 | global batch size:     8 | lm loss: 3.109913E+00 | loss scale: 262144.0 | grad norm: 0.825 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 02:15:43] iteration   216600/  500000 | consumed samples:      1732800 | elapsed time per iteration (ms): 324.5 | learning rate: 4.384445E-05 | global batch size:     8 | lm loss: 3.074035E+00 | loss scale: 262144.0 | grad norm: 0.842 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 02:16:16] iteration   216700/  500000 | consumed samples:      1733600 | elapsed time per iteration (ms): 323.8 | learning rate: 4.378503E-05 | global batch size:     8 | lm loss: 3.103791E+00 | loss scale: 262144.0 | grad norm: 0.830 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 02:16:48] iteration   216800/  500000 | consumed samples:      1734400 | elapsed time per iteration (ms): 324.2 | learning rate: 4.372564E-05 | global batch size:     8 | lm loss: 3.118324E+00 | loss scale: 262144.0 | grad norm: 0.798 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 02:17:20] iteration   216900/  500000 | consumed samples:      1735200 | elapsed time per iteration (ms): 320.1 | learning rate: 4.366688E-05 | global batch size:     8 | lm loss: 3.109680E+00 | loss scale: 524288.0 | grad norm: 0.797 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-22 02:17:52] iteration   217000/  500000 | consumed samples:      1736000 | elapsed time per iteration (ms): 321.7 | learning rate: 4.360757E-05 | global batch size:     8 | lm loss: 3.081236E+00 | loss scale: 524288.0 | grad norm: 0.815 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1065.18, 1065.18)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 217000 | lm loss value: 3.788041E+00 | lm loss PPL: 4.416978E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 02:18:26] iteration   217100/  500000 | consumed samples:      1736800 | elapsed time per iteration (ms): 321.5 | learning rate: 4.354829E-05 | global batch size:     8 | lm loss: 3.118006E+00 | loss scale: 524288.0 | grad norm: 0.788 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 02:18:58] iteration   217200/  500000 | consumed samples:      1737600 | elapsed time per iteration (ms): 321.6 | learning rate: 4.348904E-05 | global batch size:     8 | lm loss: 3.080467E+00 | loss scale: 524288.0 | grad norm: 0.786 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 02:19:30] iteration   217300/  500000 | consumed samples:      1738400 | elapsed time per iteration (ms): 322.7 | learning rate: 4.342984E-05 | global batch size:     8 | lm loss: 3.096607E+00 | loss scale: 524288.0 | grad norm: 0.785 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 02:20:02] iteration   217400/  500000 | consumed samples:      1739200 | elapsed time per iteration (ms): 320.7 | learning rate: 4.337066E-05 | global batch size:     8 | lm loss: 3.097385E+00 | loss scale: 524288.0 | grad norm: 0.833 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 02:20:34] iteration   217500/  500000 | consumed samples:      1740000 | elapsed time per iteration (ms): 323.5 | learning rate: 4.331212E-05 | global batch size:     8 | lm loss: 3.129718E+00 | loss scale: 262144.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-22 02:21:07] iteration   217600/  500000 | consumed samples:      1740800 | elapsed time per iteration (ms): 321.3 | learning rate: 4.325302E-05 | global batch size:     8 | lm loss: 3.121087E+00 | loss scale: 262144.0 | grad norm: 0.804 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 02:21:39] iteration   217700/  500000 | consumed samples:      1741600 | elapsed time per iteration (ms): 322.2 | learning rate: 4.319395E-05 | global batch size:     8 | lm loss: 3.117822E+00 | loss scale: 262144.0 | grad norm: 0.818 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 02:22:11] iteration   217800/  500000 | consumed samples:      1742400 | elapsed time per iteration (ms): 321.2 | learning rate: 4.313493E-05 | global batch size:     8 | lm loss: 3.092348E+00 | loss scale: 262144.0 | grad norm: 0.833 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 02:22:43] iteration   217900/  500000 | consumed samples:      1743200 | elapsed time per iteration (ms): 322.4 | learning rate: 4.307593E-05 | global batch size:     8 | lm loss: 3.036296E+00 | loss scale: 262144.0 | grad norm: 0.799 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 02:23:15] iteration   218000/  500000 | consumed samples:      1744000 | elapsed time per iteration (ms): 320.4 | learning rate: 4.301698E-05 | global batch size:     8 | lm loss: 3.087191E+00 | loss scale: 262144.0 | grad norm: 0.878 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1063.44, 1063.44)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 218000 | lm loss value: 3.807588E+00 | lm loss PPL: 4.504168E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 02:23:48] iteration   218100/  500000 | consumed samples:      1744800 | elapsed time per iteration (ms): 321.6 | learning rate: 4.295806E-05 | global batch size:     8 | lm loss: 3.114055E+00 | loss scale: 262144.0 | grad norm: 0.903 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 02:24:21] iteration   218200/  500000 | consumed samples:      1745600 | elapsed time per iteration (ms): 321.9 | learning rate: 4.289918E-05 | global batch size:     8 | lm loss: 3.066936E+00 | loss scale: 262144.0 | grad norm: 0.804 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 02:24:53] iteration   218300/  500000 | consumed samples:      1746400 | elapsed time per iteration (ms): 322.0 | learning rate: 4.284033E-05 | global batch size:     8 | lm loss: 3.075811E+00 | loss scale: 262144.0 | grad norm: 0.761 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 02:25:25] iteration   218400/  500000 | consumed samples:      1747200 | elapsed time per iteration (ms): 322.0 | learning rate: 4.278152E-05 | global batch size:     8 | lm loss: 3.105295E+00 | loss scale: 262144.0 | grad norm: 0.831 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 02:25:57] iteration   218500/  500000 | consumed samples:      1748000 | elapsed time per iteration (ms): 322.8 | learning rate: 4.272275E-05 | global batch size:     8 | lm loss: 3.085596E+00 | loss scale: 524288.0 | grad norm: 0.809 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 02:26:29] iteration   218600/  500000 | consumed samples:      1748800 | elapsed time per iteration (ms): 319.4 | learning rate: 4.266401E-05 | global batch size:     8 | lm loss: 3.088763E+00 | loss scale: 524288.0 | grad norm: 0.816 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 02:27:02] iteration   218700/  500000 | consumed samples:      1749600 | elapsed time per iteration (ms): 323.5 | learning rate: 4.260531E-05 | global batch size:     8 | lm loss: 3.108660E+00 | loss scale: 524288.0 | grad norm: 0.832 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 02:27:34] iteration   218800/  500000 | consumed samples:      1750400 | elapsed time per iteration (ms): 323.2 | learning rate: 4.254665E-05 | global batch size:     8 | lm loss: 3.083315E+00 | loss scale: 524288.0 | grad norm: 0.799 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 02:28:06] iteration   218900/  500000 | consumed samples:      1751200 | elapsed time per iteration (ms): 322.8 | learning rate: 4.248802E-05 | global batch size:     8 | lm loss: 3.130269E+00 | loss scale: 524288.0 | grad norm: 0.859 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 02:28:39] iteration   219000/  500000 | consumed samples:      1752000 | elapsed time per iteration (ms): 323.4 | learning rate: 4.243002E-05 | global batch size:     8 | lm loss: 3.095743E+00 | loss scale: 524288.0 | grad norm: 0.838 | number of skipped iterations:   1 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1064.34, 1064.34)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 219000 | lm loss value: 3.693937E+00 | lm loss PPL: 4.020283E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 02:29:12] iteration   219100/  500000 | consumed samples:      1752800 | elapsed time per iteration (ms): 322.5 | learning rate: 4.237147E-05 | global batch size:     8 | lm loss: 3.054596E+00 | loss scale: 524288.0 | grad norm: 0.822 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 02:29:44] iteration   219200/  500000 | consumed samples:      1753600 | elapsed time per iteration (ms): 323.8 | learning rate: 4.231295E-05 | global batch size:     8 | lm loss: 3.139745E+00 | loss scale: 524288.0 | grad norm: 0.785 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 02:30:16] iteration   219300/  500000 | consumed samples:      1754400 | elapsed time per iteration (ms): 319.7 | learning rate: 4.225506E-05 | global batch size:     8 | lm loss: 3.125576E+00 | loss scale: 262144.0 | grad norm: 0.893 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-22 02:30:48] iteration   219400/  500000 | consumed samples:      1755200 | elapsed time per iteration (ms): 321.1 | learning rate: 4.219661E-05 | global batch size:     8 | lm loss: 3.093214E+00 | loss scale: 262144.0 | grad norm: 0.792 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 02:31:21] iteration   219500/  500000 | consumed samples:      1756000 | elapsed time per iteration (ms): 322.6 | learning rate: 4.213821E-05 | global batch size:     8 | lm loss: 3.083790E+00 | loss scale: 262144.0 | grad norm: 0.816 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 02:31:53] iteration   219600/  500000 | consumed samples:      1756800 | elapsed time per iteration (ms): 324.0 | learning rate: 4.207984E-05 | global batch size:     8 | lm loss: 3.122491E+00 | loss scale: 262144.0 | grad norm: 0.796 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 02:32:25] iteration   219700/  500000 | consumed samples:      1757600 | elapsed time per iteration (ms): 320.6 | learning rate: 4.202151E-05 | global batch size:     8 | lm loss: 3.070616E+00 | loss scale: 262144.0 | grad norm: 0.739 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 02:32:57] iteration   219800/  500000 | consumed samples:      1758400 | elapsed time per iteration (ms): 321.4 | learning rate: 4.196322E-05 | global batch size:     8 | lm loss: 3.096566E+00 | loss scale: 262144.0 | grad norm: 0.864 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 02:33:29] iteration   219900/  500000 | consumed samples:      1759200 | elapsed time per iteration (ms): 322.6 | learning rate: 4.190496E-05 | global batch size:     8 | lm loss: 3.070457E+00 | loss scale: 262144.0 | grad norm: 0.811 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 02:34:02] iteration   220000/  500000 | consumed samples:      1760000 | elapsed time per iteration (ms): 322.9 | learning rate: 4.184675E-05 | global batch size:     8 | lm loss: 3.089749E+00 | loss scale: 262144.0 | grad norm: 0.834 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1064.72, 1064.72)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 220000 | lm loss value: 3.702587E+00 | lm loss PPL: 4.055207E+01 | 
--------------------------------------------------------------------------------------------------
saving checkpoint at iteration  220000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-max in torch format
  successfully saved checkpoint at iteration  220000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-max
(min, max) time across ranks (ms):
    save-checkpoint ................................: (5661.47, 5661.47)
 [2024-06-22 02:34:40] iteration   220100/  500000 | consumed samples:      1760800 | elapsed time per iteration (ms): 319.8 | learning rate: 4.178857E-05 | global batch size:     8 | lm loss: 3.109810E+00 | loss scale: 262144.0 | grad norm: 0.858 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 02:35:13] iteration   220200/  500000 | consumed samples:      1761600 | elapsed time per iteration (ms): 322.8 | learning rate: 4.173100E-05 | global batch size:     8 | lm loss: 3.109418E+00 | loss scale: 131072.0 | grad norm: 0.836 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-22 02:35:45] iteration   220300/  500000 | consumed samples:      1762400 | elapsed time per iteration (ms): 322.3 | learning rate: 4.167290E-05 | global batch size:     8 | lm loss: 3.132529E+00 | loss scale: 131072.0 | grad norm: 0.819 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 02:36:17] iteration   220400/  500000 | consumed samples:      1763200 | elapsed time per iteration (ms): 323.5 | learning rate: 4.161483E-05 | global batch size:     8 | lm loss: 3.112488E+00 | loss scale: 131072.0 | grad norm: 0.843 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 02:36:50] iteration   220500/  500000 | consumed samples:      1764000 | elapsed time per iteration (ms): 323.5 | learning rate: 4.155680E-05 | global batch size:     8 | lm loss: 3.104461E+00 | loss scale: 131072.0 | grad norm: 0.855 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 02:37:22] iteration   220600/  500000 | consumed samples:      1764800 | elapsed time per iteration (ms): 321.7 | learning rate: 4.149881E-05 | global batch size:     8 | lm loss: 3.132950E+00 | loss scale: 131072.0 | grad norm: 0.805 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 02:37:54] iteration   220700/  500000 | consumed samples:      1765600 | elapsed time per iteration (ms): 323.6 | learning rate: 4.144085E-05 | global batch size:     8 | lm loss: 3.085135E+00 | loss scale: 131072.0 | grad norm: 0.836 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 02:38:26] iteration   220800/  500000 | consumed samples:      1766400 | elapsed time per iteration (ms): 321.9 | learning rate: 4.138294E-05 | global batch size:     8 | lm loss: 3.118998E+00 | loss scale: 131072.0 | grad norm: 0.741 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 02:38:58] iteration   220900/  500000 | consumed samples:      1767200 | elapsed time per iteration (ms): 321.1 | learning rate: 4.132506E-05 | global batch size:     8 | lm loss: 3.105970E+00 | loss scale: 131072.0 | grad norm: 0.851 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 02:39:31] iteration   221000/  500000 | consumed samples:      1768000 | elapsed time per iteration (ms): 321.9 | learning rate: 4.126722E-05 | global batch size:     8 | lm loss: 3.115461E+00 | loss scale: 131072.0 | grad norm: 0.777 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1063.81, 1063.81)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 221000 | lm loss value: 3.535978E+00 | lm loss PPL: 3.432857E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 02:40:04] iteration   221100/  500000 | consumed samples:      1768800 | elapsed time per iteration (ms): 322.6 | learning rate: 4.120941E-05 | global batch size:     8 | lm loss: 3.049601E+00 | loss scale: 131072.0 | grad norm: 0.822 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 02:40:36] iteration   221200/  500000 | consumed samples:      1769600 | elapsed time per iteration (ms): 320.8 | learning rate: 4.115165E-05 | global batch size:     8 | lm loss: 3.112765E+00 | loss scale: 262144.0 | grad norm: 0.882 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 02:41:08] iteration   221300/  500000 | consumed samples:      1770400 | elapsed time per iteration (ms): 319.9 | learning rate: 4.109392E-05 | global batch size:     8 | lm loss: 3.143301E+00 | loss scale: 262144.0 | grad norm: 0.890 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 02:41:40] iteration   221400/  500000 | consumed samples:      1771200 | elapsed time per iteration (ms): 321.2 | learning rate: 4.103624E-05 | global batch size:     8 | lm loss: 3.029796E+00 | loss scale: 262144.0 | grad norm: 0.830 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 02:42:12] iteration   221500/  500000 | consumed samples:      1772000 | elapsed time per iteration (ms): 321.4 | learning rate: 4.097859E-05 | global batch size:     8 | lm loss: 3.105507E+00 | loss scale: 262144.0 | grad norm: 0.802 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 02:42:45] iteration   221600/  500000 | consumed samples:      1772800 | elapsed time per iteration (ms): 322.8 | learning rate: 4.092155E-05 | global batch size:     8 | lm loss: 3.085721E+00 | loss scale: 262144.0 | grad norm: 0.830 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-22 02:43:17] iteration   221700/  500000 | consumed samples:      1773600 | elapsed time per iteration (ms): 321.5 | learning rate: 4.086398E-05 | global batch size:     8 | lm loss: 3.097201E+00 | loss scale: 262144.0 | grad norm: 0.827 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 02:43:49] iteration   221800/  500000 | consumed samples:      1774400 | elapsed time per iteration (ms): 320.3 | learning rate: 4.080644E-05 | global batch size:     8 | lm loss: 3.089901E+00 | loss scale: 262144.0 | grad norm: 0.811 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 02:44:21] iteration   221900/  500000 | consumed samples:      1775200 | elapsed time per iteration (ms): 320.0 | learning rate: 4.074895E-05 | global batch size:     8 | lm loss: 3.103068E+00 | loss scale: 262144.0 | grad norm: 0.798 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 02:44:53] iteration   222000/  500000 | consumed samples:      1776000 | elapsed time per iteration (ms): 323.1 | learning rate: 4.069149E-05 | global batch size:     8 | lm loss: 3.126213E+00 | loss scale: 262144.0 | grad norm: 0.844 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1063.02, 1063.02)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 222000 | lm loss value: 3.609020E+00 | lm loss PPL: 3.692983E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 02:45:26] iteration   222100/  500000 | consumed samples:      1776800 | elapsed time per iteration (ms): 320.5 | learning rate: 4.063407E-05 | global batch size:     8 | lm loss: 3.079173E+00 | loss scale: 262144.0 | grad norm: 0.823 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 02:45:58] iteration   222200/  500000 | consumed samples:      1777600 | elapsed time per iteration (ms): 320.3 | learning rate: 4.057669E-05 | global batch size:     8 | lm loss: 3.089733E+00 | loss scale: 262144.0 | grad norm: 0.843 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 02:46:30] iteration   222300/  500000 | consumed samples:      1778400 | elapsed time per iteration (ms): 319.1 | learning rate: 4.051935E-05 | global batch size:     8 | lm loss: 3.108058E+00 | loss scale: 262144.0 | grad norm: 0.820 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 02:47:03] iteration   222400/  500000 | consumed samples:      1779200 | elapsed time per iteration (ms): 324.2 | learning rate: 4.046205E-05 | global batch size:     8 | lm loss: 3.086085E+00 | loss scale: 262144.0 | grad norm: 0.827 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 02:47:35] iteration   222500/  500000 | consumed samples:      1780000 | elapsed time per iteration (ms): 321.4 | learning rate: 4.040478E-05 | global batch size:     8 | lm loss: 3.129837E+00 | loss scale: 262144.0 | grad norm: 0.801 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 02:48:07] iteration   222600/  500000 | consumed samples:      1780800 | elapsed time per iteration (ms): 319.6 | learning rate: 4.034756E-05 | global batch size:     8 | lm loss: 3.106276E+00 | loss scale: 524288.0 | grad norm: 0.804 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 02:48:39] iteration   222700/  500000 | consumed samples:      1781600 | elapsed time per iteration (ms): 323.0 | learning rate: 4.029037E-05 | global batch size:     8 | lm loss: 3.138972E+00 | loss scale: 524288.0 | grad norm: 0.824 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 02:49:11] iteration   222800/  500000 | consumed samples:      1782400 | elapsed time per iteration (ms): 320.6 | learning rate: 4.023323E-05 | global batch size:     8 | lm loss: 3.090455E+00 | loss scale: 524288.0 | grad norm: 0.846 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 02:49:43] iteration   222900/  500000 | consumed samples:      1783200 | elapsed time per iteration (ms): 323.5 | learning rate: 4.017669E-05 | global batch size:     8 | lm loss: 3.076601E+00 | loss scale: 524288.0 | grad norm: 0.817 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-22 02:50:15] iteration   223000/  500000 | consumed samples:      1784000 | elapsed time per iteration (ms): 320.5 | learning rate: 4.012019E-05 | global batch size:     8 | lm loss: 3.065414E+00 | loss scale: 262144.0 | grad norm: 0.886 | number of skipped iterations:   1 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1063.82, 1063.82)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 223000 | lm loss value: 3.660405E+00 | lm loss PPL: 3.887710E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 02:50:49] iteration   223100/  500000 | consumed samples:      1784800 | elapsed time per iteration (ms): 322.6 | learning rate: 4.006316E-05 | global batch size:     8 | lm loss: 3.090364E+00 | loss scale: 262144.0 | grad norm: 0.845 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 02:51:21] iteration   223200/  500000 | consumed samples:      1785600 | elapsed time per iteration (ms): 320.4 | learning rate: 4.000617E-05 | global batch size:     8 | lm loss: 3.072196E+00 | loss scale: 262144.0 | grad norm: 0.820 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 02:51:53] iteration   223300/  500000 | consumed samples:      1786400 | elapsed time per iteration (ms): 322.8 | learning rate: 3.994922E-05 | global batch size:     8 | lm loss: 3.074265E+00 | loss scale: 262144.0 | grad norm: 0.824 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 02:52:25] iteration   223400/  500000 | consumed samples:      1787200 | elapsed time per iteration (ms): 321.3 | learning rate: 3.989231E-05 | global batch size:     8 | lm loss: 3.090731E+00 | loss scale: 262144.0 | grad norm: 0.826 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 02:52:57] iteration   223500/  500000 | consumed samples:      1788000 | elapsed time per iteration (ms): 322.6 | learning rate: 3.983544E-05 | global batch size:     8 | lm loss: 3.063674E+00 | loss scale: 262144.0 | grad norm: 0.814 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 02:53:30] iteration   223600/  500000 | consumed samples:      1788800 | elapsed time per iteration (ms): 322.2 | learning rate: 3.977860E-05 | global batch size:     8 | lm loss: 3.112437E+00 | loss scale: 262144.0 | grad norm: 0.849 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 02:54:02] iteration   223700/  500000 | consumed samples:      1789600 | elapsed time per iteration (ms): 322.7 | learning rate: 3.972181E-05 | global batch size:     8 | lm loss: 3.109756E+00 | loss scale: 262144.0 | grad norm: 0.905 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 02:54:34] iteration   223800/  500000 | consumed samples:      1790400 | elapsed time per iteration (ms): 321.2 | learning rate: 3.966505E-05 | global batch size:     8 | lm loss: 3.133595E+00 | loss scale: 262144.0 | grad norm: 0.749 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 02:55:06] iteration   223900/  500000 | consumed samples:      1791200 | elapsed time per iteration (ms): 321.0 | learning rate: 3.960834E-05 | global batch size:     8 | lm loss: 3.070618E+00 | loss scale: 262144.0 | grad norm: 0.832 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 02:55:38] iteration   224000/  500000 | consumed samples:      1792000 | elapsed time per iteration (ms): 322.7 | learning rate: 3.955167E-05 | global batch size:     8 | lm loss: 3.058875E+00 | loss scale: 524288.0 | grad norm: 0.826 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1069.37, 1069.37)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 224000 | lm loss value: 3.789088E+00 | lm loss PPL: 4.421605E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 02:56:12] iteration   224100/  500000 | consumed samples:      1792800 | elapsed time per iteration (ms): 322.8 | learning rate: 3.949503E-05 | global batch size:     8 | lm loss: 3.097415E+00 | loss scale: 524288.0 | grad norm: 0.829 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 02:56:44] iteration   224200/  500000 | consumed samples:      1793600 | elapsed time per iteration (ms): 321.0 | learning rate: 3.943844E-05 | global batch size:     8 | lm loss: 3.085680E+00 | loss scale: 524288.0 | grad norm: 0.798 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 02:57:16] iteration   224300/  500000 | consumed samples:      1794400 | elapsed time per iteration (ms): 319.0 | learning rate: 3.938188E-05 | global batch size:     8 | lm loss: 3.089508E+00 | loss scale: 524288.0 | grad norm: 0.844 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 02:57:48] iteration   224400/  500000 | consumed samples:      1795200 | elapsed time per iteration (ms): 322.0 | learning rate: 3.932537E-05 | global batch size:     8 | lm loss: 3.082824E+00 | loss scale: 524288.0 | grad norm: 0.830 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 02:58:20] iteration   224500/  500000 | consumed samples:      1796000 | elapsed time per iteration (ms): 322.8 | learning rate: 3.926889E-05 | global batch size:     8 | lm loss: 3.069537E+00 | loss scale: 524288.0 | grad norm: 0.834 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 02:58:53] iteration   224600/  500000 | consumed samples:      1796800 | elapsed time per iteration (ms): 323.0 | learning rate: 3.921246E-05 | global batch size:     8 | lm loss: 3.115319E+00 | loss scale: 524288.0 | grad norm: 0.811 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 02:59:24] iteration   224700/  500000 | consumed samples:      1797600 | elapsed time per iteration (ms): 318.7 | learning rate: 3.915606E-05 | global batch size:     8 | lm loss: 3.095257E+00 | loss scale: 524288.0 | grad norm: 0.814 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 02:59:57] iteration   224800/  500000 | consumed samples:      1798400 | elapsed time per iteration (ms): 322.0 | learning rate: 3.909971E-05 | global batch size:     8 | lm loss: 3.110097E+00 | loss scale: 524288.0 | grad norm: 0.846 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 03:00:29] iteration   224900/  500000 | consumed samples:      1799200 | elapsed time per iteration (ms): 321.3 | learning rate: 3.904339E-05 | global batch size:     8 | lm loss: 3.151725E+00 | loss scale: 524288.0 | grad norm: 0.846 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 03:01:01] iteration   225000/  500000 | consumed samples:      1800000 | elapsed time per iteration (ms): 320.5 | learning rate: 3.898768E-05 | global batch size:     8 | lm loss: 3.067063E+00 | loss scale: 1048576.0 | grad norm: 0.818 | number of skipped iterations:   1 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1064.07, 1064.07)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 225000 | lm loss value: 3.689317E+00 | lm loss PPL: 4.001751E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 03:01:34] iteration   225100/  500000 | consumed samples:      1800800 | elapsed time per iteration (ms): 320.3 | learning rate: 3.893257E-05 | global batch size:     8 | lm loss: 3.099327E+00 | loss scale: 262144.0 | grad norm: 0.854 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-22 03:02:06] iteration   225200/  500000 | consumed samples:      1801600 | elapsed time per iteration (ms): 321.4 | learning rate: 3.887638E-05 | global batch size:     8 | lm loss: 3.060006E+00 | loss scale: 262144.0 | grad norm: 0.811 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 03:02:38] iteration   225300/  500000 | consumed samples:      1802400 | elapsed time per iteration (ms): 322.5 | learning rate: 3.882022E-05 | global batch size:     8 | lm loss: 3.094746E+00 | loss scale: 262144.0 | grad norm: 0.831 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 03:03:10] iteration   225400/  500000 | consumed samples:      1803200 | elapsed time per iteration (ms): 320.9 | learning rate: 3.876411E-05 | global batch size:     8 | lm loss: 3.086780E+00 | loss scale: 262144.0 | grad norm: 0.837 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 03:03:42] iteration   225500/  500000 | consumed samples:      1804000 | elapsed time per iteration (ms): 320.4 | learning rate: 3.870803E-05 | global batch size:     8 | lm loss: 3.101124E+00 | loss scale: 262144.0 | grad norm: 0.822 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 03:04:15] iteration   225600/  500000 | consumed samples:      1804800 | elapsed time per iteration (ms): 321.3 | learning rate: 3.865200E-05 | global batch size:     8 | lm loss: 3.053988E+00 | loss scale: 262144.0 | grad norm: 0.842 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 03:04:47] iteration   225700/  500000 | consumed samples:      1805600 | elapsed time per iteration (ms): 322.5 | learning rate: 3.859601E-05 | global batch size:     8 | lm loss: 3.077336E+00 | loss scale: 262144.0 | grad norm: 0.828 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 03:05:19] iteration   225800/  500000 | consumed samples:      1806400 | elapsed time per iteration (ms): 323.2 | learning rate: 3.854006E-05 | global batch size:     8 | lm loss: 3.064157E+00 | loss scale: 262144.0 | grad norm: 0.854 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 03:05:51] iteration   225900/  500000 | consumed samples:      1807200 | elapsed time per iteration (ms): 323.3 | learning rate: 3.848415E-05 | global batch size:     8 | lm loss: 3.114639E+00 | loss scale: 262144.0 | grad norm: 0.822 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 03:06:24] iteration   226000/  500000 | consumed samples:      1808000 | elapsed time per iteration (ms): 322.1 | learning rate: 3.842828E-05 | global batch size:     8 | lm loss: 3.114916E+00 | loss scale: 262144.0 | grad norm: 0.800 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1064.72, 1064.72)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 226000 | lm loss value: 3.738473E+00 | lm loss PPL: 4.203376E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 03:06:57] iteration   226100/  500000 | consumed samples:      1808800 | elapsed time per iteration (ms): 321.5 | learning rate: 3.837245E-05 | global batch size:     8 | lm loss: 3.052733E+00 | loss scale: 524288.0 | grad norm: 0.839 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 03:07:29] iteration   226200/  500000 | consumed samples:      1809600 | elapsed time per iteration (ms): 322.0 | learning rate: 3.831722E-05 | global batch size:     8 | lm loss: 3.047398E+00 | loss scale: 524288.0 | grad norm: 0.849 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-22 03:08:01] iteration   226300/  500000 | consumed samples:      1810400 | elapsed time per iteration (ms): 319.1 | learning rate: 3.826203E-05 | global batch size:     8 | lm loss: 3.059783E+00 | loss scale: 262144.0 | grad norm: 1.047 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-22 03:08:33] iteration   226400/  500000 | consumed samples:      1811200 | elapsed time per iteration (ms): 322.2 | learning rate: 3.820688E-05 | global batch size:     8 | lm loss: 3.118621E+00 | loss scale: 131072.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-22 03:09:06] iteration   226500/  500000 | consumed samples:      1812000 | elapsed time per iteration (ms): 323.0 | learning rate: 3.815121E-05 | global batch size:     8 | lm loss: 3.077598E+00 | loss scale: 131072.0 | grad norm: 0.808 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 03:09:38] iteration   226600/  500000 | consumed samples:      1812800 | elapsed time per iteration (ms): 323.1 | learning rate: 3.809559E-05 | global batch size:     8 | lm loss: 3.087329E+00 | loss scale: 131072.0 | grad norm: 0.796 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 03:10:10] iteration   226700/  500000 | consumed samples:      1813600 | elapsed time per iteration (ms): 322.4 | learning rate: 3.804001E-05 | global batch size:     8 | lm loss: 3.085660E+00 | loss scale: 131072.0 | grad norm: 0.875 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 03:10:42] iteration   226800/  500000 | consumed samples:      1814400 | elapsed time per iteration (ms): 323.5 | learning rate: 3.798446E-05 | global batch size:     8 | lm loss: 3.080052E+00 | loss scale: 131072.0 | grad norm: 0.860 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 03:11:15] iteration   226900/  500000 | consumed samples:      1815200 | elapsed time per iteration (ms): 321.0 | learning rate: 3.792896E-05 | global batch size:     8 | lm loss: 3.061525E+00 | loss scale: 131072.0 | grad norm: 0.815 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 03:11:47] iteration   227000/  500000 | consumed samples:      1816000 | elapsed time per iteration (ms): 324.0 | learning rate: 3.787350E-05 | global batch size:     8 | lm loss: 3.093475E+00 | loss scale: 131072.0 | grad norm: 0.878 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1067.11, 1067.11)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 227000 | lm loss value: 3.630118E+00 | lm loss PPL: 3.771726E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 03:12:20] iteration   227100/  500000 | consumed samples:      1816800 | elapsed time per iteration (ms): 321.2 | learning rate: 3.781808E-05 | global batch size:     8 | lm loss: 3.089031E+00 | loss scale: 131072.0 | grad norm: 0.870 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 03:12:52] iteration   227200/  500000 | consumed samples:      1817600 | elapsed time per iteration (ms): 322.3 | learning rate: 3.776271E-05 | global batch size:     8 | lm loss: 3.071063E+00 | loss scale: 131072.0 | grad norm: 0.816 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 03:13:25] iteration   227300/  500000 | consumed samples:      1818400 | elapsed time per iteration (ms): 323.8 | learning rate: 3.770737E-05 | global batch size:     8 | lm loss: 3.080631E+00 | loss scale: 131072.0 | grad norm: 0.821 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 03:13:57] iteration   227400/  500000 | consumed samples:      1819200 | elapsed time per iteration (ms): 320.1 | learning rate: 3.765208E-05 | global batch size:     8 | lm loss: 3.053647E+00 | loss scale: 262144.0 | grad norm: 0.829 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 03:14:29] iteration   227500/  500000 | consumed samples:      1820000 | elapsed time per iteration (ms): 322.0 | learning rate: 3.759683E-05 | global batch size:     8 | lm loss: 3.050398E+00 | loss scale: 262144.0 | grad norm: 0.824 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 03:15:01] iteration   227600/  500000 | consumed samples:      1820800 | elapsed time per iteration (ms): 321.2 | learning rate: 3.754162E-05 | global batch size:     8 | lm loss: 3.102690E+00 | loss scale: 262144.0 | grad norm: 0.853 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 03:15:33] iteration   227700/  500000 | consumed samples:      1821600 | elapsed time per iteration (ms): 321.1 | learning rate: 3.748700E-05 | global batch size:     8 | lm loss: 3.068952E+00 | loss scale: 262144.0 | grad norm: 0.812 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-22 03:16:05] iteration   227800/  500000 | consumed samples:      1822400 | elapsed time per iteration (ms): 321.4 | learning rate: 3.743187E-05 | global batch size:     8 | lm loss: 3.094479E+00 | loss scale: 262144.0 | grad norm: 0.848 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 03:16:38] iteration   227900/  500000 | consumed samples:      1823200 | elapsed time per iteration (ms): 322.9 | learning rate: 3.737679E-05 | global batch size:     8 | lm loss: 3.068666E+00 | loss scale: 262144.0 | grad norm: 0.810 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 03:17:10] iteration   228000/  500000 | consumed samples:      1824000 | elapsed time per iteration (ms): 321.5 | learning rate: 3.732174E-05 | global batch size:     8 | lm loss: 3.067717E+00 | loss scale: 262144.0 | grad norm: 0.858 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1063.92, 1063.92)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 228000 | lm loss value: 3.619519E+00 | lm loss PPL: 3.731960E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 03:17:43] iteration   228100/  500000 | consumed samples:      1824800 | elapsed time per iteration (ms): 323.9 | learning rate: 3.726674E-05 | global batch size:     8 | lm loss: 3.106590E+00 | loss scale: 262144.0 | grad norm: 0.842 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 03:18:16] iteration   228200/  500000 | consumed samples:      1825600 | elapsed time per iteration (ms): 323.3 | learning rate: 3.721178E-05 | global batch size:     8 | lm loss: 3.084486E+00 | loss scale: 262144.0 | grad norm: 0.865 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 03:18:48] iteration   228300/  500000 | consumed samples:      1826400 | elapsed time per iteration (ms): 323.2 | learning rate: 3.715687E-05 | global batch size:     8 | lm loss: 3.097336E+00 | loss scale: 262144.0 | grad norm: 0.850 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 03:19:20] iteration   228400/  500000 | consumed samples:      1827200 | elapsed time per iteration (ms): 319.0 | learning rate: 3.710199E-05 | global batch size:     8 | lm loss: 3.076125E+00 | loss scale: 262144.0 | grad norm: 0.831 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 03:19:52] iteration   228500/  500000 | consumed samples:      1828000 | elapsed time per iteration (ms): 320.6 | learning rate: 3.704716E-05 | global batch size:     8 | lm loss: 3.038352E+00 | loss scale: 262144.0 | grad norm: 0.825 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 03:20:24] iteration   228600/  500000 | consumed samples:      1828800 | elapsed time per iteration (ms): 320.7 | learning rate: 3.699237E-05 | global batch size:     8 | lm loss: 3.064005E+00 | loss scale: 262144.0 | grad norm: 0.845 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 03:20:56] iteration   228700/  500000 | consumed samples:      1829600 | elapsed time per iteration (ms): 323.4 | learning rate: 3.693762E-05 | global batch size:     8 | lm loss: 3.044106E+00 | loss scale: 524288.0 | grad norm: 0.860 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 03:21:28] iteration   228800/  500000 | consumed samples:      1830400 | elapsed time per iteration (ms): 321.6 | learning rate: 3.688291E-05 | global batch size:     8 | lm loss: 3.080129E+00 | loss scale: 524288.0 | grad norm: 0.834 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 03:22:01] iteration   228900/  500000 | consumed samples:      1831200 | elapsed time per iteration (ms): 323.5 | learning rate: 3.682825E-05 | global batch size:     8 | lm loss: 3.069646E+00 | loss scale: 524288.0 | grad norm: 0.825 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 03:22:33] iteration   229000/  500000 | consumed samples:      1832000 | elapsed time per iteration (ms): 323.1 | learning rate: 3.677363E-05 | global batch size:     8 | lm loss: 3.079195E+00 | loss scale: 524288.0 | grad norm: 0.823 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1063.65, 1063.65)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 229000 | lm loss value: 3.725379E+00 | lm loss PPL: 4.148693E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 03:23:06] iteration   229100/  500000 | consumed samples:      1832800 | elapsed time per iteration (ms): 322.3 | learning rate: 3.671905E-05 | global batch size:     8 | lm loss: 3.096703E+00 | loss scale: 524288.0 | grad norm: 0.838 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 03:23:39] iteration   229200/  500000 | consumed samples:      1833600 | elapsed time per iteration (ms): 323.1 | learning rate: 3.666451E-05 | global batch size:     8 | lm loss: 3.072002E+00 | loss scale: 524288.0 | grad norm: 0.806 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 03:24:11] iteration   229300/  500000 | consumed samples:      1834400 | elapsed time per iteration (ms): 320.8 | learning rate: 3.661002E-05 | global batch size:     8 | lm loss: 3.043310E+00 | loss scale: 524288.0 | grad norm: 0.848 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 03:24:43] iteration   229400/  500000 | consumed samples:      1835200 | elapsed time per iteration (ms): 323.5 | learning rate: 3.655557E-05 | global batch size:     8 | lm loss: 3.063174E+00 | loss scale: 524288.0 | grad norm: 0.886 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 03:25:15] iteration   229500/  500000 | consumed samples:      1836000 | elapsed time per iteration (ms): 320.7 | learning rate: 3.650116E-05 | global batch size:     8 | lm loss: 3.036422E+00 | loss scale: 524288.0 | grad norm: 0.836 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 03:25:47] iteration   229600/  500000 | consumed samples:      1836800 | elapsed time per iteration (ms): 323.6 | learning rate: 3.644680E-05 | global batch size:     8 | lm loss: 3.055791E+00 | loss scale: 524288.0 | grad norm: 0.858 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 03:26:20] iteration   229700/  500000 | consumed samples:      1837600 | elapsed time per iteration (ms): 322.0 | learning rate: 3.639302E-05 | global batch size:     8 | lm loss: 3.059711E+00 | loss scale: 524288.0 | grad norm: 0.873 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-22 03:26:52] iteration   229800/  500000 | consumed samples:      1838400 | elapsed time per iteration (ms): 324.3 | learning rate: 3.633874E-05 | global batch size:     8 | lm loss: 3.033279E+00 | loss scale: 524288.0 | grad norm: 0.843 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 03:27:24] iteration   229900/  500000 | consumed samples:      1839200 | elapsed time per iteration (ms): 322.4 | learning rate: 3.628450E-05 | global batch size:     8 | lm loss: 3.101249E+00 | loss scale: 524288.0 | grad norm: 0.852 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 03:27:57] iteration   230000/  500000 | consumed samples:      1840000 | elapsed time per iteration (ms): 321.4 | learning rate: 3.623031E-05 | global batch size:     8 | lm loss: 3.076626E+00 | loss scale: 524288.0 | grad norm: 0.823 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1064.14, 1064.14)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 230000 | lm loss value: 3.633737E+00 | lm loss PPL: 3.785403E+01 | 
--------------------------------------------------------------------------------------------------
saving checkpoint at iteration  230000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-max in torch format
  successfully saved checkpoint at iteration  230000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-max
(min, max) time across ranks (ms):
    save-checkpoint ................................: (5695.26, 5695.26)
 [2024-06-22 03:28:35] iteration   230100/  500000 | consumed samples:      1840800 | elapsed time per iteration (ms): 322.0 | learning rate: 3.617615E-05 | global batch size:     8 | lm loss: 3.083439E+00 | loss scale: 524288.0 | grad norm: 0.802 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 03:29:08] iteration   230200/  500000 | consumed samples:      1841600 | elapsed time per iteration (ms): 322.5 | learning rate: 3.612205E-05 | global batch size:     8 | lm loss: 3.076545E+00 | loss scale: 524288.0 | grad norm: 0.868 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 03:29:40] iteration   230300/  500000 | consumed samples:      1842400 | elapsed time per iteration (ms): 324.3 | learning rate: 3.606852E-05 | global batch size:     8 | lm loss: 3.065764E+00 | loss scale: 262144.0 | grad norm: 0.838 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-22 03:30:12] iteration   230400/  500000 | consumed samples:      1843200 | elapsed time per iteration (ms): 321.9 | learning rate: 3.601450E-05 | global batch size:     8 | lm loss: 3.092245E+00 | loss scale: 262144.0 | grad norm: 0.834 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 03:30:45] iteration   230500/  500000 | consumed samples:      1844000 | elapsed time per iteration (ms): 322.1 | learning rate: 3.596052E-05 | global batch size:     8 | lm loss: 3.033159E+00 | loss scale: 262144.0 | grad norm: 0.870 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 03:31:17] iteration   230600/  500000 | consumed samples:      1844800 | elapsed time per iteration (ms): 320.8 | learning rate: 3.590659E-05 | global batch size:     8 | lm loss: 3.094337E+00 | loss scale: 262144.0 | grad norm: 0.822 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 03:31:49] iteration   230700/  500000 | consumed samples:      1845600 | elapsed time per iteration (ms): 322.0 | learning rate: 3.585269E-05 | global batch size:     8 | lm loss: 3.125623E+00 | loss scale: 262144.0 | grad norm: 0.816 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 03:32:21] iteration   230800/  500000 | consumed samples:      1846400 | elapsed time per iteration (ms): 321.9 | learning rate: 3.579884E-05 | global batch size:     8 | lm loss: 3.090064E+00 | loss scale: 262144.0 | grad norm: 0.816 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 03:32:53] iteration   230900/  500000 | consumed samples:      1847200 | elapsed time per iteration (ms): 319.2 | learning rate: 3.574504E-05 | global batch size:     8 | lm loss: 3.045990E+00 | loss scale: 262144.0 | grad norm: 0.808 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 03:33:25] iteration   231000/  500000 | consumed samples:      1848000 | elapsed time per iteration (ms): 320.9 | learning rate: 3.569128E-05 | global batch size:     8 | lm loss: 3.065874E+00 | loss scale: 262144.0 | grad norm: 0.825 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1063.79, 1063.79)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 231000 | lm loss value: 3.778090E+00 | lm loss PPL: 4.373243E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 03:33:58] iteration   231100/  500000 | consumed samples:      1848800 | elapsed time per iteration (ms): 323.2 | learning rate: 3.563756E-05 | global batch size:     8 | lm loss: 3.102965E+00 | loss scale: 262144.0 | grad norm: 0.923 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 03:34:31] iteration   231200/  500000 | consumed samples:      1849600 | elapsed time per iteration (ms): 322.8 | learning rate: 3.558389E-05 | global batch size:     8 | lm loss: 3.066438E+00 | loss scale: 262144.0 | grad norm: 0.821 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 03:35:03] iteration   231300/  500000 | consumed samples:      1850400 | elapsed time per iteration (ms): 322.9 | learning rate: 3.553025E-05 | global batch size:     8 | lm loss: 3.081627E+00 | loss scale: 524288.0 | grad norm: 0.801 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 03:35:35] iteration   231400/  500000 | consumed samples:      1851200 | elapsed time per iteration (ms): 321.9 | learning rate: 3.547667E-05 | global batch size:     8 | lm loss: 3.088823E+00 | loss scale: 524288.0 | grad norm: 0.796 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 03:36:07] iteration   231500/  500000 | consumed samples:      1852000 | elapsed time per iteration (ms): 320.7 | learning rate: 3.542312E-05 | global batch size:     8 | lm loss: 3.075777E+00 | loss scale: 524288.0 | grad norm: 0.790 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 03:36:39] iteration   231600/  500000 | consumed samples:      1852800 | elapsed time per iteration (ms): 322.4 | learning rate: 3.536962E-05 | global batch size:     8 | lm loss: 3.087094E+00 | loss scale: 524288.0 | grad norm: 0.841 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 03:37:12] iteration   231700/  500000 | consumed samples:      1853600 | elapsed time per iteration (ms): 321.8 | learning rate: 3.531670E-05 | global batch size:     8 | lm loss: 3.086408E+00 | loss scale: 524288.0 | grad norm: 0.853 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-22 03:37:44] iteration   231800/  500000 | consumed samples:      1854400 | elapsed time per iteration (ms): 322.3 | learning rate: 3.526329E-05 | global batch size:     8 | lm loss: 3.094138E+00 | loss scale: 524288.0 | grad norm: 0.831 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 03:38:16] iteration   231900/  500000 | consumed samples:      1855200 | elapsed time per iteration (ms): 323.5 | learning rate: 3.520992E-05 | global batch size:     8 | lm loss: 3.066518E+00 | loss scale: 524288.0 | grad norm: 0.875 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 03:38:49] iteration   232000/  500000 | consumed samples:      1856000 | elapsed time per iteration (ms): 323.7 | learning rate: 3.515660E-05 | global batch size:     8 | lm loss: 3.085125E+00 | loss scale: 524288.0 | grad norm: 0.857 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1066.74, 1066.74)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 232000 | lm loss value: 3.678587E+00 | lm loss PPL: 3.959043E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 03:39:22] iteration   232100/  500000 | consumed samples:      1856800 | elapsed time per iteration (ms): 322.8 | learning rate: 3.510332E-05 | global batch size:     8 | lm loss: 3.084139E+00 | loss scale: 524288.0 | grad norm: 0.827 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 03:39:54] iteration   232200/  500000 | consumed samples:      1857600 | elapsed time per iteration (ms): 319.7 | learning rate: 3.505008E-05 | global batch size:     8 | lm loss: 3.076864E+00 | loss scale: 524288.0 | grad norm: 0.889 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 03:40:26] iteration   232300/  500000 | consumed samples:      1858400 | elapsed time per iteration (ms): 323.2 | learning rate: 3.499689E-05 | global batch size:     8 | lm loss: 3.074846E+00 | loss scale: 524288.0 | grad norm: 0.865 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 03:40:59] iteration   232400/  500000 | consumed samples:      1859200 | elapsed time per iteration (ms): 323.8 | learning rate: 3.494374E-05 | global batch size:     8 | lm loss: 3.076183E+00 | loss scale: 524288.0 | grad norm: 0.881 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 03:41:31] iteration   232500/  500000 | consumed samples:      1860000 | elapsed time per iteration (ms): 322.5 | learning rate: 3.489064E-05 | global batch size:     8 | lm loss: 3.089132E+00 | loss scale: 524288.0 | grad norm: 0.821 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 03:42:03] iteration   232600/  500000 | consumed samples:      1860800 | elapsed time per iteration (ms): 323.5 | learning rate: 3.483811E-05 | global batch size:     8 | lm loss: 3.089386E+00 | loss scale: 262144.0 | grad norm: 0.856 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-22 03:42:36] iteration   232700/  500000 | consumed samples:      1861600 | elapsed time per iteration (ms): 323.2 | learning rate: 3.478510E-05 | global batch size:     8 | lm loss: 3.113878E+00 | loss scale: 262144.0 | grad norm: 0.818 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 03:43:08] iteration   232800/  500000 | consumed samples:      1862400 | elapsed time per iteration (ms): 322.6 | learning rate: 3.473213E-05 | global batch size:     8 | lm loss: 3.060493E+00 | loss scale: 262144.0 | grad norm: 0.845 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 03:43:40] iteration   232900/  500000 | consumed samples:      1863200 | elapsed time per iteration (ms): 321.2 | learning rate: 3.467920E-05 | global batch size:     8 | lm loss: 3.094707E+00 | loss scale: 262144.0 | grad norm: 0.869 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 03:44:12] iteration   233000/  500000 | consumed samples:      1864000 | elapsed time per iteration (ms): 322.1 | learning rate: 3.462632E-05 | global batch size:     8 | lm loss: 3.061070E+00 | loss scale: 262144.0 | grad norm: 0.864 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1063.34, 1063.34)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 233000 | lm loss value: 3.688888E+00 | lm loss PPL: 4.000034E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 03:44:45] iteration   233100/  500000 | consumed samples:      1864800 | elapsed time per iteration (ms): 320.6 | learning rate: 3.457348E-05 | global batch size:     8 | lm loss: 3.085091E+00 | loss scale: 262144.0 | grad norm: 0.846 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 03:45:18] iteration   233200/  500000 | consumed samples:      1865600 | elapsed time per iteration (ms): 323.4 | learning rate: 3.452069E-05 | global batch size:     8 | lm loss: 3.058675E+00 | loss scale: 262144.0 | grad norm: 0.854 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 03:45:50] iteration   233300/  500000 | consumed samples:      1866400 | elapsed time per iteration (ms): 323.2 | learning rate: 3.446795E-05 | global batch size:     8 | lm loss: 3.055542E+00 | loss scale: 262144.0 | grad norm: 0.868 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 03:46:22] iteration   233400/  500000 | consumed samples:      1867200 | elapsed time per iteration (ms): 322.6 | learning rate: 3.441524E-05 | global batch size:     8 | lm loss: 3.068969E+00 | loss scale: 262144.0 | grad norm: 0.882 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 03:46:54] iteration   233500/  500000 | consumed samples:      1868000 | elapsed time per iteration (ms): 322.4 | learning rate: 3.436259E-05 | global batch size:     8 | lm loss: 3.124395E+00 | loss scale: 262144.0 | grad norm: 0.873 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 03:47:27] iteration   233600/  500000 | consumed samples:      1868800 | elapsed time per iteration (ms): 323.7 | learning rate: 3.430997E-05 | global batch size:     8 | lm loss: 3.086800E+00 | loss scale: 524288.0 | grad norm: 0.802 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 03:47:59] iteration   233700/  500000 | consumed samples:      1869600 | elapsed time per iteration (ms): 324.4 | learning rate: 3.425740E-05 | global batch size:     8 | lm loss: 3.087264E+00 | loss scale: 524288.0 | grad norm: 0.849 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 03:48:32] iteration   233800/  500000 | consumed samples:      1870400 | elapsed time per iteration (ms): 323.1 | learning rate: 3.420488E-05 | global batch size:     8 | lm loss: 3.075757E+00 | loss scale: 524288.0 | grad norm: 0.881 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 03:49:04] iteration   233900/  500000 | consumed samples:      1871200 | elapsed time per iteration (ms): 322.0 | learning rate: 3.415240E-05 | global batch size:     8 | lm loss: 3.032866E+00 | loss scale: 524288.0 | grad norm: 0.848 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 03:49:36] iteration   234000/  500000 | consumed samples:      1872000 | elapsed time per iteration (ms): 322.5 | learning rate: 3.409997E-05 | global batch size:     8 | lm loss: 3.044196E+00 | loss scale: 524288.0 | grad norm: 0.869 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1069.59, 1069.59)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 234000 | lm loss value: 3.642099E+00 | lm loss PPL: 3.817186E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 03:50:09] iteration   234100/  500000 | consumed samples:      1872800 | elapsed time per iteration (ms): 320.0 | learning rate: 3.404758E-05 | global batch size:     8 | lm loss: 3.077164E+00 | loss scale: 524288.0 | grad norm: 0.824 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 03:50:41] iteration   234200/  500000 | consumed samples:      1873600 | elapsed time per iteration (ms): 322.2 | learning rate: 3.399524E-05 | global batch size:     8 | lm loss: 3.066486E+00 | loss scale: 524288.0 | grad norm: 0.837 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 03:51:14] iteration   234300/  500000 | consumed samples:      1874400 | elapsed time per iteration (ms): 322.3 | learning rate: 3.394347E-05 | global batch size:     8 | lm loss: 3.035009E+00 | loss scale: 524288.0 | grad norm: 0.761 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-22 03:51:46] iteration   234400/  500000 | consumed samples:      1875200 | elapsed time per iteration (ms): 321.1 | learning rate: 3.389122E-05 | global batch size:     8 | lm loss: 3.074029E+00 | loss scale: 524288.0 | grad norm: 0.895 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 03:52:18] iteration   234500/  500000 | consumed samples:      1876000 | elapsed time per iteration (ms): 319.8 | learning rate: 3.383901E-05 | global batch size:     8 | lm loss: 3.068491E+00 | loss scale: 524288.0 | grad norm: 0.837 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 03:52:50] iteration   234600/  500000 | consumed samples:      1876800 | elapsed time per iteration (ms): 322.7 | learning rate: 3.378685E-05 | global batch size:     8 | lm loss: 3.042076E+00 | loss scale: 524288.0 | grad norm: 0.859 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 03:53:22] iteration   234700/  500000 | consumed samples:      1877600 | elapsed time per iteration (ms): 320.5 | learning rate: 3.373473E-05 | global batch size:     8 | lm loss: 3.117900E+00 | loss scale: 524288.0 | grad norm: 0.824 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 03:53:54] iteration   234800/  500000 | consumed samples:      1878400 | elapsed time per iteration (ms): 323.3 | learning rate: 3.368266E-05 | global batch size:     8 | lm loss: 3.063138E+00 | loss scale: 524288.0 | grad norm: 0.850 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 03:54:27] iteration   234900/  500000 | consumed samples:      1879200 | elapsed time per iteration (ms): 322.8 | learning rate: 3.363064E-05 | global batch size:     8 | lm loss: 3.107278E+00 | loss scale: 524288.0 | grad norm: 0.891 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 03:54:59] iteration   235000/  500000 | consumed samples:      1880000 | elapsed time per iteration (ms): 319.8 | learning rate: 3.357866E-05 | global batch size:     8 | lm loss: 3.053072E+00 | loss scale: 524288.0 | grad norm: 0.796 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1067.09, 1067.09)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 235000 | lm loss value: 3.600242E+00 | lm loss PPL: 3.660709E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 03:55:32] iteration   235100/  500000 | consumed samples:      1880800 | elapsed time per iteration (ms): 322.6 | learning rate: 3.352672E-05 | global batch size:     8 | lm loss: 3.046198E+00 | loss scale: 524288.0 | grad norm: 0.764 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 03:56:04] iteration   235200/  500000 | consumed samples:      1881600 | elapsed time per iteration (ms): 321.6 | learning rate: 3.347483E-05 | global batch size:     8 | lm loss: 3.114070E+00 | loss scale: 524288.0 | grad norm: 0.861 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 03:56:36] iteration   235300/  500000 | consumed samples:      1882400 | elapsed time per iteration (ms): 318.7 | learning rate: 3.342403E-05 | global batch size:     8 | lm loss: 3.068156E+00 | loss scale: 524288.0 | grad norm: 0.840 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-22 03:57:08] iteration   235400/  500000 | consumed samples:      1883200 | elapsed time per iteration (ms): 319.7 | learning rate: 3.337223E-05 | global batch size:     8 | lm loss: 3.064508E+00 | loss scale: 524288.0 | grad norm: 0.860 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 03:57:40] iteration   235500/  500000 | consumed samples:      1884000 | elapsed time per iteration (ms): 323.6 | learning rate: 3.332048E-05 | global batch size:     8 | lm loss: 3.055479E+00 | loss scale: 524288.0 | grad norm: 0.850 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 03:58:12] iteration   235600/  500000 | consumed samples:      1884800 | elapsed time per iteration (ms): 321.2 | learning rate: 3.326929E-05 | global batch size:     8 | lm loss: 3.069971E+00 | loss scale: 262144.0 | grad norm: 0.790 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-22 03:58:45] iteration   235700/  500000 | consumed samples:      1885600 | elapsed time per iteration (ms): 321.5 | learning rate: 3.321763E-05 | global batch size:     8 | lm loss: 3.065107E+00 | loss scale: 262144.0 | grad norm: 0.821 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 03:59:17] iteration   235800/  500000 | consumed samples:      1886400 | elapsed time per iteration (ms): 321.4 | learning rate: 3.316602E-05 | global batch size:     8 | lm loss: 3.072635E+00 | loss scale: 262144.0 | grad norm: 0.881 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 03:59:49] iteration   235900/  500000 | consumed samples:      1887200 | elapsed time per iteration (ms): 323.9 | learning rate: 3.311445E-05 | global batch size:     8 | lm loss: 3.049242E+00 | loss scale: 262144.0 | grad norm: 0.880 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 04:00:21] iteration   236000/  500000 | consumed samples:      1888000 | elapsed time per iteration (ms): 320.0 | learning rate: 3.306293E-05 | global batch size:     8 | lm loss: 3.048150E+00 | loss scale: 262144.0 | grad norm: 0.828 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1063.93, 1063.93)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 236000 | lm loss value: 3.687131E+00 | lm loss PPL: 3.993013E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 04:00:54] iteration   236100/  500000 | consumed samples:      1888800 | elapsed time per iteration (ms): 323.5 | learning rate: 3.301145E-05 | global batch size:     8 | lm loss: 3.065133E+00 | loss scale: 262144.0 | grad norm: 0.828 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 04:01:26] iteration   236200/  500000 | consumed samples:      1889600 | elapsed time per iteration (ms): 320.5 | learning rate: 3.296054E-05 | global batch size:     8 | lm loss: 3.050463E+00 | loss scale: 131072.0 | grad norm: 0.850 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-22 04:01:59] iteration   236300/  500000 | consumed samples:      1890400 | elapsed time per iteration (ms): 323.5 | learning rate: 3.290915E-05 | global batch size:     8 | lm loss: 3.128184E+00 | loss scale: 131072.0 | grad norm: 0.842 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 04:02:31] iteration   236400/  500000 | consumed samples:      1891200 | elapsed time per iteration (ms): 320.5 | learning rate: 3.285781E-05 | global batch size:     8 | lm loss: 3.072423E+00 | loss scale: 131072.0 | grad norm: 0.891 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 04:03:03] iteration   236500/  500000 | consumed samples:      1892000 | elapsed time per iteration (ms): 322.2 | learning rate: 3.280652E-05 | global batch size:     8 | lm loss: 3.046862E+00 | loss scale: 131072.0 | grad norm: 0.878 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 04:03:35] iteration   236600/  500000 | consumed samples:      1892800 | elapsed time per iteration (ms): 322.6 | learning rate: 3.275528E-05 | global batch size:     8 | lm loss: 3.065853E+00 | loss scale: 131072.0 | grad norm: 0.855 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 04:04:08] iteration   236700/  500000 | consumed samples:      1893600 | elapsed time per iteration (ms): 321.8 | learning rate: 3.270408E-05 | global batch size:     8 | lm loss: 3.042423E+00 | loss scale: 131072.0 | grad norm: 0.831 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 04:04:40] iteration   236800/  500000 | consumed samples:      1894400 | elapsed time per iteration (ms): 323.9 | learning rate: 3.265293E-05 | global batch size:     8 | lm loss: 3.081092E+00 | loss scale: 131072.0 | grad norm: 0.823 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 04:05:12] iteration   236900/  500000 | consumed samples:      1895200 | elapsed time per iteration (ms): 323.1 | learning rate: 3.260182E-05 | global batch size:     8 | lm loss: 3.078064E+00 | loss scale: 131072.0 | grad norm: 0.856 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 04:05:45] iteration   237000/  500000 | consumed samples:      1896000 | elapsed time per iteration (ms): 323.6 | learning rate: 3.255076E-05 | global batch size:     8 | lm loss: 3.091997E+00 | loss scale: 131072.0 | grad norm: 0.834 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1064.92, 1064.92)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 237000 | lm loss value: 3.769079E+00 | lm loss PPL: 4.334013E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 04:06:18] iteration   237100/  500000 | consumed samples:      1896800 | elapsed time per iteration (ms): 322.5 | learning rate: 3.249975E-05 | global batch size:     8 | lm loss: 3.084438E+00 | loss scale: 131072.0 | grad norm: 0.912 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 04:06:50] iteration   237200/  500000 | consumed samples:      1897600 | elapsed time per iteration (ms): 322.8 | learning rate: 3.244879E-05 | global batch size:     8 | lm loss: 3.060015E+00 | loss scale: 262144.0 | grad norm: 0.801 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 04:07:22] iteration   237300/  500000 | consumed samples:      1898400 | elapsed time per iteration (ms): 319.4 | learning rate: 3.239889E-05 | global batch size:     8 | lm loss: 3.055490E+00 | loss scale: 131072.0 | grad norm: 0.825 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-22 04:07:54] iteration   237400/  500000 | consumed samples:      1899200 | elapsed time per iteration (ms): 321.1 | learning rate: 3.234801E-05 | global batch size:     8 | lm loss: 3.035344E+00 | loss scale: 131072.0 | grad norm: 0.811 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 04:08:26] iteration   237500/  500000 | consumed samples:      1900000 | elapsed time per iteration (ms): 321.0 | learning rate: 3.229719E-05 | global batch size:     8 | lm loss: 3.093723E+00 | loss scale: 131072.0 | grad norm: 0.851 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 04:08:59] iteration   237600/  500000 | consumed samples:      1900800 | elapsed time per iteration (ms): 324.7 | learning rate: 3.224641E-05 | global batch size:     8 | lm loss: 3.090051E+00 | loss scale: 131072.0 | grad norm: 0.900 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 04:09:31] iteration   237700/  500000 | consumed samples:      1901600 | elapsed time per iteration (ms): 320.5 | learning rate: 3.219568E-05 | global batch size:     8 | lm loss: 3.025358E+00 | loss scale: 131072.0 | grad norm: 0.839 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 04:10:03] iteration   237800/  500000 | consumed samples:      1902400 | elapsed time per iteration (ms): 323.1 | learning rate: 3.214499E-05 | global batch size:     8 | lm loss: 3.094088E+00 | loss scale: 131072.0 | grad norm: 0.884 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 04:10:35] iteration   237900/  500000 | consumed samples:      1903200 | elapsed time per iteration (ms): 320.0 | learning rate: 3.209435E-05 | global batch size:     8 | lm loss: 3.047096E+00 | loss scale: 131072.0 | grad norm: 0.843 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 04:11:07] iteration   238000/  500000 | consumed samples:      1904000 | elapsed time per iteration (ms): 321.7 | learning rate: 3.204376E-05 | global batch size:     8 | lm loss: 3.050553E+00 | loss scale: 131072.0 | grad norm: 0.893 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1062.57, 1062.57)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 238000 | lm loss value: 3.687912E+00 | lm loss PPL: 3.996134E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 04:11:40] iteration   238100/  500000 | consumed samples:      1904800 | elapsed time per iteration (ms): 320.5 | learning rate: 3.199322E-05 | global batch size:     8 | lm loss: 3.076915E+00 | loss scale: 131072.0 | grad norm: 0.804 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 04:12:12] iteration   238200/  500000 | consumed samples:      1905600 | elapsed time per iteration (ms): 320.0 | learning rate: 3.194272E-05 | global batch size:     8 | lm loss: 3.045649E+00 | loss scale: 131072.0 | grad norm: 0.897 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 04:12:45] iteration   238300/  500000 | consumed samples:      1906400 | elapsed time per iteration (ms): 320.2 | learning rate: 3.189228E-05 | global batch size:     8 | lm loss: 3.069171E+00 | loss scale: 262144.0 | grad norm: 0.829 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 04:13:17] iteration   238400/  500000 | consumed samples:      1907200 | elapsed time per iteration (ms): 321.1 | learning rate: 3.184187E-05 | global batch size:     8 | lm loss: 3.038794E+00 | loss scale: 262144.0 | grad norm: 0.822 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 04:13:49] iteration   238500/  500000 | consumed samples:      1908000 | elapsed time per iteration (ms): 322.8 | learning rate: 3.179152E-05 | global batch size:     8 | lm loss: 3.028495E+00 | loss scale: 262144.0 | grad norm: 0.888 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 04:14:21] iteration   238600/  500000 | consumed samples:      1908800 | elapsed time per iteration (ms): 319.8 | learning rate: 3.174121E-05 | global batch size:     8 | lm loss: 3.067138E+00 | loss scale: 262144.0 | grad norm: 0.861 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 04:14:53] iteration   238700/  500000 | consumed samples:      1909600 | elapsed time per iteration (ms): 321.2 | learning rate: 3.169095E-05 | global batch size:     8 | lm loss: 3.069154E+00 | loss scale: 262144.0 | grad norm: 0.904 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 04:15:25] iteration   238800/  500000 | consumed samples:      1910400 | elapsed time per iteration (ms): 320.9 | learning rate: 3.164074E-05 | global batch size:     8 | lm loss: 3.079121E+00 | loss scale: 262144.0 | grad norm: 0.855 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 04:15:57] iteration   238900/  500000 | consumed samples:      1911200 | elapsed time per iteration (ms): 318.6 | learning rate: 3.159058E-05 | global batch size:     8 | lm loss: 3.034645E+00 | loss scale: 262144.0 | grad norm: 0.838 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 04:16:29] iteration   239000/  500000 | consumed samples:      1912000 | elapsed time per iteration (ms): 320.0 | learning rate: 3.154046E-05 | global batch size:     8 | lm loss: 3.048988E+00 | loss scale: 262144.0 | grad norm: 0.837 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1066.17, 1066.17)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 239000 | lm loss value: 3.733216E+00 | lm loss PPL: 4.181336E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 04:17:02] iteration   239100/  500000 | consumed samples:      1912800 | elapsed time per iteration (ms): 324.3 | learning rate: 3.149039E-05 | global batch size:     8 | lm loss: 3.034304E+00 | loss scale: 262144.0 | grad norm: 0.849 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 04:17:35] iteration   239200/  500000 | consumed samples:      1913600 | elapsed time per iteration (ms): 322.1 | learning rate: 3.144037E-05 | global batch size:     8 | lm loss: 3.058838E+00 | loss scale: 262144.0 | grad norm: 0.847 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 04:18:07] iteration   239300/  500000 | consumed samples:      1914400 | elapsed time per iteration (ms): 321.5 | learning rate: 3.139039E-05 | global batch size:     8 | lm loss: 3.054168E+00 | loss scale: 524288.0 | grad norm: 0.843 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 04:18:39] iteration   239400/  500000 | consumed samples:      1915200 | elapsed time per iteration (ms): 321.8 | learning rate: 3.134047E-05 | global batch size:     8 | lm loss: 3.092963E+00 | loss scale: 524288.0 | grad norm: 0.870 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 04:19:11] iteration   239500/  500000 | consumed samples:      1916000 | elapsed time per iteration (ms): 320.8 | learning rate: 3.129059E-05 | global batch size:     8 | lm loss: 3.043703E+00 | loss scale: 524288.0 | grad norm: 0.841 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 04:19:43] iteration   239600/  500000 | consumed samples:      1916800 | elapsed time per iteration (ms): 323.1 | learning rate: 3.124076E-05 | global batch size:     8 | lm loss: 3.013056E+00 | loss scale: 524288.0 | grad norm: 0.872 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 04:20:15] iteration   239700/  500000 | consumed samples:      1917600 | elapsed time per iteration (ms): 320.2 | learning rate: 3.119148E-05 | global batch size:     8 | lm loss: 3.049119E+00 | loss scale: 524288.0 | grad norm: 0.826 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-22 04:20:47] iteration   239800/  500000 | consumed samples:      1918400 | elapsed time per iteration (ms): 319.9 | learning rate: 3.114174E-05 | global batch size:     8 | lm loss: 3.030144E+00 | loss scale: 524288.0 | grad norm: 0.884 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 04:21:20] iteration   239900/  500000 | consumed samples:      1919200 | elapsed time per iteration (ms): 322.5 | learning rate: 3.109205E-05 | global batch size:     8 | lm loss: 3.087604E+00 | loss scale: 524288.0 | grad norm: 0.854 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 04:21:52] iteration   240000/  500000 | consumed samples:      1920000 | elapsed time per iteration (ms): 322.0 | learning rate: 3.104242E-05 | global batch size:     8 | lm loss: 3.041717E+00 | loss scale: 524288.0 | grad norm: 0.910 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1063.66, 1063.66)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 240000 | lm loss value: 3.616386E+00 | lm loss PPL: 3.720289E+01 | 
--------------------------------------------------------------------------------------------------
saving checkpoint at iteration  240000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-max in torch format
  successfully saved checkpoint at iteration  240000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-max
(min, max) time across ranks (ms):
    save-checkpoint ................................: (5617.48, 5617.48)
 [2024-06-22 04:22:31] iteration   240100/  500000 | consumed samples:      1920800 | elapsed time per iteration (ms): 320.9 | learning rate: 3.099283E-05 | global batch size:     8 | lm loss: 3.043874E+00 | loss scale: 524288.0 | grad norm: 0.878 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 04:23:03] iteration   240200/  500000 | consumed samples:      1921600 | elapsed time per iteration (ms): 320.5 | learning rate: 3.094328E-05 | global batch size:     8 | lm loss: 3.066671E+00 | loss scale: 524288.0 | grad norm: 0.842 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 04:23:35] iteration   240300/  500000 | consumed samples:      1922400 | elapsed time per iteration (ms): 322.1 | learning rate: 3.089379E-05 | global batch size:     8 | lm loss: 3.087987E+00 | loss scale: 524288.0 | grad norm: 0.851 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 04:24:07] iteration   240400/  500000 | consumed samples:      1923200 | elapsed time per iteration (ms): 321.2 | learning rate: 3.084484E-05 | global batch size:     8 | lm loss: 3.076136E+00 | loss scale: 262144.0 | grad norm: 0.847 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-22 04:24:39] iteration   240500/  500000 | consumed samples:      1924000 | elapsed time per iteration (ms): 324.2 | learning rate: 3.079544E-05 | global batch size:     8 | lm loss: 3.056775E+00 | loss scale: 262144.0 | grad norm: 0.826 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 04:25:12] iteration   240600/  500000 | consumed samples:      1924800 | elapsed time per iteration (ms): 321.8 | learning rate: 3.074609E-05 | global batch size:     8 | lm loss: 3.066755E+00 | loss scale: 262144.0 | grad norm: 0.864 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 04:25:44] iteration   240700/  500000 | consumed samples:      1925600 | elapsed time per iteration (ms): 321.3 | learning rate: 3.069679E-05 | global batch size:     8 | lm loss: 3.055078E+00 | loss scale: 262144.0 | grad norm: 0.852 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 04:26:16] iteration   240800/  500000 | consumed samples:      1926400 | elapsed time per iteration (ms): 321.3 | learning rate: 3.064754E-05 | global batch size:     8 | lm loss: 3.045530E+00 | loss scale: 262144.0 | grad norm: 0.919 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 04:26:48] iteration   240900/  500000 | consumed samples:      1927200 | elapsed time per iteration (ms): 324.0 | learning rate: 3.059833E-05 | global batch size:     8 | lm loss: 3.052012E+00 | loss scale: 262144.0 | grad norm: 0.854 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 04:27:20] iteration   241000/  500000 | consumed samples:      1928000 | elapsed time per iteration (ms): 321.2 | learning rate: 3.054918E-05 | global batch size:     8 | lm loss: 3.032190E+00 | loss scale: 262144.0 | grad norm: 0.952 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1063.85, 1063.85)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 241000 | lm loss value: 3.685163E+00 | lm loss PPL: 3.985164E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 04:27:54] iteration   241100/  500000 | consumed samples:      1928800 | elapsed time per iteration (ms): 323.4 | learning rate: 3.050007E-05 | global batch size:     8 | lm loss: 3.074108E+00 | loss scale: 262144.0 | grad norm: 0.806 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 04:28:26] iteration   241200/  500000 | consumed samples:      1929600 | elapsed time per iteration (ms): 321.5 | learning rate: 3.045101E-05 | global batch size:     8 | lm loss: 3.060530E+00 | loss scale: 262144.0 | grad norm: 0.873 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 04:28:58] iteration   241300/  500000 | consumed samples:      1930400 | elapsed time per iteration (ms): 321.4 | learning rate: 3.040200E-05 | global batch size:     8 | lm loss: 3.056488E+00 | loss scale: 262144.0 | grad norm: 0.843 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 04:29:30] iteration   241400/  500000 | consumed samples:      1931200 | elapsed time per iteration (ms): 320.7 | learning rate: 3.035304E-05 | global batch size:     8 | lm loss: 3.078993E+00 | loss scale: 524288.0 | grad norm: 0.851 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 04:30:02] iteration   241500/  500000 | consumed samples:      1932000 | elapsed time per iteration (ms): 320.8 | learning rate: 3.030413E-05 | global batch size:     8 | lm loss: 3.079832E+00 | loss scale: 524288.0 | grad norm: 0.870 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 04:30:34] iteration   241600/  500000 | consumed samples:      1932800 | elapsed time per iteration (ms): 321.7 | learning rate: 3.025527E-05 | global batch size:     8 | lm loss: 3.025691E+00 | loss scale: 524288.0 | grad norm: 0.886 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 04:31:07] iteration   241700/  500000 | consumed samples:      1933600 | elapsed time per iteration (ms): 321.8 | learning rate: 3.020645E-05 | global batch size:     8 | lm loss: 3.039149E+00 | loss scale: 524288.0 | grad norm: 0.862 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 04:31:39] iteration   241800/  500000 | consumed samples:      1934400 | elapsed time per iteration (ms): 322.0 | learning rate: 3.015769E-05 | global batch size:     8 | lm loss: 3.043255E+00 | loss scale: 524288.0 | grad norm: 0.819 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 04:32:11] iteration   241900/  500000 | consumed samples:      1935200 | elapsed time per iteration (ms): 322.3 | learning rate: 3.010897E-05 | global batch size:     8 | lm loss: 3.084011E+00 | loss scale: 524288.0 | grad norm: 0.846 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 04:32:43] iteration   242000/  500000 | consumed samples:      1936000 | elapsed time per iteration (ms): 320.0 | learning rate: 3.006031E-05 | global batch size:     8 | lm loss: 3.098344E+00 | loss scale: 524288.0 | grad norm: 0.805 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1064.01, 1064.01)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 242000 | lm loss value: 3.522079E+00 | lm loss PPL: 3.385475E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 04:33:16] iteration   242100/  500000 | consumed samples:      1936800 | elapsed time per iteration (ms): 323.3 | learning rate: 3.001169E-05 | global batch size:     8 | lm loss: 3.067914E+00 | loss scale: 524288.0 | grad norm: 0.903 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 04:33:49] iteration   242200/  500000 | consumed samples:      1937600 | elapsed time per iteration (ms): 322.6 | learning rate: 2.996312E-05 | global batch size:     8 | lm loss: 3.016889E+00 | loss scale: 524288.0 | grad norm: 0.840 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 04:34:21] iteration   242300/  500000 | consumed samples:      1938400 | elapsed time per iteration (ms): 321.3 | learning rate: 2.991460E-05 | global batch size:     8 | lm loss: 3.071483E+00 | loss scale: 524288.0 | grad norm: 0.847 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 04:34:53] iteration   242400/  500000 | consumed samples:      1939200 | elapsed time per iteration (ms): 323.2 | learning rate: 2.986710E-05 | global batch size:     8 | lm loss: 3.055124E+00 | loss scale: 524288.0 | grad norm: 0.867 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-22 04:35:25] iteration   242500/  500000 | consumed samples:      1940000 | elapsed time per iteration (ms): 321.4 | learning rate: 2.981868E-05 | global batch size:     8 | lm loss: 3.056683E+00 | loss scale: 524288.0 | grad norm: 0.864 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 04:35:57] iteration   242600/  500000 | consumed samples:      1940800 | elapsed time per iteration (ms): 322.3 | learning rate: 2.977030E-05 | global batch size:     8 | lm loss: 3.052600E+00 | loss scale: 524288.0 | grad norm: 0.831 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 04:36:29] iteration   242700/  500000 | consumed samples:      1941600 | elapsed time per iteration (ms): 319.5 | learning rate: 2.972198E-05 | global batch size:     8 | lm loss: 3.025582E+00 | loss scale: 524288.0 | grad norm: 0.904 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 04:37:02] iteration   242800/  500000 | consumed samples:      1942400 | elapsed time per iteration (ms): 321.9 | learning rate: 2.967371E-05 | global batch size:     8 | lm loss: 3.008362E+00 | loss scale: 524288.0 | grad norm: 0.798 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 04:37:34] iteration   242900/  500000 | consumed samples:      1943200 | elapsed time per iteration (ms): 318.9 | learning rate: 2.962548E-05 | global batch size:     8 | lm loss: 3.051233E+00 | loss scale: 524288.0 | grad norm: 0.837 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 04:38:06] iteration   243000/  500000 | consumed samples:      1944000 | elapsed time per iteration (ms): 321.9 | learning rate: 2.957731E-05 | global batch size:     8 | lm loss: 3.051966E+00 | loss scale: 524288.0 | grad norm: 0.850 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1063.74, 1063.74)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 243000 | lm loss value: 3.742402E+00 | lm loss PPL: 4.219924E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 04:38:39] iteration   243100/  500000 | consumed samples:      1944800 | elapsed time per iteration (ms): 320.8 | learning rate: 2.952918E-05 | global batch size:     8 | lm loss: 3.028568E+00 | loss scale: 524288.0 | grad norm: 0.854 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 04:39:11] iteration   243200/  500000 | consumed samples:      1945600 | elapsed time per iteration (ms): 321.6 | learning rate: 2.948111E-05 | global batch size:     8 | lm loss: 3.035018E+00 | loss scale: 524288.0 | grad norm: 0.830 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 04:39:43] iteration   243300/  500000 | consumed samples:      1946400 | elapsed time per iteration (ms): 322.1 | learning rate: 2.943356E-05 | global batch size:     8 | lm loss: 2.994344E+00 | loss scale: 262144.0 | grad norm: 0.868 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-22 04:40:15] iteration   243400/  500000 | consumed samples:      1947200 | elapsed time per iteration (ms): 320.6 | learning rate: 2.938559E-05 | global batch size:     8 | lm loss: 2.999243E+00 | loss scale: 262144.0 | grad norm: 0.912 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 04:40:48] iteration   243500/  500000 | consumed samples:      1948000 | elapsed time per iteration (ms): 323.4 | learning rate: 2.933766E-05 | global batch size:     8 | lm loss: 3.016269E+00 | loss scale: 262144.0 | grad norm: 0.885 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 04:41:20] iteration   243600/  500000 | consumed samples:      1948800 | elapsed time per iteration (ms): 323.1 | learning rate: 2.928978E-05 | global batch size:     8 | lm loss: 3.041046E+00 | loss scale: 262144.0 | grad norm: 0.840 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 04:41:52] iteration   243700/  500000 | consumed samples:      1949600 | elapsed time per iteration (ms): 323.5 | learning rate: 2.924196E-05 | global batch size:     8 | lm loss: 3.039147E+00 | loss scale: 262144.0 | grad norm: 0.864 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 04:42:25] iteration   243800/  500000 | consumed samples:      1950400 | elapsed time per iteration (ms): 322.1 | learning rate: 2.919418E-05 | global batch size:     8 | lm loss: 3.049915E+00 | loss scale: 262144.0 | grad norm: 0.834 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 04:42:57] iteration   243900/  500000 | consumed samples:      1951200 | elapsed time per iteration (ms): 324.4 | learning rate: 2.914645E-05 | global batch size:     8 | lm loss: 3.034800E+00 | loss scale: 262144.0 | grad norm: 0.855 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 04:43:29] iteration   244000/  500000 | consumed samples:      1952000 | elapsed time per iteration (ms): 323.5 | learning rate: 2.909877E-05 | global batch size:     8 | lm loss: 3.069284E+00 | loss scale: 262144.0 | grad norm: 0.809 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1064.81, 1064.81)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 244000 | lm loss value: 3.626022E+00 | lm loss PPL: 3.756311E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 04:44:03] iteration   244100/  500000 | consumed samples:      1952800 | elapsed time per iteration (ms): 323.6 | learning rate: 2.905115E-05 | global batch size:     8 | lm loss: 3.079354E+00 | loss scale: 262144.0 | grad norm: 0.856 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 04:44:35] iteration   244200/  500000 | consumed samples:      1953600 | elapsed time per iteration (ms): 320.2 | learning rate: 2.900357E-05 | global batch size:     8 | lm loss: 3.057517E+00 | loss scale: 262144.0 | grad norm: 0.855 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 04:45:07] iteration   244300/  500000 | consumed samples:      1954400 | elapsed time per iteration (ms): 322.5 | learning rate: 2.895604E-05 | global batch size:     8 | lm loss: 3.050384E+00 | loss scale: 524288.0 | grad norm: 0.849 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 04:45:39] iteration   244400/  500000 | consumed samples:      1955200 | elapsed time per iteration (ms): 320.8 | learning rate: 2.890857E-05 | global batch size:     8 | lm loss: 3.033092E+00 | loss scale: 524288.0 | grad norm: 0.883 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 04:46:11] iteration   244500/  500000 | consumed samples:      1956000 | elapsed time per iteration (ms): 321.5 | learning rate: 2.886114E-05 | global batch size:     8 | lm loss: 3.037945E+00 | loss scale: 524288.0 | grad norm: 0.845 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 04:46:43] iteration   244600/  500000 | consumed samples:      1956800 | elapsed time per iteration (ms): 321.9 | learning rate: 2.881376E-05 | global batch size:     8 | lm loss: 3.062230E+00 | loss scale: 524288.0 | grad norm: 0.899 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 04:47:16] iteration   244700/  500000 | consumed samples:      1957600 | elapsed time per iteration (ms): 321.9 | learning rate: 2.876644E-05 | global batch size:     8 | lm loss: 3.084319E+00 | loss scale: 524288.0 | grad norm: 0.903 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 04:47:48] iteration   244800/  500000 | consumed samples:      1958400 | elapsed time per iteration (ms): 320.9 | learning rate: 2.871963E-05 | global batch size:     8 | lm loss: 3.077341E+00 | loss scale: 524288.0 | grad norm: 0.871 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-22 04:48:20] iteration   244900/  500000 | consumed samples:      1959200 | elapsed time per iteration (ms): 323.6 | learning rate: 2.867241E-05 | global batch size:     8 | lm loss: 3.062733E+00 | loss scale: 524288.0 | grad norm: 0.871 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 04:48:52] iteration   245000/  500000 | consumed samples:      1960000 | elapsed time per iteration (ms): 324.1 | learning rate: 2.862571E-05 | global batch size:     8 | lm loss: 3.041737E+00 | loss scale: 262144.0 | grad norm: 0.818 | number of skipped iterations:   1 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1064.51, 1064.51)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 245000 | lm loss value: 3.651524E+00 | lm loss PPL: 3.853333E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 04:49:26] iteration   245100/  500000 | consumed samples:      1960800 | elapsed time per iteration (ms): 322.7 | learning rate: 2.857858E-05 | global batch size:     8 | lm loss: 3.046787E+00 | loss scale: 262144.0 | grad norm: 0.932 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 04:49:58] iteration   245200/  500000 | consumed samples:      1961600 | elapsed time per iteration (ms): 321.3 | learning rate: 2.853151E-05 | global batch size:     8 | lm loss: 3.058973E+00 | loss scale: 262144.0 | grad norm: 0.859 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 04:50:30] iteration   245300/  500000 | consumed samples:      1962400 | elapsed time per iteration (ms): 322.7 | learning rate: 2.848495E-05 | global batch size:     8 | lm loss: 3.055370E+00 | loss scale: 131072.0 | grad norm: 0.880 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-22 04:51:02] iteration   245400/  500000 | consumed samples:      1963200 | elapsed time per iteration (ms): 322.0 | learning rate: 2.843798E-05 | global batch size:     8 | lm loss: 3.014065E+00 | loss scale: 131072.0 | grad norm: 0.817 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 04:51:35] iteration   245500/  500000 | consumed samples:      1964000 | elapsed time per iteration (ms): 322.3 | learning rate: 2.839106E-05 | global batch size:     8 | lm loss: 3.013228E+00 | loss scale: 131072.0 | grad norm: 0.856 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 04:52:07] iteration   245600/  500000 | consumed samples:      1964800 | elapsed time per iteration (ms): 321.7 | learning rate: 2.834418E-05 | global batch size:     8 | lm loss: 3.057917E+00 | loss scale: 131072.0 | grad norm: 0.847 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 04:52:39] iteration   245700/  500000 | consumed samples:      1965600 | elapsed time per iteration (ms): 323.2 | learning rate: 2.829736E-05 | global batch size:     8 | lm loss: 3.043568E+00 | loss scale: 131072.0 | grad norm: 0.869 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 04:53:12] iteration   245800/  500000 | consumed samples:      1966400 | elapsed time per iteration (ms): 323.8 | learning rate: 2.825059E-05 | global batch size:     8 | lm loss: 3.058083E+00 | loss scale: 131072.0 | grad norm: 0.869 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 04:53:44] iteration   245900/  500000 | consumed samples:      1967200 | elapsed time per iteration (ms): 325.0 | learning rate: 2.820387E-05 | global batch size:     8 | lm loss: 3.013182E+00 | loss scale: 131072.0 | grad norm: 0.880 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 04:54:16] iteration   246000/  500000 | consumed samples:      1968000 | elapsed time per iteration (ms): 322.3 | learning rate: 2.815720E-05 | global batch size:     8 | lm loss: 3.026645E+00 | loss scale: 131072.0 | grad norm: 0.804 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1064.75, 1064.75)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 246000 | lm loss value: 3.883366E+00 | lm loss PPL: 4.858750E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 04:54:50] iteration   246100/  500000 | consumed samples:      1968800 | elapsed time per iteration (ms): 323.4 | learning rate: 2.811058E-05 | global batch size:     8 | lm loss: 3.047073E+00 | loss scale: 131072.0 | grad norm: 0.854 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 04:55:22] iteration   246200/  500000 | consumed samples:      1969600 | elapsed time per iteration (ms): 320.1 | learning rate: 2.806402E-05 | global batch size:     8 | lm loss: 3.085193E+00 | loss scale: 131072.0 | grad norm: 0.895 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 04:55:54] iteration   246300/  500000 | consumed samples:      1970400 | elapsed time per iteration (ms): 323.3 | learning rate: 2.801750E-05 | global batch size:     8 | lm loss: 3.025685E+00 | loss scale: 262144.0 | grad norm: 0.865 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 04:56:26] iteration   246400/  500000 | consumed samples:      1971200 | elapsed time per iteration (ms): 321.1 | learning rate: 2.797150E-05 | global batch size:     8 | lm loss: 3.060797E+00 | loss scale: 262144.0 | grad norm: 0.877 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-22 04:56:58] iteration   246500/  500000 | consumed samples:      1972000 | elapsed time per iteration (ms): 322.2 | learning rate: 2.792509E-05 | global batch size:     8 | lm loss: 3.067177E+00 | loss scale: 262144.0 | grad norm: 0.827 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 04:57:30] iteration   246600/  500000 | consumed samples:      1972800 | elapsed time per iteration (ms): 321.6 | learning rate: 2.787873E-05 | global batch size:     8 | lm loss: 3.046599E+00 | loss scale: 262144.0 | grad norm: 0.813 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 04:58:03] iteration   246700/  500000 | consumed samples:      1973600 | elapsed time per iteration (ms): 323.4 | learning rate: 2.783241E-05 | global batch size:     8 | lm loss: 3.048084E+00 | loss scale: 262144.0 | grad norm: 0.846 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 04:58:35] iteration   246800/  500000 | consumed samples:      1974400 | elapsed time per iteration (ms): 321.2 | learning rate: 2.778615E-05 | global batch size:     8 | lm loss: 3.044833E+00 | loss scale: 262144.0 | grad norm: 0.892 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 04:59:07] iteration   246900/  500000 | consumed samples:      1975200 | elapsed time per iteration (ms): 322.6 | learning rate: 2.773995E-05 | global batch size:     8 | lm loss: 3.066579E+00 | loss scale: 262144.0 | grad norm: 0.874 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 04:59:39] iteration   247000/  500000 | consumed samples:      1976000 | elapsed time per iteration (ms): 322.4 | learning rate: 2.769379E-05 | global batch size:     8 | lm loss: 3.048091E+00 | loss scale: 262144.0 | grad norm: 0.863 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1074.27, 1074.27)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 247000 | lm loss value: 3.660607E+00 | lm loss PPL: 3.888493E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 05:00:13] iteration   247100/  500000 | consumed samples:      1976800 | elapsed time per iteration (ms): 321.3 | learning rate: 2.764768E-05 | global batch size:     8 | lm loss: 3.025370E+00 | loss scale: 262144.0 | grad norm: 0.845 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 05:00:45] iteration   247200/  500000 | consumed samples:      1977600 | elapsed time per iteration (ms): 321.7 | learning rate: 2.760163E-05 | global batch size:     8 | lm loss: 3.035547E+00 | loss scale: 262144.0 | grad norm: 0.829 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 05:01:17] iteration   247300/  500000 | consumed samples:      1978400 | elapsed time per iteration (ms): 320.0 | learning rate: 2.755562E-05 | global batch size:     8 | lm loss: 3.026782E+00 | loss scale: 262144.0 | grad norm: 0.856 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 05:01:49] iteration   247400/  500000 | consumed samples:      1979200 | elapsed time per iteration (ms): 323.7 | learning rate: 2.750967E-05 | global batch size:     8 | lm loss: 3.003280E+00 | loss scale: 524288.0 | grad norm: 0.873 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 05:02:21] iteration   247500/  500000 | consumed samples:      1980000 | elapsed time per iteration (ms): 320.9 | learning rate: 2.746423E-05 | global batch size:     8 | lm loss: 3.019317E+00 | loss scale: 524288.0 | grad norm: 0.837 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-22 05:02:53] iteration   247600/  500000 | consumed samples:      1980800 | elapsed time per iteration (ms): 320.9 | learning rate: 2.741838E-05 | global batch size:     8 | lm loss: 3.078324E+00 | loss scale: 524288.0 | grad norm: 0.899 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 05:03:26] iteration   247700/  500000 | consumed samples:      1981600 | elapsed time per iteration (ms): 322.6 | learning rate: 2.737259E-05 | global batch size:     8 | lm loss: 3.083030E+00 | loss scale: 524288.0 | grad norm: 0.843 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 05:03:58] iteration   247800/  500000 | consumed samples:      1982400 | elapsed time per iteration (ms): 323.4 | learning rate: 2.732684E-05 | global batch size:     8 | lm loss: 3.077683E+00 | loss scale: 524288.0 | grad norm: 0.912 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 05:04:30] iteration   247900/  500000 | consumed samples:      1983200 | elapsed time per iteration (ms): 320.5 | learning rate: 2.728115E-05 | global batch size:     8 | lm loss: 3.058077E+00 | loss scale: 524288.0 | grad norm: 0.867 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 05:05:02] iteration   248000/  500000 | consumed samples:      1984000 | elapsed time per iteration (ms): 322.4 | learning rate: 2.723551E-05 | global batch size:     8 | lm loss: 3.058078E+00 | loss scale: 524288.0 | grad norm: 0.871 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1064.83, 1064.83)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 248000 | lm loss value: 3.757111E+00 | lm loss PPL: 4.282453E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 05:05:35] iteration   248100/  500000 | consumed samples:      1984800 | elapsed time per iteration (ms): 321.8 | learning rate: 2.718992E-05 | global batch size:     8 | lm loss: 3.108966E+00 | loss scale: 524288.0 | grad norm: 0.938 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 05:06:07] iteration   248200/  500000 | consumed samples:      1985600 | elapsed time per iteration (ms): 319.6 | learning rate: 2.714438E-05 | global batch size:     8 | lm loss: 3.060169E+00 | loss scale: 524288.0 | grad norm: 0.864 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 05:06:40] iteration   248300/  500000 | consumed samples:      1986400 | elapsed time per iteration (ms): 320.8 | learning rate: 2.709889E-05 | global batch size:     8 | lm loss: 3.097225E+00 | loss scale: 524288.0 | grad norm: 0.844 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 05:07:12] iteration   248400/  500000 | consumed samples:      1987200 | elapsed time per iteration (ms): 320.8 | learning rate: 2.705346E-05 | global batch size:     8 | lm loss: 3.050831E+00 | loss scale: 524288.0 | grad norm: 0.867 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 05:07:44] iteration   248500/  500000 | consumed samples:      1988000 | elapsed time per iteration (ms): 322.7 | learning rate: 2.700899E-05 | global batch size:     8 | lm loss: 3.024535E+00 | loss scale: 524288.0 | grad norm: 0.917 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-22 05:08:16] iteration   248600/  500000 | consumed samples:      1988800 | elapsed time per iteration (ms): 321.7 | learning rate: 2.696365E-05 | global batch size:     8 | lm loss: 3.020175E+00 | loss scale: 524288.0 | grad norm: 0.890 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 05:08:48] iteration   248700/  500000 | consumed samples:      1989600 | elapsed time per iteration (ms): 324.3 | learning rate: 2.691838E-05 | global batch size:     8 | lm loss: 3.080961E+00 | loss scale: 524288.0 | grad norm: 0.850 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 05:09:21] iteration   248800/  500000 | consumed samples:      1990400 | elapsed time per iteration (ms): 320.6 | learning rate: 2.687315E-05 | global batch size:     8 | lm loss: 3.054596E+00 | loss scale: 524288.0 | grad norm: 0.869 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 05:09:53] iteration   248900/  500000 | consumed samples:      1991200 | elapsed time per iteration (ms): 322.6 | learning rate: 2.682798E-05 | global batch size:     8 | lm loss: 3.073302E+00 | loss scale: 524288.0 | grad norm: 0.872 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 05:10:25] iteration   249000/  500000 | consumed samples:      1992000 | elapsed time per iteration (ms): 321.0 | learning rate: 2.678331E-05 | global batch size:     8 | lm loss: 3.027678E+00 | loss scale: 262144.0 | grad norm: 0.835 | number of skipped iterations:   1 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1063.03, 1063.03)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 249000 | lm loss value: 3.718282E+00 | lm loss PPL: 4.119356E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 05:10:58] iteration   249100/  500000 | consumed samples:      1992800 | elapsed time per iteration (ms): 321.8 | learning rate: 2.673824E-05 | global batch size:     8 | lm loss: 2.975595E+00 | loss scale: 262144.0 | grad norm: 0.843 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 05:11:30] iteration   249200/  500000 | consumed samples:      1993600 | elapsed time per iteration (ms): 323.3 | learning rate: 2.669322E-05 | global batch size:     8 | lm loss: 3.077878E+00 | loss scale: 262144.0 | grad norm: 0.865 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 05:12:03] iteration   249300/  500000 | consumed samples:      1994400 | elapsed time per iteration (ms): 322.1 | learning rate: 2.664825E-05 | global batch size:     8 | lm loss: 3.089067E+00 | loss scale: 262144.0 | grad norm: 0.877 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 05:12:35] iteration   249400/  500000 | consumed samples:      1995200 | elapsed time per iteration (ms): 324.3 | learning rate: 2.660334E-05 | global batch size:     8 | lm loss: 2.987716E+00 | loss scale: 262144.0 | grad norm: 0.856 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 05:13:07] iteration   249500/  500000 | consumed samples:      1996000 | elapsed time per iteration (ms): 323.7 | learning rate: 2.655848E-05 | global batch size:     8 | lm loss: 3.043815E+00 | loss scale: 262144.0 | grad norm: 0.858 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 05:13:40] iteration   249600/  500000 | consumed samples:      1996800 | elapsed time per iteration (ms): 322.9 | learning rate: 2.651367E-05 | global batch size:     8 | lm loss: 3.018018E+00 | loss scale: 262144.0 | grad norm: 0.884 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 05:14:12] iteration   249700/  500000 | consumed samples:      1997600 | elapsed time per iteration (ms): 323.2 | learning rate: 2.646892E-05 | global batch size:     8 | lm loss: 3.024453E+00 | loss scale: 262144.0 | grad norm: 0.845 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 05:14:44] iteration   249800/  500000 | consumed samples:      1998400 | elapsed time per iteration (ms): 320.8 | learning rate: 2.642422E-05 | global batch size:     8 | lm loss: 3.049583E+00 | loss scale: 262144.0 | grad norm: 0.853 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 05:15:16] iteration   249900/  500000 | consumed samples:      1999200 | elapsed time per iteration (ms): 321.2 | learning rate: 2.637957E-05 | global batch size:     8 | lm loss: 3.078593E+00 | loss scale: 262144.0 | grad norm: 0.880 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 05:15:48] iteration   250000/  500000 | consumed samples:      2000000 | elapsed time per iteration (ms): 320.5 | learning rate: 2.633497E-05 | global batch size:     8 | lm loss: 3.024896E+00 | loss scale: 524288.0 | grad norm: 0.833 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1065.45, 1065.45)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 250000 | lm loss value: 3.759274E+00 | lm loss PPL: 4.291724E+01 | 
--------------------------------------------------------------------------------------------------
saving checkpoint at iteration  250000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-max in torch format
  successfully saved checkpoint at iteration  250000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-max
(min, max) time across ranks (ms):
    save-checkpoint ................................: (5707.60, 5707.60)
 [2024-06-22 05:16:27] iteration   250100/  500000 | consumed samples:      2000800 | elapsed time per iteration (ms): 322.0 | learning rate: 2.629043E-05 | global batch size:     8 | lm loss: 3.032646E+00 | loss scale: 524288.0 | grad norm: 0.830 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 05:17:00] iteration   250200/  500000 | consumed samples:      2001600 | elapsed time per iteration (ms): 322.6 | learning rate: 2.624593E-05 | global batch size:     8 | lm loss: 3.044840E+00 | loss scale: 524288.0 | grad norm: 0.825 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 05:17:32] iteration   250300/  500000 | consumed samples:      2002400 | elapsed time per iteration (ms): 320.7 | learning rate: 2.620150E-05 | global batch size:     8 | lm loss: 3.084091E+00 | loss scale: 524288.0 | grad norm: 0.877 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 05:18:04] iteration   250400/  500000 | consumed samples:      2003200 | elapsed time per iteration (ms): 321.2 | learning rate: 2.615711E-05 | global batch size:     8 | lm loss: 3.078311E+00 | loss scale: 524288.0 | grad norm: 0.910 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 05:18:36] iteration   250500/  500000 | consumed samples:      2004000 | elapsed time per iteration (ms): 321.6 | learning rate: 2.611278E-05 | global batch size:     8 | lm loss: 3.042734E+00 | loss scale: 524288.0 | grad norm: 0.844 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 05:19:08] iteration   250600/  500000 | consumed samples:      2004800 | elapsed time per iteration (ms): 323.0 | learning rate: 2.606894E-05 | global batch size:     8 | lm loss: 3.029324E+00 | loss scale: 524288.0 | grad norm: 0.878 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-22 05:19:41] iteration   250700/  500000 | consumed samples:      2005600 | elapsed time per iteration (ms): 323.7 | learning rate: 2.602516E-05 | global batch size:     8 | lm loss: 3.021103E+00 | loss scale: 262144.0 | grad norm: 0.925 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-22 05:20:13] iteration   250800/  500000 | consumed samples:      2006400 | elapsed time per iteration (ms): 324.3 | learning rate: 2.598098E-05 | global batch size:     8 | lm loss: 2.994500E+00 | loss scale: 262144.0 | grad norm: 0.861 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 05:20:45] iteration   250900/  500000 | consumed samples:      2007200 | elapsed time per iteration (ms): 324.4 | learning rate: 2.593686E-05 | global batch size:     8 | lm loss: 3.030504E+00 | loss scale: 262144.0 | grad norm: 0.861 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 05:21:18] iteration   251000/  500000 | consumed samples:      2008000 | elapsed time per iteration (ms): 321.8 | learning rate: 2.589279E-05 | global batch size:     8 | lm loss: 3.048762E+00 | loss scale: 262144.0 | grad norm: 0.866 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1066.26, 1066.26)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 251000 | lm loss value: 3.612277E+00 | lm loss PPL: 3.705030E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 05:21:51] iteration   251100/  500000 | consumed samples:      2008800 | elapsed time per iteration (ms): 324.2 | learning rate: 2.584878E-05 | global batch size:     8 | lm loss: 2.989360E+00 | loss scale: 262144.0 | grad norm: 0.956 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 05:22:23] iteration   251200/  500000 | consumed samples:      2009600 | elapsed time per iteration (ms): 321.5 | learning rate: 2.580481E-05 | global batch size:     8 | lm loss: 3.006099E+00 | loss scale: 262144.0 | grad norm: 0.875 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 05:22:56] iteration   251300/  500000 | consumed samples:      2010400 | elapsed time per iteration (ms): 322.5 | learning rate: 2.576091E-05 | global batch size:     8 | lm loss: 3.023708E+00 | loss scale: 262144.0 | grad norm: 0.871 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 05:23:28] iteration   251400/  500000 | consumed samples:      2011200 | elapsed time per iteration (ms): 320.5 | learning rate: 2.571705E-05 | global batch size:     8 | lm loss: 3.018709E+00 | loss scale: 262144.0 | grad norm: 0.813 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 05:24:00] iteration   251500/  500000 | consumed samples:      2012000 | elapsed time per iteration (ms): 321.7 | learning rate: 2.567325E-05 | global batch size:     8 | lm loss: 3.064654E+00 | loss scale: 262144.0 | grad norm: 0.884 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 05:24:32] iteration   251600/  500000 | consumed samples:      2012800 | elapsed time per iteration (ms): 320.4 | learning rate: 2.562950E-05 | global batch size:     8 | lm loss: 3.025549E+00 | loss scale: 262144.0 | grad norm: 0.896 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 05:25:04] iteration   251700/  500000 | consumed samples:      2013600 | elapsed time per iteration (ms): 322.1 | learning rate: 2.558581E-05 | global batch size:     8 | lm loss: 3.070435E+00 | loss scale: 524288.0 | grad norm: 0.887 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 05:25:36] iteration   251800/  500000 | consumed samples:      2014400 | elapsed time per iteration (ms): 320.9 | learning rate: 2.554216E-05 | global batch size:     8 | lm loss: 3.012774E+00 | loss scale: 524288.0 | grad norm: 0.861 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 05:26:08] iteration   251900/  500000 | consumed samples:      2015200 | elapsed time per iteration (ms): 321.1 | learning rate: 2.549858E-05 | global batch size:     8 | lm loss: 3.076441E+00 | loss scale: 524288.0 | grad norm: 0.843 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 05:26:40] iteration   252000/  500000 | consumed samples:      2016000 | elapsed time per iteration (ms): 321.0 | learning rate: 2.545504E-05 | global batch size:     8 | lm loss: 3.076340E+00 | loss scale: 524288.0 | grad norm: 0.882 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1066.18, 1066.18)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 252000 | lm loss value: 3.663391E+00 | lm loss PPL: 3.899335E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 05:27:13] iteration   252100/  500000 | consumed samples:      2016800 | elapsed time per iteration (ms): 320.0 | learning rate: 2.541156E-05 | global batch size:     8 | lm loss: 3.057049E+00 | loss scale: 524288.0 | grad norm: 0.873 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 05:27:45] iteration   252200/  500000 | consumed samples:      2017600 | elapsed time per iteration (ms): 319.2 | learning rate: 2.536814E-05 | global batch size:     8 | lm loss: 3.041369E+00 | loss scale: 524288.0 | grad norm: 0.860 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 05:28:17] iteration   252300/  500000 | consumed samples:      2018400 | elapsed time per iteration (ms): 318.9 | learning rate: 2.532476E-05 | global batch size:     8 | lm loss: 3.014666E+00 | loss scale: 524288.0 | grad norm: 0.932 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 05:28:49] iteration   252400/  500000 | consumed samples:      2019200 | elapsed time per iteration (ms): 323.1 | learning rate: 2.528144E-05 | global batch size:     8 | lm loss: 3.060783E+00 | loss scale: 524288.0 | grad norm: 0.888 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 05:29:22] iteration   252500/  500000 | consumed samples:      2020000 | elapsed time per iteration (ms): 320.6 | learning rate: 2.523818E-05 | global batch size:     8 | lm loss: 3.076575E+00 | loss scale: 524288.0 | grad norm: 0.848 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 05:29:54] iteration   252600/  500000 | consumed samples:      2020800 | elapsed time per iteration (ms): 321.3 | learning rate: 2.519497E-05 | global batch size:     8 | lm loss: 3.024525E+00 | loss scale: 524288.0 | grad norm: 0.863 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 05:30:26] iteration   252700/  500000 | consumed samples:      2021600 | elapsed time per iteration (ms): 321.3 | learning rate: 2.515224E-05 | global batch size:     8 | lm loss: 3.029794E+00 | loss scale: 524288.0 | grad norm: 0.829 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-22 05:30:58] iteration   252800/  500000 | consumed samples:      2022400 | elapsed time per iteration (ms): 322.1 | learning rate: 2.510913E-05 | global batch size:     8 | lm loss: 3.068138E+00 | loss scale: 524288.0 | grad norm: 0.879 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 05:31:30] iteration   252900/  500000 | consumed samples:      2023200 | elapsed time per iteration (ms): 320.6 | learning rate: 2.506651E-05 | global batch size:     8 | lm loss: 3.050332E+00 | loss scale: 262144.0 | grad norm: 0.848 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-22 05:32:02] iteration   253000/  500000 | consumed samples:      2024000 | elapsed time per iteration (ms): 322.4 | learning rate: 2.502352E-05 | global batch size:     8 | lm loss: 3.010189E+00 | loss scale: 262144.0 | grad norm: 0.893 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1063.80, 1063.80)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 253000 | lm loss value: 3.589206E+00 | lm loss PPL: 3.620533E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 05:32:36] iteration   253100/  500000 | consumed samples:      2024800 | elapsed time per iteration (ms): 321.4 | learning rate: 2.498057E-05 | global batch size:     8 | lm loss: 3.028130E+00 | loss scale: 262144.0 | grad norm: 0.876 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 05:33:08] iteration   253200/  500000 | consumed samples:      2025600 | elapsed time per iteration (ms): 323.8 | learning rate: 2.493769E-05 | global batch size:     8 | lm loss: 3.002367E+00 | loss scale: 262144.0 | grad norm: 0.867 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 05:33:40] iteration   253300/  500000 | consumed samples:      2026400 | elapsed time per iteration (ms): 322.4 | learning rate: 2.489485E-05 | global batch size:     8 | lm loss: 3.030957E+00 | loss scale: 262144.0 | grad norm: 0.889 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 05:34:12] iteration   253400/  500000 | consumed samples:      2027200 | elapsed time per iteration (ms): 320.4 | learning rate: 2.485207E-05 | global batch size:     8 | lm loss: 2.990709E+00 | loss scale: 262144.0 | grad norm: 0.858 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 05:34:44] iteration   253500/  500000 | consumed samples:      2028000 | elapsed time per iteration (ms): 322.0 | learning rate: 2.480934E-05 | global batch size:     8 | lm loss: 3.115262E+00 | loss scale: 262144.0 | grad norm: 0.884 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 05:35:17] iteration   253600/  500000 | consumed samples:      2028800 | elapsed time per iteration (ms): 322.0 | learning rate: 2.476667E-05 | global batch size:     8 | lm loss: 3.020460E+00 | loss scale: 262144.0 | grad norm: 0.916 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 05:35:49] iteration   253700/  500000 | consumed samples:      2029600 | elapsed time per iteration (ms): 324.6 | learning rate: 2.472406E-05 | global batch size:     8 | lm loss: 2.995825E+00 | loss scale: 262144.0 | grad norm: 0.865 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 05:36:21] iteration   253800/  500000 | consumed samples:      2030400 | elapsed time per iteration (ms): 321.2 | learning rate: 2.468149E-05 | global batch size:     8 | lm loss: 3.052546E+00 | loss scale: 262144.0 | grad norm: 0.879 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 05:36:53] iteration   253900/  500000 | consumed samples:      2031200 | elapsed time per iteration (ms): 323.2 | learning rate: 2.463898E-05 | global batch size:     8 | lm loss: 3.029933E+00 | loss scale: 524288.0 | grad norm: 0.855 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 05:37:26] iteration   254000/  500000 | consumed samples:      2032000 | elapsed time per iteration (ms): 322.9 | learning rate: 2.459695E-05 | global batch size:     8 | lm loss: 3.069504E+00 | loss scale: 524288.0 | grad norm: 0.861 | number of skipped iterations:   1 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1074.87, 1074.87)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 254000 | lm loss value: 3.808082E+00 | lm loss PPL: 4.506392E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 05:37:59] iteration   254100/  500000 | consumed samples:      2032800 | elapsed time per iteration (ms): 320.6 | learning rate: 2.455455E-05 | global batch size:     8 | lm loss: 3.028711E+00 | loss scale: 524288.0 | grad norm: 0.879 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 05:38:31] iteration   254200/  500000 | consumed samples:      2033600 | elapsed time per iteration (ms): 322.4 | learning rate: 2.451221E-05 | global batch size:     8 | lm loss: 2.999417E+00 | loss scale: 524288.0 | grad norm: 0.898 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 05:39:03] iteration   254300/  500000 | consumed samples:      2034400 | elapsed time per iteration (ms): 320.5 | learning rate: 2.447034E-05 | global batch size:     8 | lm loss: 3.048005E+00 | loss scale: 262144.0 | grad norm: 0.869 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-22 05:39:35] iteration   254400/  500000 | consumed samples:      2035200 | elapsed time per iteration (ms): 319.4 | learning rate: 2.442810E-05 | global batch size:     8 | lm loss: 3.009955E+00 | loss scale: 262144.0 | grad norm: 0.888 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 05:40:07] iteration   254500/  500000 | consumed samples:      2036000 | elapsed time per iteration (ms): 319.7 | learning rate: 2.438592E-05 | global batch size:     8 | lm loss: 3.022866E+00 | loss scale: 262144.0 | grad norm: 0.874 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 05:40:39] iteration   254600/  500000 | consumed samples:      2036800 | elapsed time per iteration (ms): 318.6 | learning rate: 2.434379E-05 | global batch size:     8 | lm loss: 3.034373E+00 | loss scale: 262144.0 | grad norm: 0.880 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 05:41:11] iteration   254700/  500000 | consumed samples:      2037600 | elapsed time per iteration (ms): 321.0 | learning rate: 2.430172E-05 | global batch size:     8 | lm loss: 3.015079E+00 | loss scale: 262144.0 | grad norm: 0.885 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 05:41:43] iteration   254800/  500000 | consumed samples:      2038400 | elapsed time per iteration (ms): 324.0 | learning rate: 2.425970E-05 | global batch size:     8 | lm loss: 3.029985E+00 | loss scale: 262144.0 | grad norm: 0.894 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 05:42:16] iteration   254900/  500000 | consumed samples:      2039200 | elapsed time per iteration (ms): 321.9 | learning rate: 2.421773E-05 | global batch size:     8 | lm loss: 3.028771E+00 | loss scale: 262144.0 | grad norm: 0.870 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 05:42:48] iteration   255000/  500000 | consumed samples:      2040000 | elapsed time per iteration (ms): 321.2 | learning rate: 2.417583E-05 | global batch size:     8 | lm loss: 2.974859E+00 | loss scale: 262144.0 | grad norm: 0.880 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1065.19, 1065.19)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 255000 | lm loss value: 3.672911E+00 | lm loss PPL: 3.936635E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 05:43:21] iteration   255100/  500000 | consumed samples:      2040800 | elapsed time per iteration (ms): 320.6 | learning rate: 2.413397E-05 | global batch size:     8 | lm loss: 3.034325E+00 | loss scale: 262144.0 | grad norm: 1.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 05:43:53] iteration   255200/  500000 | consumed samples:      2041600 | elapsed time per iteration (ms): 321.7 | learning rate: 2.409217E-05 | global batch size:     8 | lm loss: 3.007185E+00 | loss scale: 262144.0 | grad norm: 0.866 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 05:44:25] iteration   255300/  500000 | consumed samples:      2042400 | elapsed time per iteration (ms): 321.0 | learning rate: 2.405043E-05 | global batch size:     8 | lm loss: 3.053014E+00 | loss scale: 524288.0 | grad norm: 0.848 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 05:44:57] iteration   255400/  500000 | consumed samples:      2043200 | elapsed time per iteration (ms): 323.1 | learning rate: 2.400874E-05 | global batch size:     8 | lm loss: 3.043205E+00 | loss scale: 524288.0 | grad norm: 1.035 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 05:45:30] iteration   255500/  500000 | consumed samples:      2044000 | elapsed time per iteration (ms): 322.9 | learning rate: 2.396711E-05 | global batch size:     8 | lm loss: 3.010696E+00 | loss scale: 524288.0 | grad norm: 0.875 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 05:46:02] iteration   255600/  500000 | consumed samples:      2044800 | elapsed time per iteration (ms): 322.5 | learning rate: 2.392553E-05 | global batch size:     8 | lm loss: 3.029092E+00 | loss scale: 524288.0 | grad norm: 0.911 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 05:46:34] iteration   255700/  500000 | consumed samples:      2045600 | elapsed time per iteration (ms): 321.7 | learning rate: 2.388400E-05 | global batch size:     8 | lm loss: 3.059737E+00 | loss scale: 524288.0 | grad norm: 0.886 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 05:47:06] iteration   255800/  500000 | consumed samples:      2046400 | elapsed time per iteration (ms): 319.0 | learning rate: 2.384253E-05 | global batch size:     8 | lm loss: 3.003303E+00 | loss scale: 524288.0 | grad norm: 0.837 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 05:47:38] iteration   255900/  500000 | consumed samples:      2047200 | elapsed time per iteration (ms): 321.2 | learning rate: 2.380112E-05 | global batch size:     8 | lm loss: 3.076425E+00 | loss scale: 524288.0 | grad norm: 0.892 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 05:48:10] iteration   256000/  500000 | consumed samples:      2048000 | elapsed time per iteration (ms): 320.1 | learning rate: 2.375976E-05 | global batch size:     8 | lm loss: 3.015885E+00 | loss scale: 524288.0 | grad norm: 0.872 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1063.20, 1063.20)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 256000 | lm loss value: 3.754589E+00 | lm loss PPL: 4.271665E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 05:48:44] iteration   256100/  500000 | consumed samples:      2048800 | elapsed time per iteration (ms): 322.7 | learning rate: 2.371846E-05 | global batch size:     8 | lm loss: 3.034899E+00 | loss scale: 524288.0 | grad norm: 0.879 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 05:49:16] iteration   256200/  500000 | consumed samples:      2049600 | elapsed time per iteration (ms): 322.5 | learning rate: 2.367721E-05 | global batch size:     8 | lm loss: 3.039012E+00 | loss scale: 524288.0 | grad norm: 0.829 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 05:49:48] iteration   256300/  500000 | consumed samples:      2050400 | elapsed time per iteration (ms): 323.1 | learning rate: 2.363684E-05 | global batch size:     8 | lm loss: 3.077245E+00 | loss scale: 524288.0 | grad norm: 0.872 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-22 05:50:20] iteration   256400/  500000 | consumed samples:      2051200 | elapsed time per iteration (ms): 321.2 | learning rate: 2.359571E-05 | global batch size:     8 | lm loss: 3.043383E+00 | loss scale: 524288.0 | grad norm: 0.881 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 05:50:52] iteration   256500/  500000 | consumed samples:      2052000 | elapsed time per iteration (ms): 320.6 | learning rate: 2.355462E-05 | global batch size:     8 | lm loss: 2.995356E+00 | loss scale: 524288.0 | grad norm: 0.864 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 05:51:24] iteration   256600/  500000 | consumed samples:      2052800 | elapsed time per iteration (ms): 321.6 | learning rate: 2.351360E-05 | global batch size:     8 | lm loss: 3.027441E+00 | loss scale: 524288.0 | grad norm: 0.813 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 05:51:57] iteration   256700/  500000 | consumed samples:      2053600 | elapsed time per iteration (ms): 322.9 | learning rate: 2.347263E-05 | global batch size:     8 | lm loss: 3.013077E+00 | loss scale: 524288.0 | grad norm: 0.849 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 05:52:29] iteration   256800/  500000 | consumed samples:      2054400 | elapsed time per iteration (ms): 320.6 | learning rate: 2.343171E-05 | global batch size:     8 | lm loss: 3.051468E+00 | loss scale: 524288.0 | grad norm: 0.869 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 05:53:01] iteration   256900/  500000 | consumed samples:      2055200 | elapsed time per iteration (ms): 322.3 | learning rate: 2.339085E-05 | global batch size:     8 | lm loss: 3.028539E+00 | loss scale: 524288.0 | grad norm: 0.873 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 05:53:33] iteration   257000/  500000 | consumed samples:      2056000 | elapsed time per iteration (ms): 322.6 | learning rate: 2.335005E-05 | global batch size:     8 | lm loss: 3.029663E+00 | loss scale: 524288.0 | grad norm: 0.911 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1069.89, 1069.89)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 257000 | lm loss value: 3.639394E+00 | lm loss PPL: 3.806874E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 05:54:07] iteration   257100/  500000 | consumed samples:      2056800 | elapsed time per iteration (ms): 322.0 | learning rate: 2.330930E-05 | global batch size:     8 | lm loss: 2.985730E+00 | loss scale: 524288.0 | grad norm: 0.910 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 05:54:39] iteration   257200/  500000 | consumed samples:      2057600 | elapsed time per iteration (ms): 323.3 | learning rate: 2.326861E-05 | global batch size:     8 | lm loss: 3.002926E+00 | loss scale: 524288.0 | grad norm: 0.875 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 05:55:11] iteration   257300/  500000 | consumed samples:      2058400 | elapsed time per iteration (ms): 321.4 | learning rate: 2.322878E-05 | global batch size:     8 | lm loss: 3.002913E+00 | loss scale: 524288.0 | grad norm: 0.888 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-22 05:55:43] iteration   257400/  500000 | consumed samples:      2059200 | elapsed time per iteration (ms): 324.5 | learning rate: 2.318820E-05 | global batch size:     8 | lm loss: 3.029307E+00 | loss scale: 524288.0 | grad norm: 0.890 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 05:56:16] iteration   257500/  500000 | consumed samples:      2060000 | elapsed time per iteration (ms): 322.4 | learning rate: 2.314767E-05 | global batch size:     8 | lm loss: 3.047647E+00 | loss scale: 524288.0 | grad norm: 0.884 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 05:56:48] iteration   257600/  500000 | consumed samples:      2060800 | elapsed time per iteration (ms): 319.0 | learning rate: 2.310720E-05 | global batch size:     8 | lm loss: 3.021898E+00 | loss scale: 524288.0 | grad norm: 0.879 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 05:57:20] iteration   257700/  500000 | consumed samples:      2061600 | elapsed time per iteration (ms): 321.8 | learning rate: 2.306679E-05 | global batch size:     8 | lm loss: 3.007967E+00 | loss scale: 524288.0 | grad norm: 0.874 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 05:57:52] iteration   257800/  500000 | consumed samples:      2062400 | elapsed time per iteration (ms): 321.4 | learning rate: 2.302643E-05 | global batch size:     8 | lm loss: 2.998545E+00 | loss scale: 524288.0 | grad norm: 0.903 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 05:58:24] iteration   257900/  500000 | consumed samples:      2063200 | elapsed time per iteration (ms): 324.5 | learning rate: 2.298613E-05 | global batch size:     8 | lm loss: 3.061959E+00 | loss scale: 524288.0 | grad norm: 0.853 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 05:58:57] iteration   258000/  500000 | consumed samples:      2064000 | elapsed time per iteration (ms): 323.8 | learning rate: 2.294588E-05 | global batch size:     8 | lm loss: 2.989101E+00 | loss scale: 524288.0 | grad norm: 0.862 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1064.85, 1064.85)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 258000 | lm loss value: 3.581378E+00 | lm loss PPL: 3.592299E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 05:59:30] iteration   258100/  500000 | consumed samples:      2064800 | elapsed time per iteration (ms): 320.1 | learning rate: 2.290569E-05 | global batch size:     8 | lm loss: 3.032356E+00 | loss scale: 524288.0 | grad norm: 0.867 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 06:00:02] iteration   258200/  500000 | consumed samples:      2065600 | elapsed time per iteration (ms): 320.6 | learning rate: 2.286556E-05 | global batch size:     8 | lm loss: 3.023600E+00 | loss scale: 524288.0 | grad norm: 0.855 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 06:00:34] iteration   258300/  500000 | consumed samples:      2066400 | elapsed time per iteration (ms): 324.2 | learning rate: 2.282548E-05 | global batch size:     8 | lm loss: 3.034371E+00 | loss scale: 1048576.0 | grad norm: 0.899 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 06:01:06] iteration   258400/  500000 | consumed samples:      2067200 | elapsed time per iteration (ms): 320.7 | learning rate: 2.278626E-05 | global batch size:     8 | lm loss: 3.038516E+00 | loss scale: 524288.0 | grad norm: 0.833 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-22 06:01:39] iteration   258500/  500000 | consumed samples:      2068000 | elapsed time per iteration (ms): 322.3 | learning rate: 2.274629E-05 | global batch size:     8 | lm loss: 3.034022E+00 | loss scale: 524288.0 | grad norm: 0.873 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 06:02:11] iteration   258600/  500000 | consumed samples:      2068800 | elapsed time per iteration (ms): 320.4 | learning rate: 2.270638E-05 | global batch size:     8 | lm loss: 3.026239E+00 | loss scale: 524288.0 | grad norm: 0.876 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 06:02:43] iteration   258700/  500000 | consumed samples:      2069600 | elapsed time per iteration (ms): 323.6 | learning rate: 2.266652E-05 | global batch size:     8 | lm loss: 3.018364E+00 | loss scale: 524288.0 | grad norm: 0.886 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 06:03:15] iteration   258800/  500000 | consumed samples:      2070400 | elapsed time per iteration (ms): 320.9 | learning rate: 2.262673E-05 | global batch size:     8 | lm loss: 3.033802E+00 | loss scale: 524288.0 | grad norm: 0.862 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 06:03:47] iteration   258900/  500000 | consumed samples:      2071200 | elapsed time per iteration (ms): 320.6 | learning rate: 2.258738E-05 | global batch size:     8 | lm loss: 3.008410E+00 | loss scale: 262144.0 | grad norm: 0.875 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-22 06:04:19] iteration   259000/  500000 | consumed samples:      2072000 | elapsed time per iteration (ms): 322.2 | learning rate: 2.254770E-05 | global batch size:     8 | lm loss: 3.039138E+00 | loss scale: 262144.0 | grad norm: 0.866 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1065.72, 1065.72)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 259000 | lm loss value: 3.697774E+00 | lm loss PPL: 4.035738E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 06:04:53] iteration   259100/  500000 | consumed samples:      2072800 | elapsed time per iteration (ms): 324.3 | learning rate: 2.250807E-05 | global batch size:     8 | lm loss: 3.031918E+00 | loss scale: 262144.0 | grad norm: 0.890 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 06:05:25] iteration   259200/  500000 | consumed samples:      2073600 | elapsed time per iteration (ms): 321.3 | learning rate: 2.246850E-05 | global batch size:     8 | lm loss: 3.050130E+00 | loss scale: 262144.0 | grad norm: 0.916 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 06:05:57] iteration   259300/  500000 | consumed samples:      2074400 | elapsed time per iteration (ms): 324.0 | learning rate: 2.242898E-05 | global batch size:     8 | lm loss: 3.000411E+00 | loss scale: 262144.0 | grad norm: 0.872 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 06:06:30] iteration   259400/  500000 | consumed samples:      2075200 | elapsed time per iteration (ms): 321.9 | learning rate: 2.238952E-05 | global batch size:     8 | lm loss: 3.028260E+00 | loss scale: 262144.0 | grad norm: 0.846 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 06:07:02] iteration   259500/  500000 | consumed samples:      2076000 | elapsed time per iteration (ms): 322.5 | learning rate: 2.235012E-05 | global batch size:     8 | lm loss: 2.992710E+00 | loss scale: 262144.0 | grad norm: 0.874 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 06:07:34] iteration   259600/  500000 | consumed samples:      2076800 | elapsed time per iteration (ms): 321.6 | learning rate: 2.231077E-05 | global batch size:     8 | lm loss: 2.984731E+00 | loss scale: 262144.0 | grad norm: 0.854 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 06:08:06] iteration   259700/  500000 | consumed samples:      2077600 | elapsed time per iteration (ms): 319.7 | learning rate: 2.227148E-05 | global batch size:     8 | lm loss: 3.009063E+00 | loss scale: 262144.0 | grad norm: 1.023 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 06:08:38] iteration   259800/  500000 | consumed samples:      2078400 | elapsed time per iteration (ms): 323.7 | learning rate: 2.223225E-05 | global batch size:     8 | lm loss: 3.038629E+00 | loss scale: 262144.0 | grad norm: 0.867 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 06:09:11] iteration   259900/  500000 | consumed samples:      2079200 | elapsed time per iteration (ms): 323.0 | learning rate: 2.219308E-05 | global batch size:     8 | lm loss: 3.011902E+00 | loss scale: 524288.0 | grad norm: 0.903 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 06:09:43] iteration   260000/  500000 | consumed samples:      2080000 | elapsed time per iteration (ms): 325.1 | learning rate: 2.215396E-05 | global batch size:     8 | lm loss: 3.020450E+00 | loss scale: 524288.0 | grad norm: 0.873 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1068.06, 1068.06)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 260000 | lm loss value: 3.657568E+00 | lm loss PPL: 3.876696E+01 | 
--------------------------------------------------------------------------------------------------
saving checkpoint at iteration  260000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-max in torch format
  successfully saved checkpoint at iteration  260000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-max
(min, max) time across ranks (ms):
    save-checkpoint ................................: (5627.00, 5627.00)
 [2024-06-22 06:10:22] iteration   260100/  500000 | consumed samples:      2080800 | elapsed time per iteration (ms): 319.8 | learning rate: 2.211490E-05 | global batch size:     8 | lm loss: 3.048745E+00 | loss scale: 524288.0 | grad norm: 0.884 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 06:10:54] iteration   260200/  500000 | consumed samples:      2081600 | elapsed time per iteration (ms): 321.4 | learning rate: 2.207589E-05 | global batch size:     8 | lm loss: 2.999709E+00 | loss scale: 524288.0 | grad norm: 0.907 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 06:11:26] iteration   260300/  500000 | consumed samples:      2082400 | elapsed time per iteration (ms): 322.7 | learning rate: 2.203694E-05 | global batch size:     8 | lm loss: 3.001300E+00 | loss scale: 524288.0 | grad norm: 0.900 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 06:11:58] iteration   260400/  500000 | consumed samples:      2083200 | elapsed time per iteration (ms): 322.1 | learning rate: 2.199805E-05 | global batch size:     8 | lm loss: 3.029052E+00 | loss scale: 524288.0 | grad norm: 0.878 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 06:12:30] iteration   260500/  500000 | consumed samples:      2084000 | elapsed time per iteration (ms): 319.1 | learning rate: 2.195922E-05 | global batch size:     8 | lm loss: 3.043809E+00 | loss scale: 524288.0 | grad norm: 0.877 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 06:13:03] iteration   260600/  500000 | consumed samples:      2084800 | elapsed time per iteration (ms): 321.3 | learning rate: 2.192044E-05 | global batch size:     8 | lm loss: 3.033464E+00 | loss scale: 524288.0 | grad norm: 0.883 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 06:13:35] iteration   260700/  500000 | consumed samples:      2085600 | elapsed time per iteration (ms): 322.2 | learning rate: 2.188172E-05 | global batch size:     8 | lm loss: 3.027483E+00 | loss scale: 524288.0 | grad norm: 0.856 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 06:14:07] iteration   260800/  500000 | consumed samples:      2086400 | elapsed time per iteration (ms): 321.7 | learning rate: 2.184345E-05 | global batch size:     8 | lm loss: 3.016921E+00 | loss scale: 524288.0 | grad norm: 0.861 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-22 06:14:39] iteration   260900/  500000 | consumed samples:      2087200 | elapsed time per iteration (ms): 323.6 | learning rate: 2.180484E-05 | global batch size:     8 | lm loss: 3.012852E+00 | loss scale: 524288.0 | grad norm: 0.888 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 06:15:11] iteration   261000/  500000 | consumed samples:      2088000 | elapsed time per iteration (ms): 321.6 | learning rate: 2.176629E-05 | global batch size:     8 | lm loss: 3.043593E+00 | loss scale: 524288.0 | grad norm: 0.913 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1064.73, 1064.73)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 261000 | lm loss value: 3.638386E+00 | lm loss PPL: 3.803042E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 06:15:45] iteration   261100/  500000 | consumed samples:      2088800 | elapsed time per iteration (ms): 322.1 | learning rate: 2.172780E-05 | global batch size:     8 | lm loss: 3.019247E+00 | loss scale: 524288.0 | grad norm: 0.881 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 06:16:17] iteration   261200/  500000 | consumed samples:      2089600 | elapsed time per iteration (ms): 324.3 | learning rate: 2.168937E-05 | global batch size:     8 | lm loss: 3.009668E+00 | loss scale: 524288.0 | grad norm: 0.893 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 06:16:49] iteration   261300/  500000 | consumed samples:      2090400 | elapsed time per iteration (ms): 322.6 | learning rate: 2.165099E-05 | global batch size:     8 | lm loss: 3.026829E+00 | loss scale: 524288.0 | grad norm: 0.886 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 06:17:21] iteration   261400/  500000 | consumed samples:      2091200 | elapsed time per iteration (ms): 320.8 | learning rate: 2.161267E-05 | global batch size:     8 | lm loss: 2.990811E+00 | loss scale: 524288.0 | grad norm: 0.873 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 06:17:54] iteration   261500/  500000 | consumed samples:      2092000 | elapsed time per iteration (ms): 320.6 | learning rate: 2.157441E-05 | global batch size:     8 | lm loss: 3.030448E+00 | loss scale: 524288.0 | grad norm: 0.867 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 06:18:26] iteration   261600/  500000 | consumed samples:      2092800 | elapsed time per iteration (ms): 323.3 | learning rate: 2.153621E-05 | global batch size:     8 | lm loss: 2.996371E+00 | loss scale: 524288.0 | grad norm: 0.916 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 06:18:58] iteration   261700/  500000 | consumed samples:      2093600 | elapsed time per iteration (ms): 322.8 | learning rate: 2.149806E-05 | global batch size:     8 | lm loss: 3.060678E+00 | loss scale: 524288.0 | grad norm: 0.854 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 06:19:30] iteration   261800/  500000 | consumed samples:      2094400 | elapsed time per iteration (ms): 320.4 | learning rate: 2.146073E-05 | global batch size:     8 | lm loss: 3.008277E+00 | loss scale: 524288.0 | grad norm: 0.888 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-22 06:20:02] iteration   261900/  500000 | consumed samples:      2095200 | elapsed time per iteration (ms): 319.1 | learning rate: 2.142270E-05 | global batch size:     8 | lm loss: 3.003800E+00 | loss scale: 524288.0 | grad norm: 0.936 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 06:20:34] iteration   262000/  500000 | consumed samples:      2096000 | elapsed time per iteration (ms): 321.1 | learning rate: 2.138472E-05 | global batch size:     8 | lm loss: 3.014904E+00 | loss scale: 524288.0 | grad norm: 0.865 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1064.67, 1064.67)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 262000 | lm loss value: 3.722588E+00 | lm loss PPL: 4.137133E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 06:21:08] iteration   262100/  500000 | consumed samples:      2096800 | elapsed time per iteration (ms): 322.5 | learning rate: 2.134680E-05 | global batch size:     8 | lm loss: 3.031962E+00 | loss scale: 524288.0 | grad norm: 0.893 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 06:21:40] iteration   262200/  500000 | consumed samples:      2097600 | elapsed time per iteration (ms): 322.0 | learning rate: 2.130894E-05 | global batch size:     8 | lm loss: 3.005943E+00 | loss scale: 524288.0 | grad norm: 0.964 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 06:22:12] iteration   262300/  500000 | consumed samples:      2098400 | elapsed time per iteration (ms): 322.1 | learning rate: 2.127114E-05 | global batch size:     8 | lm loss: 2.997647E+00 | loss scale: 524288.0 | grad norm: 0.855 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 06:22:44] iteration   262400/  500000 | consumed samples:      2099200 | elapsed time per iteration (ms): 323.2 | learning rate: 2.123340E-05 | global batch size:     8 | lm loss: 2.959198E+00 | loss scale: 524288.0 | grad norm: 0.901 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 06:23:16] iteration   262500/  500000 | consumed samples:      2100000 | elapsed time per iteration (ms): 321.3 | learning rate: 2.119571E-05 | global batch size:     8 | lm loss: 3.036008E+00 | loss scale: 524288.0 | grad norm: 0.866 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 06:23:49] iteration   262600/  500000 | consumed samples:      2100800 | elapsed time per iteration (ms): 323.6 | learning rate: 2.115808E-05 | global batch size:     8 | lm loss: 3.007868E+00 | loss scale: 524288.0 | grad norm: 0.895 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 06:24:21] iteration   262700/  500000 | consumed samples:      2101600 | elapsed time per iteration (ms): 322.1 | learning rate: 2.112051E-05 | global batch size:     8 | lm loss: 3.038653E+00 | loss scale: 524288.0 | grad norm: 0.884 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 06:24:53] iteration   262800/  500000 | consumed samples:      2102400 | elapsed time per iteration (ms): 322.6 | learning rate: 2.108337E-05 | global batch size:     8 | lm loss: 3.016687E+00 | loss scale: 262144.0 | grad norm: 0.870 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-22 06:25:26] iteration   262900/  500000 | consumed samples:      2103200 | elapsed time per iteration (ms): 323.3 | learning rate: 2.104592E-05 | global batch size:     8 | lm loss: 3.011342E+00 | loss scale: 262144.0 | grad norm: 0.860 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 06:25:58] iteration   263000/  500000 | consumed samples:      2104000 | elapsed time per iteration (ms): 323.5 | learning rate: 2.100852E-05 | global batch size:     8 | lm loss: 3.087618E+00 | loss scale: 262144.0 | grad norm: 0.906 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1066.31, 1066.31)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 263000 | lm loss value: 3.596053E+00 | lm loss PPL: 3.645408E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 06:26:31] iteration   263100/  500000 | consumed samples:      2104800 | elapsed time per iteration (ms): 324.3 | learning rate: 2.097118E-05 | global batch size:     8 | lm loss: 2.977106E+00 | loss scale: 262144.0 | grad norm: 0.887 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 06:27:04] iteration   263200/  500000 | consumed samples:      2105600 | elapsed time per iteration (ms): 322.0 | learning rate: 2.093390E-05 | global batch size:     8 | lm loss: 3.008619E+00 | loss scale: 262144.0 | grad norm: 0.843 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 06:27:36] iteration   263300/  500000 | consumed samples:      2106400 | elapsed time per iteration (ms): 322.7 | learning rate: 2.089667E-05 | global batch size:     8 | lm loss: 2.998227E+00 | loss scale: 262144.0 | grad norm: 0.896 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 06:28:08] iteration   263400/  500000 | consumed samples:      2107200 | elapsed time per iteration (ms): 321.6 | learning rate: 2.085951E-05 | global batch size:     8 | lm loss: 3.029115E+00 | loss scale: 262144.0 | grad norm: 0.860 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 06:28:40] iteration   263500/  500000 | consumed samples:      2108000 | elapsed time per iteration (ms): 322.8 | learning rate: 2.082240E-05 | global batch size:     8 | lm loss: 3.080776E+00 | loss scale: 262144.0 | grad norm: 0.847 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 06:29:13] iteration   263600/  500000 | consumed samples:      2108800 | elapsed time per iteration (ms): 322.6 | learning rate: 2.078535E-05 | global batch size:     8 | lm loss: 3.002843E+00 | loss scale: 262144.0 | grad norm: 0.837 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 06:29:45] iteration   263700/  500000 | consumed samples:      2109600 | elapsed time per iteration (ms): 323.2 | learning rate: 2.074836E-05 | global batch size:     8 | lm loss: 3.019901E+00 | loss scale: 262144.0 | grad norm: 0.878 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 06:30:17] iteration   263800/  500000 | consumed samples:      2110400 | elapsed time per iteration (ms): 322.3 | learning rate: 2.071180E-05 | global batch size:     8 | lm loss: 3.013714E+00 | loss scale: 524288.0 | grad norm: 0.869 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-22 06:30:50] iteration   263900/  500000 | consumed samples:      2111200 | elapsed time per iteration (ms): 324.2 | learning rate: 2.067492E-05 | global batch size:     8 | lm loss: 3.007921E+00 | loss scale: 524288.0 | grad norm: 0.894 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 06:31:22] iteration   264000/  500000 | consumed samples:      2112000 | elapsed time per iteration (ms): 322.0 | learning rate: 2.063810E-05 | global batch size:     8 | lm loss: 3.046199E+00 | loss scale: 524288.0 | grad norm: 0.910 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1065.69, 1065.69)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 264000 | lm loss value: 3.746578E+00 | lm loss PPL: 4.237582E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 06:31:55] iteration   264100/  500000 | consumed samples:      2112800 | elapsed time per iteration (ms): 322.5 | learning rate: 2.060135E-05 | global batch size:     8 | lm loss: 3.070583E+00 | loss scale: 524288.0 | grad norm: 0.861 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 06:32:27] iteration   264200/  500000 | consumed samples:      2113600 | elapsed time per iteration (ms): 319.7 | learning rate: 2.056465E-05 | global batch size:     8 | lm loss: 3.016206E+00 | loss scale: 524288.0 | grad norm: 0.849 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 06:32:59] iteration   264300/  500000 | consumed samples:      2114400 | elapsed time per iteration (ms): 320.4 | learning rate: 2.052801E-05 | global batch size:     8 | lm loss: 3.044423E+00 | loss scale: 524288.0 | grad norm: 0.870 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 06:33:31] iteration   264400/  500000 | consumed samples:      2115200 | elapsed time per iteration (ms): 320.6 | learning rate: 2.049142E-05 | global batch size:     8 | lm loss: 3.013096E+00 | loss scale: 524288.0 | grad norm: 0.915 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 06:34:03] iteration   264500/  500000 | consumed samples:      2116000 | elapsed time per iteration (ms): 320.9 | learning rate: 2.045490E-05 | global batch size:     8 | lm loss: 3.030228E+00 | loss scale: 524288.0 | grad norm: 0.897 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 06:34:36] iteration   264600/  500000 | consumed samples:      2116800 | elapsed time per iteration (ms): 323.5 | learning rate: 2.041843E-05 | global batch size:     8 | lm loss: 3.039913E+00 | loss scale: 524288.0 | grad norm: 0.858 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 06:35:08] iteration   264700/  500000 | consumed samples:      2117600 | elapsed time per iteration (ms): 322.9 | learning rate: 2.038202E-05 | global batch size:     8 | lm loss: 3.016328E+00 | loss scale: 524288.0 | grad norm: 0.891 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 06:35:40] iteration   264800/  500000 | consumed samples:      2118400 | elapsed time per iteration (ms): 319.4 | learning rate: 2.034604E-05 | global batch size:     8 | lm loss: 2.985438E+00 | loss scale: 1048576.0 | grad norm: 0.888 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-22 06:36:12] iteration   264900/  500000 | consumed samples:      2119200 | elapsed time per iteration (ms): 320.4 | learning rate: 2.031011E-05 | global batch size:     8 | lm loss: 3.032774E+00 | loss scale: 524288.0 | grad norm: 0.856 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-22 06:36:44] iteration   265000/  500000 | consumed samples:      2120000 | elapsed time per iteration (ms): 324.0 | learning rate: 2.027388E-05 | global batch size:     8 | lm loss: 2.988247E+00 | loss scale: 524288.0 | grad norm: 0.901 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1076.18, 1076.18)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 265000 | lm loss value: 3.721674E+00 | lm loss PPL: 4.133353E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 06:37:18] iteration   265100/  500000 | consumed samples:      2120800 | elapsed time per iteration (ms): 321.9 | learning rate: 2.023771E-05 | global batch size:     8 | lm loss: 3.012369E+00 | loss scale: 524288.0 | grad norm: 0.865 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 06:37:50] iteration   265200/  500000 | consumed samples:      2121600 | elapsed time per iteration (ms): 322.2 | learning rate: 2.020159E-05 | global batch size:     8 | lm loss: 2.989586E+00 | loss scale: 524288.0 | grad norm: 0.863 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 06:38:22] iteration   265300/  500000 | consumed samples:      2122400 | elapsed time per iteration (ms): 322.4 | learning rate: 2.016553E-05 | global batch size:     8 | lm loss: 3.044332E+00 | loss scale: 524288.0 | grad norm: 0.881 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 06:38:54] iteration   265400/  500000 | consumed samples:      2123200 | elapsed time per iteration (ms): 322.4 | learning rate: 2.012954E-05 | global batch size:     8 | lm loss: 3.068086E+00 | loss scale: 524288.0 | grad norm: 0.912 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 06:39:26] iteration   265500/  500000 | consumed samples:      2124000 | elapsed time per iteration (ms): 321.1 | learning rate: 2.009360E-05 | global batch size:     8 | lm loss: 3.003729E+00 | loss scale: 524288.0 | grad norm: 0.944 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 06:39:59] iteration   265600/  500000 | consumed samples:      2124800 | elapsed time per iteration (ms): 322.3 | learning rate: 2.005772E-05 | global batch size:     8 | lm loss: 3.031095E+00 | loss scale: 524288.0 | grad norm: 0.910 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 06:40:31] iteration   265700/  500000 | consumed samples:      2125600 | elapsed time per iteration (ms): 321.8 | learning rate: 2.002190E-05 | global batch size:     8 | lm loss: 3.042441E+00 | loss scale: 524288.0 | grad norm: 0.828 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 06:41:03] iteration   265800/  500000 | consumed samples:      2126400 | elapsed time per iteration (ms): 322.0 | learning rate: 1.998614E-05 | global batch size:     8 | lm loss: 2.988093E+00 | loss scale: 524288.0 | grad norm: 0.891 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 06:41:35] iteration   265900/  500000 | consumed samples:      2127200 | elapsed time per iteration (ms): 323.0 | learning rate: 1.995115E-05 | global batch size:     8 | lm loss: 3.019816E+00 | loss scale: 524288.0 | grad norm: 0.893 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-22 06:42:07] iteration   266000/  500000 | consumed samples:      2128000 | elapsed time per iteration (ms): 321.8 | learning rate: 1.991586E-05 | global batch size:     8 | lm loss: 3.011096E+00 | loss scale: 262144.0 | grad norm: 0.900 | number of skipped iterations:   1 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1068.89, 1068.89)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 266000 | lm loss value: 3.750011E+00 | lm loss PPL: 4.252156E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 06:42:41] iteration   266100/  500000 | consumed samples:      2128800 | elapsed time per iteration (ms): 322.6 | learning rate: 1.988063E-05 | global batch size:     8 | lm loss: 3.049363E+00 | loss scale: 131072.0 | grad norm: 0.896 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-22 06:43:13] iteration   266200/  500000 | consumed samples:      2129600 | elapsed time per iteration (ms): 322.8 | learning rate: 1.984510E-05 | global batch size:     8 | lm loss: 3.016961E+00 | loss scale: 131072.0 | grad norm: 0.876 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 06:43:45] iteration   266300/  500000 | consumed samples:      2130400 | elapsed time per iteration (ms): 322.0 | learning rate: 1.980963E-05 | global batch size:     8 | lm loss: 2.999785E+00 | loss scale: 131072.0 | grad norm: 0.873 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 06:44:17] iteration   266400/  500000 | consumed samples:      2131200 | elapsed time per iteration (ms): 321.2 | learning rate: 1.977422E-05 | global batch size:     8 | lm loss: 2.988899E+00 | loss scale: 131072.0 | grad norm: 0.913 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 06:44:50] iteration   266500/  500000 | consumed samples:      2132000 | elapsed time per iteration (ms): 324.0 | learning rate: 1.973887E-05 | global batch size:     8 | lm loss: 3.044005E+00 | loss scale: 131072.0 | grad norm: 0.859 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 06:45:22] iteration   266600/  500000 | consumed samples:      2132800 | elapsed time per iteration (ms): 322.2 | learning rate: 1.970358E-05 | global batch size:     8 | lm loss: 3.010566E+00 | loss scale: 131072.0 | grad norm: 0.856 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 06:45:54] iteration   266700/  500000 | consumed samples:      2133600 | elapsed time per iteration (ms): 322.5 | learning rate: 1.966835E-05 | global batch size:     8 | lm loss: 3.002688E+00 | loss scale: 131072.0 | grad norm: 0.875 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 06:46:27] iteration   266800/  500000 | consumed samples:      2134400 | elapsed time per iteration (ms): 324.2 | learning rate: 1.963318E-05 | global batch size:     8 | lm loss: 2.987998E+00 | loss scale: 131072.0 | grad norm: 0.910 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 06:46:59] iteration   266900/  500000 | consumed samples:      2135200 | elapsed time per iteration (ms): 322.2 | learning rate: 1.959807E-05 | global batch size:     8 | lm loss: 3.006684E+00 | loss scale: 131072.0 | grad norm: 0.894 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 06:47:31] iteration   267000/  500000 | consumed samples:      2136000 | elapsed time per iteration (ms): 319.0 | learning rate: 1.956301E-05 | global batch size:     8 | lm loss: 3.007554E+00 | loss scale: 131072.0 | grad norm: 0.900 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1063.26, 1063.26)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 267000 | lm loss value: 3.700893E+00 | lm loss PPL: 4.048345E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 06:48:04] iteration   267100/  500000 | consumed samples:      2136800 | elapsed time per iteration (ms): 323.0 | learning rate: 1.952802E-05 | global batch size:     8 | lm loss: 2.988703E+00 | loss scale: 262144.0 | grad norm: 0.841 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 06:48:36] iteration   267200/  500000 | consumed samples:      2137600 | elapsed time per iteration (ms): 320.8 | learning rate: 1.949308E-05 | global batch size:     8 | lm loss: 2.999301E+00 | loss scale: 262144.0 | grad norm: 0.809 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 06:49:08] iteration   267300/  500000 | consumed samples:      2138400 | elapsed time per iteration (ms): 320.0 | learning rate: 1.945821E-05 | global batch size:     8 | lm loss: 3.017581E+00 | loss scale: 262144.0 | grad norm: 0.867 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 06:49:40] iteration   267400/  500000 | consumed samples:      2139200 | elapsed time per iteration (ms): 322.2 | learning rate: 1.942339E-05 | global batch size:     8 | lm loss: 3.028425E+00 | loss scale: 262144.0 | grad norm: 0.947 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 06:50:13] iteration   267500/  500000 | consumed samples:      2140000 | elapsed time per iteration (ms): 321.5 | learning rate: 1.938864E-05 | global batch size:     8 | lm loss: 3.018869E+00 | loss scale: 262144.0 | grad norm: 0.904 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 06:50:45] iteration   267600/  500000 | consumed samples:      2140800 | elapsed time per iteration (ms): 323.2 | learning rate: 1.935394E-05 | global batch size:     8 | lm loss: 3.037053E+00 | loss scale: 262144.0 | grad norm: 0.893 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 06:51:17] iteration   267700/  500000 | consumed samples:      2141600 | elapsed time per iteration (ms): 321.5 | learning rate: 1.931930E-05 | global batch size:     8 | lm loss: 2.978137E+00 | loss scale: 262144.0 | grad norm: 0.880 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 06:51:49] iteration   267800/  500000 | consumed samples:      2142400 | elapsed time per iteration (ms): 323.3 | learning rate: 1.928473E-05 | global batch size:     8 | lm loss: 3.033263E+00 | loss scale: 262144.0 | grad norm: 0.882 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 06:52:22] iteration   267900/  500000 | consumed samples:      2143200 | elapsed time per iteration (ms): 321.7 | learning rate: 1.925021E-05 | global batch size:     8 | lm loss: 3.024190E+00 | loss scale: 262144.0 | grad norm: 0.898 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 06:52:54] iteration   268000/  500000 | consumed samples:      2144000 | elapsed time per iteration (ms): 322.3 | learning rate: 1.921575E-05 | global batch size:     8 | lm loss: 3.047125E+00 | loss scale: 262144.0 | grad norm: 0.893 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1065.20, 1065.20)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 268000 | lm loss value: 3.617061E+00 | lm loss PPL: 3.722799E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 06:53:27] iteration   268100/  500000 | consumed samples:      2144800 | elapsed time per iteration (ms): 319.9 | learning rate: 1.918135E-05 | global batch size:     8 | lm loss: 3.035870E+00 | loss scale: 524288.0 | grad norm: 0.916 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 06:53:59] iteration   268200/  500000 | consumed samples:      2145600 | elapsed time per iteration (ms): 320.7 | learning rate: 1.914702E-05 | global batch size:     8 | lm loss: 2.982943E+00 | loss scale: 524288.0 | grad norm: 0.908 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 06:54:31] iteration   268300/  500000 | consumed samples:      2146400 | elapsed time per iteration (ms): 320.4 | learning rate: 1.911274E-05 | global batch size:     8 | lm loss: 3.052529E+00 | loss scale: 524288.0 | grad norm: 0.901 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 06:55:03] iteration   268400/  500000 | consumed samples:      2147200 | elapsed time per iteration (ms): 322.1 | learning rate: 1.907852E-05 | global batch size:     8 | lm loss: 2.965720E+00 | loss scale: 524288.0 | grad norm: 0.900 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 06:55:36] iteration   268500/  500000 | consumed samples:      2148000 | elapsed time per iteration (ms): 324.1 | learning rate: 1.904436E-05 | global batch size:     8 | lm loss: 2.981422E+00 | loss scale: 524288.0 | grad norm: 0.881 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 06:56:08] iteration   268600/  500000 | consumed samples:      2148800 | elapsed time per iteration (ms): 322.4 | learning rate: 1.901026E-05 | global batch size:     8 | lm loss: 3.031682E+00 | loss scale: 524288.0 | grad norm: 0.871 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 06:56:40] iteration   268700/  500000 | consumed samples:      2149600 | elapsed time per iteration (ms): 323.3 | learning rate: 1.897622E-05 | global batch size:     8 | lm loss: 2.991778E+00 | loss scale: 524288.0 | grad norm: 0.875 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 06:57:12] iteration   268800/  500000 | consumed samples:      2150400 | elapsed time per iteration (ms): 322.7 | learning rate: 1.894293E-05 | global batch size:     8 | lm loss: 3.022817E+00 | loss scale: 262144.0 | grad norm: 0.854 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-22 06:57:45] iteration   268900/  500000 | consumed samples:      2151200 | elapsed time per iteration (ms): 323.9 | learning rate: 1.890901E-05 | global batch size:     8 | lm loss: 3.017078E+00 | loss scale: 262144.0 | grad norm: 0.867 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 06:58:17] iteration   269000/  500000 | consumed samples:      2152000 | elapsed time per iteration (ms): 321.9 | learning rate: 1.887515E-05 | global batch size:     8 | lm loss: 3.013834E+00 | loss scale: 262144.0 | grad norm: 0.884 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1066.10, 1066.10)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 269000 | lm loss value: 3.772640E+00 | lm loss PPL: 4.349475E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 06:58:51] iteration   269100/  500000 | consumed samples:      2152800 | elapsed time per iteration (ms): 325.6 | learning rate: 1.884135E-05 | global batch size:     8 | lm loss: 2.989369E+00 | loss scale: 262144.0 | grad norm: 0.885 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 06:59:23] iteration   269200/  500000 | consumed samples:      2153600 | elapsed time per iteration (ms): 321.3 | learning rate: 1.880761E-05 | global batch size:     8 | lm loss: 3.015384E+00 | loss scale: 262144.0 | grad norm: 0.910 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 06:59:55] iteration   269300/  500000 | consumed samples:      2154400 | elapsed time per iteration (ms): 323.5 | learning rate: 1.877393E-05 | global batch size:     8 | lm loss: 2.983568E+00 | loss scale: 262144.0 | grad norm: 0.884 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 07:00:27] iteration   269400/  500000 | consumed samples:      2155200 | elapsed time per iteration (ms): 322.7 | learning rate: 1.874031E-05 | global batch size:     8 | lm loss: 3.035602E+00 | loss scale: 262144.0 | grad norm: 0.896 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 07:01:00] iteration   269500/  500000 | consumed samples:      2156000 | elapsed time per iteration (ms): 323.8 | learning rate: 1.870675E-05 | global batch size:     8 | lm loss: 3.006335E+00 | loss scale: 262144.0 | grad norm: 0.876 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 07:01:32] iteration   269600/  500000 | consumed samples:      2156800 | elapsed time per iteration (ms): 319.5 | learning rate: 1.867325E-05 | global batch size:     8 | lm loss: 3.027093E+00 | loss scale: 262144.0 | grad norm: 0.883 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 07:02:04] iteration   269700/  500000 | consumed samples:      2157600 | elapsed time per iteration (ms): 322.5 | learning rate: 1.863981E-05 | global batch size:     8 | lm loss: 3.013787E+00 | loss scale: 262144.0 | grad norm: 0.874 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 07:02:36] iteration   269800/  500000 | consumed samples:      2158400 | elapsed time per iteration (ms): 321.1 | learning rate: 1.860644E-05 | global batch size:     8 | lm loss: 3.000714E+00 | loss scale: 524288.0 | grad norm: 0.912 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 07:03:08] iteration   269900/  500000 | consumed samples:      2159200 | elapsed time per iteration (ms): 321.8 | learning rate: 1.857312E-05 | global batch size:     8 | lm loss: 3.023801E+00 | loss scale: 524288.0 | grad norm: 0.940 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 07:03:41] iteration   270000/  500000 | consumed samples:      2160000 | elapsed time per iteration (ms): 323.1 | learning rate: 1.853986E-05 | global batch size:     8 | lm loss: 2.988144E+00 | loss scale: 524288.0 | grad norm: 0.867 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1063.26, 1063.26)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 270000 | lm loss value: 3.564496E+00 | lm loss PPL: 3.532163E+01 | 
--------------------------------------------------------------------------------------------------
saving checkpoint at iteration  270000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-max in torch format
  successfully saved checkpoint at iteration  270000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-max
(min, max) time across ranks (ms):
    save-checkpoint ................................: (5581.12, 5581.12)
 [2024-06-22 07:04:19] iteration   270100/  500000 | consumed samples:      2160800 | elapsed time per iteration (ms): 321.2 | learning rate: 1.850700E-05 | global batch size:     8 | lm loss: 3.009296E+00 | loss scale: 524288.0 | grad norm: 0.901 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-22 07:04:52] iteration   270200/  500000 | consumed samples:      2161600 | elapsed time per iteration (ms): 324.1 | learning rate: 1.847386E-05 | global batch size:     8 | lm loss: 3.030442E+00 | loss scale: 524288.0 | grad norm: 0.957 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 07:05:24] iteration   270300/  500000 | consumed samples:      2162400 | elapsed time per iteration (ms): 321.3 | learning rate: 1.844112E-05 | global batch size:     8 | lm loss: 3.023187E+00 | loss scale: 262144.0 | grad norm: 0.881 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-22 07:05:56] iteration   270400/  500000 | consumed samples:      2163200 | elapsed time per iteration (ms): 320.4 | learning rate: 1.840810E-05 | global batch size:     8 | lm loss: 3.006000E+00 | loss scale: 262144.0 | grad norm: 0.875 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 07:06:28] iteration   270500/  500000 | consumed samples:      2164000 | elapsed time per iteration (ms): 322.4 | learning rate: 1.837514E-05 | global batch size:     8 | lm loss: 3.006088E+00 | loss scale: 262144.0 | grad norm: 0.887 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 07:07:00] iteration   270600/  500000 | consumed samples:      2164800 | elapsed time per iteration (ms): 322.6 | learning rate: 1.834225E-05 | global batch size:     8 | lm loss: 3.061074E+00 | loss scale: 262144.0 | grad norm: 0.882 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 07:07:33] iteration   270700/  500000 | consumed samples:      2165600 | elapsed time per iteration (ms): 322.5 | learning rate: 1.830941E-05 | global batch size:     8 | lm loss: 3.010046E+00 | loss scale: 262144.0 | grad norm: 0.886 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 07:08:05] iteration   270800/  500000 | consumed samples:      2166400 | elapsed time per iteration (ms): 319.5 | learning rate: 1.827664E-05 | global batch size:     8 | lm loss: 3.013441E+00 | loss scale: 262144.0 | grad norm: 0.864 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 07:08:37] iteration   270900/  500000 | consumed samples:      2167200 | elapsed time per iteration (ms): 320.4 | learning rate: 1.824393E-05 | global batch size:     8 | lm loss: 3.041342E+00 | loss scale: 262144.0 | grad norm: 0.866 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 07:09:09] iteration   271000/  500000 | consumed samples:      2168000 | elapsed time per iteration (ms): 320.2 | learning rate: 1.821128E-05 | global batch size:     8 | lm loss: 3.010281E+00 | loss scale: 262144.0 | grad norm: 0.876 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1064.11, 1064.11)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 271000 | lm loss value: 3.608872E+00 | lm loss PPL: 3.692438E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 07:09:42] iteration   271100/  500000 | consumed samples:      2168800 | elapsed time per iteration (ms): 322.9 | learning rate: 1.817868E-05 | global batch size:     8 | lm loss: 2.985186E+00 | loss scale: 262144.0 | grad norm: 0.930 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 07:10:14] iteration   271200/  500000 | consumed samples:      2169600 | elapsed time per iteration (ms): 320.9 | learning rate: 1.814615E-05 | global batch size:     8 | lm loss: 2.993813E+00 | loss scale: 262144.0 | grad norm: 0.898 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 07:10:46] iteration   271300/  500000 | consumed samples:      2170400 | elapsed time per iteration (ms): 322.8 | learning rate: 1.811368E-05 | global batch size:     8 | lm loss: 3.061263E+00 | loss scale: 524288.0 | grad norm: 0.847 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 07:11:19] iteration   271400/  500000 | consumed samples:      2171200 | elapsed time per iteration (ms): 323.2 | learning rate: 1.808127E-05 | global batch size:     8 | lm loss: 3.012354E+00 | loss scale: 524288.0 | grad norm: 0.855 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 07:11:51] iteration   271500/  500000 | consumed samples:      2172000 | elapsed time per iteration (ms): 321.7 | learning rate: 1.804893E-05 | global batch size:     8 | lm loss: 2.991550E+00 | loss scale: 524288.0 | grad norm: 0.910 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 07:12:23] iteration   271600/  500000 | consumed samples:      2172800 | elapsed time per iteration (ms): 323.9 | learning rate: 1.801664E-05 | global batch size:     8 | lm loss: 3.033433E+00 | loss scale: 524288.0 | grad norm: 0.916 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 07:12:55] iteration   271700/  500000 | consumed samples:      2173600 | elapsed time per iteration (ms): 321.7 | learning rate: 1.798441E-05 | global batch size:     8 | lm loss: 2.985580E+00 | loss scale: 524288.0 | grad norm: 0.886 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 07:13:28] iteration   271800/  500000 | consumed samples:      2174400 | elapsed time per iteration (ms): 321.1 | learning rate: 1.795225E-05 | global batch size:     8 | lm loss: 3.028585E+00 | loss scale: 524288.0 | grad norm: 0.865 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 07:14:00] iteration   271900/  500000 | consumed samples:      2175200 | elapsed time per iteration (ms): 322.2 | learning rate: 1.792014E-05 | global batch size:     8 | lm loss: 2.986077E+00 | loss scale: 524288.0 | grad norm: 0.869 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 07:14:32] iteration   272000/  500000 | consumed samples:      2176000 | elapsed time per iteration (ms): 322.1 | learning rate: 1.788810E-05 | global batch size:     8 | lm loss: 3.021795E+00 | loss scale: 524288.0 | grad norm: 0.894 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1066.47, 1066.47)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 272000 | lm loss value: 3.598627E+00 | lm loss PPL: 3.654802E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 07:15:05] iteration   272100/  500000 | consumed samples:      2176800 | elapsed time per iteration (ms): 321.0 | learning rate: 1.785612E-05 | global batch size:     8 | lm loss: 3.012259E+00 | loss scale: 524288.0 | grad norm: 0.919 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 07:15:37] iteration   272200/  500000 | consumed samples:      2177600 | elapsed time per iteration (ms): 323.8 | learning rate: 1.782420E-05 | global batch size:     8 | lm loss: 2.978925E+00 | loss scale: 524288.0 | grad norm: 0.857 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 07:16:10] iteration   272300/  500000 | consumed samples:      2178400 | elapsed time per iteration (ms): 322.9 | learning rate: 1.779297E-05 | global batch size:     8 | lm loss: 2.979895E+00 | loss scale: 524288.0 | grad norm: 0.902 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-22 07:16:42] iteration   272400/  500000 | consumed samples:      2179200 | elapsed time per iteration (ms): 322.3 | learning rate: 1.776117E-05 | global batch size:     8 | lm loss: 3.012771E+00 | loss scale: 524288.0 | grad norm: 0.928 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 07:17:14] iteration   272500/  500000 | consumed samples:      2180000 | elapsed time per iteration (ms): 322.0 | learning rate: 1.772943E-05 | global batch size:     8 | lm loss: 2.979929E+00 | loss scale: 524288.0 | grad norm: 0.896 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 07:17:47] iteration   272600/  500000 | consumed samples:      2180800 | elapsed time per iteration (ms): 323.8 | learning rate: 1.769776E-05 | global batch size:     8 | lm loss: 3.030347E+00 | loss scale: 524288.0 | grad norm: 0.864 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 07:18:19] iteration   272700/  500000 | consumed samples:      2181600 | elapsed time per iteration (ms): 323.2 | learning rate: 1.766614E-05 | global batch size:     8 | lm loss: 3.013268E+00 | loss scale: 524288.0 | grad norm: 0.831 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 07:18:51] iteration   272800/  500000 | consumed samples:      2182400 | elapsed time per iteration (ms): 323.0 | learning rate: 1.763459E-05 | global batch size:     8 | lm loss: 2.981419E+00 | loss scale: 524288.0 | grad norm: 0.896 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 07:19:23] iteration   272900/  500000 | consumed samples:      2183200 | elapsed time per iteration (ms): 321.7 | learning rate: 1.760309E-05 | global batch size:     8 | lm loss: 3.022286E+00 | loss scale: 524288.0 | grad norm: 0.937 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 07:19:56] iteration   273000/  500000 | consumed samples:      2184000 | elapsed time per iteration (ms): 321.9 | learning rate: 1.757166E-05 | global batch size:     8 | lm loss: 3.002498E+00 | loss scale: 524288.0 | grad norm: 0.910 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1068.15, 1068.15)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 273000 | lm loss value: 3.520293E+00 | lm loss PPL: 3.379432E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 07:20:29] iteration   273100/  500000 | consumed samples:      2184800 | elapsed time per iteration (ms): 320.6 | learning rate: 1.754029E-05 | global batch size:     8 | lm loss: 3.016655E+00 | loss scale: 524288.0 | grad norm: 0.858 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 07:21:01] iteration   273200/  500000 | consumed samples:      2185600 | elapsed time per iteration (ms): 319.3 | learning rate: 1.750898E-05 | global batch size:     8 | lm loss: 3.029592E+00 | loss scale: 524288.0 | grad norm: 0.895 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 07:21:33] iteration   273300/  500000 | consumed samples:      2186400 | elapsed time per iteration (ms): 321.7 | learning rate: 1.747867E-05 | global batch size:     8 | lm loss: 3.060728E+00 | loss scale: 262144.0 | grad norm: 0.921 | number of skipped iterations:   3 | number of nan iterations:   0 |
 [2024-06-22 07:22:05] iteration   273400/  500000 | consumed samples:      2187200 | elapsed time per iteration (ms): 321.8 | learning rate: 1.744748E-05 | global batch size:     8 | lm loss: 3.008901E+00 | loss scale: 262144.0 | grad norm: 0.895 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 07:22:37] iteration   273500/  500000 | consumed samples:      2188000 | elapsed time per iteration (ms): 322.2 | learning rate: 1.741635E-05 | global batch size:     8 | lm loss: 3.050477E+00 | loss scale: 262144.0 | grad norm: 0.889 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 07:23:09] iteration   273600/  500000 | consumed samples:      2188800 | elapsed time per iteration (ms): 321.2 | learning rate: 1.738529E-05 | global batch size:     8 | lm loss: 3.004012E+00 | loss scale: 262144.0 | grad norm: 0.863 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 07:23:42] iteration   273700/  500000 | consumed samples:      2189600 | elapsed time per iteration (ms): 324.1 | learning rate: 1.735428E-05 | global batch size:     8 | lm loss: 3.019136E+00 | loss scale: 262144.0 | grad norm: 0.889 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 07:24:14] iteration   273800/  500000 | consumed samples:      2190400 | elapsed time per iteration (ms): 324.1 | learning rate: 1.732334E-05 | global batch size:     8 | lm loss: 3.006957E+00 | loss scale: 262144.0 | grad norm: 0.924 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 07:24:46] iteration   273900/  500000 | consumed samples:      2191200 | elapsed time per iteration (ms): 322.3 | learning rate: 1.729246E-05 | global batch size:     8 | lm loss: 2.980654E+00 | loss scale: 262144.0 | grad norm: 0.899 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 07:25:19] iteration   274000/  500000 | consumed samples:      2192000 | elapsed time per iteration (ms): 322.2 | learning rate: 1.726164E-05 | global batch size:     8 | lm loss: 2.987947E+00 | loss scale: 262144.0 | grad norm: 0.858 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1063.98, 1063.98)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 274000 | lm loss value: 3.673671E+00 | lm loss PPL: 3.939625E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 07:25:52] iteration   274100/  500000 | consumed samples:      2192800 | elapsed time per iteration (ms): 323.2 | learning rate: 1.723089E-05 | global batch size:     8 | lm loss: 3.019733E+00 | loss scale: 262144.0 | grad norm: 0.885 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 07:26:24] iteration   274200/  500000 | consumed samples:      2193600 | elapsed time per iteration (ms): 322.1 | learning rate: 1.720019E-05 | global batch size:     8 | lm loss: 2.990721E+00 | loss scale: 262144.0 | grad norm: 0.909 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 07:26:56] iteration   274300/  500000 | consumed samples:      2194400 | elapsed time per iteration (ms): 321.1 | learning rate: 1.716956E-05 | global batch size:     8 | lm loss: 3.007859E+00 | loss scale: 524288.0 | grad norm: 0.877 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 07:27:28] iteration   274400/  500000 | consumed samples:      2195200 | elapsed time per iteration (ms): 319.5 | learning rate: 1.713899E-05 | global batch size:     8 | lm loss: 2.997874E+00 | loss scale: 524288.0 | grad norm: 0.919 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 07:28:00] iteration   274500/  500000 | consumed samples:      2196000 | elapsed time per iteration (ms): 321.5 | learning rate: 1.710848E-05 | global batch size:     8 | lm loss: 2.979233E+00 | loss scale: 524288.0 | grad norm: 0.928 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 07:28:32] iteration   274600/  500000 | consumed samples:      2196800 | elapsed time per iteration (ms): 319.8 | learning rate: 1.707803E-05 | global batch size:     8 | lm loss: 2.987661E+00 | loss scale: 524288.0 | grad norm: 0.916 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 07:29:05] iteration   274700/  500000 | consumed samples:      2197600 | elapsed time per iteration (ms): 322.9 | learning rate: 1.704764E-05 | global batch size:     8 | lm loss: 2.985861E+00 | loss scale: 524288.0 | grad norm: 0.859 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 07:29:37] iteration   274800/  500000 | consumed samples:      2198400 | elapsed time per iteration (ms): 318.7 | learning rate: 1.701732E-05 | global batch size:     8 | lm loss: 3.007058E+00 | loss scale: 524288.0 | grad norm: 0.858 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 07:30:09] iteration   274900/  500000 | consumed samples:      2199200 | elapsed time per iteration (ms): 320.0 | learning rate: 1.698705E-05 | global batch size:     8 | lm loss: 2.982018E+00 | loss scale: 524288.0 | grad norm: 0.895 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 07:30:41] iteration   275000/  500000 | consumed samples:      2200000 | elapsed time per iteration (ms): 319.6 | learning rate: 1.695685E-05 | global batch size:     8 | lm loss: 3.037803E+00 | loss scale: 524288.0 | grad norm: 0.923 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1063.84, 1063.84)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 275000 | lm loss value: 3.650676E+00 | lm loss PPL: 3.850068E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 07:31:14] iteration   275100/  500000 | consumed samples:      2200800 | elapsed time per iteration (ms): 320.2 | learning rate: 1.692672E-05 | global batch size:     8 | lm loss: 2.996963E+00 | loss scale: 524288.0 | grad norm: 0.875 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 07:31:46] iteration   275200/  500000 | consumed samples:      2201600 | elapsed time per iteration (ms): 321.9 | learning rate: 1.689664E-05 | global batch size:     8 | lm loss: 3.017367E+00 | loss scale: 524288.0 | grad norm: 0.813 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 07:32:18] iteration   275300/  500000 | consumed samples:      2202400 | elapsed time per iteration (ms): 323.0 | learning rate: 1.686663E-05 | global batch size:     8 | lm loss: 3.030696E+00 | loss scale: 1048576.0 | grad norm: 0.883 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 07:32:50] iteration   275400/  500000 | consumed samples:      2203200 | elapsed time per iteration (ms): 323.5 | learning rate: 1.683727E-05 | global batch size:     8 | lm loss: 2.999547E+00 | loss scale: 524288.0 | grad norm: 0.939 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-22 07:33:23] iteration   275500/  500000 | consumed samples:      2204000 | elapsed time per iteration (ms): 322.2 | learning rate: 1.680738E-05 | global batch size:     8 | lm loss: 2.996878E+00 | loss scale: 524288.0 | grad norm: 0.884 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 07:33:55] iteration   275600/  500000 | consumed samples:      2204800 | elapsed time per iteration (ms): 321.9 | learning rate: 1.677755E-05 | global batch size:     8 | lm loss: 3.000060E+00 | loss scale: 524288.0 | grad norm: 0.902 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 07:34:27] iteration   275700/  500000 | consumed samples:      2205600 | elapsed time per iteration (ms): 321.0 | learning rate: 1.674778E-05 | global batch size:     8 | lm loss: 3.007446E+00 | loss scale: 524288.0 | grad norm: 0.882 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 07:34:59] iteration   275800/  500000 | consumed samples:      2206400 | elapsed time per iteration (ms): 321.4 | learning rate: 1.671838E-05 | global batch size:     8 | lm loss: 2.990801E+00 | loss scale: 262144.0 | grad norm: 0.917 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-22 07:35:31] iteration   275900/  500000 | consumed samples:      2207200 | elapsed time per iteration (ms): 322.0 | learning rate: 1.668873E-05 | global batch size:     8 | lm loss: 3.004500E+00 | loss scale: 262144.0 | grad norm: 0.880 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 07:36:03] iteration   276000/  500000 | consumed samples:      2208000 | elapsed time per iteration (ms): 321.4 | learning rate: 1.665915E-05 | global batch size:     8 | lm loss: 3.008999E+00 | loss scale: 262144.0 | grad norm: 0.869 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1064.55, 1064.55)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 276000 | lm loss value: 3.773285E+00 | lm loss PPL: 4.352282E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 07:36:37] iteration   276100/  500000 | consumed samples:      2208800 | elapsed time per iteration (ms): 321.0 | learning rate: 1.662963E-05 | global batch size:     8 | lm loss: 2.979261E+00 | loss scale: 262144.0 | grad norm: 0.893 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 07:37:09] iteration   276200/  500000 | consumed samples:      2209600 | elapsed time per iteration (ms): 323.9 | learning rate: 1.660018E-05 | global batch size:     8 | lm loss: 3.015166E+00 | loss scale: 262144.0 | grad norm: 0.899 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 07:37:41] iteration   276300/  500000 | consumed samples:      2210400 | elapsed time per iteration (ms): 323.2 | learning rate: 1.657078E-05 | global batch size:     8 | lm loss: 3.006562E+00 | loss scale: 262144.0 | grad norm: 0.899 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 07:38:13] iteration   276400/  500000 | consumed samples:      2211200 | elapsed time per iteration (ms): 320.7 | learning rate: 1.654145E-05 | global batch size:     8 | lm loss: 2.998778E+00 | loss scale: 262144.0 | grad norm: 0.891 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 07:38:45] iteration   276500/  500000 | consumed samples:      2212000 | elapsed time per iteration (ms): 319.7 | learning rate: 1.651218E-05 | global batch size:     8 | lm loss: 2.995844E+00 | loss scale: 262144.0 | grad norm: 0.906 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 07:39:17] iteration   276600/  500000 | consumed samples:      2212800 | elapsed time per iteration (ms): 319.9 | learning rate: 1.648297E-05 | global batch size:     8 | lm loss: 3.033297E+00 | loss scale: 262144.0 | grad norm: 0.954 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 07:39:49] iteration   276700/  500000 | consumed samples:      2213600 | elapsed time per iteration (ms): 321.6 | learning rate: 1.645383E-05 | global batch size:     8 | lm loss: 3.010083E+00 | loss scale: 262144.0 | grad norm: 0.894 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 07:40:21] iteration   276800/  500000 | consumed samples:      2214400 | elapsed time per iteration (ms): 318.5 | learning rate: 1.642475E-05 | global batch size:     8 | lm loss: 3.043872E+00 | loss scale: 524288.0 | grad norm: 0.893 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 07:40:53] iteration   276900/  500000 | consumed samples:      2215200 | elapsed time per iteration (ms): 319.4 | learning rate: 1.639573E-05 | global batch size:     8 | lm loss: 2.985833E+00 | loss scale: 524288.0 | grad norm: 0.897 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 07:41:25] iteration   277000/  500000 | consumed samples:      2216000 | elapsed time per iteration (ms): 320.6 | learning rate: 1.636677E-05 | global batch size:     8 | lm loss: 2.991699E+00 | loss scale: 524288.0 | grad norm: 0.885 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1063.98, 1063.98)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 277000 | lm loss value: 3.681496E+00 | lm loss PPL: 3.970576E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 07:41:59] iteration   277100/  500000 | consumed samples:      2216800 | elapsed time per iteration (ms): 322.9 | learning rate: 1.633788E-05 | global batch size:     8 | lm loss: 3.009887E+00 | loss scale: 524288.0 | grad norm: 0.938 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 07:42:31] iteration   277200/  500000 | consumed samples:      2217600 | elapsed time per iteration (ms): 321.0 | learning rate: 1.630905E-05 | global batch size:     8 | lm loss: 2.999017E+00 | loss scale: 524288.0 | grad norm: 0.911 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 07:43:03] iteration   277300/  500000 | consumed samples:      2218400 | elapsed time per iteration (ms): 324.3 | learning rate: 1.628028E-05 | global batch size:     8 | lm loss: 2.977954E+00 | loss scale: 524288.0 | grad norm: 0.911 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 07:43:35] iteration   277400/  500000 | consumed samples:      2219200 | elapsed time per iteration (ms): 319.3 | learning rate: 1.625157E-05 | global batch size:     8 | lm loss: 2.974655E+00 | loss scale: 524288.0 | grad norm: 0.885 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 07:44:07] iteration   277500/  500000 | consumed samples:      2220000 | elapsed time per iteration (ms): 321.1 | learning rate: 1.622293E-05 | global batch size:     8 | lm loss: 3.007642E+00 | loss scale: 524288.0 | grad norm: 0.947 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 07:44:39] iteration   277600/  500000 | consumed samples:      2220800 | elapsed time per iteration (ms): 321.9 | learning rate: 1.619435E-05 | global batch size:     8 | lm loss: 2.993987E+00 | loss scale: 524288.0 | grad norm: 0.861 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 07:45:12] iteration   277700/  500000 | consumed samples:      2221600 | elapsed time per iteration (ms): 321.6 | learning rate: 1.616583E-05 | global batch size:     8 | lm loss: 3.033252E+00 | loss scale: 524288.0 | grad norm: 0.924 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 07:45:44] iteration   277800/  500000 | consumed samples:      2222400 | elapsed time per iteration (ms): 322.0 | learning rate: 1.613794E-05 | global batch size:     8 | lm loss: 3.010858E+00 | loss scale: 524288.0 | grad norm: 0.881 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-22 07:46:16] iteration   277900/  500000 | consumed samples:      2223200 | elapsed time per iteration (ms): 321.2 | learning rate: 1.610955E-05 | global batch size:     8 | lm loss: 3.032161E+00 | loss scale: 524288.0 | grad norm: 0.903 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 07:46:48] iteration   278000/  500000 | consumed samples:      2224000 | elapsed time per iteration (ms): 324.8 | learning rate: 1.608122E-05 | global batch size:     8 | lm loss: 2.986961E+00 | loss scale: 524288.0 | grad norm: 0.889 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1069.63, 1069.63)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 278000 | lm loss value: 3.597934E+00 | lm loss PPL: 3.652268E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 07:47:22] iteration   278100/  500000 | consumed samples:      2224800 | elapsed time per iteration (ms): 322.0 | learning rate: 1.605295E-05 | global batch size:     8 | lm loss: 2.995110E+00 | loss scale: 524288.0 | grad norm: 0.892 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 07:47:54] iteration   278200/  500000 | consumed samples:      2225600 | elapsed time per iteration (ms): 323.9 | learning rate: 1.602474E-05 | global batch size:     8 | lm loss: 3.012503E+00 | loss scale: 524288.0 | grad norm: 0.900 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 07:48:26] iteration   278300/  500000 | consumed samples:      2226400 | elapsed time per iteration (ms): 321.8 | learning rate: 1.599660E-05 | global batch size:     8 | lm loss: 2.984599E+00 | loss scale: 524288.0 | grad norm: 0.895 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 07:48:59] iteration   278400/  500000 | consumed samples:      2227200 | elapsed time per iteration (ms): 323.7 | learning rate: 1.596852E-05 | global batch size:     8 | lm loss: 2.964898E+00 | loss scale: 524288.0 | grad norm: 0.890 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 07:49:31] iteration   278500/  500000 | consumed samples:      2228000 | elapsed time per iteration (ms): 319.4 | learning rate: 1.594050E-05 | global batch size:     8 | lm loss: 2.941046E+00 | loss scale: 524288.0 | grad norm: 0.917 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 07:50:03] iteration   278600/  500000 | consumed samples:      2228800 | elapsed time per iteration (ms): 323.9 | learning rate: 1.591255E-05 | global batch size:     8 | lm loss: 3.005047E+00 | loss scale: 524288.0 | grad norm: 0.897 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 07:50:35] iteration   278700/  500000 | consumed samples:      2229600 | elapsed time per iteration (ms): 320.7 | learning rate: 1.588466E-05 | global batch size:     8 | lm loss: 3.041456E+00 | loss scale: 524288.0 | grad norm: 0.971 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 07:51:07] iteration   278800/  500000 | consumed samples:      2230400 | elapsed time per iteration (ms): 321.3 | learning rate: 1.585683E-05 | global batch size:     8 | lm loss: 3.018603E+00 | loss scale: 1048576.0 | grad norm: 0.848 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 07:51:40] iteration   278900/  500000 | consumed samples:      2231200 | elapsed time per iteration (ms): 324.1 | learning rate: 1.582962E-05 | global batch size:     8 | lm loss: 2.994200E+00 | loss scale: 524288.0 | grad norm: 0.903 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-22 07:52:12] iteration   279000/  500000 | consumed samples:      2232000 | elapsed time per iteration (ms): 321.2 | learning rate: 1.580192E-05 | global batch size:     8 | lm loss: 3.016942E+00 | loss scale: 524288.0 | grad norm: 0.893 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1064.50, 1064.50)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 279000 | lm loss value: 3.695646E+00 | lm loss PPL: 4.027156E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 07:52:45] iteration   279100/  500000 | consumed samples:      2232800 | elapsed time per iteration (ms): 320.3 | learning rate: 1.577428E-05 | global batch size:     8 | lm loss: 3.049472E+00 | loss scale: 524288.0 | grad norm: 0.910 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 07:53:17] iteration   279200/  500000 | consumed samples:      2233600 | elapsed time per iteration (ms): 321.0 | learning rate: 1.574670E-05 | global batch size:     8 | lm loss: 2.970404E+00 | loss scale: 524288.0 | grad norm: 0.933 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 07:53:49] iteration   279300/  500000 | consumed samples:      2234400 | elapsed time per iteration (ms): 321.4 | learning rate: 1.571919E-05 | global batch size:     8 | lm loss: 2.958072E+00 | loss scale: 524288.0 | grad norm: 0.919 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 07:54:21] iteration   279400/  500000 | consumed samples:      2235200 | elapsed time per iteration (ms): 321.1 | learning rate: 1.569174E-05 | global batch size:     8 | lm loss: 2.967355E+00 | loss scale: 524288.0 | grad norm: 0.936 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 07:54:53] iteration   279500/  500000 | consumed samples:      2236000 | elapsed time per iteration (ms): 322.9 | learning rate: 1.566436E-05 | global batch size:     8 | lm loss: 2.967255E+00 | loss scale: 524288.0 | grad norm: 0.907 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 07:55:26] iteration   279600/  500000 | consumed samples:      2236800 | elapsed time per iteration (ms): 322.6 | learning rate: 1.563703E-05 | global batch size:     8 | lm loss: 2.993931E+00 | loss scale: 524288.0 | grad norm: 0.919 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 07:55:58] iteration   279700/  500000 | consumed samples:      2237600 | elapsed time per iteration (ms): 321.3 | learning rate: 1.560977E-05 | global batch size:     8 | lm loss: 3.044643E+00 | loss scale: 524288.0 | grad norm: 0.944 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 07:56:30] iteration   279800/  500000 | consumed samples:      2238400 | elapsed time per iteration (ms): 321.9 | learning rate: 1.558258E-05 | global batch size:     8 | lm loss: 3.002572E+00 | loss scale: 524288.0 | grad norm: 0.907 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 07:57:03] iteration   279900/  500000 | consumed samples:      2239200 | elapsed time per iteration (ms): 325.1 | learning rate: 1.555598E-05 | global batch size:     8 | lm loss: 2.958207E+00 | loss scale: 524288.0 | grad norm: 0.961 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-22 07:57:35] iteration   280000/  500000 | consumed samples:      2240000 | elapsed time per iteration (ms): 322.8 | learning rate: 1.552891E-05 | global batch size:     8 | lm loss: 3.027060E+00 | loss scale: 524288.0 | grad norm: 0.912 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1064.79, 1064.79)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 280000 | lm loss value: 3.616140E+00 | lm loss PPL: 3.719371E+01 | 
--------------------------------------------------------------------------------------------------
saving checkpoint at iteration  280000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-max in torch format
  successfully saved checkpoint at iteration  280000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-max
(min, max) time across ranks (ms):
    save-checkpoint ................................: (5602.41, 5602.41)
 [2024-06-22 07:58:14] iteration   280100/  500000 | consumed samples:      2240800 | elapsed time per iteration (ms): 320.5 | learning rate: 1.550191E-05 | global batch size:     8 | lm loss: 2.973265E+00 | loss scale: 524288.0 | grad norm: 0.878 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 07:58:46] iteration   280200/  500000 | consumed samples:      2241600 | elapsed time per iteration (ms): 324.3 | learning rate: 1.547496E-05 | global batch size:     8 | lm loss: 2.972022E+00 | loss scale: 524288.0 | grad norm: 0.892 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 07:59:18] iteration   280300/  500000 | consumed samples:      2242400 | elapsed time per iteration (ms): 322.7 | learning rate: 1.544808E-05 | global batch size:     8 | lm loss: 3.025224E+00 | loss scale: 524288.0 | grad norm: 0.910 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 07:59:51] iteration   280400/  500000 | consumed samples:      2243200 | elapsed time per iteration (ms): 324.0 | learning rate: 1.542153E-05 | global batch size:     8 | lm loss: 2.981034E+00 | loss scale: 262144.0 | grad norm: 0.904 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-22 08:00:23] iteration   280500/  500000 | consumed samples:      2244000 | elapsed time per iteration (ms): 323.0 | learning rate: 1.539478E-05 | global batch size:     8 | lm loss: 2.994559E+00 | loss scale: 262144.0 | grad norm: 0.911 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 08:00:55] iteration   280600/  500000 | consumed samples:      2244800 | elapsed time per iteration (ms): 323.2 | learning rate: 1.536808E-05 | global batch size:     8 | lm loss: 2.982379E+00 | loss scale: 262144.0 | grad norm: 0.906 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 08:01:27] iteration   280700/  500000 | consumed samples:      2245600 | elapsed time per iteration (ms): 322.3 | learning rate: 1.534146E-05 | global batch size:     8 | lm loss: 2.996152E+00 | loss scale: 262144.0 | grad norm: 0.971 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 08:02:00] iteration   280800/  500000 | consumed samples:      2246400 | elapsed time per iteration (ms): 322.4 | learning rate: 1.531489E-05 | global batch size:     8 | lm loss: 2.991888E+00 | loss scale: 262144.0 | grad norm: 0.895 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 08:02:32] iteration   280900/  500000 | consumed samples:      2247200 | elapsed time per iteration (ms): 323.6 | learning rate: 1.528839E-05 | global batch size:     8 | lm loss: 3.027228E+00 | loss scale: 262144.0 | grad norm: 0.901 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 08:03:04] iteration   281000/  500000 | consumed samples:      2248000 | elapsed time per iteration (ms): 323.6 | learning rate: 1.526196E-05 | global batch size:     8 | lm loss: 2.999932E+00 | loss scale: 262144.0 | grad norm: 0.895 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1063.63, 1063.63)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 281000 | lm loss value: 3.729640E+00 | lm loss PPL: 4.166410E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 08:03:37] iteration   281100/  500000 | consumed samples:      2248800 | elapsed time per iteration (ms): 319.7 | learning rate: 1.523558E-05 | global batch size:     8 | lm loss: 2.999719E+00 | loss scale: 262144.0 | grad norm: 0.876 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 08:04:10] iteration   281200/  500000 | consumed samples:      2249600 | elapsed time per iteration (ms): 321.1 | learning rate: 1.520927E-05 | global batch size:     8 | lm loss: 2.928311E+00 | loss scale: 262144.0 | grad norm: 0.893 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 08:04:42] iteration   281300/  500000 | consumed samples:      2250400 | elapsed time per iteration (ms): 320.8 | learning rate: 1.518303E-05 | global batch size:     8 | lm loss: 3.017341E+00 | loss scale: 262144.0 | grad norm: 0.905 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 08:05:14] iteration   281400/  500000 | consumed samples:      2251200 | elapsed time per iteration (ms): 320.4 | learning rate: 1.515685E-05 | global batch size:     8 | lm loss: 3.032437E+00 | loss scale: 524288.0 | grad norm: 0.879 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 08:05:46] iteration   281500/  500000 | consumed samples:      2252000 | elapsed time per iteration (ms): 322.3 | learning rate: 1.513073E-05 | global batch size:     8 | lm loss: 2.997918E+00 | loss scale: 524288.0 | grad norm: 0.764 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 08:06:18] iteration   281600/  500000 | consumed samples:      2252800 | elapsed time per iteration (ms): 321.9 | learning rate: 1.510467E-05 | global batch size:     8 | lm loss: 3.017441E+00 | loss scale: 524288.0 | grad norm: 0.868 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 08:06:51] iteration   281700/  500000 | consumed samples:      2253600 | elapsed time per iteration (ms): 323.6 | learning rate: 1.507868E-05 | global batch size:     8 | lm loss: 3.023215E+00 | loss scale: 524288.0 | grad norm: 0.901 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 08:07:23] iteration   281800/  500000 | consumed samples:      2254400 | elapsed time per iteration (ms): 320.3 | learning rate: 1.505276E-05 | global batch size:     8 | lm loss: 2.982667E+00 | loss scale: 524288.0 | grad norm: 0.879 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 08:07:55] iteration   281900/  500000 | consumed samples:      2255200 | elapsed time per iteration (ms): 322.6 | learning rate: 1.502715E-05 | global batch size:     8 | lm loss: 2.987076E+00 | loss scale: 524288.0 | grad norm: 0.867 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-22 08:08:27] iteration   282000/  500000 | consumed samples:      2256000 | elapsed time per iteration (ms): 324.1 | learning rate: 1.500135E-05 | global batch size:     8 | lm loss: 3.031801E+00 | loss scale: 524288.0 | grad norm: 0.899 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1065.18, 1065.18)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 282000 | lm loss value: 3.587686E+00 | lm loss PPL: 3.615032E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 08:09:00] iteration   282100/  500000 | consumed samples:      2256800 | elapsed time per iteration (ms): 322.0 | learning rate: 1.497562E-05 | global batch size:     8 | lm loss: 2.965652E+00 | loss scale: 524288.0 | grad norm: 0.915 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 08:09:33] iteration   282200/  500000 | consumed samples:      2257600 | elapsed time per iteration (ms): 323.1 | learning rate: 1.494995E-05 | global batch size:     8 | lm loss: 2.985033E+00 | loss scale: 524288.0 | grad norm: 0.941 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 08:10:05] iteration   282300/  500000 | consumed samples:      2258400 | elapsed time per iteration (ms): 323.3 | learning rate: 1.492434E-05 | global batch size:     8 | lm loss: 2.906833E+00 | loss scale: 524288.0 | grad norm: 0.869 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 08:10:37] iteration   282400/  500000 | consumed samples:      2259200 | elapsed time per iteration (ms): 322.7 | learning rate: 1.489879E-05 | global batch size:     8 | lm loss: 3.004826E+00 | loss scale: 524288.0 | grad norm: 0.865 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 08:11:10] iteration   282500/  500000 | consumed samples:      2260000 | elapsed time per iteration (ms): 322.1 | learning rate: 1.487331E-05 | global batch size:     8 | lm loss: 2.994853E+00 | loss scale: 524288.0 | grad norm: 0.920 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 08:11:42] iteration   282600/  500000 | consumed samples:      2260800 | elapsed time per iteration (ms): 323.3 | learning rate: 1.484790E-05 | global batch size:     8 | lm loss: 2.971553E+00 | loss scale: 524288.0 | grad norm: 0.889 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 08:12:14] iteration   282700/  500000 | consumed samples:      2261600 | elapsed time per iteration (ms): 321.2 | learning rate: 1.482255E-05 | global batch size:     8 | lm loss: 3.055739E+00 | loss scale: 524288.0 | grad norm: 0.922 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 08:12:46] iteration   282800/  500000 | consumed samples:      2262400 | elapsed time per iteration (ms): 321.6 | learning rate: 1.479726E-05 | global batch size:     8 | lm loss: 2.995878E+00 | loss scale: 524288.0 | grad norm: 0.914 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 08:13:19] iteration   282900/  500000 | consumed samples:      2263200 | elapsed time per iteration (ms): 324.0 | learning rate: 1.477204E-05 | global batch size:     8 | lm loss: 3.007422E+00 | loss scale: 1048576.0 | grad norm: 0.896 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 08:13:51] iteration   283000/  500000 | consumed samples:      2264000 | elapsed time per iteration (ms): 319.9 | learning rate: 1.474738E-05 | global batch size:     8 | lm loss: 2.989891E+00 | loss scale: 524288.0 | grad norm: 0.917 | number of skipped iterations:   2 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1065.07, 1065.07)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 283000 | lm loss value: 3.692603E+00 | lm loss PPL: 4.014920E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 08:14:24] iteration   283100/  500000 | consumed samples:      2264800 | elapsed time per iteration (ms): 323.1 | learning rate: 1.472228E-05 | global batch size:     8 | lm loss: 2.977055E+00 | loss scale: 524288.0 | grad norm: 0.891 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 08:14:56] iteration   283200/  500000 | consumed samples:      2265600 | elapsed time per iteration (ms): 322.5 | learning rate: 1.469725E-05 | global batch size:     8 | lm loss: 3.008918E+00 | loss scale: 524288.0 | grad norm: 0.871 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 08:15:28] iteration   283300/  500000 | consumed samples:      2266400 | elapsed time per iteration (ms): 321.5 | learning rate: 1.467253E-05 | global batch size:     8 | lm loss: 2.975953E+00 | loss scale: 262144.0 | grad norm: 0.893 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-22 08:16:01] iteration   283400/  500000 | consumed samples:      2267200 | elapsed time per iteration (ms): 322.4 | learning rate: 1.464763E-05 | global batch size:     8 | lm loss: 2.957942E+00 | loss scale: 262144.0 | grad norm: 0.922 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 08:16:33] iteration   283500/  500000 | consumed samples:      2268000 | elapsed time per iteration (ms): 319.8 | learning rate: 1.462279E-05 | global batch size:     8 | lm loss: 2.952971E+00 | loss scale: 262144.0 | grad norm: 0.912 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 08:17:05] iteration   283600/  500000 | consumed samples:      2268800 | elapsed time per iteration (ms): 320.8 | learning rate: 1.459801E-05 | global batch size:     8 | lm loss: 2.936946E+00 | loss scale: 262144.0 | grad norm: 0.951 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 08:17:37] iteration   283700/  500000 | consumed samples:      2269600 | elapsed time per iteration (ms): 321.8 | learning rate: 1.457330E-05 | global batch size:     8 | lm loss: 3.001474E+00 | loss scale: 262144.0 | grad norm: 0.931 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 08:18:09] iteration   283800/  500000 | consumed samples:      2270400 | elapsed time per iteration (ms): 321.7 | learning rate: 1.454890E-05 | global batch size:     8 | lm loss: 3.011113E+00 | loss scale: 131072.0 | grad norm: 0.925 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-22 08:18:41] iteration   283900/  500000 | consumed samples:      2271200 | elapsed time per iteration (ms): 322.5 | learning rate: 1.452432E-05 | global batch size:     8 | lm loss: 3.008326E+00 | loss scale: 131072.0 | grad norm: 0.896 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 08:19:13] iteration   284000/  500000 | consumed samples:      2272000 | elapsed time per iteration (ms): 321.8 | learning rate: 1.449980E-05 | global batch size:     8 | lm loss: 3.027573E+00 | loss scale: 131072.0 | grad norm: 0.923 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1071.86, 1071.86)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 284000 | lm loss value: 3.574693E+00 | lm loss PPL: 3.568366E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 08:19:47] iteration   284100/  500000 | consumed samples:      2272800 | elapsed time per iteration (ms): 324.4 | learning rate: 1.447534E-05 | global batch size:     8 | lm loss: 2.977874E+00 | loss scale: 131072.0 | grad norm: 0.915 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 08:20:19] iteration   284200/  500000 | consumed samples:      2273600 | elapsed time per iteration (ms): 321.8 | learning rate: 1.445095E-05 | global batch size:     8 | lm loss: 2.973938E+00 | loss scale: 131072.0 | grad norm: 0.924 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 08:20:51] iteration   284300/  500000 | consumed samples:      2274400 | elapsed time per iteration (ms): 323.3 | learning rate: 1.442663E-05 | global batch size:     8 | lm loss: 2.971207E+00 | loss scale: 131072.0 | grad norm: 0.922 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 08:21:23] iteration   284400/  500000 | consumed samples:      2275200 | elapsed time per iteration (ms): 320.2 | learning rate: 1.440237E-05 | global batch size:     8 | lm loss: 2.999950E+00 | loss scale: 131072.0 | grad norm: 0.960 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 08:21:56] iteration   284500/  500000 | consumed samples:      2276000 | elapsed time per iteration (ms): 322.3 | learning rate: 1.437817E-05 | global batch size:     8 | lm loss: 3.054516E+00 | loss scale: 131072.0 | grad norm: 0.932 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 08:22:28] iteration   284600/  500000 | consumed samples:      2276800 | elapsed time per iteration (ms): 322.5 | learning rate: 1.435404E-05 | global batch size:     8 | lm loss: 2.989069E+00 | loss scale: 131072.0 | grad norm: 0.948 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 08:23:00] iteration   284700/  500000 | consumed samples:      2277600 | elapsed time per iteration (ms): 320.4 | learning rate: 1.432997E-05 | global batch size:     8 | lm loss: 2.993217E+00 | loss scale: 131072.0 | grad norm: 0.951 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 08:23:32] iteration   284800/  500000 | consumed samples:      2278400 | elapsed time per iteration (ms): 320.9 | learning rate: 1.430597E-05 | global batch size:     8 | lm loss: 2.972586E+00 | loss scale: 262144.0 | grad norm: 0.900 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 08:24:04] iteration   284900/  500000 | consumed samples:      2279200 | elapsed time per iteration (ms): 323.1 | learning rate: 1.428203E-05 | global batch size:     8 | lm loss: 2.979885E+00 | loss scale: 262144.0 | grad norm: 0.900 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 08:24:37] iteration   285000/  500000 | consumed samples:      2280000 | elapsed time per iteration (ms): 324.3 | learning rate: 1.425816E-05 | global batch size:     8 | lm loss: 3.027129E+00 | loss scale: 262144.0 | grad norm: 0.852 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1065.80, 1065.80)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 285000 | lm loss value: 3.515280E+00 | lm loss PPL: 3.362536E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 08:25:10] iteration   285100/  500000 | consumed samples:      2280800 | elapsed time per iteration (ms): 321.2 | learning rate: 1.423435E-05 | global batch size:     8 | lm loss: 2.983838E+00 | loss scale: 262144.0 | grad norm: 0.948 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 08:25:42] iteration   285200/  500000 | consumed samples:      2281600 | elapsed time per iteration (ms): 322.4 | learning rate: 1.421060E-05 | global batch size:     8 | lm loss: 2.985265E+00 | loss scale: 262144.0 | grad norm: 0.881 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 08:26:14] iteration   285300/  500000 | consumed samples:      2282400 | elapsed time per iteration (ms): 321.7 | learning rate: 1.418692E-05 | global batch size:     8 | lm loss: 3.021039E+00 | loss scale: 262144.0 | grad norm: 0.850 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 08:26:47] iteration   285400/  500000 | consumed samples:      2283200 | elapsed time per iteration (ms): 323.9 | learning rate: 1.416331E-05 | global batch size:     8 | lm loss: 2.994456E+00 | loss scale: 262144.0 | grad norm: 0.882 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 08:27:19] iteration   285500/  500000 | consumed samples:      2284000 | elapsed time per iteration (ms): 320.6 | learning rate: 1.413976E-05 | global batch size:     8 | lm loss: 2.964333E+00 | loss scale: 262144.0 | grad norm: 0.891 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 08:27:51] iteration   285600/  500000 | consumed samples:      2284800 | elapsed time per iteration (ms): 322.2 | learning rate: 1.411627E-05 | global batch size:     8 | lm loss: 2.991122E+00 | loss scale: 262144.0 | grad norm: 0.875 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 08:28:23] iteration   285700/  500000 | consumed samples:      2285600 | elapsed time per iteration (ms): 321.8 | learning rate: 1.409285E-05 | global batch size:     8 | lm loss: 3.019919E+00 | loss scale: 262144.0 | grad norm: 0.929 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 08:28:56] iteration   285800/  500000 | consumed samples:      2286400 | elapsed time per iteration (ms): 322.3 | learning rate: 1.406950E-05 | global batch size:     8 | lm loss: 2.994118E+00 | loss scale: 524288.0 | grad norm: 0.888 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 08:29:28] iteration   285900/  500000 | consumed samples:      2287200 | elapsed time per iteration (ms): 320.3 | learning rate: 1.404620E-05 | global batch size:     8 | lm loss: 2.993681E+00 | loss scale: 524288.0 | grad norm: 0.864 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 08:30:00] iteration   286000/  500000 | consumed samples:      2288000 | elapsed time per iteration (ms): 323.7 | learning rate: 1.402298E-05 | global batch size:     8 | lm loss: 2.970465E+00 | loss scale: 524288.0 | grad norm: 0.905 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1065.76, 1065.76)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 286000 | lm loss value: 3.621861E+00 | lm loss PPL: 3.740710E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 08:30:33] iteration   286100/  500000 | consumed samples:      2288800 | elapsed time per iteration (ms): 323.0 | learning rate: 1.399982E-05 | global batch size:     8 | lm loss: 3.011519E+00 | loss scale: 524288.0 | grad norm: 0.916 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 08:31:06] iteration   286200/  500000 | consumed samples:      2289600 | elapsed time per iteration (ms): 322.7 | learning rate: 1.397672E-05 | global batch size:     8 | lm loss: 3.004191E+00 | loss scale: 524288.0 | grad norm: 0.947 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 08:31:38] iteration   286300/  500000 | consumed samples:      2290400 | elapsed time per iteration (ms): 322.3 | learning rate: 1.395369E-05 | global batch size:     8 | lm loss: 3.013125E+00 | loss scale: 524288.0 | grad norm: 0.863 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 08:32:10] iteration   286400/  500000 | consumed samples:      2291200 | elapsed time per iteration (ms): 322.8 | learning rate: 1.393072E-05 | global batch size:     8 | lm loss: 3.055870E+00 | loss scale: 524288.0 | grad norm: 0.880 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 08:32:42] iteration   286500/  500000 | consumed samples:      2292000 | elapsed time per iteration (ms): 323.3 | learning rate: 1.390805E-05 | global batch size:     8 | lm loss: 2.960331E+00 | loss scale: 524288.0 | grad norm: 0.912 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-22 08:33:15] iteration   286600/  500000 | consumed samples:      2292800 | elapsed time per iteration (ms): 321.5 | learning rate: 1.388521E-05 | global batch size:     8 | lm loss: 3.021661E+00 | loss scale: 524288.0 | grad norm: 0.940 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 08:33:47] iteration   286700/  500000 | consumed samples:      2293600 | elapsed time per iteration (ms): 322.0 | learning rate: 1.386244E-05 | global batch size:     8 | lm loss: 2.994739E+00 | loss scale: 524288.0 | grad norm: 0.934 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 08:34:19] iteration   286800/  500000 | consumed samples:      2294400 | elapsed time per iteration (ms): 321.7 | learning rate: 1.383973E-05 | global batch size:     8 | lm loss: 3.016502E+00 | loss scale: 524288.0 | grad norm: 0.907 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 08:34:51] iteration   286900/  500000 | consumed samples:      2295200 | elapsed time per iteration (ms): 322.1 | learning rate: 1.381709E-05 | global batch size:     8 | lm loss: 2.980339E+00 | loss scale: 524288.0 | grad norm: 0.869 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 08:35:23] iteration   287000/  500000 | consumed samples:      2296000 | elapsed time per iteration (ms): 320.3 | learning rate: 1.379451E-05 | global batch size:     8 | lm loss: 2.941011E+00 | loss scale: 524288.0 | grad norm: 0.933 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1063.35, 1063.35)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 287000 | lm loss value: 3.777797E+00 | lm loss PPL: 4.371964E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 08:35:57] iteration   287100/  500000 | consumed samples:      2296800 | elapsed time per iteration (ms): 322.8 | learning rate: 1.377200E-05 | global batch size:     8 | lm loss: 2.955461E+00 | loss scale: 524288.0 | grad norm: 0.905 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 08:36:29] iteration   287200/  500000 | consumed samples:      2297600 | elapsed time per iteration (ms): 323.3 | learning rate: 1.374955E-05 | global batch size:     8 | lm loss: 2.990782E+00 | loss scale: 524288.0 | grad norm: 0.866 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 08:37:01] iteration   287300/  500000 | consumed samples:      2298400 | elapsed time per iteration (ms): 322.0 | learning rate: 1.372717E-05 | global batch size:     8 | lm loss: 3.014912E+00 | loss scale: 524288.0 | grad norm: 0.902 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 08:37:33] iteration   287400/  500000 | consumed samples:      2299200 | elapsed time per iteration (ms): 322.8 | learning rate: 1.370508E-05 | global batch size:     8 | lm loss: 2.996559E+00 | loss scale: 262144.0 | grad norm: 0.878 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-22 08:38:05] iteration   287500/  500000 | consumed samples:      2300000 | elapsed time per iteration (ms): 321.2 | learning rate: 1.368283E-05 | global batch size:     8 | lm loss: 2.972443E+00 | loss scale: 262144.0 | grad norm: 0.949 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 08:38:38] iteration   287600/  500000 | consumed samples:      2300800 | elapsed time per iteration (ms): 322.9 | learning rate: 1.366064E-05 | global batch size:     8 | lm loss: 3.008049E+00 | loss scale: 262144.0 | grad norm: 0.918 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 08:39:10] iteration   287700/  500000 | consumed samples:      2301600 | elapsed time per iteration (ms): 322.5 | learning rate: 1.363852E-05 | global batch size:     8 | lm loss: 3.004454E+00 | loss scale: 262144.0 | grad norm: 0.898 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 08:39:42] iteration   287800/  500000 | consumed samples:      2302400 | elapsed time per iteration (ms): 323.2 | learning rate: 1.361646E-05 | global batch size:     8 | lm loss: 3.018582E+00 | loss scale: 262144.0 | grad norm: 0.887 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 08:40:14] iteration   287900/  500000 | consumed samples:      2303200 | elapsed time per iteration (ms): 321.5 | learning rate: 1.359447E-05 | global batch size:     8 | lm loss: 2.994279E+00 | loss scale: 262144.0 | grad norm: 0.907 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 08:40:47] iteration   288000/  500000 | consumed samples:      2304000 | elapsed time per iteration (ms): 324.5 | learning rate: 1.357255E-05 | global batch size:     8 | lm loss: 2.991532E+00 | loss scale: 262144.0 | grad norm: 0.931 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1064.89, 1064.89)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 288000 | lm loss value: 3.694740E+00 | lm loss PPL: 4.023511E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 08:41:20] iteration   288100/  500000 | consumed samples:      2304800 | elapsed time per iteration (ms): 323.0 | learning rate: 1.355090E-05 | global batch size:     8 | lm loss: 2.954205E+00 | loss scale: 131072.0 | grad norm: 0.881 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-22 08:41:53] iteration   288200/  500000 | consumed samples:      2305600 | elapsed time per iteration (ms): 324.4 | learning rate: 1.352911E-05 | global batch size:     8 | lm loss: 2.982722E+00 | loss scale: 131072.0 | grad norm: 0.893 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 08:42:25] iteration   288300/  500000 | consumed samples:      2306400 | elapsed time per iteration (ms): 322.5 | learning rate: 1.350738E-05 | global batch size:     8 | lm loss: 3.062000E+00 | loss scale: 131072.0 | grad norm: 0.885 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 08:42:57] iteration   288400/  500000 | consumed samples:      2307200 | elapsed time per iteration (ms): 322.7 | learning rate: 1.348571E-05 | global batch size:     8 | lm loss: 2.982055E+00 | loss scale: 131072.0 | grad norm: 0.909 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 08:43:29] iteration   288500/  500000 | consumed samples:      2308000 | elapsed time per iteration (ms): 318.9 | learning rate: 1.346411E-05 | global batch size:     8 | lm loss: 2.947839E+00 | loss scale: 131072.0 | grad norm: 0.873 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 08:44:01] iteration   288600/  500000 | consumed samples:      2308800 | elapsed time per iteration (ms): 318.8 | learning rate: 1.344258E-05 | global batch size:     8 | lm loss: 2.952444E+00 | loss scale: 131072.0 | grad norm: 0.902 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 08:44:33] iteration   288700/  500000 | consumed samples:      2309600 | elapsed time per iteration (ms): 320.1 | learning rate: 1.342111E-05 | global batch size:     8 | lm loss: 2.948956E+00 | loss scale: 131072.0 | grad norm: 0.947 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 08:45:05] iteration   288800/  500000 | consumed samples:      2310400 | elapsed time per iteration (ms): 321.0 | learning rate: 1.339971E-05 | global batch size:     8 | lm loss: 2.993756E+00 | loss scale: 131072.0 | grad norm: 0.914 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 08:45:37] iteration   288900/  500000 | consumed samples:      2311200 | elapsed time per iteration (ms): 323.3 | learning rate: 1.337837E-05 | global batch size:     8 | lm loss: 2.975208E+00 | loss scale: 131072.0 | grad norm: 0.929 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 08:46:09] iteration   289000/  500000 | consumed samples:      2312000 | elapsed time per iteration (ms): 320.4 | learning rate: 1.335710E-05 | global batch size:     8 | lm loss: 2.988902E+00 | loss scale: 131072.0 | grad norm: 0.891 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1067.15, 1067.15)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 289000 | lm loss value: 3.599874E+00 | lm loss PPL: 3.659363E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 08:46:43] iteration   289100/  500000 | consumed samples:      2312800 | elapsed time per iteration (ms): 325.6 | learning rate: 1.333589E-05 | global batch size:     8 | lm loss: 3.013256E+00 | loss scale: 262144.0 | grad norm: 0.890 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 08:47:15] iteration   289200/  500000 | consumed samples:      2313600 | elapsed time per iteration (ms): 322.4 | learning rate: 1.331475E-05 | global batch size:     8 | lm loss: 2.953066E+00 | loss scale: 262144.0 | grad norm: 0.885 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 08:47:48] iteration   289300/  500000 | consumed samples:      2314400 | elapsed time per iteration (ms): 321.9 | learning rate: 1.329368E-05 | global batch size:     8 | lm loss: 3.017750E+00 | loss scale: 262144.0 | grad norm: 0.917 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 08:48:20] iteration   289400/  500000 | consumed samples:      2315200 | elapsed time per iteration (ms): 323.1 | learning rate: 1.327267E-05 | global batch size:     8 | lm loss: 2.954815E+00 | loss scale: 262144.0 | grad norm: 0.900 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 08:48:52] iteration   289500/  500000 | consumed samples:      2316000 | elapsed time per iteration (ms): 320.1 | learning rate: 1.325172E-05 | global batch size:     8 | lm loss: 2.970354E+00 | loss scale: 262144.0 | grad norm: 0.947 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 08:49:24] iteration   289600/  500000 | consumed samples:      2316800 | elapsed time per iteration (ms): 321.2 | learning rate: 1.323084E-05 | global batch size:     8 | lm loss: 2.986241E+00 | loss scale: 262144.0 | grad norm: 0.921 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 08:49:56] iteration   289700/  500000 | consumed samples:      2317600 | elapsed time per iteration (ms): 320.9 | learning rate: 1.321003E-05 | global batch size:     8 | lm loss: 3.013546E+00 | loss scale: 262144.0 | grad norm: 0.893 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 08:50:28] iteration   289800/  500000 | consumed samples:      2318400 | elapsed time per iteration (ms): 318.7 | learning rate: 1.318928E-05 | global batch size:     8 | lm loss: 3.002337E+00 | loss scale: 262144.0 | grad norm: 0.916 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 08:51:00] iteration   289900/  500000 | consumed samples:      2319200 | elapsed time per iteration (ms): 320.3 | learning rate: 1.316860E-05 | global batch size:     8 | lm loss: 2.990967E+00 | loss scale: 262144.0 | grad norm: 0.939 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 08:51:32] iteration   290000/  500000 | consumed samples:      2320000 | elapsed time per iteration (ms): 322.1 | learning rate: 1.314799E-05 | global batch size:     8 | lm loss: 3.017176E+00 | loss scale: 262144.0 | grad norm: 0.902 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1064.59, 1064.59)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 290000 | lm loss value: 3.634860E+00 | lm loss PPL: 3.789654E+01 | 
--------------------------------------------------------------------------------------------------
saving checkpoint at iteration  290000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-max in torch format
  successfully saved checkpoint at iteration  290000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-max
(min, max) time across ranks (ms):
    save-checkpoint ................................: (5551.98, 5551.98)
 [2024-06-22 08:52:11] iteration   290100/  500000 | consumed samples:      2320800 | elapsed time per iteration (ms): 319.9 | learning rate: 1.312744E-05 | global batch size:     8 | lm loss: 2.980350E+00 | loss scale: 524288.0 | grad norm: 0.908 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 08:52:43] iteration   290200/  500000 | consumed samples:      2321600 | elapsed time per iteration (ms): 319.9 | learning rate: 1.310695E-05 | global batch size:     8 | lm loss: 2.992166E+00 | loss scale: 524288.0 | grad norm: 0.929 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 08:53:15] iteration   290300/  500000 | consumed samples:      2322400 | elapsed time per iteration (ms): 322.2 | learning rate: 1.308653E-05 | global batch size:     8 | lm loss: 3.002708E+00 | loss scale: 524288.0 | grad norm: 0.918 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 08:53:47] iteration   290400/  500000 | consumed samples:      2323200 | elapsed time per iteration (ms): 323.1 | learning rate: 1.306618E-05 | global batch size:     8 | lm loss: 2.998046E+00 | loss scale: 524288.0 | grad norm: 0.897 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 08:54:20] iteration   290500/  500000 | consumed samples:      2324000 | elapsed time per iteration (ms): 323.4 | learning rate: 1.304589E-05 | global batch size:     8 | lm loss: 2.979949E+00 | loss scale: 524288.0 | grad norm: 0.878 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 08:54:52] iteration   290600/  500000 | consumed samples:      2324800 | elapsed time per iteration (ms): 324.2 | learning rate: 1.302567E-05 | global batch size:     8 | lm loss: 2.970642E+00 | loss scale: 524288.0 | grad norm: 0.915 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 08:55:24] iteration   290700/  500000 | consumed samples:      2325600 | elapsed time per iteration (ms): 320.0 | learning rate: 1.300552E-05 | global batch size:     8 | lm loss: 3.000211E+00 | loss scale: 524288.0 | grad norm: 0.915 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 08:55:56] iteration   290800/  500000 | consumed samples:      2326400 | elapsed time per iteration (ms): 323.3 | learning rate: 1.298543E-05 | global batch size:     8 | lm loss: 3.008025E+00 | loss scale: 524288.0 | grad norm: 0.907 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 08:56:29] iteration   290900/  500000 | consumed samples:      2327200 | elapsed time per iteration (ms): 321.3 | learning rate: 1.296541E-05 | global batch size:     8 | lm loss: 3.022322E+00 | loss scale: 524288.0 | grad norm: 0.894 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 08:57:01] iteration   291000/  500000 | consumed samples:      2328000 | elapsed time per iteration (ms): 322.0 | learning rate: 1.294545E-05 | global batch size:     8 | lm loss: 3.010330E+00 | loss scale: 524288.0 | grad norm: 0.877 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1064.87, 1064.87)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 291000 | lm loss value: 3.684669E+00 | lm loss PPL: 3.983193E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 08:57:34] iteration   291100/  500000 | consumed samples:      2328800 | elapsed time per iteration (ms): 322.8 | learning rate: 1.292575E-05 | global batch size:     8 | lm loss: 2.976535E+00 | loss scale: 1048576.0 | grad norm: 0.946 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-22 08:58:06] iteration   291200/  500000 | consumed samples:      2329600 | elapsed time per iteration (ms): 320.1 | learning rate: 1.290613E-05 | global batch size:     8 | lm loss: 2.964015E+00 | loss scale: 524288.0 | grad norm: 0.896 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-22 08:58:38] iteration   291300/  500000 | consumed samples:      2330400 | elapsed time per iteration (ms): 323.0 | learning rate: 1.288637E-05 | global batch size:     8 | lm loss: 2.977079E+00 | loss scale: 524288.0 | grad norm: 0.958 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 08:59:11] iteration   291400/  500000 | consumed samples:      2331200 | elapsed time per iteration (ms): 322.7 | learning rate: 1.286667E-05 | global batch size:     8 | lm loss: 2.972127E+00 | loss scale: 524288.0 | grad norm: 0.893 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 08:59:43] iteration   291500/  500000 | consumed samples:      2332000 | elapsed time per iteration (ms): 321.5 | learning rate: 1.284704E-05 | global batch size:     8 | lm loss: 2.986760E+00 | loss scale: 524288.0 | grad norm: 0.871 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 09:00:15] iteration   291600/  500000 | consumed samples:      2332800 | elapsed time per iteration (ms): 321.1 | learning rate: 1.282748E-05 | global batch size:     8 | lm loss: 3.000156E+00 | loss scale: 524288.0 | grad norm: 0.911 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 09:00:47] iteration   291700/  500000 | consumed samples:      2333600 | elapsed time per iteration (ms): 323.0 | learning rate: 1.280798E-05 | global batch size:     8 | lm loss: 2.992982E+00 | loss scale: 524288.0 | grad norm: 0.943 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 09:01:19] iteration   291800/  500000 | consumed samples:      2334400 | elapsed time per iteration (ms): 320.4 | learning rate: 1.278855E-05 | global batch size:     8 | lm loss: 3.026478E+00 | loss scale: 524288.0 | grad norm: 0.908 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 09:01:52] iteration   291900/  500000 | consumed samples:      2335200 | elapsed time per iteration (ms): 322.7 | learning rate: 1.276919E-05 | global batch size:     8 | lm loss: 2.950235E+00 | loss scale: 524288.0 | grad norm: 0.983 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 09:02:24] iteration   292000/  500000 | consumed samples:      2336000 | elapsed time per iteration (ms): 323.5 | learning rate: 1.274989E-05 | global batch size:     8 | lm loss: 3.005867E+00 | loss scale: 524288.0 | grad norm: 0.922 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1064.65, 1064.65)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 292000 | lm loss value: 3.621938E+00 | lm loss PPL: 3.741000E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 09:02:57] iteration   292100/  500000 | consumed samples:      2336800 | elapsed time per iteration (ms): 323.4 | learning rate: 1.273066E-05 | global batch size:     8 | lm loss: 2.970752E+00 | loss scale: 524288.0 | grad norm: 0.912 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 09:03:29] iteration   292200/  500000 | consumed samples:      2337600 | elapsed time per iteration (ms): 322.2 | learning rate: 1.271187E-05 | global batch size:     8 | lm loss: 3.034878E+00 | loss scale: 524288.0 | grad norm: 0.902 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-22 09:04:02] iteration   292300/  500000 | consumed samples:      2338400 | elapsed time per iteration (ms): 320.2 | learning rate: 1.269277E-05 | global batch size:     8 | lm loss: 3.011471E+00 | loss scale: 524288.0 | grad norm: 0.924 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 09:04:34] iteration   292400/  500000 | consumed samples:      2339200 | elapsed time per iteration (ms): 322.8 | learning rate: 1.267374E-05 | global batch size:     8 | lm loss: 2.980045E+00 | loss scale: 524288.0 | grad norm: 0.906 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 09:05:06] iteration   292500/  500000 | consumed samples:      2340000 | elapsed time per iteration (ms): 321.8 | learning rate: 1.265477E-05 | global batch size:     8 | lm loss: 2.990842E+00 | loss scale: 524288.0 | grad norm: 0.929 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 09:05:38] iteration   292600/  500000 | consumed samples:      2340800 | elapsed time per iteration (ms): 320.5 | learning rate: 1.263586E-05 | global batch size:     8 | lm loss: 3.038630E+00 | loss scale: 524288.0 | grad norm: 0.926 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 09:06:10] iteration   292700/  500000 | consumed samples:      2341600 | elapsed time per iteration (ms): 322.5 | learning rate: 1.261703E-05 | global batch size:     8 | lm loss: 2.954464E+00 | loss scale: 524288.0 | grad norm: 0.910 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 09:06:43] iteration   292800/  500000 | consumed samples:      2342400 | elapsed time per iteration (ms): 322.8 | learning rate: 1.259826E-05 | global batch size:     8 | lm loss: 2.991974E+00 | loss scale: 524288.0 | grad norm: 0.908 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 09:07:15] iteration   292900/  500000 | consumed samples:      2343200 | elapsed time per iteration (ms): 321.3 | learning rate: 1.257955E-05 | global batch size:     8 | lm loss: 2.999350E+00 | loss scale: 524288.0 | grad norm: 0.908 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 09:07:47] iteration   293000/  500000 | consumed samples:      2344000 | elapsed time per iteration (ms): 321.2 | learning rate: 1.256092E-05 | global batch size:     8 | lm loss: 3.013132E+00 | loss scale: 524288.0 | grad norm: 0.981 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1066.90, 1066.90)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 293000 | lm loss value: 3.730958E+00 | lm loss PPL: 4.171905E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 09:08:20] iteration   293100/  500000 | consumed samples:      2344800 | elapsed time per iteration (ms): 320.5 | learning rate: 1.254234E-05 | global batch size:     8 | lm loss: 2.997457E+00 | loss scale: 524288.0 | grad norm: 0.895 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 09:08:52] iteration   293200/  500000 | consumed samples:      2345600 | elapsed time per iteration (ms): 323.9 | learning rate: 1.252421E-05 | global batch size:     8 | lm loss: 2.969481E+00 | loss scale: 524288.0 | grad norm: 0.908 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-22 09:09:24] iteration   293300/  500000 | consumed samples:      2346400 | elapsed time per iteration (ms): 319.9 | learning rate: 1.250577E-05 | global batch size:     8 | lm loss: 2.965867E+00 | loss scale: 524288.0 | grad norm: 0.915 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 09:09:56] iteration   293400/  500000 | consumed samples:      2347200 | elapsed time per iteration (ms): 320.4 | learning rate: 1.248740E-05 | global batch size:     8 | lm loss: 2.944939E+00 | loss scale: 524288.0 | grad norm: 0.885 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 09:10:29] iteration   293500/  500000 | consumed samples:      2348000 | elapsed time per iteration (ms): 321.5 | learning rate: 1.246909E-05 | global batch size:     8 | lm loss: 2.979767E+00 | loss scale: 524288.0 | grad norm: 0.905 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 09:11:01] iteration   293600/  500000 | consumed samples:      2348800 | elapsed time per iteration (ms): 320.6 | learning rate: 1.245085E-05 | global batch size:     8 | lm loss: 2.960264E+00 | loss scale: 524288.0 | grad norm: 0.893 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 09:11:33] iteration   293700/  500000 | consumed samples:      2349600 | elapsed time per iteration (ms): 322.1 | learning rate: 1.243285E-05 | global batch size:     8 | lm loss: 2.953337E+00 | loss scale: 262144.0 | grad norm: 0.905 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-22 09:12:05] iteration   293800/  500000 | consumed samples:      2350400 | elapsed time per iteration (ms): 320.7 | learning rate: 1.241475E-05 | global batch size:     8 | lm loss: 3.001255E+00 | loss scale: 262144.0 | grad norm: 0.874 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 09:12:37] iteration   293900/  500000 | consumed samples:      2351200 | elapsed time per iteration (ms): 322.3 | learning rate: 1.239670E-05 | global batch size:     8 | lm loss: 2.966571E+00 | loss scale: 262144.0 | grad norm: 0.912 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 09:13:09] iteration   294000/  500000 | consumed samples:      2352000 | elapsed time per iteration (ms): 321.5 | learning rate: 1.237873E-05 | global batch size:     8 | lm loss: 2.979994E+00 | loss scale: 262144.0 | grad norm: 0.957 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1065.32, 1065.32)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 294000 | lm loss value: 3.774845E+00 | lm loss PPL: 4.359076E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 09:13:43] iteration   294100/  500000 | consumed samples:      2352800 | elapsed time per iteration (ms): 323.1 | learning rate: 1.236082E-05 | global batch size:     8 | lm loss: 2.961272E+00 | loss scale: 262144.0 | grad norm: 0.979 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 09:14:15] iteration   294200/  500000 | consumed samples:      2353600 | elapsed time per iteration (ms): 320.3 | learning rate: 1.234298E-05 | global batch size:     8 | lm loss: 2.958084E+00 | loss scale: 262144.0 | grad norm: 0.953 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 09:14:47] iteration   294300/  500000 | consumed samples:      2354400 | elapsed time per iteration (ms): 322.3 | learning rate: 1.232520E-05 | global batch size:     8 | lm loss: 2.986496E+00 | loss scale: 262144.0 | grad norm: 0.945 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 09:15:19] iteration   294400/  500000 | consumed samples:      2355200 | elapsed time per iteration (ms): 319.6 | learning rate: 1.230749E-05 | global batch size:     8 | lm loss: 2.989903E+00 | loss scale: 262144.0 | grad norm: 0.901 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 09:15:51] iteration   294500/  500000 | consumed samples:      2356000 | elapsed time per iteration (ms): 322.4 | learning rate: 1.228985E-05 | global batch size:     8 | lm loss: 3.007414E+00 | loss scale: 262144.0 | grad norm: 0.898 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 09:16:23] iteration   294600/  500000 | consumed samples:      2356800 | elapsed time per iteration (ms): 322.2 | learning rate: 1.227227E-05 | global batch size:     8 | lm loss: 2.950167E+00 | loss scale: 262144.0 | grad norm: 0.926 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 09:16:55] iteration   294700/  500000 | consumed samples:      2357600 | elapsed time per iteration (ms): 322.0 | learning rate: 1.225476E-05 | global batch size:     8 | lm loss: 2.999495E+00 | loss scale: 524288.0 | grad norm: 0.909 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 09:17:28] iteration   294800/  500000 | consumed samples:      2358400 | elapsed time per iteration (ms): 322.0 | learning rate: 1.223732E-05 | global batch size:     8 | lm loss: 2.994139E+00 | loss scale: 524288.0 | grad norm: 0.855 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 09:18:00] iteration   294900/  500000 | consumed samples:      2359200 | elapsed time per iteration (ms): 320.9 | learning rate: 1.221994E-05 | global batch size:     8 | lm loss: 2.995632E+00 | loss scale: 524288.0 | grad norm: 0.863 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 09:18:32] iteration   295000/  500000 | consumed samples:      2360000 | elapsed time per iteration (ms): 319.9 | learning rate: 1.220281E-05 | global batch size:     8 | lm loss: 3.004382E+00 | loss scale: 524288.0 | grad norm: 0.916 | number of skipped iterations:   1 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1065.60, 1065.60)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 295000 | lm loss value: 3.732028E+00 | lm loss PPL: 4.176370E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 09:19:05] iteration   295100/  500000 | consumed samples:      2360800 | elapsed time per iteration (ms): 322.5 | learning rate: 1.218573E-05 | global batch size:     8 | lm loss: 2.965892E+00 | loss scale: 262144.0 | grad norm: 0.900 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-22 09:19:37] iteration   295200/  500000 | consumed samples:      2361600 | elapsed time per iteration (ms): 323.1 | learning rate: 1.216856E-05 | global batch size:     8 | lm loss: 2.988499E+00 | loss scale: 262144.0 | grad norm: 0.952 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 09:20:10] iteration   295300/  500000 | consumed samples:      2362400 | elapsed time per iteration (ms): 322.0 | learning rate: 1.215144E-05 | global batch size:     8 | lm loss: 3.024431E+00 | loss scale: 262144.0 | grad norm: 0.902 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 09:20:42] iteration   295400/  500000 | consumed samples:      2363200 | elapsed time per iteration (ms): 323.2 | learning rate: 1.213440E-05 | global batch size:     8 | lm loss: 3.034618E+00 | loss scale: 262144.0 | grad norm: 0.925 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 09:21:14] iteration   295500/  500000 | consumed samples:      2364000 | elapsed time per iteration (ms): 321.7 | learning rate: 1.211742E-05 | global batch size:     8 | lm loss: 3.007785E+00 | loss scale: 262144.0 | grad norm: 0.934 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 09:21:46] iteration   295600/  500000 | consumed samples:      2364800 | elapsed time per iteration (ms): 320.9 | learning rate: 1.210051E-05 | global batch size:     8 | lm loss: 2.993707E+00 | loss scale: 262144.0 | grad norm: 0.902 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 09:22:18] iteration   295700/  500000 | consumed samples:      2365600 | elapsed time per iteration (ms): 321.3 | learning rate: 1.208367E-05 | global batch size:     8 | lm loss: 2.979226E+00 | loss scale: 262144.0 | grad norm: 0.937 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 09:22:51] iteration   295800/  500000 | consumed samples:      2366400 | elapsed time per iteration (ms): 323.4 | learning rate: 1.206689E-05 | global batch size:     8 | lm loss: 3.006015E+00 | loss scale: 262144.0 | grad norm: 0.966 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 09:23:23] iteration   295900/  500000 | consumed samples:      2367200 | elapsed time per iteration (ms): 322.7 | learning rate: 1.205018E-05 | global batch size:     8 | lm loss: 3.000552E+00 | loss scale: 262144.0 | grad norm: 0.909 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 09:23:55] iteration   296000/  500000 | consumed samples:      2368000 | elapsed time per iteration (ms): 320.4 | learning rate: 1.203354E-05 | global batch size:     8 | lm loss: 2.975077E+00 | loss scale: 262144.0 | grad norm: 0.888 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1063.11, 1063.11)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 296000 | lm loss value: 3.741669E+00 | lm loss PPL: 4.216832E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 09:24:28] iteration   296100/  500000 | consumed samples:      2368800 | elapsed time per iteration (ms): 322.4 | learning rate: 1.201696E-05 | global batch size:     8 | lm loss: 2.959384E+00 | loss scale: 524288.0 | grad norm: 0.920 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 09:25:01] iteration   296200/  500000 | consumed samples:      2369600 | elapsed time per iteration (ms): 323.6 | learning rate: 1.200045E-05 | global batch size:     8 | lm loss: 2.981288E+00 | loss scale: 524288.0 | grad norm: 0.903 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 09:25:32] iteration   296300/  500000 | consumed samples:      2370400 | elapsed time per iteration (ms): 318.8 | learning rate: 1.198401E-05 | global batch size:     8 | lm loss: 2.973376E+00 | loss scale: 524288.0 | grad norm: 0.922 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 09:26:05] iteration   296400/  500000 | consumed samples:      2371200 | elapsed time per iteration (ms): 321.6 | learning rate: 1.196763E-05 | global batch size:     8 | lm loss: 2.977482E+00 | loss scale: 524288.0 | grad norm: 0.915 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 09:26:37] iteration   296500/  500000 | consumed samples:      2372000 | elapsed time per iteration (ms): 321.0 | learning rate: 1.195132E-05 | global batch size:     8 | lm loss: 2.981542E+00 | loss scale: 524288.0 | grad norm: 0.948 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 09:27:09] iteration   296600/  500000 | consumed samples:      2372800 | elapsed time per iteration (ms): 322.5 | learning rate: 1.193508E-05 | global batch size:     8 | lm loss: 2.969868E+00 | loss scale: 524288.0 | grad norm: 0.872 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 09:27:41] iteration   296700/  500000 | consumed samples:      2373600 | elapsed time per iteration (ms): 321.6 | learning rate: 1.191890E-05 | global batch size:     8 | lm loss: 2.942660E+00 | loss scale: 524288.0 | grad norm: 0.910 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 09:28:13] iteration   296800/  500000 | consumed samples:      2374400 | elapsed time per iteration (ms): 321.5 | learning rate: 1.190279E-05 | global batch size:     8 | lm loss: 2.966912E+00 | loss scale: 524288.0 | grad norm: 0.869 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 09:28:46] iteration   296900/  500000 | consumed samples:      2375200 | elapsed time per iteration (ms): 323.0 | learning rate: 1.188675E-05 | global batch size:     8 | lm loss: 3.023684E+00 | loss scale: 524288.0 | grad norm: 0.980 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 09:29:18] iteration   297000/  500000 | consumed samples:      2376000 | elapsed time per iteration (ms): 322.9 | learning rate: 1.187078E-05 | global batch size:     8 | lm loss: 2.963978E+00 | loss scale: 524288.0 | grad norm: 0.920 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1067.43, 1067.43)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 297000 | lm loss value: 3.725218E+00 | lm loss PPL: 4.148026E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 09:29:51] iteration   297100/  500000 | consumed samples:      2376800 | elapsed time per iteration (ms): 322.3 | learning rate: 1.185519E-05 | global batch size:     8 | lm loss: 2.971988E+00 | loss scale: 524288.0 | grad norm: 0.906 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-22 09:30:24] iteration   297200/  500000 | consumed samples:      2377600 | elapsed time per iteration (ms): 325.0 | learning rate: 1.183935E-05 | global batch size:     8 | lm loss: 2.992206E+00 | loss scale: 524288.0 | grad norm: 0.933 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 09:30:56] iteration   297300/  500000 | consumed samples:      2378400 | elapsed time per iteration (ms): 323.3 | learning rate: 1.182357E-05 | global batch size:     8 | lm loss: 2.968126E+00 | loss scale: 524288.0 | grad norm: 0.887 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 09:31:28] iteration   297400/  500000 | consumed samples:      2379200 | elapsed time per iteration (ms): 320.0 | learning rate: 1.180802E-05 | global batch size:     8 | lm loss: 3.009731E+00 | loss scale: 262144.0 | grad norm: 0.925 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-22 09:32:00] iteration   297500/  500000 | consumed samples:      2380000 | elapsed time per iteration (ms): 323.2 | learning rate: 1.179238E-05 | global batch size:     8 | lm loss: 3.001378E+00 | loss scale: 262144.0 | grad norm: 0.955 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 09:32:33] iteration   297600/  500000 | consumed samples:      2380800 | elapsed time per iteration (ms): 323.6 | learning rate: 1.177680E-05 | global batch size:     8 | lm loss: 3.002783E+00 | loss scale: 262144.0 | grad norm: 0.939 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 09:33:05] iteration   297700/  500000 | consumed samples:      2381600 | elapsed time per iteration (ms): 323.0 | learning rate: 1.176130E-05 | global batch size:     8 | lm loss: 2.950831E+00 | loss scale: 262144.0 | grad norm: 0.855 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 09:33:37] iteration   297800/  500000 | consumed samples:      2382400 | elapsed time per iteration (ms): 321.3 | learning rate: 1.174586E-05 | global batch size:     8 | lm loss: 2.948323E+00 | loss scale: 262144.0 | grad norm: 1.038 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 09:34:09] iteration   297900/  500000 | consumed samples:      2383200 | elapsed time per iteration (ms): 320.3 | learning rate: 1.173048E-05 | global batch size:     8 | lm loss: 2.965100E+00 | loss scale: 262144.0 | grad norm: 0.886 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 09:34:41] iteration   298000/  500000 | consumed samples:      2384000 | elapsed time per iteration (ms): 322.3 | learning rate: 1.171518E-05 | global batch size:     8 | lm loss: 2.955249E+00 | loss scale: 262144.0 | grad norm: 0.903 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1068.15, 1068.15)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 298000 | lm loss value: 3.574287E+00 | lm loss PPL: 3.566917E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 09:35:15] iteration   298100/  500000 | consumed samples:      2384800 | elapsed time per iteration (ms): 322.2 | learning rate: 1.169994E-05 | global batch size:     8 | lm loss: 2.978502E+00 | loss scale: 262144.0 | grad norm: 0.893 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 09:35:47] iteration   298200/  500000 | consumed samples:      2385600 | elapsed time per iteration (ms): 323.9 | learning rate: 1.168477E-05 | global batch size:     8 | lm loss: 2.967847E+00 | loss scale: 262144.0 | grad norm: 0.938 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 09:36:19] iteration   298300/  500000 | consumed samples:      2386400 | elapsed time per iteration (ms): 320.6 | learning rate: 1.166966E-05 | global batch size:     8 | lm loss: 2.972394E+00 | loss scale: 262144.0 | grad norm: 0.880 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 09:36:51] iteration   298400/  500000 | consumed samples:      2387200 | elapsed time per iteration (ms): 321.8 | learning rate: 1.165463E-05 | global batch size:     8 | lm loss: 2.998727E+00 | loss scale: 524288.0 | grad norm: 0.906 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 09:37:24] iteration   298500/  500000 | consumed samples:      2388000 | elapsed time per iteration (ms): 323.3 | learning rate: 1.163966E-05 | global batch size:     8 | lm loss: 2.968124E+00 | loss scale: 524288.0 | grad norm: 0.831 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 09:37:56] iteration   298600/  500000 | consumed samples:      2388800 | elapsed time per iteration (ms): 322.0 | learning rate: 1.162490E-05 | global batch size:     8 | lm loss: 2.989763E+00 | loss scale: 524288.0 | grad norm: 0.912 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-22 09:38:29] iteration   298700/  500000 | consumed samples:      2389600 | elapsed time per iteration (ms): 326.6 | learning rate: 1.161006E-05 | global batch size:     8 | lm loss: 2.996439E+00 | loss scale: 524288.0 | grad norm: 0.900 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 09:39:01] iteration   298800/  500000 | consumed samples:      2390400 | elapsed time per iteration (ms): 322.9 | learning rate: 1.159530E-05 | global batch size:     8 | lm loss: 2.974270E+00 | loss scale: 524288.0 | grad norm: 0.916 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 09:39:33] iteration   298900/  500000 | consumed samples:      2391200 | elapsed time per iteration (ms): 322.2 | learning rate: 1.158059E-05 | global batch size:     8 | lm loss: 2.988889E+00 | loss scale: 524288.0 | grad norm: 0.932 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 09:40:05] iteration   299000/  500000 | consumed samples:      2392000 | elapsed time per iteration (ms): 321.8 | learning rate: 1.156596E-05 | global batch size:     8 | lm loss: 2.983696E+00 | loss scale: 524288.0 | grad norm: 0.923 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1067.79, 1067.79)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 299000 | lm loss value: 3.725246E+00 | lm loss PPL: 4.148145E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 09:40:38] iteration   299100/  500000 | consumed samples:      2392800 | elapsed time per iteration (ms): 321.5 | learning rate: 1.155139E-05 | global batch size:     8 | lm loss: 2.959899E+00 | loss scale: 524288.0 | grad norm: 0.897 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 09:41:11] iteration   299200/  500000 | consumed samples:      2393600 | elapsed time per iteration (ms): 322.0 | learning rate: 1.153689E-05 | global batch size:     8 | lm loss: 2.979521E+00 | loss scale: 524288.0 | grad norm: 0.941 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 09:41:43] iteration   299300/  500000 | consumed samples:      2394400 | elapsed time per iteration (ms): 322.0 | learning rate: 1.152246E-05 | global batch size:     8 | lm loss: 2.951015E+00 | loss scale: 524288.0 | grad norm: 0.954 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 09:42:15] iteration   299400/  500000 | consumed samples:      2395200 | elapsed time per iteration (ms): 320.5 | learning rate: 1.150809E-05 | global batch size:     8 | lm loss: 2.974538E+00 | loss scale: 524288.0 | grad norm: 0.934 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 09:42:47] iteration   299500/  500000 | consumed samples:      2396000 | elapsed time per iteration (ms): 322.9 | learning rate: 1.149380E-05 | global batch size:     8 | lm loss: 2.933289E+00 | loss scale: 524288.0 | grad norm: 0.896 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 09:43:19] iteration   299600/  500000 | consumed samples:      2396800 | elapsed time per iteration (ms): 322.4 | learning rate: 1.147971E-05 | global batch size:     8 | lm loss: 2.930763E+00 | loss scale: 1048576.0 | grad norm: 0.940 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-22 09:43:52] iteration   299700/  500000 | consumed samples:      2397600 | elapsed time per iteration (ms): 321.8 | learning rate: 1.146569E-05 | global batch size:     8 | lm loss: 2.978679E+00 | loss scale: 524288.0 | grad norm: 0.885 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-22 09:44:24] iteration   299800/  500000 | consumed samples:      2398400 | elapsed time per iteration (ms): 321.7 | learning rate: 1.145159E-05 | global batch size:     8 | lm loss: 2.968977E+00 | loss scale: 524288.0 | grad norm: 0.881 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 09:44:56] iteration   299900/  500000 | consumed samples:      2399200 | elapsed time per iteration (ms): 324.0 | learning rate: 1.143756E-05 | global batch size:     8 | lm loss: 2.981128E+00 | loss scale: 524288.0 | grad norm: 0.966 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 09:45:28] iteration   300000/  500000 | consumed samples:      2400000 | elapsed time per iteration (ms): 320.4 | learning rate: 1.142360E-05 | global batch size:     8 | lm loss: 3.052435E+00 | loss scale: 524288.0 | grad norm: 0.940 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1065.49, 1065.49)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 300000 | lm loss value: 3.703450E+00 | lm loss PPL: 4.058711E+01 | 
--------------------------------------------------------------------------------------------------
saving checkpoint at iteration  300000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-max in torch format
  successfully saved checkpoint at iteration  300000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-max
(min, max) time across ranks (ms):
    save-checkpoint ................................: (5579.33, 5579.33)
 [2024-06-22 09:46:07] iteration   300100/  500000 | consumed samples:      2400800 | elapsed time per iteration (ms): 319.8 | learning rate: 1.140970E-05 | global batch size:     8 | lm loss: 2.996892E+00 | loss scale: 524288.0 | grad norm: 0.957 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 09:46:39] iteration   300200/  500000 | consumed samples:      2401600 | elapsed time per iteration (ms): 322.2 | learning rate: 1.139588E-05 | global batch size:     8 | lm loss: 2.969501E+00 | loss scale: 524288.0 | grad norm: 0.886 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 09:47:11] iteration   300300/  500000 | consumed samples:      2402400 | elapsed time per iteration (ms): 323.7 | learning rate: 1.138212E-05 | global batch size:     8 | lm loss: 2.950965E+00 | loss scale: 524288.0 | grad norm: 0.900 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 09:47:44] iteration   300400/  500000 | consumed samples:      2403200 | elapsed time per iteration (ms): 321.9 | learning rate: 1.136842E-05 | global batch size:     8 | lm loss: 2.949764E+00 | loss scale: 524288.0 | grad norm: 0.897 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 09:48:16] iteration   300500/  500000 | consumed samples:      2404000 | elapsed time per iteration (ms): 323.8 | learning rate: 1.135480E-05 | global batch size:     8 | lm loss: 2.958412E+00 | loss scale: 524288.0 | grad norm: 0.913 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 09:48:48] iteration   300600/  500000 | consumed samples:      2404800 | elapsed time per iteration (ms): 320.4 | learning rate: 1.134124E-05 | global batch size:     8 | lm loss: 2.983399E+00 | loss scale: 524288.0 | grad norm: 0.880 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 09:49:20] iteration   300700/  500000 | consumed samples:      2405600 | elapsed time per iteration (ms): 317.6 | learning rate: 1.132802E-05 | global batch size:     8 | lm loss: 2.980297E+00 | loss scale: 524288.0 | grad norm: 1.000 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-22 09:49:52] iteration   300800/  500000 | consumed samples:      2406400 | elapsed time per iteration (ms): 323.2 | learning rate: 1.131460E-05 | global batch size:     8 | lm loss: 2.975294E+00 | loss scale: 524288.0 | grad norm: 0.917 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 09:50:24] iteration   300900/  500000 | consumed samples:      2407200 | elapsed time per iteration (ms): 320.2 | learning rate: 1.130124E-05 | global batch size:     8 | lm loss: 2.997361E+00 | loss scale: 524288.0 | grad norm: 0.873 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 09:50:56] iteration   301000/  500000 | consumed samples:      2408000 | elapsed time per iteration (ms): 321.4 | learning rate: 1.128795E-05 | global batch size:     8 | lm loss: 2.998640E+00 | loss scale: 524288.0 | grad norm: 0.934 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1067.74, 1067.74)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 301000 | lm loss value: 3.648430E+00 | lm loss PPL: 3.841429E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 09:51:29] iteration   301100/  500000 | consumed samples:      2408800 | elapsed time per iteration (ms): 319.5 | learning rate: 1.127473E-05 | global batch size:     8 | lm loss: 3.020694E+00 | loss scale: 524288.0 | grad norm: 0.935 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 09:52:01] iteration   301200/  500000 | consumed samples:      2409600 | elapsed time per iteration (ms): 321.8 | learning rate: 1.126158E-05 | global batch size:     8 | lm loss: 2.986224E+00 | loss scale: 524288.0 | grad norm: 0.938 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 09:52:34] iteration   301300/  500000 | consumed samples:      2410400 | elapsed time per iteration (ms): 321.9 | learning rate: 1.124849E-05 | global batch size:     8 | lm loss: 2.935702E+00 | loss scale: 524288.0 | grad norm: 0.945 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 09:53:06] iteration   301400/  500000 | consumed samples:      2411200 | elapsed time per iteration (ms): 321.7 | learning rate: 1.123547E-05 | global batch size:     8 | lm loss: 2.977487E+00 | loss scale: 524288.0 | grad norm: 0.987 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 09:53:38] iteration   301500/  500000 | consumed samples:      2412000 | elapsed time per iteration (ms): 322.4 | learning rate: 1.122252E-05 | global batch size:     8 | lm loss: 2.993861E+00 | loss scale: 524288.0 | grad norm: 0.982 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 09:54:10] iteration   301600/  500000 | consumed samples:      2412800 | elapsed time per iteration (ms): 324.0 | learning rate: 1.120964E-05 | global batch size:     8 | lm loss: 2.984571E+00 | loss scale: 524288.0 | grad norm: 0.937 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 09:54:43] iteration   301700/  500000 | consumed samples:      2413600 | elapsed time per iteration (ms): 323.7 | learning rate: 1.119708E-05 | global batch size:     8 | lm loss: 2.971685E+00 | loss scale: 524288.0 | grad norm: 0.875 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-22 09:55:15] iteration   301800/  500000 | consumed samples:      2414400 | elapsed time per iteration (ms): 322.7 | learning rate: 1.118433E-05 | global batch size:     8 | lm loss: 2.979444E+00 | loss scale: 524288.0 | grad norm: 0.996 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 09:55:47] iteration   301900/  500000 | consumed samples:      2415200 | elapsed time per iteration (ms): 322.9 | learning rate: 1.117165E-05 | global batch size:     8 | lm loss: 2.977897E+00 | loss scale: 524288.0 | grad norm: 0.826 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 09:56:20] iteration   302000/  500000 | consumed samples:      2416000 | elapsed time per iteration (ms): 323.0 | learning rate: 1.115904E-05 | global batch size:     8 | lm loss: 2.997104E+00 | loss scale: 524288.0 | grad norm: 0.951 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1064.16, 1064.16)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 302000 | lm loss value: 3.689980E+00 | lm loss PPL: 4.004406E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 09:56:53] iteration   302100/  500000 | consumed samples:      2416800 | elapsed time per iteration (ms): 321.1 | learning rate: 1.114649E-05 | global batch size:     8 | lm loss: 2.976102E+00 | loss scale: 524288.0 | grad norm: 0.912 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 09:57:25] iteration   302200/  500000 | consumed samples:      2417600 | elapsed time per iteration (ms): 320.9 | learning rate: 1.113401E-05 | global batch size:     8 | lm loss: 2.999703E+00 | loss scale: 524288.0 | grad norm: 0.890 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 09:57:57] iteration   302300/  500000 | consumed samples:      2418400 | elapsed time per iteration (ms): 322.1 | learning rate: 1.112160E-05 | global batch size:     8 | lm loss: 2.955045E+00 | loss scale: 524288.0 | grad norm: 0.913 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 09:58:29] iteration   302400/  500000 | consumed samples:      2419200 | elapsed time per iteration (ms): 321.1 | learning rate: 1.110926E-05 | global batch size:     8 | lm loss: 2.983177E+00 | loss scale: 524288.0 | grad norm: 0.881 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 09:59:01] iteration   302500/  500000 | consumed samples:      2420000 | elapsed time per iteration (ms): 321.7 | learning rate: 1.109698E-05 | global batch size:     8 | lm loss: 2.981116E+00 | loss scale: 524288.0 | grad norm: 0.973 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 09:59:34] iteration   302600/  500000 | consumed samples:      2420800 | elapsed time per iteration (ms): 323.3 | learning rate: 1.108478E-05 | global batch size:     8 | lm loss: 2.973876E+00 | loss scale: 524288.0 | grad norm: 0.844 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 10:00:06] iteration   302700/  500000 | consumed samples:      2421600 | elapsed time per iteration (ms): 322.9 | learning rate: 1.107276E-05 | global batch size:     8 | lm loss: 2.972631E+00 | loss scale: 262144.0 | grad norm: 0.934 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-22 10:00:38] iteration   302800/  500000 | consumed samples:      2422400 | elapsed time per iteration (ms): 322.2 | learning rate: 1.106069E-05 | global batch size:     8 | lm loss: 2.988820E+00 | loss scale: 262144.0 | grad norm: 0.930 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 10:01:10] iteration   302900/  500000 | consumed samples:      2423200 | elapsed time per iteration (ms): 321.2 | learning rate: 1.104868E-05 | global batch size:     8 | lm loss: 2.954478E+00 | loss scale: 262144.0 | grad norm: 0.948 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 10:01:42] iteration   303000/  500000 | consumed samples:      2424000 | elapsed time per iteration (ms): 319.1 | learning rate: 1.103675E-05 | global batch size:     8 | lm loss: 2.974243E+00 | loss scale: 262144.0 | grad norm: 0.931 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1072.42, 1072.42)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 303000 | lm loss value: 3.684618E+00 | lm loss PPL: 3.982992E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 10:02:16] iteration   303100/  500000 | consumed samples:      2424800 | elapsed time per iteration (ms): 322.7 | learning rate: 1.102488E-05 | global batch size:     8 | lm loss: 2.990361E+00 | loss scale: 262144.0 | grad norm: 0.951 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 10:02:48] iteration   303200/  500000 | consumed samples:      2425600 | elapsed time per iteration (ms): 320.5 | learning rate: 1.101308E-05 | global batch size:     8 | lm loss: 2.932773E+00 | loss scale: 262144.0 | grad norm: 0.901 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 10:03:20] iteration   303300/  500000 | consumed samples:      2426400 | elapsed time per iteration (ms): 320.7 | learning rate: 1.100134E-05 | global batch size:     8 | lm loss: 2.986295E+00 | loss scale: 262144.0 | grad norm: 0.931 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 10:03:52] iteration   303400/  500000 | consumed samples:      2427200 | elapsed time per iteration (ms): 320.2 | learning rate: 1.098968E-05 | global batch size:     8 | lm loss: 2.955412E+00 | loss scale: 262144.0 | grad norm: 0.924 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 10:04:24] iteration   303500/  500000 | consumed samples:      2428000 | elapsed time per iteration (ms): 320.9 | learning rate: 1.097808E-05 | global batch size:     8 | lm loss: 2.988594E+00 | loss scale: 262144.0 | grad norm: 0.896 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 10:04:56] iteration   303600/  500000 | consumed samples:      2428800 | elapsed time per iteration (ms): 319.7 | learning rate: 1.096655E-05 | global batch size:     8 | lm loss: 2.946307E+00 | loss scale: 262144.0 | grad norm: 0.898 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 10:05:28] iteration   303700/  500000 | consumed samples:      2429600 | elapsed time per iteration (ms): 319.9 | learning rate: 1.095509E-05 | global batch size:     8 | lm loss: 3.004401E+00 | loss scale: 524288.0 | grad norm: 0.916 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 10:06:00] iteration   303800/  500000 | consumed samples:      2430400 | elapsed time per iteration (ms): 320.5 | learning rate: 1.094369E-05 | global batch size:     8 | lm loss: 2.966569E+00 | loss scale: 524288.0 | grad norm: 0.913 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 10:06:32] iteration   303900/  500000 | consumed samples:      2431200 | elapsed time per iteration (ms): 319.5 | learning rate: 1.093237E-05 | global batch size:     8 | lm loss: 3.005252E+00 | loss scale: 524288.0 | grad norm: 0.886 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 10:07:04] iteration   304000/  500000 | consumed samples:      2432000 | elapsed time per iteration (ms): 322.1 | learning rate: 1.092111E-05 | global batch size:     8 | lm loss: 2.971301E+00 | loss scale: 524288.0 | grad norm: 0.890 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1064.58, 1064.58)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 304000 | lm loss value: 3.658995E+00 | lm loss PPL: 3.882229E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 10:07:37] iteration   304100/  500000 | consumed samples:      2432800 | elapsed time per iteration (ms): 323.7 | learning rate: 1.090992E-05 | global batch size:     8 | lm loss: 2.972788E+00 | loss scale: 524288.0 | grad norm: 0.950 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 10:08:10] iteration   304200/  500000 | consumed samples:      2433600 | elapsed time per iteration (ms): 322.0 | learning rate: 1.089880E-05 | global batch size:     8 | lm loss: 2.979067E+00 | loss scale: 524288.0 | grad norm: 0.882 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 10:08:42] iteration   304300/  500000 | consumed samples:      2434400 | elapsed time per iteration (ms): 321.0 | learning rate: 1.088785E-05 | global batch size:     8 | lm loss: 2.978431E+00 | loss scale: 524288.0 | grad norm: 0.924 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-22 10:09:14] iteration   304400/  500000 | consumed samples:      2435200 | elapsed time per iteration (ms): 321.3 | learning rate: 1.087687E-05 | global batch size:     8 | lm loss: 2.970061E+00 | loss scale: 524288.0 | grad norm: 0.957 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 10:09:46] iteration   304500/  500000 | consumed samples:      2436000 | elapsed time per iteration (ms): 321.2 | learning rate: 1.086595E-05 | global batch size:     8 | lm loss: 2.962738E+00 | loss scale: 524288.0 | grad norm: 0.920 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 10:10:18] iteration   304600/  500000 | consumed samples:      2436800 | elapsed time per iteration (ms): 319.9 | learning rate: 1.085510E-05 | global batch size:     8 | lm loss: 2.988735E+00 | loss scale: 524288.0 | grad norm: 0.905 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 10:10:50] iteration   304700/  500000 | consumed samples:      2437600 | elapsed time per iteration (ms): 320.8 | learning rate: 1.084431E-05 | global batch size:     8 | lm loss: 2.978944E+00 | loss scale: 524288.0 | grad norm: 0.909 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 10:11:22] iteration   304800/  500000 | consumed samples:      2438400 | elapsed time per iteration (ms): 319.9 | learning rate: 1.083360E-05 | global batch size:     8 | lm loss: 2.935460E+00 | loss scale: 524288.0 | grad norm: 0.871 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 10:11:54] iteration   304900/  500000 | consumed samples:      2439200 | elapsed time per iteration (ms): 320.4 | learning rate: 1.082295E-05 | global batch size:     8 | lm loss: 2.982354E+00 | loss scale: 524288.0 | grad norm: 0.893 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 10:12:27] iteration   305000/  500000 | consumed samples:      2440000 | elapsed time per iteration (ms): 324.5 | learning rate: 1.081237E-05 | global batch size:     8 | lm loss: 2.932244E+00 | loss scale: 524288.0 | grad norm: 0.891 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1064.67, 1064.67)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 305000 | lm loss value: 3.815705E+00 | lm loss PPL: 4.540875E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 10:13:00] iteration   305100/  500000 | consumed samples:      2440800 | elapsed time per iteration (ms): 323.0 | learning rate: 1.080186E-05 | global batch size:     8 | lm loss: 2.957307E+00 | loss scale: 524288.0 | grad norm: 0.892 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 10:13:32] iteration   305200/  500000 | consumed samples:      2441600 | elapsed time per iteration (ms): 321.0 | learning rate: 1.079142E-05 | global batch size:     8 | lm loss: 2.973296E+00 | loss scale: 524288.0 | grad norm: 0.895 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 10:14:04] iteration   305300/  500000 | consumed samples:      2442400 | elapsed time per iteration (ms): 322.1 | learning rate: 1.078104E-05 | global batch size:     8 | lm loss: 3.000359E+00 | loss scale: 1048576.0 | grad norm: 0.927 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 10:14:36] iteration   305400/  500000 | consumed samples:      2443200 | elapsed time per iteration (ms): 321.0 | learning rate: 1.077094E-05 | global batch size:     8 | lm loss: 2.958794E+00 | loss scale: 524288.0 | grad norm: 0.933 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-22 10:15:08] iteration   305500/  500000 | consumed samples:      2444000 | elapsed time per iteration (ms): 320.0 | learning rate: 1.076070E-05 | global batch size:     8 | lm loss: 3.031214E+00 | loss scale: 524288.0 | grad norm: 0.936 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 10:15:41] iteration   305600/  500000 | consumed samples:      2444800 | elapsed time per iteration (ms): 321.7 | learning rate: 1.075063E-05 | global batch size:     8 | lm loss: 2.976359E+00 | loss scale: 262144.0 | grad norm: 0.919 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-22 10:16:13] iteration   305700/  500000 | consumed samples:      2445600 | elapsed time per iteration (ms): 321.8 | learning rate: 1.074053E-05 | global batch size:     8 | lm loss: 2.967174E+00 | loss scale: 262144.0 | grad norm: 0.905 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 10:16:45] iteration   305800/  500000 | consumed samples:      2446400 | elapsed time per iteration (ms): 325.0 | learning rate: 1.073049E-05 | global batch size:     8 | lm loss: 3.009001E+00 | loss scale: 262144.0 | grad norm: 0.959 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 10:17:17] iteration   305900/  500000 | consumed samples:      2447200 | elapsed time per iteration (ms): 322.0 | learning rate: 1.072052E-05 | global batch size:     8 | lm loss: 2.954427E+00 | loss scale: 262144.0 | grad norm: 0.943 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 10:17:50] iteration   306000/  500000 | consumed samples:      2448000 | elapsed time per iteration (ms): 323.1 | learning rate: 1.071062E-05 | global batch size:     8 | lm loss: 2.968363E+00 | loss scale: 262144.0 | grad norm: 0.934 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1063.59, 1063.59)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 306000 | lm loss value: 3.629557E+00 | lm loss PPL: 3.769610E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 10:18:23] iteration   306100/  500000 | consumed samples:      2448800 | elapsed time per iteration (ms): 323.4 | learning rate: 1.070079E-05 | global batch size:     8 | lm loss: 2.985017E+00 | loss scale: 262144.0 | grad norm: 0.895 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 10:18:55] iteration   306200/  500000 | consumed samples:      2449600 | elapsed time per iteration (ms): 323.0 | learning rate: 1.069103E-05 | global batch size:     8 | lm loss: 2.957586E+00 | loss scale: 262144.0 | grad norm: 0.908 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 10:19:28] iteration   306300/  500000 | consumed samples:      2450400 | elapsed time per iteration (ms): 323.6 | learning rate: 1.068133E-05 | global batch size:     8 | lm loss: 2.975995E+00 | loss scale: 262144.0 | grad norm: 0.949 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 10:20:00] iteration   306400/  500000 | consumed samples:      2451200 | elapsed time per iteration (ms): 323.0 | learning rate: 1.067170E-05 | global batch size:     8 | lm loss: 2.934251E+00 | loss scale: 262144.0 | grad norm: 0.942 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 10:20:32] iteration   306500/  500000 | consumed samples:      2452000 | elapsed time per iteration (ms): 322.7 | learning rate: 1.066214E-05 | global batch size:     8 | lm loss: 2.961100E+00 | loss scale: 262144.0 | grad norm: 0.905 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 10:21:05] iteration   306600/  500000 | consumed samples:      2452800 | elapsed time per iteration (ms): 321.9 | learning rate: 1.065265E-05 | global batch size:     8 | lm loss: 2.977775E+00 | loss scale: 524288.0 | grad norm: 0.897 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 10:21:37] iteration   306700/  500000 | consumed samples:      2453600 | elapsed time per iteration (ms): 323.0 | learning rate: 1.064323E-05 | global batch size:     8 | lm loss: 3.017096E+00 | loss scale: 524288.0 | grad norm: 0.944 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 10:22:09] iteration   306800/  500000 | consumed samples:      2454400 | elapsed time per iteration (ms): 322.8 | learning rate: 1.063388E-05 | global batch size:     8 | lm loss: 2.986546E+00 | loss scale: 524288.0 | grad norm: 0.914 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 10:22:41] iteration   306900/  500000 | consumed samples:      2455200 | elapsed time per iteration (ms): 322.5 | learning rate: 1.062459E-05 | global batch size:     8 | lm loss: 2.986075E+00 | loss scale: 524288.0 | grad norm: 0.914 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 10:23:13] iteration   307000/  500000 | consumed samples:      2456000 | elapsed time per iteration (ms): 321.3 | learning rate: 1.061537E-05 | global batch size:     8 | lm loss: 2.951682E+00 | loss scale: 524288.0 | grad norm: 0.971 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1064.46, 1064.46)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 307000 | lm loss value: 3.740767E+00 | lm loss PPL: 4.213030E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 10:23:47] iteration   307100/  500000 | consumed samples:      2456800 | elapsed time per iteration (ms): 324.3 | learning rate: 1.060622E-05 | global batch size:     8 | lm loss: 2.972230E+00 | loss scale: 524288.0 | grad norm: 0.924 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 10:24:19] iteration   307200/  500000 | consumed samples:      2457600 | elapsed time per iteration (ms): 321.5 | learning rate: 1.059714E-05 | global batch size:     8 | lm loss: 2.950944E+00 | loss scale: 524288.0 | grad norm: 0.915 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 10:24:52] iteration   307300/  500000 | consumed samples:      2458400 | elapsed time per iteration (ms): 325.3 | learning rate: 1.058813E-05 | global batch size:     8 | lm loss: 2.976237E+00 | loss scale: 524288.0 | grad norm: 0.970 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 10:25:24] iteration   307400/  500000 | consumed samples:      2459200 | elapsed time per iteration (ms): 323.6 | learning rate: 1.057918E-05 | global batch size:     8 | lm loss: 2.964358E+00 | loss scale: 524288.0 | grad norm: 0.938 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 10:25:56] iteration   307500/  500000 | consumed samples:      2460000 | elapsed time per iteration (ms): 322.1 | learning rate: 1.057030E-05 | global batch size:     8 | lm loss: 3.013097E+00 | loss scale: 524288.0 | grad norm: 0.937 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 10:26:28] iteration   307600/  500000 | consumed samples:      2460800 | elapsed time per iteration (ms): 321.2 | learning rate: 1.056167E-05 | global batch size:     8 | lm loss: 2.984482E+00 | loss scale: 524288.0 | grad norm: 0.898 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-22 10:27:01] iteration   307700/  500000 | consumed samples:      2461600 | elapsed time per iteration (ms): 321.6 | learning rate: 1.055293E-05 | global batch size:     8 | lm loss: 2.958535E+00 | loss scale: 524288.0 | grad norm: 0.953 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 10:27:33] iteration   307800/  500000 | consumed samples:      2462400 | elapsed time per iteration (ms): 321.9 | learning rate: 1.054425E-05 | global batch size:     8 | lm loss: 2.996717E+00 | loss scale: 524288.0 | grad norm: 0.939 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 10:28:05] iteration   307900/  500000 | consumed samples:      2463200 | elapsed time per iteration (ms): 322.9 | learning rate: 1.053565E-05 | global batch size:     8 | lm loss: 2.984021E+00 | loss scale: 524288.0 | grad norm: 0.898 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 10:28:37] iteration   308000/  500000 | consumed samples:      2464000 | elapsed time per iteration (ms): 321.7 | learning rate: 1.052711E-05 | global batch size:     8 | lm loss: 2.977607E+00 | loss scale: 524288.0 | grad norm: 0.878 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1067.05, 1067.05)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 308000 | lm loss value: 3.742790E+00 | lm loss PPL: 4.221561E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 10:29:10] iteration   308100/  500000 | consumed samples:      2464800 | elapsed time per iteration (ms): 320.8 | learning rate: 1.051864E-05 | global batch size:     8 | lm loss: 2.983384E+00 | loss scale: 524288.0 | grad norm: 0.955 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 10:29:42] iteration   308200/  500000 | consumed samples:      2465600 | elapsed time per iteration (ms): 321.0 | learning rate: 1.051024E-05 | global batch size:     8 | lm loss: 3.004319E+00 | loss scale: 524288.0 | grad norm: 0.947 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 10:30:15] iteration   308300/  500000 | consumed samples:      2466400 | elapsed time per iteration (ms): 322.1 | learning rate: 1.050191E-05 | global batch size:     8 | lm loss: 2.979522E+00 | loss scale: 524288.0 | grad norm: 0.931 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 10:30:47] iteration   308400/  500000 | consumed samples:      2467200 | elapsed time per iteration (ms): 319.6 | learning rate: 1.049373E-05 | global batch size:     8 | lm loss: 2.998358E+00 | loss scale: 262144.0 | grad norm: 0.915 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-22 10:31:18] iteration   308500/  500000 | consumed samples:      2468000 | elapsed time per iteration (ms): 318.8 | learning rate: 1.048553E-05 | global batch size:     8 | lm loss: 2.949126E+00 | loss scale: 262144.0 | grad norm: 0.958 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 10:31:50] iteration   308600/  500000 | consumed samples:      2468800 | elapsed time per iteration (ms): 319.0 | learning rate: 1.047741E-05 | global batch size:     8 | lm loss: 2.953614E+00 | loss scale: 262144.0 | grad norm: 0.890 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 10:32:22] iteration   308700/  500000 | consumed samples:      2469600 | elapsed time per iteration (ms): 318.9 | learning rate: 1.046935E-05 | global batch size:     8 | lm loss: 3.001390E+00 | loss scale: 262144.0 | grad norm: 0.972 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 10:32:54] iteration   308800/  500000 | consumed samples:      2470400 | elapsed time per iteration (ms): 319.9 | learning rate: 1.046136E-05 | global batch size:     8 | lm loss: 2.955497E+00 | loss scale: 262144.0 | grad norm: 0.917 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 10:33:26] iteration   308900/  500000 | consumed samples:      2471200 | elapsed time per iteration (ms): 320.5 | learning rate: 1.045343E-05 | global batch size:     8 | lm loss: 2.932748E+00 | loss scale: 262144.0 | grad norm: 0.929 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 10:33:58] iteration   309000/  500000 | consumed samples:      2472000 | elapsed time per iteration (ms): 320.2 | learning rate: 1.044558E-05 | global batch size:     8 | lm loss: 2.939755E+00 | loss scale: 262144.0 | grad norm: 0.929 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1064.03, 1064.03)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 309000 | lm loss value: 3.600159E+00 | lm loss PPL: 3.660404E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 10:34:31] iteration   309100/  500000 | consumed samples:      2472800 | elapsed time per iteration (ms): 318.6 | learning rate: 1.043779E-05 | global batch size:     8 | lm loss: 2.975611E+00 | loss scale: 262144.0 | grad norm: 0.908 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 10:35:03] iteration   309200/  500000 | consumed samples:      2473600 | elapsed time per iteration (ms): 321.9 | learning rate: 1.043008E-05 | global batch size:     8 | lm loss: 2.970249E+00 | loss scale: 262144.0 | grad norm: 0.954 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 10:35:36] iteration   309300/  500000 | consumed samples:      2474400 | elapsed time per iteration (ms): 322.1 | learning rate: 1.042243E-05 | global batch size:     8 | lm loss: 2.965818E+00 | loss scale: 262144.0 | grad norm: 0.921 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 10:36:08] iteration   309400/  500000 | consumed samples:      2475200 | elapsed time per iteration (ms): 319.7 | learning rate: 1.041485E-05 | global batch size:     8 | lm loss: 2.984202E+00 | loss scale: 524288.0 | grad norm: 0.898 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 10:36:40] iteration   309500/  500000 | consumed samples:      2476000 | elapsed time per iteration (ms): 322.2 | learning rate: 1.040741E-05 | global batch size:     8 | lm loss: 2.962491E+00 | loss scale: 524288.0 | grad norm: 0.926 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-22 10:37:12] iteration   309600/  500000 | consumed samples:      2476800 | elapsed time per iteration (ms): 320.4 | learning rate: 1.040004E-05 | global batch size:     8 | lm loss: 3.018679E+00 | loss scale: 262144.0 | grad norm: 0.892 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-22 10:37:44] iteration   309700/  500000 | consumed samples:      2477600 | elapsed time per iteration (ms): 320.6 | learning rate: 1.039266E-05 | global batch size:     8 | lm loss: 3.010161E+00 | loss scale: 262144.0 | grad norm: 0.901 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 10:38:16] iteration   309800/  500000 | consumed samples:      2478400 | elapsed time per iteration (ms): 323.1 | learning rate: 1.038536E-05 | global batch size:     8 | lm loss: 3.013344E+00 | loss scale: 262144.0 | grad norm: 0.934 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 10:38:48] iteration   309900/  500000 | consumed samples:      2479200 | elapsed time per iteration (ms): 320.4 | learning rate: 1.037812E-05 | global batch size:     8 | lm loss: 2.970150E+00 | loss scale: 262144.0 | grad norm: 0.940 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 10:39:21] iteration   310000/  500000 | consumed samples:      2480000 | elapsed time per iteration (ms): 323.9 | learning rate: 1.037095E-05 | global batch size:     8 | lm loss: 2.988792E+00 | loss scale: 262144.0 | grad norm: 0.911 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1063.99, 1063.99)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 310000 | lm loss value: 3.854346E+00 | lm loss PPL: 4.719774E+01 | 
--------------------------------------------------------------------------------------------------
saving checkpoint at iteration  310000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-max in torch format
  successfully saved checkpoint at iteration  310000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-max
(min, max) time across ranks (ms):
    save-checkpoint ................................: (5684.40, 5684.40)
 [2024-06-22 10:40:00] iteration   310100/  500000 | consumed samples:      2480800 | elapsed time per iteration (ms): 321.7 | learning rate: 1.036384E-05 | global batch size:     8 | lm loss: 2.959079E+00 | loss scale: 262144.0 | grad norm: 0.969 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 10:40:32] iteration   310200/  500000 | consumed samples:      2481600 | elapsed time per iteration (ms): 323.5 | learning rate: 1.035681E-05 | global batch size:     8 | lm loss: 2.952637E+00 | loss scale: 262144.0 | grad norm: 0.941 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 10:41:04] iteration   310300/  500000 | consumed samples:      2482400 | elapsed time per iteration (ms): 322.8 | learning rate: 1.034984E-05 | global batch size:     8 | lm loss: 2.955461E+00 | loss scale: 262144.0 | grad norm: 0.892 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 10:41:36] iteration   310400/  500000 | consumed samples:      2483200 | elapsed time per iteration (ms): 322.7 | learning rate: 1.034295E-05 | global batch size:     8 | lm loss: 3.003234E+00 | loss scale: 262144.0 | grad norm: 0.928 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 10:42:09] iteration   310500/  500000 | consumed samples:      2484000 | elapsed time per iteration (ms): 322.7 | learning rate: 1.033612E-05 | global batch size:     8 | lm loss: 2.950166E+00 | loss scale: 262144.0 | grad norm: 0.915 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 10:42:41] iteration   310600/  500000 | consumed samples:      2484800 | elapsed time per iteration (ms): 323.2 | learning rate: 1.032936E-05 | global batch size:     8 | lm loss: 2.973244E+00 | loss scale: 524288.0 | grad norm: 0.945 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 10:43:13] iteration   310700/  500000 | consumed samples:      2485600 | elapsed time per iteration (ms): 323.3 | learning rate: 1.032267E-05 | global batch size:     8 | lm loss: 2.964648E+00 | loss scale: 524288.0 | grad norm: 0.938 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 10:43:46] iteration   310800/  500000 | consumed samples:      2486400 | elapsed time per iteration (ms): 321.0 | learning rate: 1.031604E-05 | global batch size:     8 | lm loss: 2.962417E+00 | loss scale: 524288.0 | grad norm: 0.907 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 10:44:18] iteration   310900/  500000 | consumed samples:      2487200 | elapsed time per iteration (ms): 321.2 | learning rate: 1.030949E-05 | global batch size:     8 | lm loss: 2.970555E+00 | loss scale: 524288.0 | grad norm: 0.953 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 10:44:50] iteration   311000/  500000 | consumed samples:      2488000 | elapsed time per iteration (ms): 321.3 | learning rate: 1.030300E-05 | global batch size:     8 | lm loss: 2.977190E+00 | loss scale: 524288.0 | grad norm: 0.909 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1063.34, 1063.34)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 311000 | lm loss value: 3.661295E+00 | lm loss PPL: 3.891169E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 10:45:23] iteration   311100/  500000 | consumed samples:      2488800 | elapsed time per iteration (ms): 321.6 | learning rate: 1.029658E-05 | global batch size:     8 | lm loss: 2.993192E+00 | loss scale: 524288.0 | grad norm: 0.916 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 10:45:55] iteration   311200/  500000 | consumed samples:      2489600 | elapsed time per iteration (ms): 321.7 | learning rate: 1.029024E-05 | global batch size:     8 | lm loss: 2.998762E+00 | loss scale: 524288.0 | grad norm: 0.905 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 10:46:27] iteration   311300/  500000 | consumed samples:      2490400 | elapsed time per iteration (ms): 322.2 | learning rate: 1.028395E-05 | global batch size:     8 | lm loss: 2.938758E+00 | loss scale: 524288.0 | grad norm: 0.924 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 10:46:59] iteration   311400/  500000 | consumed samples:      2491200 | elapsed time per iteration (ms): 321.3 | learning rate: 1.027774E-05 | global batch size:     8 | lm loss: 2.985812E+00 | loss scale: 524288.0 | grad norm: 0.887 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 10:47:32] iteration   311500/  500000 | consumed samples:      2492000 | elapsed time per iteration (ms): 320.3 | learning rate: 1.027160E-05 | global batch size:     8 | lm loss: 2.968504E+00 | loss scale: 524288.0 | grad norm: 0.925 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 10:48:04] iteration   311600/  500000 | consumed samples:      2492800 | elapsed time per iteration (ms): 322.2 | learning rate: 1.026565E-05 | global batch size:     8 | lm loss: 2.963621E+00 | loss scale: 524288.0 | grad norm: 0.908 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-22 10:48:36] iteration   311700/  500000 | consumed samples:      2493600 | elapsed time per iteration (ms): 324.5 | learning rate: 1.025964E-05 | global batch size:     8 | lm loss: 2.957589E+00 | loss scale: 524288.0 | grad norm: 0.924 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 10:49:08] iteration   311800/  500000 | consumed samples:      2494400 | elapsed time per iteration (ms): 322.3 | learning rate: 1.025370E-05 | global batch size:     8 | lm loss: 2.940686E+00 | loss scale: 524288.0 | grad norm: 0.885 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 10:49:40] iteration   311900/  500000 | consumed samples:      2495200 | elapsed time per iteration (ms): 320.8 | learning rate: 1.024783E-05 | global batch size:     8 | lm loss: 2.988299E+00 | loss scale: 524288.0 | grad norm: 0.893 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 10:50:13] iteration   312000/  500000 | consumed samples:      2496000 | elapsed time per iteration (ms): 320.4 | learning rate: 1.024203E-05 | global batch size:     8 | lm loss: 2.963949E+00 | loss scale: 524288.0 | grad norm: 0.897 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1071.50, 1071.50)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 312000 | lm loss value: 3.681433E+00 | lm loss PPL: 3.970324E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 10:50:46] iteration   312100/  500000 | consumed samples:      2496800 | elapsed time per iteration (ms): 322.2 | learning rate: 1.023629E-05 | global batch size:     8 | lm loss: 3.000903E+00 | loss scale: 524288.0 | grad norm: 0.931 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 10:51:18] iteration   312200/  500000 | consumed samples:      2497600 | elapsed time per iteration (ms): 320.9 | learning rate: 1.023063E-05 | global batch size:     8 | lm loss: 3.001620E+00 | loss scale: 524288.0 | grad norm: 0.964 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 10:51:50] iteration   312300/  500000 | consumed samples:      2498400 | elapsed time per iteration (ms): 322.2 | learning rate: 1.022503E-05 | global batch size:     8 | lm loss: 2.955415E+00 | loss scale: 524288.0 | grad norm: 0.941 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 10:52:22] iteration   312400/  500000 | consumed samples:      2499200 | elapsed time per iteration (ms): 322.4 | learning rate: 1.021951E-05 | global batch size:     8 | lm loss: 2.952108E+00 | loss scale: 524288.0 | grad norm: 0.903 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 10:52:55] iteration   312500/  500000 | consumed samples:      2500000 | elapsed time per iteration (ms): 323.4 | learning rate: 1.021405E-05 | global batch size:     8 | lm loss: 3.020120E+00 | loss scale: 524288.0 | grad norm: 0.878 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 10:53:27] iteration   312600/  500000 | consumed samples:      2500800 | elapsed time per iteration (ms): 322.8 | learning rate: 1.020876E-05 | global batch size:     8 | lm loss: 2.929920E+00 | loss scale: 524288.0 | grad norm: 0.941 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-22 10:53:59] iteration   312700/  500000 | consumed samples:      2501600 | elapsed time per iteration (ms): 324.1 | learning rate: 1.020349E-05 | global batch size:     8 | lm loss: 2.935427E+00 | loss scale: 262144.0 | grad norm: 0.886 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-22 10:54:32] iteration   312800/  500000 | consumed samples:      2502400 | elapsed time per iteration (ms): 321.1 | learning rate: 1.019824E-05 | global batch size:     8 | lm loss: 2.976347E+00 | loss scale: 262144.0 | grad norm: 0.903 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 10:55:04] iteration   312900/  500000 | consumed samples:      2503200 | elapsed time per iteration (ms): 324.6 | learning rate: 1.019305E-05 | global batch size:     8 | lm loss: 2.964669E+00 | loss scale: 262144.0 | grad norm: 0.952 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 10:55:36] iteration   313000/  500000 | consumed samples:      2504000 | elapsed time per iteration (ms): 322.6 | learning rate: 1.018794E-05 | global batch size:     8 | lm loss: 2.975225E+00 | loss scale: 262144.0 | grad norm: 0.904 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1063.81, 1063.81)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 313000 | lm loss value: 3.563148E+00 | lm loss PPL: 3.527406E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 10:56:10] iteration   313100/  500000 | consumed samples:      2504800 | elapsed time per iteration (ms): 322.8 | learning rate: 1.018289E-05 | global batch size:     8 | lm loss: 2.934884E+00 | loss scale: 262144.0 | grad norm: 0.947 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 10:56:42] iteration   313200/  500000 | consumed samples:      2505600 | elapsed time per iteration (ms): 321.9 | learning rate: 1.017791E-05 | global batch size:     8 | lm loss: 3.022441E+00 | loss scale: 262144.0 | grad norm: 0.898 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 10:57:14] iteration   313300/  500000 | consumed samples:      2506400 | elapsed time per iteration (ms): 323.1 | learning rate: 1.017299E-05 | global batch size:     8 | lm loss: 2.973311E+00 | loss scale: 262144.0 | grad norm: 0.943 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 10:57:46] iteration   313400/  500000 | consumed samples:      2507200 | elapsed time per iteration (ms): 321.4 | learning rate: 1.016815E-05 | global batch size:     8 | lm loss: 3.003980E+00 | loss scale: 262144.0 | grad norm: 0.914 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 10:58:18] iteration   313500/  500000 | consumed samples:      2508000 | elapsed time per iteration (ms): 321.7 | learning rate: 1.016338E-05 | global batch size:     8 | lm loss: 2.983243E+00 | loss scale: 262144.0 | grad norm: 0.878 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 10:58:51] iteration   313600/  500000 | consumed samples:      2508800 | elapsed time per iteration (ms): 321.4 | learning rate: 1.015867E-05 | global batch size:     8 | lm loss: 2.934066E+00 | loss scale: 262144.0 | grad norm: 0.911 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 10:59:23] iteration   313700/  500000 | consumed samples:      2509600 | elapsed time per iteration (ms): 322.4 | learning rate: 1.015404E-05 | global batch size:     8 | lm loss: 3.002541E+00 | loss scale: 524288.0 | grad norm: 0.933 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 10:59:55] iteration   313800/  500000 | consumed samples:      2510400 | elapsed time per iteration (ms): 320.9 | learning rate: 1.014951E-05 | global batch size:     8 | lm loss: 2.958335E+00 | loss scale: 524288.0 | grad norm: 0.928 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-22 11:00:27] iteration   313900/  500000 | consumed samples:      2511200 | elapsed time per iteration (ms): 322.4 | learning rate: 1.014501E-05 | global batch size:     8 | lm loss: 2.998350E+00 | loss scale: 524288.0 | grad norm: 0.914 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 11:01:00] iteration   314000/  500000 | consumed samples:      2512000 | elapsed time per iteration (ms): 325.2 | learning rate: 1.014058E-05 | global batch size:     8 | lm loss: 2.957061E+00 | loss scale: 524288.0 | grad norm: 0.890 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1071.29, 1071.29)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 314000 | lm loss value: 3.729693E+00 | lm loss PPL: 4.166631E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 11:01:33] iteration   314100/  500000 | consumed samples:      2512800 | elapsed time per iteration (ms): 321.3 | learning rate: 1.013622E-05 | global batch size:     8 | lm loss: 2.948435E+00 | loss scale: 524288.0 | grad norm: 0.947 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 11:02:05] iteration   314200/  500000 | consumed samples:      2513600 | elapsed time per iteration (ms): 322.2 | learning rate: 1.013197E-05 | global batch size:     8 | lm loss: 3.009918E+00 | loss scale: 262144.0 | grad norm: 0.895 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-22 11:02:37] iteration   314300/  500000 | consumed samples:      2514400 | elapsed time per iteration (ms): 323.7 | learning rate: 1.012774E-05 | global batch size:     8 | lm loss: 2.972533E+00 | loss scale: 262144.0 | grad norm: 0.915 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 11:03:10] iteration   314400/  500000 | consumed samples:      2515200 | elapsed time per iteration (ms): 321.5 | learning rate: 1.012358E-05 | global batch size:     8 | lm loss: 2.975028E+00 | loss scale: 262144.0 | grad norm: 0.905 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 11:03:42] iteration   314500/  500000 | consumed samples:      2516000 | elapsed time per iteration (ms): 320.5 | learning rate: 1.011949E-05 | global batch size:     8 | lm loss: 3.008744E+00 | loss scale: 262144.0 | grad norm: 0.886 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 11:04:14] iteration   314600/  500000 | consumed samples:      2516800 | elapsed time per iteration (ms): 320.8 | learning rate: 1.011547E-05 | global batch size:     8 | lm loss: 2.981941E+00 | loss scale: 262144.0 | grad norm: 0.927 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 11:04:46] iteration   314700/  500000 | consumed samples:      2517600 | elapsed time per iteration (ms): 321.2 | learning rate: 1.011152E-05 | global batch size:     8 | lm loss: 2.971995E+00 | loss scale: 262144.0 | grad norm: 0.928 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 11:05:18] iteration   314800/  500000 | consumed samples:      2518400 | elapsed time per iteration (ms): 322.0 | learning rate: 1.010764E-05 | global batch size:     8 | lm loss: 2.950533E+00 | loss scale: 262144.0 | grad norm: 0.941 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 11:05:50] iteration   314900/  500000 | consumed samples:      2519200 | elapsed time per iteration (ms): 322.6 | learning rate: 1.010383E-05 | global batch size:     8 | lm loss: 2.946075E+00 | loss scale: 262144.0 | grad norm: 0.829 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 11:06:23] iteration   315000/  500000 | consumed samples:      2520000 | elapsed time per iteration (ms): 323.2 | learning rate: 1.010008E-05 | global batch size:     8 | lm loss: 2.960309E+00 | loss scale: 262144.0 | grad norm: 0.921 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1064.59, 1064.59)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 315000 | lm loss value: 3.565214E+00 | lm loss PPL: 3.534701E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 11:06:56] iteration   315100/  500000 | consumed samples:      2520800 | elapsed time per iteration (ms): 321.4 | learning rate: 1.009641E-05 | global batch size:     8 | lm loss: 2.975032E+00 | loss scale: 262144.0 | grad norm: 0.921 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 11:07:28] iteration   315200/  500000 | consumed samples:      2521600 | elapsed time per iteration (ms): 321.9 | learning rate: 1.009280E-05 | global batch size:     8 | lm loss: 3.004836E+00 | loss scale: 524288.0 | grad norm: 0.964 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 11:08:00] iteration   315300/  500000 | consumed samples:      2522400 | elapsed time per iteration (ms): 324.3 | learning rate: 1.008926E-05 | global batch size:     8 | lm loss: 2.929834E+00 | loss scale: 524288.0 | grad norm: 0.945 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 11:08:33] iteration   315400/  500000 | consumed samples:      2523200 | elapsed time per iteration (ms): 322.3 | learning rate: 1.008579E-05 | global batch size:     8 | lm loss: 2.985052E+00 | loss scale: 524288.0 | grad norm: 0.846 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 11:09:05] iteration   315500/  500000 | consumed samples:      2524000 | elapsed time per iteration (ms): 322.9 | learning rate: 1.008239E-05 | global batch size:     8 | lm loss: 2.964306E+00 | loss scale: 524288.0 | grad norm: 0.898 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 11:09:37] iteration   315600/  500000 | consumed samples:      2524800 | elapsed time per iteration (ms): 323.6 | learning rate: 1.007906E-05 | global batch size:     8 | lm loss: 2.931210E+00 | loss scale: 524288.0 | grad norm: 0.915 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 11:10:10] iteration   315700/  500000 | consumed samples:      2525600 | elapsed time per iteration (ms): 322.3 | learning rate: 1.007579E-05 | global batch size:     8 | lm loss: 2.929445E+00 | loss scale: 524288.0 | grad norm: 0.953 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 11:10:42] iteration   315800/  500000 | consumed samples:      2526400 | elapsed time per iteration (ms): 324.3 | learning rate: 1.007260E-05 | global batch size:     8 | lm loss: 2.993226E+00 | loss scale: 524288.0 | grad norm: 0.892 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 11:11:14] iteration   315900/  500000 | consumed samples:      2527200 | elapsed time per iteration (ms): 321.4 | learning rate: 1.006947E-05 | global batch size:     8 | lm loss: 3.026686E+00 | loss scale: 524288.0 | grad norm: 0.941 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 11:11:46] iteration   316000/  500000 | consumed samples:      2528000 | elapsed time per iteration (ms): 319.7 | learning rate: 1.006641E-05 | global batch size:     8 | lm loss: 2.966923E+00 | loss scale: 524288.0 | grad norm: 0.946 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1063.03, 1063.03)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 316000 | lm loss value: 3.712091E+00 | lm loss PPL: 4.093934E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 11:12:19] iteration   316100/  500000 | consumed samples:      2528800 | elapsed time per iteration (ms): 321.4 | learning rate: 1.006342E-05 | global batch size:     8 | lm loss: 2.923298E+00 | loss scale: 524288.0 | grad norm: 0.934 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 11:12:51] iteration   316200/  500000 | consumed samples:      2529600 | elapsed time per iteration (ms): 321.7 | learning rate: 1.006056E-05 | global batch size:     8 | lm loss: 2.991118E+00 | loss scale: 524288.0 | grad norm: 0.911 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-22 11:13:24] iteration   316300/  500000 | consumed samples:      2530400 | elapsed time per iteration (ms): 321.6 | learning rate: 1.005771E-05 | global batch size:     8 | lm loss: 2.983220E+00 | loss scale: 524288.0 | grad norm: 0.944 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 11:13:56] iteration   316400/  500000 | consumed samples:      2531200 | elapsed time per iteration (ms): 322.4 | learning rate: 1.005493E-05 | global batch size:     8 | lm loss: 2.959288E+00 | loss scale: 524288.0 | grad norm: 0.919 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 11:14:28] iteration   316500/  500000 | consumed samples:      2532000 | elapsed time per iteration (ms): 321.1 | learning rate: 1.005221E-05 | global batch size:     8 | lm loss: 2.908833E+00 | loss scale: 524288.0 | grad norm: 0.931 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 11:15:00] iteration   316600/  500000 | consumed samples:      2532800 | elapsed time per iteration (ms): 325.3 | learning rate: 1.004956E-05 | global batch size:     8 | lm loss: 2.976458E+00 | loss scale: 524288.0 | grad norm: 0.947 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 11:15:32] iteration   316700/  500000 | consumed samples:      2533600 | elapsed time per iteration (ms): 319.8 | learning rate: 1.004699E-05 | global batch size:     8 | lm loss: 2.995300E+00 | loss scale: 524288.0 | grad norm: 0.911 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 11:16:05] iteration   316800/  500000 | consumed samples:      2534400 | elapsed time per iteration (ms): 321.5 | learning rate: 1.004448E-05 | global batch size:     8 | lm loss: 2.960853E+00 | loss scale: 524288.0 | grad norm: 0.903 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 11:16:37] iteration   316900/  500000 | consumed samples:      2535200 | elapsed time per iteration (ms): 320.1 | learning rate: 1.004204E-05 | global batch size:     8 | lm loss: 2.950211E+00 | loss scale: 524288.0 | grad norm: 0.932 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 11:17:09] iteration   317000/  500000 | consumed samples:      2536000 | elapsed time per iteration (ms): 320.5 | learning rate: 1.003967E-05 | global batch size:     8 | lm loss: 3.003827E+00 | loss scale: 524288.0 | grad norm: 0.910 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1064.66, 1064.66)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 317000 | lm loss value: 3.725340E+00 | lm loss PPL: 4.148535E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 11:17:42] iteration   317100/  500000 | consumed samples:      2536800 | elapsed time per iteration (ms): 321.6 | learning rate: 1.003737E-05 | global batch size:     8 | lm loss: 2.936251E+00 | loss scale: 524288.0 | grad norm: 0.952 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 11:18:14] iteration   317200/  500000 | consumed samples:      2537600 | elapsed time per iteration (ms): 321.1 | learning rate: 1.003515E-05 | global batch size:     8 | lm loss: 2.994010E+00 | loss scale: 1048576.0 | grad norm: 0.895 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-22 11:18:46] iteration   317300/  500000 | consumed samples:      2538400 | elapsed time per iteration (ms): 320.5 | learning rate: 1.003301E-05 | global batch size:     8 | lm loss: 2.984167E+00 | loss scale: 524288.0 | grad norm: 0.887 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-22 11:19:18] iteration   317400/  500000 | consumed samples:      2539200 | elapsed time per iteration (ms): 321.4 | learning rate: 1.003091E-05 | global batch size:     8 | lm loss: 2.938782E+00 | loss scale: 524288.0 | grad norm: 0.891 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 11:19:50] iteration   317500/  500000 | consumed samples:      2540000 | elapsed time per iteration (ms): 321.9 | learning rate: 1.002888E-05 | global batch size:     8 | lm loss: 2.981544E+00 | loss scale: 524288.0 | grad norm: 0.890 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 11:20:22] iteration   317600/  500000 | consumed samples:      2540800 | elapsed time per iteration (ms): 320.9 | learning rate: 1.002692E-05 | global batch size:     8 | lm loss: 2.979451E+00 | loss scale: 524288.0 | grad norm: 0.833 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 11:20:55] iteration   317700/  500000 | consumed samples:      2541600 | elapsed time per iteration (ms): 321.7 | learning rate: 1.002503E-05 | global batch size:     8 | lm loss: 2.950741E+00 | loss scale: 524288.0 | grad norm: 0.946 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 11:21:27] iteration   317800/  500000 | consumed samples:      2542400 | elapsed time per iteration (ms): 320.9 | learning rate: 1.002323E-05 | global batch size:     8 | lm loss: 3.017710E+00 | loss scale: 262144.0 | grad norm: 0.929 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-22 11:21:59] iteration   317900/  500000 | consumed samples:      2543200 | elapsed time per iteration (ms): 321.5 | learning rate: 1.002148E-05 | global batch size:     8 | lm loss: 2.980848E+00 | loss scale: 262144.0 | grad norm: 0.966 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 11:22:31] iteration   318000/  500000 | consumed samples:      2544000 | elapsed time per iteration (ms): 318.2 | learning rate: 1.001979E-05 | global batch size:     8 | lm loss: 2.984179E+00 | loss scale: 262144.0 | grad norm: 0.928 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1063.39, 1063.39)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 318000 | lm loss value: 3.660482E+00 | lm loss PPL: 3.888009E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 11:23:04] iteration   318100/  500000 | consumed samples:      2544800 | elapsed time per iteration (ms): 320.3 | learning rate: 1.001818E-05 | global batch size:     8 | lm loss: 2.954276E+00 | loss scale: 262144.0 | grad norm: 0.944 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 11:23:36] iteration   318200/  500000 | consumed samples:      2545600 | elapsed time per iteration (ms): 323.9 | learning rate: 1.001663E-05 | global batch size:     8 | lm loss: 2.963868E+00 | loss scale: 262144.0 | grad norm: 0.921 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 11:24:08] iteration   318300/  500000 | consumed samples:      2546400 | elapsed time per iteration (ms): 321.3 | learning rate: 1.001515E-05 | global batch size:     8 | lm loss: 2.939901E+00 | loss scale: 262144.0 | grad norm: 0.929 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 11:24:41] iteration   318400/  500000 | consumed samples:      2547200 | elapsed time per iteration (ms): 322.8 | learning rate: 1.001374E-05 | global batch size:     8 | lm loss: 2.978521E+00 | loss scale: 262144.0 | grad norm: 0.996 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 11:25:13] iteration   318500/  500000 | consumed samples:      2548000 | elapsed time per iteration (ms): 322.8 | learning rate: 1.001240E-05 | global batch size:     8 | lm loss: 2.993589E+00 | loss scale: 262144.0 | grad norm: 0.879 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 11:25:45] iteration   318600/  500000 | consumed samples:      2548800 | elapsed time per iteration (ms): 323.2 | learning rate: 1.001113E-05 | global batch size:     8 | lm loss: 3.000694E+00 | loss scale: 262144.0 | grad norm: 0.989 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 11:26:17] iteration   318700/  500000 | consumed samples:      2549600 | elapsed time per iteration (ms): 321.7 | learning rate: 1.000992E-05 | global batch size:     8 | lm loss: 2.958260E+00 | loss scale: 262144.0 | grad norm: 0.947 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 11:26:50] iteration   318800/  500000 | consumed samples:      2550400 | elapsed time per iteration (ms): 324.5 | learning rate: 1.000880E-05 | global batch size:     8 | lm loss: 2.985580E+00 | loss scale: 131072.0 | grad norm: 0.938 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-22 11:27:22] iteration   318900/  500000 | consumed samples:      2551200 | elapsed time per iteration (ms): 320.3 | learning rate: 1.000773E-05 | global batch size:     8 | lm loss: 2.928905E+00 | loss scale: 131072.0 | grad norm: 0.895 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 11:27:54] iteration   319000/  500000 | consumed samples:      2552000 | elapsed time per iteration (ms): 320.7 | learning rate: 1.000674E-05 | global batch size:     8 | lm loss: 2.996633E+00 | loss scale: 131072.0 | grad norm: 0.904 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1064.95, 1064.95)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 319000 | lm loss value: 3.653350E+00 | lm loss PPL: 3.860376E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 11:28:27] iteration   319100/  500000 | consumed samples:      2552800 | elapsed time per iteration (ms): 321.1 | learning rate: 1.000581E-05 | global batch size:     8 | lm loss: 2.970013E+00 | loss scale: 131072.0 | grad norm: 0.949 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 11:28:59] iteration   319200/  500000 | consumed samples:      2553600 | elapsed time per iteration (ms): 323.2 | learning rate: 1.000495E-05 | global batch size:     8 | lm loss: 2.993107E+00 | loss scale: 131072.0 | grad norm: 0.940 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 11:29:32] iteration   319300/  500000 | consumed samples:      2554400 | elapsed time per iteration (ms): 323.3 | learning rate: 1.000416E-05 | global batch size:     8 | lm loss: 2.919611E+00 | loss scale: 131072.0 | grad norm: 0.932 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 11:30:04] iteration   319400/  500000 | consumed samples:      2555200 | elapsed time per iteration (ms): 319.9 | learning rate: 1.000343E-05 | global batch size:     8 | lm loss: 2.958343E+00 | loss scale: 131072.0 | grad norm: 0.934 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 11:30:36] iteration   319500/  500000 | consumed samples:      2556000 | elapsed time per iteration (ms): 321.7 | learning rate: 1.000278E-05 | global batch size:     8 | lm loss: 2.918522E+00 | loss scale: 131072.0 | grad norm: 0.897 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 11:31:08] iteration   319600/  500000 | consumed samples:      2556800 | elapsed time per iteration (ms): 321.2 | learning rate: 1.000220E-05 | global batch size:     8 | lm loss: 2.986044E+00 | loss scale: 131072.0 | grad norm: 0.922 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 11:31:40] iteration   319700/  500000 | consumed samples:      2557600 | elapsed time per iteration (ms): 322.8 | learning rate: 1.000168E-05 | global batch size:     8 | lm loss: 2.956292E+00 | loss scale: 131072.0 | grad norm: 0.897 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 11:32:12] iteration   319800/  500000 | consumed samples:      2558400 | elapsed time per iteration (ms): 319.9 | learning rate: 1.000123E-05 | global batch size:     8 | lm loss: 2.985153E+00 | loss scale: 262144.0 | grad norm: 0.937 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 11:32:44] iteration   319900/  500000 | consumed samples:      2559200 | elapsed time per iteration (ms): 318.7 | learning rate: 1.000086E-05 | global batch size:     8 | lm loss: 3.005884E+00 | loss scale: 262144.0 | grad norm: 0.902 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 11:33:16] iteration   320000/  500000 | consumed samples:      2560000 | elapsed time per iteration (ms): 319.9 | learning rate: 1.000055E-05 | global batch size:     8 | lm loss: 2.975489E+00 | loss scale: 262144.0 | grad norm: 0.916 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1063.66, 1063.66)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 320000 | lm loss value: 3.710387E+00 | lm loss PPL: 4.086962E+01 | 
--------------------------------------------------------------------------------------------------
saving checkpoint at iteration  320000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-max in torch format
  successfully saved checkpoint at iteration  320000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-max
(min, max) time across ranks (ms):
    save-checkpoint ................................: (5630.60, 5630.60)
 [2024-06-22 11:33:55] iteration   320100/  500000 | consumed samples:      2560800 | elapsed time per iteration (ms): 320.4 | learning rate: 1.000031E-05 | global batch size:     8 | lm loss: 2.969497E+00 | loss scale: 262144.0 | grad norm: 0.959 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 11:34:27] iteration   320200/  500000 | consumed samples:      2561600 | elapsed time per iteration (ms): 322.2 | learning rate: 1.000014E-05 | global batch size:     8 | lm loss: 2.981485E+00 | loss scale: 262144.0 | grad norm: 0.929 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 11:35:00] iteration   320300/  500000 | consumed samples:      2562400 | elapsed time per iteration (ms): 325.6 | learning rate: 1.000003E-05 | global batch size:     8 | lm loss: 2.940943E+00 | loss scale: 262144.0 | grad norm: 0.927 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 11:35:32] iteration   320400/  500000 | consumed samples:      2563200 | elapsed time per iteration (ms): 321.1 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.949839E+00 | loss scale: 262144.0 | grad norm: 0.909 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 11:36:04] iteration   320500/  500000 | consumed samples:      2564000 | elapsed time per iteration (ms): 322.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 3.000235E+00 | loss scale: 262144.0 | grad norm: 0.949 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 11:36:36] iteration   320600/  500000 | consumed samples:      2564800 | elapsed time per iteration (ms): 322.0 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.974090E+00 | loss scale: 262144.0 | grad norm: 0.937 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 11:37:08] iteration   320700/  500000 | consumed samples:      2565600 | elapsed time per iteration (ms): 322.1 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.889761E+00 | loss scale: 262144.0 | grad norm: 0.902 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 11:37:41] iteration   320800/  500000 | consumed samples:      2566400 | elapsed time per iteration (ms): 324.4 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.928105E+00 | loss scale: 524288.0 | grad norm: 0.913 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 11:38:13] iteration   320900/  500000 | consumed samples:      2567200 | elapsed time per iteration (ms): 321.0 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.989755E+00 | loss scale: 524288.0 | grad norm: 0.956 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 11:38:45] iteration   321000/  500000 | consumed samples:      2568000 | elapsed time per iteration (ms): 321.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.941829E+00 | loss scale: 524288.0 | grad norm: 0.944 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1062.28, 1062.28)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 321000 | lm loss value: 3.886078E+00 | lm loss PPL: 4.871945E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 11:39:18] iteration   321100/  500000 | consumed samples:      2568800 | elapsed time per iteration (ms): 320.1 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.967798E+00 | loss scale: 524288.0 | grad norm: 0.973 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 11:39:50] iteration   321200/  500000 | consumed samples:      2569600 | elapsed time per iteration (ms): 322.1 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.961932E+00 | loss scale: 524288.0 | grad norm: 0.986 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-22 11:40:23] iteration   321300/  500000 | consumed samples:      2570400 | elapsed time per iteration (ms): 323.1 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 3.002208E+00 | loss scale: 524288.0 | grad norm: 0.906 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 11:40:55] iteration   321400/  500000 | consumed samples:      2571200 | elapsed time per iteration (ms): 320.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.949163E+00 | loss scale: 524288.0 | grad norm: 0.921 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 11:41:27] iteration   321500/  500000 | consumed samples:      2572000 | elapsed time per iteration (ms): 322.9 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.981117E+00 | loss scale: 524288.0 | grad norm: 0.970 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 11:41:59] iteration   321600/  500000 | consumed samples:      2572800 | elapsed time per iteration (ms): 322.4 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.989908E+00 | loss scale: 524288.0 | grad norm: 0.879 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 11:42:32] iteration   321700/  500000 | consumed samples:      2573600 | elapsed time per iteration (ms): 323.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.958587E+00 | loss scale: 524288.0 | grad norm: 0.905 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 11:43:04] iteration   321800/  500000 | consumed samples:      2574400 | elapsed time per iteration (ms): 321.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.964784E+00 | loss scale: 524288.0 | grad norm: 0.932 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 11:43:36] iteration   321900/  500000 | consumed samples:      2575200 | elapsed time per iteration (ms): 321.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.972341E+00 | loss scale: 524288.0 | grad norm: 0.874 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 11:44:08] iteration   322000/  500000 | consumed samples:      2576000 | elapsed time per iteration (ms): 322.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.952221E+00 | loss scale: 524288.0 | grad norm: 0.901 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1064.90, 1064.90)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 322000 | lm loss value: 3.663184E+00 | lm loss PPL: 3.898526E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 11:44:42] iteration   322100/  500000 | consumed samples:      2576800 | elapsed time per iteration (ms): 323.9 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.968304E+00 | loss scale: 524288.0 | grad norm: 0.939 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 11:45:13] iteration   322200/  500000 | consumed samples:      2577600 | elapsed time per iteration (ms): 318.6 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.942230E+00 | loss scale: 524288.0 | grad norm: 0.923 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-22 11:45:46] iteration   322300/  500000 | consumed samples:      2578400 | elapsed time per iteration (ms): 320.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.941751E+00 | loss scale: 524288.0 | grad norm: 0.961 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 11:46:18] iteration   322400/  500000 | consumed samples:      2579200 | elapsed time per iteration (ms): 324.6 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.974442E+00 | loss scale: 524288.0 | grad norm: 0.876 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 11:46:50] iteration   322500/  500000 | consumed samples:      2580000 | elapsed time per iteration (ms): 322.4 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.953692E+00 | loss scale: 524288.0 | grad norm: 0.936 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 11:47:22] iteration   322600/  500000 | consumed samples:      2580800 | elapsed time per iteration (ms): 320.9 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 3.004226E+00 | loss scale: 262144.0 | grad norm: 0.917 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-22 11:47:55] iteration   322700/  500000 | consumed samples:      2581600 | elapsed time per iteration (ms): 323.4 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.996347E+00 | loss scale: 262144.0 | grad norm: 0.962 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 11:48:27] iteration   322800/  500000 | consumed samples:      2582400 | elapsed time per iteration (ms): 325.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.986305E+00 | loss scale: 262144.0 | grad norm: 0.934 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 11:49:00] iteration   322900/  500000 | consumed samples:      2583200 | elapsed time per iteration (ms): 325.1 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.963864E+00 | loss scale: 262144.0 | grad norm: 0.966 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 11:49:32] iteration   323000/  500000 | consumed samples:      2584000 | elapsed time per iteration (ms): 321.6 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.959043E+00 | loss scale: 262144.0 | grad norm: 0.945 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1065.58, 1065.58)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 323000 | lm loss value: 3.763918E+00 | lm loss PPL: 4.311701E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 11:50:05] iteration   323100/  500000 | consumed samples:      2584800 | elapsed time per iteration (ms): 323.9 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.950588E+00 | loss scale: 262144.0 | grad norm: 0.926 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 11:50:38] iteration   323200/  500000 | consumed samples:      2585600 | elapsed time per iteration (ms): 322.1 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.946486E+00 | loss scale: 262144.0 | grad norm: 0.941 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 11:51:10] iteration   323300/  500000 | consumed samples:      2586400 | elapsed time per iteration (ms): 321.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.984165E+00 | loss scale: 262144.0 | grad norm: 0.958 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 11:51:42] iteration   323400/  500000 | consumed samples:      2587200 | elapsed time per iteration (ms): 322.9 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.994703E+00 | loss scale: 262144.0 | grad norm: 0.912 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 11:52:14] iteration   323500/  500000 | consumed samples:      2588000 | elapsed time per iteration (ms): 320.1 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.942076E+00 | loss scale: 262144.0 | grad norm: 0.948 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 11:52:46] iteration   323600/  500000 | consumed samples:      2588800 | elapsed time per iteration (ms): 321.9 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.953620E+00 | loss scale: 524288.0 | grad norm: 0.921 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 11:53:18] iteration   323700/  500000 | consumed samples:      2589600 | elapsed time per iteration (ms): 321.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.948879E+00 | loss scale: 524288.0 | grad norm: 0.876 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 11:53:51] iteration   323800/  500000 | consumed samples:      2590400 | elapsed time per iteration (ms): 322.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.984115E+00 | loss scale: 524288.0 | grad norm: 0.915 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 11:54:23] iteration   323900/  500000 | consumed samples:      2591200 | elapsed time per iteration (ms): 322.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.921027E+00 | loss scale: 524288.0 | grad norm: 0.916 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 11:54:55] iteration   324000/  500000 | consumed samples:      2592000 | elapsed time per iteration (ms): 321.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.948175E+00 | loss scale: 524288.0 | grad norm: 0.933 | number of skipped iterations:   1 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1063.27, 1063.27)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 324000 | lm loss value: 3.661263E+00 | lm loss PPL: 3.891046E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 11:55:28] iteration   324100/  500000 | consumed samples:      2592800 | elapsed time per iteration (ms): 322.0 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 3.003934E+00 | loss scale: 524288.0 | grad norm: 0.953 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 11:56:00] iteration   324200/  500000 | consumed samples:      2593600 | elapsed time per iteration (ms): 320.1 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.974525E+00 | loss scale: 524288.0 | grad norm: 0.940 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 11:56:32] iteration   324300/  500000 | consumed samples:      2594400 | elapsed time per iteration (ms): 319.6 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.965070E+00 | loss scale: 262144.0 | grad norm: 0.979 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-22 11:57:04] iteration   324400/  500000 | consumed samples:      2595200 | elapsed time per iteration (ms): 318.6 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 3.002276E+00 | loss scale: 262144.0 | grad norm: 0.941 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 11:57:36] iteration   324500/  500000 | consumed samples:      2596000 | elapsed time per iteration (ms): 321.1 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.987933E+00 | loss scale: 262144.0 | grad norm: 0.967 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 11:58:08] iteration   324600/  500000 | consumed samples:      2596800 | elapsed time per iteration (ms): 320.4 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.956662E+00 | loss scale: 262144.0 | grad norm: 0.936 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 11:58:40] iteration   324700/  500000 | consumed samples:      2597600 | elapsed time per iteration (ms): 319.4 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.981731E+00 | loss scale: 262144.0 | grad norm: 0.959 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 11:59:12] iteration   324800/  500000 | consumed samples:      2598400 | elapsed time per iteration (ms): 321.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.989241E+00 | loss scale: 262144.0 | grad norm: 0.889 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 11:59:44] iteration   324900/  500000 | consumed samples:      2599200 | elapsed time per iteration (ms): 321.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.959250E+00 | loss scale: 262144.0 | grad norm: 0.945 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 12:00:17] iteration   325000/  500000 | consumed samples:      2600000 | elapsed time per iteration (ms): 322.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.956693E+00 | loss scale: 262144.0 | grad norm: 0.968 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1063.13, 1063.13)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 325000 | lm loss value: 3.667317E+00 | lm loss PPL: 3.914674E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 12:00:50] iteration   325100/  500000 | consumed samples:      2600800 | elapsed time per iteration (ms): 320.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.926837E+00 | loss scale: 262144.0 | grad norm: 0.963 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 12:01:22] iteration   325200/  500000 | consumed samples:      2601600 | elapsed time per iteration (ms): 321.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.973798E+00 | loss scale: 262144.0 | grad norm: 0.947 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 12:01:54] iteration   325300/  500000 | consumed samples:      2602400 | elapsed time per iteration (ms): 321.1 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.936326E+00 | loss scale: 524288.0 | grad norm: 0.931 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 12:02:26] iteration   325400/  500000 | consumed samples:      2603200 | elapsed time per iteration (ms): 321.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.961612E+00 | loss scale: 524288.0 | grad norm: 0.910 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 12:02:58] iteration   325500/  500000 | consumed samples:      2604000 | elapsed time per iteration (ms): 320.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.990627E+00 | loss scale: 524288.0 | grad norm: 0.927 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 12:03:31] iteration   325600/  500000 | consumed samples:      2604800 | elapsed time per iteration (ms): 323.0 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.930940E+00 | loss scale: 524288.0 | grad norm: 0.914 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-22 12:04:03] iteration   325700/  500000 | consumed samples:      2605600 | elapsed time per iteration (ms): 320.9 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.971882E+00 | loss scale: 524288.0 | grad norm: 0.895 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 12:04:35] iteration   325800/  500000 | consumed samples:      2606400 | elapsed time per iteration (ms): 321.6 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.936143E+00 | loss scale: 524288.0 | grad norm: 0.936 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 12:05:07] iteration   325900/  500000 | consumed samples:      2607200 | elapsed time per iteration (ms): 321.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.969545E+00 | loss scale: 524288.0 | grad norm: 0.961 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 12:05:39] iteration   326000/  500000 | consumed samples:      2608000 | elapsed time per iteration (ms): 322.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.938322E+00 | loss scale: 524288.0 | grad norm: 0.933 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1066.19, 1066.19)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 326000 | lm loss value: 3.595909E+00 | lm loss PPL: 3.644882E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 12:06:12] iteration   326100/  500000 | consumed samples:      2608800 | elapsed time per iteration (ms): 321.4 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.953945E+00 | loss scale: 524288.0 | grad norm: 0.972 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 12:06:45] iteration   326200/  500000 | consumed samples:      2609600 | elapsed time per iteration (ms): 320.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.946379E+00 | loss scale: 524288.0 | grad norm: 0.929 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 12:07:17] iteration   326300/  500000 | consumed samples:      2610400 | elapsed time per iteration (ms): 321.6 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.998642E+00 | loss scale: 524288.0 | grad norm: 0.934 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 12:07:49] iteration   326400/  500000 | consumed samples:      2611200 | elapsed time per iteration (ms): 321.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.921505E+00 | loss scale: 524288.0 | grad norm: 0.922 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 12:08:21] iteration   326500/  500000 | consumed samples:      2612000 | elapsed time per iteration (ms): 318.1 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.993276E+00 | loss scale: 524288.0 | grad norm: 0.927 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 12:08:53] iteration   326600/  500000 | consumed samples:      2612800 | elapsed time per iteration (ms): 319.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 3.003735E+00 | loss scale: 524288.0 | grad norm: 0.969 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-22 12:09:25] iteration   326700/  500000 | consumed samples:      2613600 | elapsed time per iteration (ms): 319.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.945980E+00 | loss scale: 524288.0 | grad norm: 0.917 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 12:09:57] iteration   326800/  500000 | consumed samples:      2614400 | elapsed time per iteration (ms): 320.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.959410E+00 | loss scale: 524288.0 | grad norm: 0.950 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 12:10:29] iteration   326900/  500000 | consumed samples:      2615200 | elapsed time per iteration (ms): 323.6 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.970537E+00 | loss scale: 524288.0 | grad norm: 0.894 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 12:11:01] iteration   327000/  500000 | consumed samples:      2616000 | elapsed time per iteration (ms): 321.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.991569E+00 | loss scale: 524288.0 | grad norm: 0.952 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1067.66, 1067.66)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 327000 | lm loss value: 3.754348E+00 | lm loss PPL: 4.270635E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 12:11:35] iteration   327100/  500000 | consumed samples:      2616800 | elapsed time per iteration (ms): 325.9 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.942404E+00 | loss scale: 524288.0 | grad norm: 0.932 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 12:12:07] iteration   327200/  500000 | consumed samples:      2617600 | elapsed time per iteration (ms): 321.9 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.948486E+00 | loss scale: 524288.0 | grad norm: 0.952 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 12:12:39] iteration   327300/  500000 | consumed samples:      2618400 | elapsed time per iteration (ms): 323.6 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.957222E+00 | loss scale: 262144.0 | grad norm: 0.930 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-22 12:13:12] iteration   327400/  500000 | consumed samples:      2619200 | elapsed time per iteration (ms): 322.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.993460E+00 | loss scale: 262144.0 | grad norm: 0.931 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 12:13:44] iteration   327500/  500000 | consumed samples:      2620000 | elapsed time per iteration (ms): 324.0 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.961462E+00 | loss scale: 262144.0 | grad norm: 0.984 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 12:14:16] iteration   327600/  500000 | consumed samples:      2620800 | elapsed time per iteration (ms): 318.9 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 3.017906E+00 | loss scale: 262144.0 | grad norm: 0.941 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 12:14:48] iteration   327700/  500000 | consumed samples:      2621600 | elapsed time per iteration (ms): 322.4 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.932508E+00 | loss scale: 262144.0 | grad norm: 0.900 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 12:15:20] iteration   327800/  500000 | consumed samples:      2622400 | elapsed time per iteration (ms): 321.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.979385E+00 | loss scale: 262144.0 | grad norm: 0.963 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 12:15:53] iteration   327900/  500000 | consumed samples:      2623200 | elapsed time per iteration (ms): 323.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.958853E+00 | loss scale: 262144.0 | grad norm: 0.911 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 12:16:25] iteration   328000/  500000 | consumed samples:      2624000 | elapsed time per iteration (ms): 322.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.956796E+00 | loss scale: 262144.0 | grad norm: 0.901 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1063.18, 1063.18)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 328000 | lm loss value: 3.734754E+00 | lm loss PPL: 4.187772E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 12:16:58] iteration   328100/  500000 | consumed samples:      2624800 | elapsed time per iteration (ms): 319.9 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.945671E+00 | loss scale: 262144.0 | grad norm: 0.971 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 12:17:30] iteration   328200/  500000 | consumed samples:      2625600 | elapsed time per iteration (ms): 321.1 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.946725E+00 | loss scale: 262144.0 | grad norm: 1.022 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 12:18:02] iteration   328300/  500000 | consumed samples:      2626400 | elapsed time per iteration (ms): 321.4 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.969437E+00 | loss scale: 524288.0 | grad norm: 0.927 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 12:18:34] iteration   328400/  500000 | consumed samples:      2627200 | elapsed time per iteration (ms): 320.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.934548E+00 | loss scale: 524288.0 | grad norm: 0.913 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 12:19:06] iteration   328500/  500000 | consumed samples:      2628000 | elapsed time per iteration (ms): 318.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.977037E+00 | loss scale: 262144.0 | grad norm: 0.921 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-22 12:19:38] iteration   328600/  500000 | consumed samples:      2628800 | elapsed time per iteration (ms): 320.9 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.972151E+00 | loss scale: 262144.0 | grad norm: 0.952 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 12:20:10] iteration   328700/  500000 | consumed samples:      2629600 | elapsed time per iteration (ms): 318.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.956944E+00 | loss scale: 262144.0 | grad norm: 0.958 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 12:20:42] iteration   328800/  500000 | consumed samples:      2630400 | elapsed time per iteration (ms): 320.1 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.996912E+00 | loss scale: 262144.0 | grad norm: 0.896 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 12:21:14] iteration   328900/  500000 | consumed samples:      2631200 | elapsed time per iteration (ms): 321.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.952223E+00 | loss scale: 131072.0 | grad norm: 0.928 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-22 12:21:47] iteration   329000/  500000 | consumed samples:      2632000 | elapsed time per iteration (ms): 323.9 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.973279E+00 | loss scale: 131072.0 | grad norm: 0.945 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1066.46, 1066.46)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 329000 | lm loss value: 3.743360E+00 | lm loss PPL: 4.223969E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 12:22:20] iteration   329100/  500000 | consumed samples:      2632800 | elapsed time per iteration (ms): 321.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.952532E+00 | loss scale: 131072.0 | grad norm: 0.885 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 12:22:52] iteration   329200/  500000 | consumed samples:      2633600 | elapsed time per iteration (ms): 323.1 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.938677E+00 | loss scale: 131072.0 | grad norm: 0.969 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 12:23:24] iteration   329300/  500000 | consumed samples:      2634400 | elapsed time per iteration (ms): 322.6 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.969285E+00 | loss scale: 131072.0 | grad norm: 0.967 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 12:23:57] iteration   329400/  500000 | consumed samples:      2635200 | elapsed time per iteration (ms): 322.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.940693E+00 | loss scale: 65536.0 | grad norm: 0.921 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-22 12:24:29] iteration   329500/  500000 | consumed samples:      2636000 | elapsed time per iteration (ms): 323.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.966081E+00 | loss scale: 65536.0 | grad norm: 0.949 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 12:25:01] iteration   329600/  500000 | consumed samples:      2636800 | elapsed time per iteration (ms): 322.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.955626E+00 | loss scale: 65536.0 | grad norm: 0.954 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 12:25:33] iteration   329700/  500000 | consumed samples:      2637600 | elapsed time per iteration (ms): 321.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.964798E+00 | loss scale: 65536.0 | grad norm: 0.903 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 12:26:06] iteration   329800/  500000 | consumed samples:      2638400 | elapsed time per iteration (ms): 322.6 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.943924E+00 | loss scale: 65536.0 | grad norm: 0.947 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 12:26:38] iteration   329900/  500000 | consumed samples:      2639200 | elapsed time per iteration (ms): 321.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.960097E+00 | loss scale: 65536.0 | grad norm: 0.967 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 12:27:10] iteration   330000/  500000 | consumed samples:      2640000 | elapsed time per iteration (ms): 321.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.944591E+00 | loss scale: 65536.0 | grad norm: 0.919 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1063.13, 1063.13)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 330000 | lm loss value: 3.641995E+00 | lm loss PPL: 3.816790E+01 | 
--------------------------------------------------------------------------------------------------
saving checkpoint at iteration  330000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-max in torch format
  successfully saved checkpoint at iteration  330000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-max
(min, max) time across ranks (ms):
    save-checkpoint ................................: (5591.44, 5591.44)
 [2024-06-22 12:27:49] iteration   330100/  500000 | consumed samples:      2640800 | elapsed time per iteration (ms): 321.6 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.965551E+00 | loss scale: 65536.0 | grad norm: 0.969 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 12:28:21] iteration   330200/  500000 | consumed samples:      2641600 | elapsed time per iteration (ms): 321.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.943998E+00 | loss scale: 32768.0 | grad norm: 0.873 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-22 12:28:53] iteration   330300/  500000 | consumed samples:      2642400 | elapsed time per iteration (ms): 322.0 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.982751E+00 | loss scale: 32768.0 | grad norm: 0.950 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 12:29:25] iteration   330400/  500000 | consumed samples:      2643200 | elapsed time per iteration (ms): 320.6 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.970248E+00 | loss scale: 32768.0 | grad norm: 0.897 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 12:29:57] iteration   330500/  500000 | consumed samples:      2644000 | elapsed time per iteration (ms): 322.0 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.965275E+00 | loss scale: 32768.0 | grad norm: 0.938 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 12:30:29] iteration   330600/  500000 | consumed samples:      2644800 | elapsed time per iteration (ms): 321.1 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.949529E+00 | loss scale: 32768.0 | grad norm: 0.893 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 12:31:02] iteration   330700/  500000 | consumed samples:      2645600 | elapsed time per iteration (ms): 322.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.977883E+00 | loss scale: 32768.0 | grad norm: 0.932 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 12:31:34] iteration   330800/  500000 | consumed samples:      2646400 | elapsed time per iteration (ms): 322.6 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.937028E+00 | loss scale: 32768.0 | grad norm: 0.961 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 12:32:06] iteration   330900/  500000 | consumed samples:      2647200 | elapsed time per iteration (ms): 320.6 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.939933E+00 | loss scale: 32768.0 | grad norm: 0.917 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 12:32:38] iteration   331000/  500000 | consumed samples:      2648000 | elapsed time per iteration (ms): 321.0 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.978559E+00 | loss scale: 32768.0 | grad norm: 0.908 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1063.81, 1063.81)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 331000 | lm loss value: 3.818215E+00 | lm loss PPL: 4.552287E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 12:33:11] iteration   331100/  500000 | consumed samples:      2648800 | elapsed time per iteration (ms): 319.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.904821E+00 | loss scale: 32768.0 | grad norm: 0.903 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 12:33:43] iteration   331200/  500000 | consumed samples:      2649600 | elapsed time per iteration (ms): 321.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.931613E+00 | loss scale: 65536.0 | grad norm: 0.976 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 12:34:15] iteration   331300/  500000 | consumed samples:      2650400 | elapsed time per iteration (ms): 320.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.977094E+00 | loss scale: 65536.0 | grad norm: 0.916 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 12:34:48] iteration   331400/  500000 | consumed samples:      2651200 | elapsed time per iteration (ms): 322.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.952181E+00 | loss scale: 65536.0 | grad norm: 0.917 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 12:35:20] iteration   331500/  500000 | consumed samples:      2652000 | elapsed time per iteration (ms): 322.0 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.940417E+00 | loss scale: 65536.0 | grad norm: 0.942 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 12:35:52] iteration   331600/  500000 | consumed samples:      2652800 | elapsed time per iteration (ms): 322.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.962627E+00 | loss scale: 65536.0 | grad norm: 0.911 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 12:36:24] iteration   331700/  500000 | consumed samples:      2653600 | elapsed time per iteration (ms): 320.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.982460E+00 | loss scale: 65536.0 | grad norm: 0.916 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 12:36:56] iteration   331800/  500000 | consumed samples:      2654400 | elapsed time per iteration (ms): 320.4 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 3.004734E+00 | loss scale: 65536.0 | grad norm: 0.914 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 12:37:28] iteration   331900/  500000 | consumed samples:      2655200 | elapsed time per iteration (ms): 321.9 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.971565E+00 | loss scale: 65536.0 | grad norm: 0.893 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 12:38:01] iteration   332000/  500000 | consumed samples:      2656000 | elapsed time per iteration (ms): 322.0 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.961812E+00 | loss scale: 65536.0 | grad norm: 0.942 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1062.76, 1062.76)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 332000 | lm loss value: 3.480934E+00 | lm loss PPL: 3.249005E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 12:38:34] iteration   332100/  500000 | consumed samples:      2656800 | elapsed time per iteration (ms): 322.6 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.999005E+00 | loss scale: 65536.0 | grad norm: 0.961 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 12:39:06] iteration   332200/  500000 | consumed samples:      2657600 | elapsed time per iteration (ms): 321.9 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.970547E+00 | loss scale: 131072.0 | grad norm: 0.920 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 12:39:39] iteration   332300/  500000 | consumed samples:      2658400 | elapsed time per iteration (ms): 324.4 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.947901E+00 | loss scale: 131072.0 | grad norm: 0.930 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 12:40:11] iteration   332400/  500000 | consumed samples:      2659200 | elapsed time per iteration (ms): 321.4 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.968263E+00 | loss scale: 131072.0 | grad norm: 0.948 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 12:40:43] iteration   332500/  500000 | consumed samples:      2660000 | elapsed time per iteration (ms): 320.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.965258E+00 | loss scale: 131072.0 | grad norm: 0.951 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 12:41:15] iteration   332600/  500000 | consumed samples:      2660800 | elapsed time per iteration (ms): 321.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.944539E+00 | loss scale: 131072.0 | grad norm: 0.894 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 12:41:47] iteration   332700/  500000 | consumed samples:      2661600 | elapsed time per iteration (ms): 322.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.944041E+00 | loss scale: 131072.0 | grad norm: 0.924 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 12:42:19] iteration   332800/  500000 | consumed samples:      2662400 | elapsed time per iteration (ms): 321.1 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.947143E+00 | loss scale: 131072.0 | grad norm: 0.951 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 12:42:51] iteration   332900/  500000 | consumed samples:      2663200 | elapsed time per iteration (ms): 322.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.964753E+00 | loss scale: 131072.0 | grad norm: 0.942 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 12:43:24] iteration   333000/  500000 | consumed samples:      2664000 | elapsed time per iteration (ms): 321.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.970336E+00 | loss scale: 131072.0 | grad norm: 1.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1065.38, 1065.38)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 333000 | lm loss value: 3.732362E+00 | lm loss PPL: 4.177767E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 12:43:57] iteration   333100/  500000 | consumed samples:      2664800 | elapsed time per iteration (ms): 322.0 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.953683E+00 | loss scale: 131072.0 | grad norm: 0.962 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 12:44:29] iteration   333200/  500000 | consumed samples:      2665600 | elapsed time per iteration (ms): 322.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 3.012039E+00 | loss scale: 262144.0 | grad norm: 0.959 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 12:45:01] iteration   333300/  500000 | consumed samples:      2666400 | elapsed time per iteration (ms): 322.4 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.980619E+00 | loss scale: 262144.0 | grad norm: 0.966 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 12:45:34] iteration   333400/  500000 | consumed samples:      2667200 | elapsed time per iteration (ms): 324.1 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.962077E+00 | loss scale: 262144.0 | grad norm: 0.930 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 12:46:06] iteration   333500/  500000 | consumed samples:      2668000 | elapsed time per iteration (ms): 321.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 3.011906E+00 | loss scale: 262144.0 | grad norm: 0.971 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 12:46:38] iteration   333600/  500000 | consumed samples:      2668800 | elapsed time per iteration (ms): 322.1 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.980726E+00 | loss scale: 262144.0 | grad norm: 0.872 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 12:47:10] iteration   333700/  500000 | consumed samples:      2669600 | elapsed time per iteration (ms): 322.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.960275E+00 | loss scale: 262144.0 | grad norm: 0.924 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 12:47:43] iteration   333800/  500000 | consumed samples:      2670400 | elapsed time per iteration (ms): 323.6 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.955957E+00 | loss scale: 262144.0 | grad norm: 0.953 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 12:48:15] iteration   333900/  500000 | consumed samples:      2671200 | elapsed time per iteration (ms): 322.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.965171E+00 | loss scale: 262144.0 | grad norm: 0.870 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 12:48:47] iteration   334000/  500000 | consumed samples:      2672000 | elapsed time per iteration (ms): 322.6 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.963233E+00 | loss scale: 262144.0 | grad norm: 0.979 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1063.08, 1063.08)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 334000 | lm loss value: 3.666113E+00 | lm loss PPL: 3.909962E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 12:49:20] iteration   334100/  500000 | consumed samples:      2672800 | elapsed time per iteration (ms): 321.6 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.970159E+00 | loss scale: 262144.0 | grad norm: 0.982 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 12:49:53] iteration   334200/  500000 | consumed samples:      2673600 | elapsed time per iteration (ms): 322.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.985055E+00 | loss scale: 524288.0 | grad norm: 0.941 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 12:50:25] iteration   334300/  500000 | consumed samples:      2674400 | elapsed time per iteration (ms): 323.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.910038E+00 | loss scale: 524288.0 | grad norm: 0.939 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 12:50:57] iteration   334400/  500000 | consumed samples:      2675200 | elapsed time per iteration (ms): 323.1 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.962873E+00 | loss scale: 524288.0 | grad norm: 0.932 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 12:51:29] iteration   334500/  500000 | consumed samples:      2676000 | elapsed time per iteration (ms): 320.9 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.949873E+00 | loss scale: 524288.0 | grad norm: 0.910 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-22 12:52:02] iteration   334600/  500000 | consumed samples:      2676800 | elapsed time per iteration (ms): 321.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.964743E+00 | loss scale: 262144.0 | grad norm: 0.968 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-22 12:52:34] iteration   334700/  500000 | consumed samples:      2677600 | elapsed time per iteration (ms): 321.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.979843E+00 | loss scale: 262144.0 | grad norm: 0.927 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 12:53:06] iteration   334800/  500000 | consumed samples:      2678400 | elapsed time per iteration (ms): 322.1 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 3.006296E+00 | loss scale: 262144.0 | grad norm: 0.920 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 12:53:38] iteration   334900/  500000 | consumed samples:      2679200 | elapsed time per iteration (ms): 322.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.937170E+00 | loss scale: 262144.0 | grad norm: 0.945 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 12:54:11] iteration   335000/  500000 | consumed samples:      2680000 | elapsed time per iteration (ms): 322.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.948717E+00 | loss scale: 262144.0 | grad norm: 1.017 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1064.23, 1064.23)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 335000 | lm loss value: 3.617182E+00 | lm loss PPL: 3.723248E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 12:54:44] iteration   335100/  500000 | consumed samples:      2680800 | elapsed time per iteration (ms): 319.4 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.925066E+00 | loss scale: 262144.0 | grad norm: 0.959 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 12:55:16] iteration   335200/  500000 | consumed samples:      2681600 | elapsed time per iteration (ms): 321.4 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.968596E+00 | loss scale: 262144.0 | grad norm: 0.920 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 12:55:48] iteration   335300/  500000 | consumed samples:      2682400 | elapsed time per iteration (ms): 322.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.937757E+00 | loss scale: 262144.0 | grad norm: 0.926 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 12:56:20] iteration   335400/  500000 | consumed samples:      2683200 | elapsed time per iteration (ms): 322.4 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.950757E+00 | loss scale: 262144.0 | grad norm: 0.931 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 12:56:52] iteration   335500/  500000 | consumed samples:      2684000 | elapsed time per iteration (ms): 322.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.993970E+00 | loss scale: 262144.0 | grad norm: 0.930 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 12:57:25] iteration   335600/  500000 | consumed samples:      2684800 | elapsed time per iteration (ms): 321.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.963058E+00 | loss scale: 524288.0 | grad norm: 0.941 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 12:57:57] iteration   335700/  500000 | consumed samples:      2685600 | elapsed time per iteration (ms): 322.4 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.956625E+00 | loss scale: 524288.0 | grad norm: 0.971 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 12:58:29] iteration   335800/  500000 | consumed samples:      2686400 | elapsed time per iteration (ms): 321.1 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.995143E+00 | loss scale: 524288.0 | grad norm: 0.911 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 12:59:01] iteration   335900/  500000 | consumed samples:      2687200 | elapsed time per iteration (ms): 322.1 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.968167E+00 | loss scale: 524288.0 | grad norm: 0.915 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 12:59:33] iteration   336000/  500000 | consumed samples:      2688000 | elapsed time per iteration (ms): 318.6 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.983998E+00 | loss scale: 524288.0 | grad norm: 0.928 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1063.12, 1063.12)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 336000 | lm loss value: 3.697880E+00 | lm loss PPL: 4.036166E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 13:00:06] iteration   336100/  500000 | consumed samples:      2688800 | elapsed time per iteration (ms): 321.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.971283E+00 | loss scale: 524288.0 | grad norm: 0.944 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 13:00:39] iteration   336200/  500000 | consumed samples:      2689600 | elapsed time per iteration (ms): 323.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.954403E+00 | loss scale: 524288.0 | grad norm: 0.913 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 13:01:11] iteration   336300/  500000 | consumed samples:      2690400 | elapsed time per iteration (ms): 322.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.981018E+00 | loss scale: 524288.0 | grad norm: 0.919 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 13:01:43] iteration   336400/  500000 | consumed samples:      2691200 | elapsed time per iteration (ms): 320.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.993015E+00 | loss scale: 524288.0 | grad norm: 0.917 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 13:02:15] iteration   336500/  500000 | consumed samples:      2692000 | elapsed time per iteration (ms): 319.9 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.970190E+00 | loss scale: 524288.0 | grad norm: 0.931 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 13:02:47] iteration   336600/  500000 | consumed samples:      2692800 | elapsed time per iteration (ms): 318.4 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.971117E+00 | loss scale: 524288.0 | grad norm: 0.901 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-22 13:03:19] iteration   336700/  500000 | consumed samples:      2693600 | elapsed time per iteration (ms): 320.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.971610E+00 | loss scale: 262144.0 | grad norm: 0.882 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-22 13:03:51] iteration   336800/  500000 | consumed samples:      2694400 | elapsed time per iteration (ms): 322.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.979433E+00 | loss scale: 262144.0 | grad norm: 0.953 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 13:04:23] iteration   336900/  500000 | consumed samples:      2695200 | elapsed time per iteration (ms): 323.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.914538E+00 | loss scale: 262144.0 | grad norm: 0.936 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 13:04:55] iteration   337000/  500000 | consumed samples:      2696000 | elapsed time per iteration (ms): 320.6 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.974724E+00 | loss scale: 262144.0 | grad norm: 0.923 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1062.67, 1062.67)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 337000 | lm loss value: 3.570792E+00 | lm loss PPL: 3.554475E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 13:05:28] iteration   337100/  500000 | consumed samples:      2696800 | elapsed time per iteration (ms): 319.9 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.953026E+00 | loss scale: 131072.0 | grad norm: 0.940 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-22 13:06:01] iteration   337200/  500000 | consumed samples:      2697600 | elapsed time per iteration (ms): 320.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.940834E+00 | loss scale: 131072.0 | grad norm: 0.910 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 13:06:33] iteration   337300/  500000 | consumed samples:      2698400 | elapsed time per iteration (ms): 321.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.932092E+00 | loss scale: 131072.0 | grad norm: 0.959 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 13:07:05] iteration   337400/  500000 | consumed samples:      2699200 | elapsed time per iteration (ms): 321.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.950924E+00 | loss scale: 131072.0 | grad norm: 0.944 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 13:07:37] iteration   337500/  500000 | consumed samples:      2700000 | elapsed time per iteration (ms): 321.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.992463E+00 | loss scale: 131072.0 | grad norm: 0.923 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 13:08:09] iteration   337600/  500000 | consumed samples:      2700800 | elapsed time per iteration (ms): 322.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.925012E+00 | loss scale: 131072.0 | grad norm: 0.959 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 13:08:41] iteration   337700/  500000 | consumed samples:      2701600 | elapsed time per iteration (ms): 321.9 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.979971E+00 | loss scale: 131072.0 | grad norm: 0.952 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 13:09:14] iteration   337800/  500000 | consumed samples:      2702400 | elapsed time per iteration (ms): 321.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.934810E+00 | loss scale: 131072.0 | grad norm: 0.974 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 13:09:46] iteration   337900/  500000 | consumed samples:      2703200 | elapsed time per iteration (ms): 324.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.955291E+00 | loss scale: 131072.0 | grad norm: 0.938 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 13:10:18] iteration   338000/  500000 | consumed samples:      2704000 | elapsed time per iteration (ms): 319.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.972209E+00 | loss scale: 131072.0 | grad norm: 0.965 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1062.38, 1062.38)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 338000 | lm loss value: 3.696404E+00 | lm loss PPL: 4.030212E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 13:10:51] iteration   338100/  500000 | consumed samples:      2704800 | elapsed time per iteration (ms): 321.0 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.945332E+00 | loss scale: 262144.0 | grad norm: 0.927 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 13:11:23] iteration   338200/  500000 | consumed samples:      2705600 | elapsed time per iteration (ms): 320.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.963226E+00 | loss scale: 262144.0 | grad norm: 0.921 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 13:11:56] iteration   338300/  500000 | consumed samples:      2706400 | elapsed time per iteration (ms): 322.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.949807E+00 | loss scale: 262144.0 | grad norm: 0.931 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 13:12:28] iteration   338400/  500000 | consumed samples:      2707200 | elapsed time per iteration (ms): 323.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.963015E+00 | loss scale: 262144.0 | grad norm: 0.964 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 13:13:00] iteration   338500/  500000 | consumed samples:      2708000 | elapsed time per iteration (ms): 323.4 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.959108E+00 | loss scale: 262144.0 | grad norm: 0.925 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 13:13:32] iteration   338600/  500000 | consumed samples:      2708800 | elapsed time per iteration (ms): 320.9 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.956578E+00 | loss scale: 262144.0 | grad norm: 0.932 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 13:14:04] iteration   338700/  500000 | consumed samples:      2709600 | elapsed time per iteration (ms): 320.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.930942E+00 | loss scale: 262144.0 | grad norm: 0.882 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 13:14:37] iteration   338800/  500000 | consumed samples:      2710400 | elapsed time per iteration (ms): 324.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.990755E+00 | loss scale: 262144.0 | grad norm: 0.994 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 13:15:09] iteration   338900/  500000 | consumed samples:      2711200 | elapsed time per iteration (ms): 324.1 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.890575E+00 | loss scale: 262144.0 | grad norm: 0.983 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 13:15:41] iteration   339000/  500000 | consumed samples:      2712000 | elapsed time per iteration (ms): 322.1 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.960441E+00 | loss scale: 262144.0 | grad norm: 0.938 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1063.70, 1063.70)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 339000 | lm loss value: 3.672706E+00 | lm loss PPL: 3.935828E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 13:16:14] iteration   339100/  500000 | consumed samples:      2712800 | elapsed time per iteration (ms): 320.0 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.976385E+00 | loss scale: 524288.0 | grad norm: 0.938 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 13:16:47] iteration   339200/  500000 | consumed samples:      2713600 | elapsed time per iteration (ms): 323.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.992714E+00 | loss scale: 524288.0 | grad norm: 0.911 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 13:17:19] iteration   339300/  500000 | consumed samples:      2714400 | elapsed time per iteration (ms): 321.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.982304E+00 | loss scale: 524288.0 | grad norm: 0.972 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 13:17:51] iteration   339400/  500000 | consumed samples:      2715200 | elapsed time per iteration (ms): 322.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.968263E+00 | loss scale: 524288.0 | grad norm: 0.937 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 13:18:23] iteration   339500/  500000 | consumed samples:      2716000 | elapsed time per iteration (ms): 320.4 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.975524E+00 | loss scale: 524288.0 | grad norm: 0.941 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 13:18:56] iteration   339600/  500000 | consumed samples:      2716800 | elapsed time per iteration (ms): 321.9 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.966684E+00 | loss scale: 524288.0 | grad norm: 0.947 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 13:19:28] iteration   339700/  500000 | consumed samples:      2717600 | elapsed time per iteration (ms): 321.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.979443E+00 | loss scale: 524288.0 | grad norm: 0.966 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 13:20:00] iteration   339800/  500000 | consumed samples:      2718400 | elapsed time per iteration (ms): 322.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.968401E+00 | loss scale: 524288.0 | grad norm: 0.988 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 13:20:32] iteration   339900/  500000 | consumed samples:      2719200 | elapsed time per iteration (ms): 323.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.974327E+00 | loss scale: 524288.0 | grad norm: 0.966 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 13:21:04] iteration   340000/  500000 | consumed samples:      2720000 | elapsed time per iteration (ms): 320.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.955245E+00 | loss scale: 524288.0 | grad norm: 0.924 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1063.47, 1063.47)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 340000 | lm loss value: 3.703991E+00 | lm loss PPL: 4.060907E+01 | 
--------------------------------------------------------------------------------------------------
saving checkpoint at iteration  340000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-max in torch format
  successfully saved checkpoint at iteration  340000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-max
(min, max) time across ranks (ms):
    save-checkpoint ................................: (5567.50, 5567.50)
 [2024-06-22 13:21:43] iteration   340100/  500000 | consumed samples:      2720800 | elapsed time per iteration (ms): 322.4 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.947953E+00 | loss scale: 1048576.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-22 13:22:15] iteration   340200/  500000 | consumed samples:      2721600 | elapsed time per iteration (ms): 321.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.958665E+00 | loss scale: 524288.0 | grad norm: 0.969 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-22 13:22:47] iteration   340300/  500000 | consumed samples:      2722400 | elapsed time per iteration (ms): 321.0 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.975304E+00 | loss scale: 524288.0 | grad norm: 0.944 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 13:23:20] iteration   340400/  500000 | consumed samples:      2723200 | elapsed time per iteration (ms): 322.1 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.996521E+00 | loss scale: 524288.0 | grad norm: 0.929 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 13:23:52] iteration   340500/  500000 | consumed samples:      2724000 | elapsed time per iteration (ms): 322.1 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.964960E+00 | loss scale: 524288.0 | grad norm: 0.913 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 13:24:24] iteration   340600/  500000 | consumed samples:      2724800 | elapsed time per iteration (ms): 321.9 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.979529E+00 | loss scale: 524288.0 | grad norm: 0.925 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 13:24:56] iteration   340700/  500000 | consumed samples:      2725600 | elapsed time per iteration (ms): 322.0 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.959195E+00 | loss scale: 524288.0 | grad norm: 0.968 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 13:25:28] iteration   340800/  500000 | consumed samples:      2726400 | elapsed time per iteration (ms): 321.6 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.927062E+00 | loss scale: 524288.0 | grad norm: 0.982 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 13:26:01] iteration   340900/  500000 | consumed samples:      2727200 | elapsed time per iteration (ms): 322.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.956201E+00 | loss scale: 524288.0 | grad norm: 0.901 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 13:26:33] iteration   341000/  500000 | consumed samples:      2728000 | elapsed time per iteration (ms): 323.6 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.975529E+00 | loss scale: 524288.0 | grad norm: 0.941 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1063.51, 1063.51)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 341000 | lm loss value: 3.705398E+00 | lm loss PPL: 4.066624E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 13:27:06] iteration   341100/  500000 | consumed samples:      2728800 | elapsed time per iteration (ms): 318.1 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.948105E+00 | loss scale: 524288.0 | grad norm: 0.906 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 13:27:38] iteration   341200/  500000 | consumed samples:      2729600 | elapsed time per iteration (ms): 320.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.933515E+00 | loss scale: 524288.0 | grad norm: 0.984 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-22 13:28:10] iteration   341300/  500000 | consumed samples:      2730400 | elapsed time per iteration (ms): 320.1 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.976151E+00 | loss scale: 524288.0 | grad norm: 0.960 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 13:28:42] iteration   341400/  500000 | consumed samples:      2731200 | elapsed time per iteration (ms): 324.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 3.002818E+00 | loss scale: 524288.0 | grad norm: 0.985 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 13:29:15] iteration   341500/  500000 | consumed samples:      2732000 | elapsed time per iteration (ms): 321.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.952184E+00 | loss scale: 524288.0 | grad norm: 0.895 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 13:29:47] iteration   341600/  500000 | consumed samples:      2732800 | elapsed time per iteration (ms): 320.1 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.947924E+00 | loss scale: 524288.0 | grad norm: 0.916 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 13:30:19] iteration   341700/  500000 | consumed samples:      2733600 | elapsed time per iteration (ms): 321.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.959325E+00 | loss scale: 524288.0 | grad norm: 0.906 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 13:30:51] iteration   341800/  500000 | consumed samples:      2734400 | elapsed time per iteration (ms): 320.9 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.957769E+00 | loss scale: 262144.0 | grad norm: 0.998 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-22 13:31:23] iteration   341900/  500000 | consumed samples:      2735200 | elapsed time per iteration (ms): 319.9 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.959641E+00 | loss scale: 262144.0 | grad norm: 0.947 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 13:31:55] iteration   342000/  500000 | consumed samples:      2736000 | elapsed time per iteration (ms): 322.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 3.010376E+00 | loss scale: 262144.0 | grad norm: 0.948 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1063.53, 1063.53)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 342000 | lm loss value: 3.647674E+00 | lm loss PPL: 3.838527E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 13:32:28] iteration   342100/  500000 | consumed samples:      2736800 | elapsed time per iteration (ms): 322.9 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.923747E+00 | loss scale: 262144.0 | grad norm: 0.980 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 13:33:01] iteration   342200/  500000 | consumed samples:      2737600 | elapsed time per iteration (ms): 321.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.935071E+00 | loss scale: 262144.0 | grad norm: 0.961 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 13:33:33] iteration   342300/  500000 | consumed samples:      2738400 | elapsed time per iteration (ms): 322.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.936549E+00 | loss scale: 262144.0 | grad norm: 0.921 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 13:34:05] iteration   342400/  500000 | consumed samples:      2739200 | elapsed time per iteration (ms): 323.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.938559E+00 | loss scale: 262144.0 | grad norm: 0.941 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 13:34:38] iteration   342500/  500000 | consumed samples:      2740000 | elapsed time per iteration (ms): 323.4 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.986750E+00 | loss scale: 262144.0 | grad norm: 0.971 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 13:35:10] iteration   342600/  500000 | consumed samples:      2740800 | elapsed time per iteration (ms): 320.0 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.974901E+00 | loss scale: 262144.0 | grad norm: 0.969 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 13:35:42] iteration   342700/  500000 | consumed samples:      2741600 | elapsed time per iteration (ms): 325.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.955663E+00 | loss scale: 262144.0 | grad norm: 0.955 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 13:36:14] iteration   342800/  500000 | consumed samples:      2742400 | elapsed time per iteration (ms): 322.6 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.980774E+00 | loss scale: 524288.0 | grad norm: 0.934 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 13:36:47] iteration   342900/  500000 | consumed samples:      2743200 | elapsed time per iteration (ms): 323.1 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.943765E+00 | loss scale: 524288.0 | grad norm: 0.945 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-22 13:37:19] iteration   343000/  500000 | consumed samples:      2744000 | elapsed time per iteration (ms): 321.1 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.955214E+00 | loss scale: 524288.0 | grad norm: 0.952 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1065.46, 1065.46)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 343000 | lm loss value: 3.665960E+00 | lm loss PPL: 3.909365E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 13:37:52] iteration   343100/  500000 | consumed samples:      2744800 | elapsed time per iteration (ms): 322.1 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.928962E+00 | loss scale: 524288.0 | grad norm: 0.956 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 13:38:24] iteration   343200/  500000 | consumed samples:      2745600 | elapsed time per iteration (ms): 319.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.950085E+00 | loss scale: 524288.0 | grad norm: 0.971 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 13:38:56] iteration   343300/  500000 | consumed samples:      2746400 | elapsed time per iteration (ms): 322.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.974240E+00 | loss scale: 524288.0 | grad norm: 0.998 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 13:39:28] iteration   343400/  500000 | consumed samples:      2747200 | elapsed time per iteration (ms): 321.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.956516E+00 | loss scale: 524288.0 | grad norm: 1.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 13:40:01] iteration   343500/  500000 | consumed samples:      2748000 | elapsed time per iteration (ms): 323.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.954486E+00 | loss scale: 524288.0 | grad norm: 0.985 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 13:40:33] iteration   343600/  500000 | consumed samples:      2748800 | elapsed time per iteration (ms): 322.0 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.964758E+00 | loss scale: 524288.0 | grad norm: 0.920 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 13:41:05] iteration   343700/  500000 | consumed samples:      2749600 | elapsed time per iteration (ms): 321.6 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.945405E+00 | loss scale: 524288.0 | grad norm: 1.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 13:41:37] iteration   343800/  500000 | consumed samples:      2750400 | elapsed time per iteration (ms): 321.6 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.981253E+00 | loss scale: 524288.0 | grad norm: 0.945 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 13:42:09] iteration   343900/  500000 | consumed samples:      2751200 | elapsed time per iteration (ms): 321.6 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.948807E+00 | loss scale: 524288.0 | grad norm: 0.983 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-22 13:42:42] iteration   344000/  500000 | consumed samples:      2752000 | elapsed time per iteration (ms): 321.0 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.964571E+00 | loss scale: 524288.0 | grad norm: 0.979 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1063.19, 1063.19)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 344000 | lm loss value: 3.645108E+00 | lm loss PPL: 3.828690E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 13:43:15] iteration   344100/  500000 | consumed samples:      2752800 | elapsed time per iteration (ms): 321.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.991538E+00 | loss scale: 524288.0 | grad norm: 0.932 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 13:43:47] iteration   344200/  500000 | consumed samples:      2753600 | elapsed time per iteration (ms): 323.9 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.981318E+00 | loss scale: 524288.0 | grad norm: 0.967 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 13:44:19] iteration   344300/  500000 | consumed samples:      2754400 | elapsed time per iteration (ms): 322.4 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.975675E+00 | loss scale: 524288.0 | grad norm: 1.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 13:44:52] iteration   344400/  500000 | consumed samples:      2755200 | elapsed time per iteration (ms): 325.0 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.962396E+00 | loss scale: 524288.0 | grad norm: 0.906 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 13:45:24] iteration   344500/  500000 | consumed samples:      2756000 | elapsed time per iteration (ms): 323.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.991064E+00 | loss scale: 524288.0 | grad norm: 0.919 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 13:45:57] iteration   344600/  500000 | consumed samples:      2756800 | elapsed time per iteration (ms): 323.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.914706E+00 | loss scale: 524288.0 | grad norm: 0.911 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 13:46:29] iteration   344700/  500000 | consumed samples:      2757600 | elapsed time per iteration (ms): 324.4 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.945928E+00 | loss scale: 524288.0 | grad norm: 0.909 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 13:47:01] iteration   344800/  500000 | consumed samples:      2758400 | elapsed time per iteration (ms): 324.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.959247E+00 | loss scale: 524288.0 | grad norm: 0.928 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 13:47:34] iteration   344900/  500000 | consumed samples:      2759200 | elapsed time per iteration (ms): 321.1 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.946844E+00 | loss scale: 524288.0 | grad norm: 0.948 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-22 13:48:06] iteration   345000/  500000 | consumed samples:      2760000 | elapsed time per iteration (ms): 320.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.925602E+00 | loss scale: 524288.0 | grad norm: 0.949 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1062.80, 1062.80)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 345000 | lm loss value: 3.590821E+00 | lm loss PPL: 3.626383E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 13:48:39] iteration   345100/  500000 | consumed samples:      2760800 | elapsed time per iteration (ms): 321.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.975872E+00 | loss scale: 524288.0 | grad norm: 0.925 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 13:49:11] iteration   345200/  500000 | consumed samples:      2761600 | elapsed time per iteration (ms): 321.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.953927E+00 | loss scale: 262144.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-22 13:49:43] iteration   345300/  500000 | consumed samples:      2762400 | elapsed time per iteration (ms): 323.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.974463E+00 | loss scale: 262144.0 | grad norm: 0.941 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 13:50:16] iteration   345400/  500000 | consumed samples:      2763200 | elapsed time per iteration (ms): 321.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.919441E+00 | loss scale: 262144.0 | grad norm: 0.940 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 13:50:48] iteration   345500/  500000 | consumed samples:      2764000 | elapsed time per iteration (ms): 321.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.959357E+00 | loss scale: 262144.0 | grad norm: 0.949 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 13:51:20] iteration   345600/  500000 | consumed samples:      2764800 | elapsed time per iteration (ms): 321.6 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.945919E+00 | loss scale: 262144.0 | grad norm: 0.951 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 13:51:52] iteration   345700/  500000 | consumed samples:      2765600 | elapsed time per iteration (ms): 322.9 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.925529E+00 | loss scale: 262144.0 | grad norm: 0.952 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 13:52:24] iteration   345800/  500000 | consumed samples:      2766400 | elapsed time per iteration (ms): 321.6 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.972403E+00 | loss scale: 262144.0 | grad norm: 0.964 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 13:52:57] iteration   345900/  500000 | consumed samples:      2767200 | elapsed time per iteration (ms): 322.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.984167E+00 | loss scale: 262144.0 | grad norm: 0.935 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 13:53:29] iteration   346000/  500000 | consumed samples:      2768000 | elapsed time per iteration (ms): 322.6 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.957606E+00 | loss scale: 262144.0 | grad norm: 0.914 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1065.14, 1065.14)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 346000 | lm loss value: 3.771843E+00 | lm loss PPL: 4.346009E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 13:54:02] iteration   346100/  500000 | consumed samples:      2768800 | elapsed time per iteration (ms): 321.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.959564E+00 | loss scale: 262144.0 | grad norm: 0.900 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 13:54:34] iteration   346200/  500000 | consumed samples:      2769600 | elapsed time per iteration (ms): 323.6 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.963085E+00 | loss scale: 524288.0 | grad norm: 0.934 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 13:55:07] iteration   346300/  500000 | consumed samples:      2770400 | elapsed time per iteration (ms): 322.4 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.923969E+00 | loss scale: 524288.0 | grad norm: 0.936 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 13:55:39] iteration   346400/  500000 | consumed samples:      2771200 | elapsed time per iteration (ms): 322.0 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.963180E+00 | loss scale: 524288.0 | grad norm: 0.951 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 13:56:11] iteration   346500/  500000 | consumed samples:      2772000 | elapsed time per iteration (ms): 321.4 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.972032E+00 | loss scale: 524288.0 | grad norm: 0.973 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 13:56:43] iteration   346600/  500000 | consumed samples:      2772800 | elapsed time per iteration (ms): 323.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.989594E+00 | loss scale: 524288.0 | grad norm: 0.943 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 13:57:15] iteration   346700/  500000 | consumed samples:      2773600 | elapsed time per iteration (ms): 320.9 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.959013E+00 | loss scale: 524288.0 | grad norm: 0.940 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 13:57:48] iteration   346800/  500000 | consumed samples:      2774400 | elapsed time per iteration (ms): 324.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.954298E+00 | loss scale: 524288.0 | grad norm: 0.937 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 13:58:20] iteration   346900/  500000 | consumed samples:      2775200 | elapsed time per iteration (ms): 321.0 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.961953E+00 | loss scale: 524288.0 | grad norm: 0.928 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 13:58:52] iteration   347000/  500000 | consumed samples:      2776000 | elapsed time per iteration (ms): 322.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.948660E+00 | loss scale: 524288.0 | grad norm: 0.913 | number of skipped iterations:   1 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1063.34, 1063.34)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 347000 | lm loss value: 3.715368E+00 | lm loss PPL: 4.107370E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 13:59:25] iteration   347100/  500000 | consumed samples:      2776800 | elapsed time per iteration (ms): 321.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.938448E+00 | loss scale: 524288.0 | grad norm: 0.940 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 13:59:58] iteration   347200/  500000 | consumed samples:      2777600 | elapsed time per iteration (ms): 320.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.943046E+00 | loss scale: 262144.0 | grad norm: 0.867 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-22 14:00:30] iteration   347300/  500000 | consumed samples:      2778400 | elapsed time per iteration (ms): 320.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.957855E+00 | loss scale: 262144.0 | grad norm: 0.985 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 14:01:02] iteration   347400/  500000 | consumed samples:      2779200 | elapsed time per iteration (ms): 321.1 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.968310E+00 | loss scale: 131072.0 | grad norm: 0.949 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-22 14:01:34] iteration   347500/  500000 | consumed samples:      2780000 | elapsed time per iteration (ms): 321.1 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.936865E+00 | loss scale: 131072.0 | grad norm: 0.948 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 14:02:06] iteration   347600/  500000 | consumed samples:      2780800 | elapsed time per iteration (ms): 321.4 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.961195E+00 | loss scale: 131072.0 | grad norm: 0.965 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 14:02:38] iteration   347700/  500000 | consumed samples:      2781600 | elapsed time per iteration (ms): 322.4 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.950567E+00 | loss scale: 131072.0 | grad norm: 0.885 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 14:03:10] iteration   347800/  500000 | consumed samples:      2782400 | elapsed time per iteration (ms): 320.6 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.972886E+00 | loss scale: 131072.0 | grad norm: 0.930 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 14:03:43] iteration   347900/  500000 | consumed samples:      2783200 | elapsed time per iteration (ms): 322.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.945173E+00 | loss scale: 131072.0 | grad norm: 0.981 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 14:04:15] iteration   348000/  500000 | consumed samples:      2784000 | elapsed time per iteration (ms): 321.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.948619E+00 | loss scale: 131072.0 | grad norm: 0.930 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1065.15, 1065.15)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 348000 | lm loss value: 3.563290E+00 | lm loss PPL: 3.527909E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 14:04:48] iteration   348100/  500000 | consumed samples:      2784800 | elapsed time per iteration (ms): 323.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.985534E+00 | loss scale: 131072.0 | grad norm: 0.964 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 14:05:20] iteration   348200/  500000 | consumed samples:      2785600 | elapsed time per iteration (ms): 320.1 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.939956E+00 | loss scale: 65536.0 | grad norm: 1.007 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-22 14:05:52] iteration   348300/  500000 | consumed samples:      2786400 | elapsed time per iteration (ms): 321.6 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.960251E+00 | loss scale: 65536.0 | grad norm: 0.930 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 14:06:24] iteration   348400/  500000 | consumed samples:      2787200 | elapsed time per iteration (ms): 321.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.942473E+00 | loss scale: 65536.0 | grad norm: 0.956 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 14:06:57] iteration   348500/  500000 | consumed samples:      2788000 | elapsed time per iteration (ms): 321.6 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 3.003318E+00 | loss scale: 65536.0 | grad norm: 0.948 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 14:07:29] iteration   348600/  500000 | consumed samples:      2788800 | elapsed time per iteration (ms): 323.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.929409E+00 | loss scale: 65536.0 | grad norm: 1.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 14:08:01] iteration   348700/  500000 | consumed samples:      2789600 | elapsed time per iteration (ms): 321.4 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.950894E+00 | loss scale: 65536.0 | grad norm: 0.985 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 14:08:33] iteration   348800/  500000 | consumed samples:      2790400 | elapsed time per iteration (ms): 322.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.949759E+00 | loss scale: 65536.0 | grad norm: 0.972 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 14:09:06] iteration   348900/  500000 | consumed samples:      2791200 | elapsed time per iteration (ms): 323.9 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.932281E+00 | loss scale: 65536.0 | grad norm: 0.938 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 14:09:38] iteration   349000/  500000 | consumed samples:      2792000 | elapsed time per iteration (ms): 319.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.928255E+00 | loss scale: 65536.0 | grad norm: 0.958 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1064.21, 1064.21)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 349000 | lm loss value: 3.767876E+00 | lm loss PPL: 4.328801E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 14:10:11] iteration   349100/  500000 | consumed samples:      2792800 | elapsed time per iteration (ms): 322.6 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.970852E+00 | loss scale: 65536.0 | grad norm: 0.975 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 14:10:43] iteration   349200/  500000 | consumed samples:      2793600 | elapsed time per iteration (ms): 321.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 3.003207E+00 | loss scale: 131072.0 | grad norm: 0.935 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 14:11:15] iteration   349300/  500000 | consumed samples:      2794400 | elapsed time per iteration (ms): 322.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.969411E+00 | loss scale: 131072.0 | grad norm: 0.893 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 14:11:47] iteration   349400/  500000 | consumed samples:      2795200 | elapsed time per iteration (ms): 320.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.937484E+00 | loss scale: 131072.0 | grad norm: 0.951 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 14:12:19] iteration   349500/  500000 | consumed samples:      2796000 | elapsed time per iteration (ms): 320.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.973360E+00 | loss scale: 131072.0 | grad norm: 0.986 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 14:12:51] iteration   349600/  500000 | consumed samples:      2796800 | elapsed time per iteration (ms): 321.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.965289E+00 | loss scale: 131072.0 | grad norm: 0.966 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 14:13:23] iteration   349700/  500000 | consumed samples:      2797600 | elapsed time per iteration (ms): 319.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.948292E+00 | loss scale: 131072.0 | grad norm: 0.926 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 14:13:56] iteration   349800/  500000 | consumed samples:      2798400 | elapsed time per iteration (ms): 323.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.978519E+00 | loss scale: 131072.0 | grad norm: 0.909 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 14:14:28] iteration   349900/  500000 | consumed samples:      2799200 | elapsed time per iteration (ms): 322.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.962985E+00 | loss scale: 131072.0 | grad norm: 0.932 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 14:15:00] iteration   350000/  500000 | consumed samples:      2800000 | elapsed time per iteration (ms): 324.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.950440E+00 | loss scale: 131072.0 | grad norm: 0.883 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1063.53, 1063.53)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 350000 | lm loss value: 3.744416E+00 | lm loss PPL: 4.228430E+01 | 
--------------------------------------------------------------------------------------------------
saving checkpoint at iteration  350000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-max in torch format
  successfully saved checkpoint at iteration  350000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-max
(min, max) time across ranks (ms):
    save-checkpoint ................................: (5750.36, 5750.36)
 [2024-06-22 14:15:39] iteration   350100/  500000 | consumed samples:      2800800 | elapsed time per iteration (ms): 319.6 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.937861E+00 | loss scale: 131072.0 | grad norm: 0.916 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 14:16:12] iteration   350200/  500000 | consumed samples:      2801600 | elapsed time per iteration (ms): 323.1 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.984788E+00 | loss scale: 262144.0 | grad norm: 0.947 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 14:16:44] iteration   350300/  500000 | consumed samples:      2802400 | elapsed time per iteration (ms): 322.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.946108E+00 | loss scale: 262144.0 | grad norm: 0.958 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 14:17:16] iteration   350400/  500000 | consumed samples:      2803200 | elapsed time per iteration (ms): 323.0 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.991811E+00 | loss scale: 262144.0 | grad norm: 0.958 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 14:17:49] iteration   350500/  500000 | consumed samples:      2804000 | elapsed time per iteration (ms): 324.4 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.981384E+00 | loss scale: 262144.0 | grad norm: 0.886 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 14:18:21] iteration   350600/  500000 | consumed samples:      2804800 | elapsed time per iteration (ms): 319.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.926208E+00 | loss scale: 262144.0 | grad norm: 0.938 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 14:18:53] iteration   350700/  500000 | consumed samples:      2805600 | elapsed time per iteration (ms): 320.0 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.989328E+00 | loss scale: 262144.0 | grad norm: 0.918 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 14:19:25] iteration   350800/  500000 | consumed samples:      2806400 | elapsed time per iteration (ms): 321.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.965349E+00 | loss scale: 262144.0 | grad norm: 0.940 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 14:19:57] iteration   350900/  500000 | consumed samples:      2807200 | elapsed time per iteration (ms): 322.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.915888E+00 | loss scale: 262144.0 | grad norm: 0.927 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 14:20:29] iteration   351000/  500000 | consumed samples:      2808000 | elapsed time per iteration (ms): 321.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.976970E+00 | loss scale: 262144.0 | grad norm: 0.939 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1067.31, 1067.31)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 351000 | lm loss value: 3.631767E+00 | lm loss PPL: 3.777952E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 14:21:02] iteration   351100/  500000 | consumed samples:      2808800 | elapsed time per iteration (ms): 319.4 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.922107E+00 | loss scale: 262144.0 | grad norm: 0.930 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 14:21:34] iteration   351200/  500000 | consumed samples:      2809600 | elapsed time per iteration (ms): 322.4 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.960224E+00 | loss scale: 524288.0 | grad norm: 1.004 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-22 14:22:06] iteration   351300/  500000 | consumed samples:      2810400 | elapsed time per iteration (ms): 320.6 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.981995E+00 | loss scale: 524288.0 | grad norm: 0.992 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 14:22:39] iteration   351400/  500000 | consumed samples:      2811200 | elapsed time per iteration (ms): 322.0 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.979863E+00 | loss scale: 524288.0 | grad norm: 0.927 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 14:23:11] iteration   351500/  500000 | consumed samples:      2812000 | elapsed time per iteration (ms): 321.9 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.955583E+00 | loss scale: 262144.0 | grad norm: 0.942 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-22 14:23:43] iteration   351600/  500000 | consumed samples:      2812800 | elapsed time per iteration (ms): 322.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.940663E+00 | loss scale: 262144.0 | grad norm: 0.950 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 14:24:15] iteration   351700/  500000 | consumed samples:      2813600 | elapsed time per iteration (ms): 321.6 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.907489E+00 | loss scale: 262144.0 | grad norm: 0.962 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 14:24:48] iteration   351800/  500000 | consumed samples:      2814400 | elapsed time per iteration (ms): 325.0 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.973685E+00 | loss scale: 262144.0 | grad norm: 0.927 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 14:25:20] iteration   351900/  500000 | consumed samples:      2815200 | elapsed time per iteration (ms): 322.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.957689E+00 | loss scale: 262144.0 | grad norm: 0.936 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 14:25:52] iteration   352000/  500000 | consumed samples:      2816000 | elapsed time per iteration (ms): 321.6 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.993747E+00 | loss scale: 262144.0 | grad norm: 0.900 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1064.60, 1064.60)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 352000 | lm loss value: 3.742716E+00 | lm loss PPL: 4.221247E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 14:26:26] iteration   352100/  500000 | consumed samples:      2816800 | elapsed time per iteration (ms): 323.1 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.948223E+00 | loss scale: 262144.0 | grad norm: 0.927 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 14:26:58] iteration   352200/  500000 | consumed samples:      2817600 | elapsed time per iteration (ms): 321.1 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.898108E+00 | loss scale: 262144.0 | grad norm: 0.976 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 14:27:30] iteration   352300/  500000 | consumed samples:      2818400 | elapsed time per iteration (ms): 321.0 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.938116E+00 | loss scale: 262144.0 | grad norm: 0.921 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 14:28:02] iteration   352400/  500000 | consumed samples:      2819200 | elapsed time per iteration (ms): 322.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.946036E+00 | loss scale: 262144.0 | grad norm: 0.964 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 14:28:34] iteration   352500/  500000 | consumed samples:      2820000 | elapsed time per iteration (ms): 323.9 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.947560E+00 | loss scale: 524288.0 | grad norm: 0.960 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 14:29:06] iteration   352600/  500000 | consumed samples:      2820800 | elapsed time per iteration (ms): 320.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.941655E+00 | loss scale: 524288.0 | grad norm: 0.912 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-22 14:29:39] iteration   352700/  500000 | consumed samples:      2821600 | elapsed time per iteration (ms): 322.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.995598E+00 | loss scale: 524288.0 | grad norm: 0.973 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 14:30:11] iteration   352800/  500000 | consumed samples:      2822400 | elapsed time per iteration (ms): 320.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.959401E+00 | loss scale: 524288.0 | grad norm: 0.929 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 14:30:43] iteration   352900/  500000 | consumed samples:      2823200 | elapsed time per iteration (ms): 320.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.981642E+00 | loss scale: 524288.0 | grad norm: 0.979 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 14:31:15] iteration   353000/  500000 | consumed samples:      2824000 | elapsed time per iteration (ms): 322.1 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.977991E+00 | loss scale: 524288.0 | grad norm: 0.944 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1063.03, 1063.03)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 353000 | lm loss value: 3.806180E+00 | lm loss PPL: 4.497827E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 14:31:48] iteration   353100/  500000 | consumed samples:      2824800 | elapsed time per iteration (ms): 323.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.970928E+00 | loss scale: 524288.0 | grad norm: 0.942 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 14:32:21] iteration   353200/  500000 | consumed samples:      2825600 | elapsed time per iteration (ms): 322.4 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.975299E+00 | loss scale: 524288.0 | grad norm: 0.948 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 14:32:53] iteration   353300/  500000 | consumed samples:      2826400 | elapsed time per iteration (ms): 321.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.942331E+00 | loss scale: 524288.0 | grad norm: 0.970 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 14:33:25] iteration   353400/  500000 | consumed samples:      2827200 | elapsed time per iteration (ms): 321.9 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.923342E+00 | loss scale: 524288.0 | grad norm: 0.917 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 14:33:57] iteration   353500/  500000 | consumed samples:      2828000 | elapsed time per iteration (ms): 323.1 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.950742E+00 | loss scale: 524288.0 | grad norm: 0.975 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 14:34:30] iteration   353600/  500000 | consumed samples:      2828800 | elapsed time per iteration (ms): 323.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.917198E+00 | loss scale: 524288.0 | grad norm: 0.908 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-22 14:35:02] iteration   353700/  500000 | consumed samples:      2829600 | elapsed time per iteration (ms): 321.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.924764E+00 | loss scale: 524288.0 | grad norm: 0.921 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 14:35:34] iteration   353800/  500000 | consumed samples:      2830400 | elapsed time per iteration (ms): 321.1 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.914597E+00 | loss scale: 524288.0 | grad norm: 1.034 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 14:36:06] iteration   353900/  500000 | consumed samples:      2831200 | elapsed time per iteration (ms): 320.6 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.931439E+00 | loss scale: 524288.0 | grad norm: 0.977 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 14:36:38] iteration   354000/  500000 | consumed samples:      2832000 | elapsed time per iteration (ms): 321.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.966043E+00 | loss scale: 524288.0 | grad norm: 0.894 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1070.35, 1070.35)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 354000 | lm loss value: 3.657465E+00 | lm loss PPL: 3.876297E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 14:37:11] iteration   354100/  500000 | consumed samples:      2832800 | elapsed time per iteration (ms): 321.9 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.963110E+00 | loss scale: 262144.0 | grad norm: 0.952 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-22 14:37:43] iteration   354200/  500000 | consumed samples:      2833600 | elapsed time per iteration (ms): 320.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.948412E+00 | loss scale: 262144.0 | grad norm: 0.912 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 14:38:16] iteration   354300/  500000 | consumed samples:      2834400 | elapsed time per iteration (ms): 322.6 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.967626E+00 | loss scale: 262144.0 | grad norm: 0.967 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 14:38:48] iteration   354400/  500000 | consumed samples:      2835200 | elapsed time per iteration (ms): 322.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.964858E+00 | loss scale: 262144.0 | grad norm: 0.910 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 14:39:20] iteration   354500/  500000 | consumed samples:      2836000 | elapsed time per iteration (ms): 321.4 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.897484E+00 | loss scale: 262144.0 | grad norm: 0.970 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 14:39:52] iteration   354600/  500000 | consumed samples:      2836800 | elapsed time per iteration (ms): 321.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.976179E+00 | loss scale: 262144.0 | grad norm: 0.962 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 14:40:25] iteration   354700/  500000 | consumed samples:      2837600 | elapsed time per iteration (ms): 322.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.926143E+00 | loss scale: 262144.0 | grad norm: 0.972 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 14:40:57] iteration   354800/  500000 | consumed samples:      2838400 | elapsed time per iteration (ms): 320.9 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.992372E+00 | loss scale: 262144.0 | grad norm: 0.871 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 14:41:29] iteration   354900/  500000 | consumed samples:      2839200 | elapsed time per iteration (ms): 321.4 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.967646E+00 | loss scale: 262144.0 | grad norm: 0.962 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 14:42:01] iteration   355000/  500000 | consumed samples:      2840000 | elapsed time per iteration (ms): 322.1 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.938249E+00 | loss scale: 262144.0 | grad norm: 0.938 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1066.12, 1066.12)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 355000 | lm loss value: 3.647379E+00 | lm loss PPL: 3.837395E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 14:42:34] iteration   355100/  500000 | consumed samples:      2840800 | elapsed time per iteration (ms): 321.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.960298E+00 | loss scale: 524288.0 | grad norm: 0.970 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 14:43:07] iteration   355200/  500000 | consumed samples:      2841600 | elapsed time per iteration (ms): 323.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.943084E+00 | loss scale: 524288.0 | grad norm: 0.933 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 14:43:39] iteration   355300/  500000 | consumed samples:      2842400 | elapsed time per iteration (ms): 322.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.986818E+00 | loss scale: 524288.0 | grad norm: 1.015 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 14:44:11] iteration   355400/  500000 | consumed samples:      2843200 | elapsed time per iteration (ms): 322.4 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.955173E+00 | loss scale: 524288.0 | grad norm: 0.939 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 14:44:43] iteration   355500/  500000 | consumed samples:      2844000 | elapsed time per iteration (ms): 323.9 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.966896E+00 | loss scale: 524288.0 | grad norm: 0.960 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 14:45:16] iteration   355600/  500000 | consumed samples:      2844800 | elapsed time per iteration (ms): 323.4 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.946584E+00 | loss scale: 524288.0 | grad norm: 0.918 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 14:45:48] iteration   355700/  500000 | consumed samples:      2845600 | elapsed time per iteration (ms): 323.0 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.984802E+00 | loss scale: 524288.0 | grad norm: 0.926 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 14:46:20] iteration   355800/  500000 | consumed samples:      2846400 | elapsed time per iteration (ms): 323.0 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.933272E+00 | loss scale: 524288.0 | grad norm: 0.953 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 14:46:53] iteration   355900/  500000 | consumed samples:      2847200 | elapsed time per iteration (ms): 323.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.949584E+00 | loss scale: 524288.0 | grad norm: 0.940 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 14:47:25] iteration   356000/  500000 | consumed samples:      2848000 | elapsed time per iteration (ms): 322.0 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.956291E+00 | loss scale: 524288.0 | grad norm: 0.956 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1063.30, 1063.30)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 356000 | lm loss value: 3.771025E+00 | lm loss PPL: 4.342457E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 14:47:58] iteration   356100/  500000 | consumed samples:      2848800 | elapsed time per iteration (ms): 322.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.916919E+00 | loss scale: 1048576.0 | grad norm: 0.949 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-22 14:48:30] iteration   356200/  500000 | consumed samples:      2849600 | elapsed time per iteration (ms): 321.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.972363E+00 | loss scale: 524288.0 | grad norm: 0.958 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-22 14:49:03] iteration   356300/  500000 | consumed samples:      2850400 | elapsed time per iteration (ms): 321.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.946456E+00 | loss scale: 524288.0 | grad norm: 0.946 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 14:49:35] iteration   356400/  500000 | consumed samples:      2851200 | elapsed time per iteration (ms): 320.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.952460E+00 | loss scale: 524288.0 | grad norm: 0.972 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 14:50:07] iteration   356500/  500000 | consumed samples:      2852000 | elapsed time per iteration (ms): 320.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.937273E+00 | loss scale: 524288.0 | grad norm: 0.938 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 14:50:39] iteration   356600/  500000 | consumed samples:      2852800 | elapsed time per iteration (ms): 322.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.974735E+00 | loss scale: 524288.0 | grad norm: 0.957 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 14:51:11] iteration   356700/  500000 | consumed samples:      2853600 | elapsed time per iteration (ms): 323.1 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.941710E+00 | loss scale: 524288.0 | grad norm: 0.977 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 14:51:43] iteration   356800/  500000 | consumed samples:      2854400 | elapsed time per iteration (ms): 322.4 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.950611E+00 | loss scale: 524288.0 | grad norm: 0.936 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 14:52:16] iteration   356900/  500000 | consumed samples:      2855200 | elapsed time per iteration (ms): 321.6 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.924442E+00 | loss scale: 524288.0 | grad norm: 0.957 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 14:52:48] iteration   357000/  500000 | consumed samples:      2856000 | elapsed time per iteration (ms): 321.1 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.907228E+00 | loss scale: 524288.0 | grad norm: 0.967 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1064.60, 1064.60)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 357000 | lm loss value: 3.757598E+00 | lm loss PPL: 4.284539E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 14:53:21] iteration   357100/  500000 | consumed samples:      2856800 | elapsed time per iteration (ms): 321.4 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.962221E+00 | loss scale: 524288.0 | grad norm: 0.939 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 14:53:53] iteration   357200/  500000 | consumed samples:      2857600 | elapsed time per iteration (ms): 323.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.968477E+00 | loss scale: 524288.0 | grad norm: 0.944 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-22 14:54:25] iteration   357300/  500000 | consumed samples:      2858400 | elapsed time per iteration (ms): 321.4 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.976516E+00 | loss scale: 524288.0 | grad norm: 0.914 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 14:54:58] iteration   357400/  500000 | consumed samples:      2859200 | elapsed time per iteration (ms): 321.9 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 3.002977E+00 | loss scale: 524288.0 | grad norm: 0.964 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 14:55:30] iteration   357500/  500000 | consumed samples:      2860000 | elapsed time per iteration (ms): 321.0 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.937413E+00 | loss scale: 262144.0 | grad norm: 0.979 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-22 14:56:02] iteration   357600/  500000 | consumed samples:      2860800 | elapsed time per iteration (ms): 322.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.963581E+00 | loss scale: 262144.0 | grad norm: 0.953 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 14:56:34] iteration   357700/  500000 | consumed samples:      2861600 | elapsed time per iteration (ms): 322.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.973350E+00 | loss scale: 262144.0 | grad norm: 0.976 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 14:57:06] iteration   357800/  500000 | consumed samples:      2862400 | elapsed time per iteration (ms): 322.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.948563E+00 | loss scale: 262144.0 | grad norm: 0.945 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 14:57:39] iteration   357900/  500000 | consumed samples:      2863200 | elapsed time per iteration (ms): 321.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.928647E+00 | loss scale: 262144.0 | grad norm: 0.916 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 14:58:11] iteration   358000/  500000 | consumed samples:      2864000 | elapsed time per iteration (ms): 319.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.917923E+00 | loss scale: 262144.0 | grad norm: 0.987 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1062.90, 1062.90)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 358000 | lm loss value: 3.755303E+00 | lm loss PPL: 4.274718E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 14:58:44] iteration   358100/  500000 | consumed samples:      2864800 | elapsed time per iteration (ms): 320.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.928789E+00 | loss scale: 262144.0 | grad norm: 0.978 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 14:59:16] iteration   358200/  500000 | consumed samples:      2865600 | elapsed time per iteration (ms): 320.1 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.952962E+00 | loss scale: 262144.0 | grad norm: 0.988 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 14:59:48] iteration   358300/  500000 | consumed samples:      2866400 | elapsed time per iteration (ms): 322.9 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.942598E+00 | loss scale: 262144.0 | grad norm: 0.934 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 15:00:20] iteration   358400/  500000 | consumed samples:      2867200 | elapsed time per iteration (ms): 319.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.954899E+00 | loss scale: 262144.0 | grad norm: 0.942 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 15:00:52] iteration   358500/  500000 | consumed samples:      2868000 | elapsed time per iteration (ms): 321.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.973175E+00 | loss scale: 524288.0 | grad norm: 0.947 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 15:01:24] iteration   358600/  500000 | consumed samples:      2868800 | elapsed time per iteration (ms): 322.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.918481E+00 | loss scale: 524288.0 | grad norm: 0.913 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 15:01:57] iteration   358700/  500000 | consumed samples:      2869600 | elapsed time per iteration (ms): 321.4 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.961499E+00 | loss scale: 524288.0 | grad norm: 0.939 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 15:02:29] iteration   358800/  500000 | consumed samples:      2870400 | elapsed time per iteration (ms): 322.9 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.979912E+00 | loss scale: 524288.0 | grad norm: 0.921 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 15:03:01] iteration   358900/  500000 | consumed samples:      2871200 | elapsed time per iteration (ms): 320.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.980009E+00 | loss scale: 524288.0 | grad norm: 0.969 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 15:03:33] iteration   359000/  500000 | consumed samples:      2872000 | elapsed time per iteration (ms): 322.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.959922E+00 | loss scale: 524288.0 | grad norm: 0.934 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1064.08, 1064.08)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 359000 | lm loss value: 3.689626E+00 | lm loss PPL: 4.002987E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 15:04:06] iteration   359100/  500000 | consumed samples:      2872800 | elapsed time per iteration (ms): 321.1 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.970419E+00 | loss scale: 524288.0 | grad norm: 0.927 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 15:04:39] iteration   359200/  500000 | consumed samples:      2873600 | elapsed time per iteration (ms): 322.6 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.974811E+00 | loss scale: 524288.0 | grad norm: 0.949 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 15:05:11] iteration   359300/  500000 | consumed samples:      2874400 | elapsed time per iteration (ms): 321.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.936422E+00 | loss scale: 524288.0 | grad norm: 0.879 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 15:05:43] iteration   359400/  500000 | consumed samples:      2875200 | elapsed time per iteration (ms): 324.1 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.920446E+00 | loss scale: 524288.0 | grad norm: 0.949 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 15:06:15] iteration   359500/  500000 | consumed samples:      2876000 | elapsed time per iteration (ms): 322.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.958156E+00 | loss scale: 524288.0 | grad norm: 0.982 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-22 15:06:48] iteration   359600/  500000 | consumed samples:      2876800 | elapsed time per iteration (ms): 325.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.928116E+00 | loss scale: 524288.0 | grad norm: 0.980 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 15:07:20] iteration   359700/  500000 | consumed samples:      2877600 | elapsed time per iteration (ms): 321.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.987619E+00 | loss scale: 524288.0 | grad norm: 0.944 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 15:07:52] iteration   359800/  500000 | consumed samples:      2878400 | elapsed time per iteration (ms): 322.4 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.926882E+00 | loss scale: 524288.0 | grad norm: 0.939 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 15:08:25] iteration   359900/  500000 | consumed samples:      2879200 | elapsed time per iteration (ms): 322.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.899023E+00 | loss scale: 524288.0 | grad norm: 0.955 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 15:08:57] iteration   360000/  500000 | consumed samples:      2880000 | elapsed time per iteration (ms): 323.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.976846E+00 | loss scale: 524288.0 | grad norm: 0.930 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1073.97, 1073.97)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 360000 | lm loss value: 3.647778E+00 | lm loss PPL: 3.838928E+01 | 
--------------------------------------------------------------------------------------------------
saving checkpoint at iteration  360000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-max in torch format
  successfully saved checkpoint at iteration  360000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-max
(min, max) time across ranks (ms):
    save-checkpoint ................................: (5687.19, 5687.19)
 [2024-06-22 15:09:36] iteration   360100/  500000 | consumed samples:      2880800 | elapsed time per iteration (ms): 322.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.956209E+00 | loss scale: 524288.0 | grad norm: 0.962 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 15:10:08] iteration   360200/  500000 | consumed samples:      2881600 | elapsed time per iteration (ms): 321.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.945638E+00 | loss scale: 524288.0 | grad norm: 1.022 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 15:10:40] iteration   360300/  500000 | consumed samples:      2882400 | elapsed time per iteration (ms): 323.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.939214E+00 | loss scale: 262144.0 | grad norm: 0.944 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-22 15:11:13] iteration   360400/  500000 | consumed samples:      2883200 | elapsed time per iteration (ms): 321.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.935301E+00 | loss scale: 262144.0 | grad norm: 0.941 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 15:11:45] iteration   360500/  500000 | consumed samples:      2884000 | elapsed time per iteration (ms): 324.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.979112E+00 | loss scale: 262144.0 | grad norm: 0.919 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 15:12:17] iteration   360600/  500000 | consumed samples:      2884800 | elapsed time per iteration (ms): 320.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.961245E+00 | loss scale: 262144.0 | grad norm: 0.973 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 15:12:49] iteration   360700/  500000 | consumed samples:      2885600 | elapsed time per iteration (ms): 321.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.963229E+00 | loss scale: 262144.0 | grad norm: 0.979 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 15:13:21] iteration   360800/  500000 | consumed samples:      2886400 | elapsed time per iteration (ms): 321.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.935837E+00 | loss scale: 262144.0 | grad norm: 0.971 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 15:13:54] iteration   360900/  500000 | consumed samples:      2887200 | elapsed time per iteration (ms): 321.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.922044E+00 | loss scale: 262144.0 | grad norm: 0.953 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 15:14:26] iteration   361000/  500000 | consumed samples:      2888000 | elapsed time per iteration (ms): 323.6 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.908239E+00 | loss scale: 262144.0 | grad norm: 0.945 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1067.23, 1067.23)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 361000 | lm loss value: 3.751690E+00 | lm loss PPL: 4.259300E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 15:14:59] iteration   361100/  500000 | consumed samples:      2888800 | elapsed time per iteration (ms): 321.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.948441E+00 | loss scale: 262144.0 | grad norm: 0.918 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 15:15:31] iteration   361200/  500000 | consumed samples:      2889600 | elapsed time per iteration (ms): 321.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.985709E+00 | loss scale: 262144.0 | grad norm: 0.982 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 15:16:03] iteration   361300/  500000 | consumed samples:      2890400 | elapsed time per iteration (ms): 320.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.949293E+00 | loss scale: 524288.0 | grad norm: 0.975 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-22 15:16:35] iteration   361400/  500000 | consumed samples:      2891200 | elapsed time per iteration (ms): 319.4 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.927775E+00 | loss scale: 524288.0 | grad norm: 0.932 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 15:17:07] iteration   361500/  500000 | consumed samples:      2892000 | elapsed time per iteration (ms): 319.6 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.956659E+00 | loss scale: 524288.0 | grad norm: 0.947 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 15:17:39] iteration   361600/  500000 | consumed samples:      2892800 | elapsed time per iteration (ms): 321.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.941143E+00 | loss scale: 262144.0 | grad norm: 0.934 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-22 15:18:12] iteration   361700/  500000 | consumed samples:      2893600 | elapsed time per iteration (ms): 323.0 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.937566E+00 | loss scale: 262144.0 | grad norm: 0.933 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 15:18:44] iteration   361800/  500000 | consumed samples:      2894400 | elapsed time per iteration (ms): 322.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.929914E+00 | loss scale: 262144.0 | grad norm: 0.959 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 15:19:16] iteration   361900/  500000 | consumed samples:      2895200 | elapsed time per iteration (ms): 320.9 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.939550E+00 | loss scale: 262144.0 | grad norm: 0.933 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 15:19:48] iteration   362000/  500000 | consumed samples:      2896000 | elapsed time per iteration (ms): 322.6 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.949953E+00 | loss scale: 262144.0 | grad norm: 0.966 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1068.81, 1068.81)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 362000 | lm loss value: 3.836997E+00 | lm loss PPL: 4.638598E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 15:20:21] iteration   362100/  500000 | consumed samples:      2896800 | elapsed time per iteration (ms): 319.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.898024E+00 | loss scale: 262144.0 | grad norm: 0.981 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 15:20:53] iteration   362200/  500000 | consumed samples:      2897600 | elapsed time per iteration (ms): 320.9 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.934403E+00 | loss scale: 262144.0 | grad norm: 0.908 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 15:21:26] iteration   362300/  500000 | consumed samples:      2898400 | elapsed time per iteration (ms): 321.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.916456E+00 | loss scale: 262144.0 | grad norm: 0.955 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 15:21:58] iteration   362400/  500000 | consumed samples:      2899200 | elapsed time per iteration (ms): 322.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.923347E+00 | loss scale: 262144.0 | grad norm: 0.982 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 15:22:30] iteration   362500/  500000 | consumed samples:      2900000 | elapsed time per iteration (ms): 322.9 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.929711E+00 | loss scale: 262144.0 | grad norm: 0.970 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 15:23:02] iteration   362600/  500000 | consumed samples:      2900800 | elapsed time per iteration (ms): 322.0 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.945704E+00 | loss scale: 524288.0 | grad norm: 0.939 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 15:23:35] iteration   362700/  500000 | consumed samples:      2901600 | elapsed time per iteration (ms): 323.0 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 3.002449E+00 | loss scale: 524288.0 | grad norm: 0.951 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 15:24:07] iteration   362800/  500000 | consumed samples:      2902400 | elapsed time per iteration (ms): 322.0 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.935780E+00 | loss scale: 524288.0 | grad norm: 0.944 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 15:24:39] iteration   362900/  500000 | consumed samples:      2903200 | elapsed time per iteration (ms): 322.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.940653E+00 | loss scale: 524288.0 | grad norm: 0.965 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 15:25:11] iteration   363000/  500000 | consumed samples:      2904000 | elapsed time per iteration (ms): 322.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.994442E+00 | loss scale: 524288.0 | grad norm: 0.988 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1065.56, 1065.56)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 363000 | lm loss value: 3.563917E+00 | lm loss PPL: 3.530120E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 15:25:45] iteration   363100/  500000 | consumed samples:      2904800 | elapsed time per iteration (ms): 323.4 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.943952E+00 | loss scale: 524288.0 | grad norm: 0.981 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 15:26:17] iteration   363200/  500000 | consumed samples:      2905600 | elapsed time per iteration (ms): 321.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.933038E+00 | loss scale: 524288.0 | grad norm: 0.984 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 15:26:49] iteration   363300/  500000 | consumed samples:      2906400 | elapsed time per iteration (ms): 325.0 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.925609E+00 | loss scale: 524288.0 | grad norm: 0.939 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 15:27:22] iteration   363400/  500000 | consumed samples:      2907200 | elapsed time per iteration (ms): 321.6 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.954767E+00 | loss scale: 524288.0 | grad norm: 0.952 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 15:27:54] iteration   363500/  500000 | consumed samples:      2908000 | elapsed time per iteration (ms): 322.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.948662E+00 | loss scale: 524288.0 | grad norm: 0.922 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 15:28:26] iteration   363600/  500000 | consumed samples:      2908800 | elapsed time per iteration (ms): 322.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.924973E+00 | loss scale: 524288.0 | grad norm: 0.983 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-22 15:28:58] iteration   363700/  500000 | consumed samples:      2909600 | elapsed time per iteration (ms): 320.0 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.986720E+00 | loss scale: 262144.0 | grad norm: 1.008 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-22 15:29:30] iteration   363800/  500000 | consumed samples:      2910400 | elapsed time per iteration (ms): 322.0 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.932978E+00 | loss scale: 262144.0 | grad norm: 0.981 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 15:30:02] iteration   363900/  500000 | consumed samples:      2911200 | elapsed time per iteration (ms): 320.4 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.936819E+00 | loss scale: 262144.0 | grad norm: 0.892 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 15:30:34] iteration   364000/  500000 | consumed samples:      2912000 | elapsed time per iteration (ms): 319.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.955716E+00 | loss scale: 262144.0 | grad norm: 0.995 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1063.75, 1063.75)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 364000 | lm loss value: 3.679913E+00 | lm loss PPL: 3.964296E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 15:31:08] iteration   364100/  500000 | consumed samples:      2912800 | elapsed time per iteration (ms): 321.6 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.972943E+00 | loss scale: 262144.0 | grad norm: 0.961 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 15:31:40] iteration   364200/  500000 | consumed samples:      2913600 | elapsed time per iteration (ms): 323.6 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.981031E+00 | loss scale: 262144.0 | grad norm: 0.983 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 15:32:12] iteration   364300/  500000 | consumed samples:      2914400 | elapsed time per iteration (ms): 320.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.955406E+00 | loss scale: 262144.0 | grad norm: 0.976 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 15:32:44] iteration   364400/  500000 | consumed samples:      2915200 | elapsed time per iteration (ms): 320.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.990923E+00 | loss scale: 262144.0 | grad norm: 0.987 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 15:33:16] iteration   364500/  500000 | consumed samples:      2916000 | elapsed time per iteration (ms): 317.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.955842E+00 | loss scale: 262144.0 | grad norm: 0.962 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 15:33:48] iteration   364600/  500000 | consumed samples:      2916800 | elapsed time per iteration (ms): 321.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.956671E+00 | loss scale: 262144.0 | grad norm: 0.932 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 15:34:20] iteration   364700/  500000 | consumed samples:      2917600 | elapsed time per iteration (ms): 320.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.968237E+00 | loss scale: 524288.0 | grad norm: 0.957 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 15:34:52] iteration   364800/  500000 | consumed samples:      2918400 | elapsed time per iteration (ms): 321.6 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.994074E+00 | loss scale: 524288.0 | grad norm: 0.932 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 15:35:24] iteration   364900/  500000 | consumed samples:      2919200 | elapsed time per iteration (ms): 321.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.950567E+00 | loss scale: 524288.0 | grad norm: 0.946 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 15:35:56] iteration   365000/  500000 | consumed samples:      2920000 | elapsed time per iteration (ms): 321.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.989184E+00 | loss scale: 524288.0 | grad norm: 0.918 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1064.41, 1064.41)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 365000 | lm loss value: 3.665306E+00 | lm loss PPL: 3.906809E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 15:36:30] iteration   365100/  500000 | consumed samples:      2920800 | elapsed time per iteration (ms): 322.4 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.938969E+00 | loss scale: 524288.0 | grad norm: 1.012 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 15:37:02] iteration   365200/  500000 | consumed samples:      2921600 | elapsed time per iteration (ms): 322.4 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.969819E+00 | loss scale: 524288.0 | grad norm: 1.032 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 15:37:34] iteration   365300/  500000 | consumed samples:      2922400 | elapsed time per iteration (ms): 321.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.987547E+00 | loss scale: 524288.0 | grad norm: 0.976 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 15:38:06] iteration   365400/  500000 | consumed samples:      2923200 | elapsed time per iteration (ms): 321.9 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.977538E+00 | loss scale: 524288.0 | grad norm: 0.973 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-22 15:38:39] iteration   365500/  500000 | consumed samples:      2924000 | elapsed time per iteration (ms): 323.1 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.963227E+00 | loss scale: 524288.0 | grad norm: 0.980 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 15:39:11] iteration   365600/  500000 | consumed samples:      2924800 | elapsed time per iteration (ms): 318.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.990815E+00 | loss scale: 524288.0 | grad norm: 0.975 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 15:39:43] iteration   365700/  500000 | consumed samples:      2925600 | elapsed time per iteration (ms): 323.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.938250E+00 | loss scale: 524288.0 | grad norm: 0.957 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 15:40:15] iteration   365800/  500000 | consumed samples:      2926400 | elapsed time per iteration (ms): 319.1 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.977222E+00 | loss scale: 524288.0 | grad norm: 1.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 15:40:47] iteration   365900/  500000 | consumed samples:      2927200 | elapsed time per iteration (ms): 322.6 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.940974E+00 | loss scale: 524288.0 | grad norm: 0.934 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 15:41:19] iteration   366000/  500000 | consumed samples:      2928000 | elapsed time per iteration (ms): 319.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.928699E+00 | loss scale: 262144.0 | grad norm: 0.994 | number of skipped iterations:   1 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1064.28, 1064.28)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 366000 | lm loss value: 3.721085E+00 | lm loss PPL: 4.130920E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 15:41:52] iteration   366100/  500000 | consumed samples:      2928800 | elapsed time per iteration (ms): 322.4 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.932917E+00 | loss scale: 262144.0 | grad norm: 0.972 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 15:42:25] iteration   366200/  500000 | consumed samples:      2929600 | elapsed time per iteration (ms): 322.0 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.935367E+00 | loss scale: 262144.0 | grad norm: 0.986 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 15:42:57] iteration   366300/  500000 | consumed samples:      2930400 | elapsed time per iteration (ms): 321.1 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.933943E+00 | loss scale: 262144.0 | grad norm: 0.917 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 15:43:29] iteration   366400/  500000 | consumed samples:      2931200 | elapsed time per iteration (ms): 322.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.945547E+00 | loss scale: 262144.0 | grad norm: 0.965 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 15:44:01] iteration   366500/  500000 | consumed samples:      2932000 | elapsed time per iteration (ms): 320.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.947115E+00 | loss scale: 262144.0 | grad norm: 0.949 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 15:44:33] iteration   366600/  500000 | consumed samples:      2932800 | elapsed time per iteration (ms): 322.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.949041E+00 | loss scale: 262144.0 | grad norm: 1.008 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 15:45:05] iteration   366700/  500000 | consumed samples:      2933600 | elapsed time per iteration (ms): 319.9 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.959046E+00 | loss scale: 262144.0 | grad norm: 0.941 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 15:45:37] iteration   366800/  500000 | consumed samples:      2934400 | elapsed time per iteration (ms): 319.9 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.948527E+00 | loss scale: 262144.0 | grad norm: 0.927 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 15:46:09] iteration   366900/  500000 | consumed samples:      2935200 | elapsed time per iteration (ms): 321.0 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.944933E+00 | loss scale: 262144.0 | grad norm: 0.946 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 15:46:41] iteration   367000/  500000 | consumed samples:      2936000 | elapsed time per iteration (ms): 322.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.947965E+00 | loss scale: 524288.0 | grad norm: 0.925 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1062.91, 1062.91)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 367000 | lm loss value: 3.621403E+00 | lm loss PPL: 3.738998E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 15:47:15] iteration   367100/  500000 | consumed samples:      2936800 | elapsed time per iteration (ms): 320.9 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.962693E+00 | loss scale: 524288.0 | grad norm: 1.004 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 15:47:47] iteration   367200/  500000 | consumed samples:      2937600 | elapsed time per iteration (ms): 322.6 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.920439E+00 | loss scale: 524288.0 | grad norm: 0.997 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 15:48:19] iteration   367300/  500000 | consumed samples:      2938400 | elapsed time per iteration (ms): 321.4 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.955844E+00 | loss scale: 524288.0 | grad norm: 0.965 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 15:48:51] iteration   367400/  500000 | consumed samples:      2939200 | elapsed time per iteration (ms): 321.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.945049E+00 | loss scale: 524288.0 | grad norm: 0.951 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 15:49:23] iteration   367500/  500000 | consumed samples:      2940000 | elapsed time per iteration (ms): 320.6 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.938542E+00 | loss scale: 524288.0 | grad norm: 0.941 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 15:49:56] iteration   367600/  500000 | consumed samples:      2940800 | elapsed time per iteration (ms): 322.4 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.961232E+00 | loss scale: 524288.0 | grad norm: 0.956 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 15:50:28] iteration   367700/  500000 | consumed samples:      2941600 | elapsed time per iteration (ms): 322.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.913761E+00 | loss scale: 524288.0 | grad norm: 0.995 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 15:51:00] iteration   367800/  500000 | consumed samples:      2942400 | elapsed time per iteration (ms): 320.1 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.942123E+00 | loss scale: 524288.0 | grad norm: 0.976 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-22 15:51:32] iteration   367900/  500000 | consumed samples:      2943200 | elapsed time per iteration (ms): 322.6 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.986549E+00 | loss scale: 524288.0 | grad norm: 0.955 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 15:52:04] iteration   368000/  500000 | consumed samples:      2944000 | elapsed time per iteration (ms): 323.4 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.917375E+00 | loss scale: 524288.0 | grad norm: 0.940 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1064.69, 1064.69)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 368000 | lm loss value: 3.688676E+00 | lm loss PPL: 3.999185E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 15:52:38] iteration   368100/  500000 | consumed samples:      2944800 | elapsed time per iteration (ms): 321.1 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.937435E+00 | loss scale: 524288.0 | grad norm: 0.950 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 15:53:10] iteration   368200/  500000 | consumed samples:      2945600 | elapsed time per iteration (ms): 322.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.953881E+00 | loss scale: 524288.0 | grad norm: 0.926 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 15:53:42] iteration   368300/  500000 | consumed samples:      2946400 | elapsed time per iteration (ms): 321.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.964826E+00 | loss scale: 524288.0 | grad norm: 0.974 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 15:54:14] iteration   368400/  500000 | consumed samples:      2947200 | elapsed time per iteration (ms): 322.1 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.965638E+00 | loss scale: 524288.0 | grad norm: 1.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 15:54:46] iteration   368500/  500000 | consumed samples:      2948000 | elapsed time per iteration (ms): 320.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.924644E+00 | loss scale: 524288.0 | grad norm: 0.957 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 15:55:18] iteration   368600/  500000 | consumed samples:      2948800 | elapsed time per iteration (ms): 321.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.943629E+00 | loss scale: 524288.0 | grad norm: 0.929 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 15:55:51] iteration   368700/  500000 | consumed samples:      2949600 | elapsed time per iteration (ms): 324.4 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.942050E+00 | loss scale: 524288.0 | grad norm: 1.031 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 15:56:23] iteration   368800/  500000 | consumed samples:      2950400 | elapsed time per iteration (ms): 322.9 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.961745E+00 | loss scale: 1048576.0 | grad norm: 0.936 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 15:56:55] iteration   368900/  500000 | consumed samples:      2951200 | elapsed time per iteration (ms): 321.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.944711E+00 | loss scale: 524288.0 | grad norm: 0.972 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-22 15:57:27] iteration   369000/  500000 | consumed samples:      2952000 | elapsed time per iteration (ms): 321.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.907816E+00 | loss scale: 524288.0 | grad norm: 0.959 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1063.32, 1063.32)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 369000 | lm loss value: 3.634377E+00 | lm loss PPL: 3.787823E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 15:58:01] iteration   369100/  500000 | consumed samples:      2952800 | elapsed time per iteration (ms): 323.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.925402E+00 | loss scale: 524288.0 | grad norm: 0.913 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 15:58:33] iteration   369200/  500000 | consumed samples:      2953600 | elapsed time per iteration (ms): 321.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.975586E+00 | loss scale: 262144.0 | grad norm: 0.971 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-22 15:59:05] iteration   369300/  500000 | consumed samples:      2954400 | elapsed time per iteration (ms): 321.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.933932E+00 | loss scale: 262144.0 | grad norm: 0.956 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 15:59:37] iteration   369400/  500000 | consumed samples:      2955200 | elapsed time per iteration (ms): 322.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.945271E+00 | loss scale: 262144.0 | grad norm: 1.019 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 16:00:09] iteration   369500/  500000 | consumed samples:      2956000 | elapsed time per iteration (ms): 321.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.918754E+00 | loss scale: 262144.0 | grad norm: 0.952 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 16:00:42] iteration   369600/  500000 | consumed samples:      2956800 | elapsed time per iteration (ms): 323.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.915152E+00 | loss scale: 262144.0 | grad norm: 0.970 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 16:01:14] iteration   369700/  500000 | consumed samples:      2957600 | elapsed time per iteration (ms): 323.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.948975E+00 | loss scale: 262144.0 | grad norm: 0.971 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 16:01:47] iteration   369800/  500000 | consumed samples:      2958400 | elapsed time per iteration (ms): 324.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.953184E+00 | loss scale: 262144.0 | grad norm: 0.938 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 16:02:19] iteration   369900/  500000 | consumed samples:      2959200 | elapsed time per iteration (ms): 322.9 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.956925E+00 | loss scale: 262144.0 | grad norm: 0.940 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 16:02:51] iteration   370000/  500000 | consumed samples:      2960000 | elapsed time per iteration (ms): 321.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.935246E+00 | loss scale: 262144.0 | grad norm: 0.971 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1063.74, 1063.74)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 370000 | lm loss value: 3.702577E+00 | lm loss PPL: 4.055167E+01 | 
--------------------------------------------------------------------------------------------------
saving checkpoint at iteration  370000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-max in torch format
  successfully saved checkpoint at iteration  370000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-max
(min, max) time across ranks (ms):
    save-checkpoint ................................: (5592.28, 5592.28)
 [2024-06-22 16:03:30] iteration   370100/  500000 | consumed samples:      2960800 | elapsed time per iteration (ms): 319.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.964502E+00 | loss scale: 262144.0 | grad norm: 0.925 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 16:04:02] iteration   370200/  500000 | consumed samples:      2961600 | elapsed time per iteration (ms): 322.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.949962E+00 | loss scale: 524288.0 | grad norm: 0.986 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 16:04:34] iteration   370300/  500000 | consumed samples:      2962400 | elapsed time per iteration (ms): 319.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.971212E+00 | loss scale: 524288.0 | grad norm: 0.986 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 16:05:06] iteration   370400/  500000 | consumed samples:      2963200 | elapsed time per iteration (ms): 319.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.954168E+00 | loss scale: 524288.0 | grad norm: 0.985 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 16:05:38] iteration   370500/  500000 | consumed samples:      2964000 | elapsed time per iteration (ms): 320.1 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.945673E+00 | loss scale: 524288.0 | grad norm: 0.862 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 16:06:10] iteration   370600/  500000 | consumed samples:      2964800 | elapsed time per iteration (ms): 320.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.967323E+00 | loss scale: 524288.0 | grad norm: 0.974 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 16:06:42] iteration   370700/  500000 | consumed samples:      2965600 | elapsed time per iteration (ms): 321.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.893441E+00 | loss scale: 524288.0 | grad norm: 1.018 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 16:07:14] iteration   370800/  500000 | consumed samples:      2966400 | elapsed time per iteration (ms): 322.4 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.925999E+00 | loss scale: 524288.0 | grad norm: 0.995 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 16:07:46] iteration   370900/  500000 | consumed samples:      2967200 | elapsed time per iteration (ms): 321.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.956977E+00 | loss scale: 524288.0 | grad norm: 0.959 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 16:08:18] iteration   371000/  500000 | consumed samples:      2968000 | elapsed time per iteration (ms): 321.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.973528E+00 | loss scale: 524288.0 | grad norm: 1.040 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1067.23, 1067.23)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 371000 | lm loss value: 3.659945E+00 | lm loss PPL: 3.885921E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 16:08:51] iteration   371100/  500000 | consumed samples:      2968800 | elapsed time per iteration (ms): 321.0 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.937344E+00 | loss scale: 524288.0 | grad norm: 0.940 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 16:09:24] iteration   371200/  500000 | consumed samples:      2969600 | elapsed time per iteration (ms): 320.4 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.952131E+00 | loss scale: 262144.0 | number of skipped iterations:   3 | number of nan iterations:   0 |
 [2024-06-22 16:09:56] iteration   371300/  500000 | consumed samples:      2970400 | elapsed time per iteration (ms): 320.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.945039E+00 | loss scale: 262144.0 | grad norm: 0.967 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 16:10:28] iteration   371400/  500000 | consumed samples:      2971200 | elapsed time per iteration (ms): 321.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.914177E+00 | loss scale: 262144.0 | grad norm: 0.990 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 16:11:00] iteration   371500/  500000 | consumed samples:      2972000 | elapsed time per iteration (ms): 320.1 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.918777E+00 | loss scale: 262144.0 | grad norm: 0.871 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 16:11:32] iteration   371600/  500000 | consumed samples:      2972800 | elapsed time per iteration (ms): 320.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.930137E+00 | loss scale: 262144.0 | grad norm: 0.950 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 16:12:04] iteration   371700/  500000 | consumed samples:      2973600 | elapsed time per iteration (ms): 323.6 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.926968E+00 | loss scale: 262144.0 | grad norm: 0.913 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 16:12:36] iteration   371800/  500000 | consumed samples:      2974400 | elapsed time per iteration (ms): 321.1 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.960983E+00 | loss scale: 262144.0 | grad norm: 0.927 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 16:13:09] iteration   371900/  500000 | consumed samples:      2975200 | elapsed time per iteration (ms): 323.0 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.993594E+00 | loss scale: 262144.0 | grad norm: 0.977 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 16:13:41] iteration   372000/  500000 | consumed samples:      2976000 | elapsed time per iteration (ms): 322.4 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.958897E+00 | loss scale: 262144.0 | grad norm: 0.964 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1062.99, 1062.99)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 372000 | lm loss value: 3.768095E+00 | lm loss PPL: 4.329749E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 16:14:14] iteration   372100/  500000 | consumed samples:      2976800 | elapsed time per iteration (ms): 323.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.944117E+00 | loss scale: 262144.0 | grad norm: 0.937 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 16:14:46] iteration   372200/  500000 | consumed samples:      2977600 | elapsed time per iteration (ms): 322.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.977914E+00 | loss scale: 524288.0 | grad norm: 0.982 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 16:15:19] iteration   372300/  500000 | consumed samples:      2978400 | elapsed time per iteration (ms): 322.6 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.936934E+00 | loss scale: 524288.0 | grad norm: 0.975 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 16:15:51] iteration   372400/  500000 | consumed samples:      2979200 | elapsed time per iteration (ms): 322.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.945489E+00 | loss scale: 524288.0 | grad norm: 0.946 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 16:16:23] iteration   372500/  500000 | consumed samples:      2980000 | elapsed time per iteration (ms): 321.4 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.911552E+00 | loss scale: 524288.0 | grad norm: 0.964 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 16:16:55] iteration   372600/  500000 | consumed samples:      2980800 | elapsed time per iteration (ms): 321.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.963274E+00 | loss scale: 524288.0 | grad norm: 0.965 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 16:17:28] iteration   372700/  500000 | consumed samples:      2981600 | elapsed time per iteration (ms): 323.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.909460E+00 | loss scale: 524288.0 | grad norm: 0.923 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 16:18:00] iteration   372800/  500000 | consumed samples:      2982400 | elapsed time per iteration (ms): 323.9 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.934075E+00 | loss scale: 524288.0 | grad norm: 0.977 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 16:18:32] iteration   372900/  500000 | consumed samples:      2983200 | elapsed time per iteration (ms): 323.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.944213E+00 | loss scale: 524288.0 | grad norm: 0.948 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 16:19:05] iteration   373000/  500000 | consumed samples:      2984000 | elapsed time per iteration (ms): 322.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.949309E+00 | loss scale: 524288.0 | grad norm: 0.996 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1062.93, 1062.93)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 373000 | lm loss value: 3.710256E+00 | lm loss PPL: 4.086426E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 16:19:38] iteration   373100/  500000 | consumed samples:      2984800 | elapsed time per iteration (ms): 323.6 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.953124E+00 | loss scale: 524288.0 | grad norm: 0.997 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 16:20:10] iteration   373200/  500000 | consumed samples:      2985600 | elapsed time per iteration (ms): 324.4 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.931845E+00 | loss scale: 1048576.0 | grad norm: 0.955 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 16:20:43] iteration   373300/  500000 | consumed samples:      2986400 | elapsed time per iteration (ms): 323.9 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.966459E+00 | loss scale: 524288.0 | grad norm: 0.965 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-22 16:21:15] iteration   373400/  500000 | consumed samples:      2987200 | elapsed time per iteration (ms): 320.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.940144E+00 | loss scale: 524288.0 | grad norm: 0.936 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 16:21:47] iteration   373500/  500000 | consumed samples:      2988000 | elapsed time per iteration (ms): 323.6 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.969734E+00 | loss scale: 524288.0 | grad norm: 1.049 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 16:22:20] iteration   373600/  500000 | consumed samples:      2988800 | elapsed time per iteration (ms): 324.6 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.954575E+00 | loss scale: 524288.0 | grad norm: 0.990 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 16:22:52] iteration   373700/  500000 | consumed samples:      2989600 | elapsed time per iteration (ms): 323.6 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.907646E+00 | loss scale: 524288.0 | grad norm: 0.984 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 16:23:24] iteration   373800/  500000 | consumed samples:      2990400 | elapsed time per iteration (ms): 320.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.954870E+00 | loss scale: 524288.0 | grad norm: 0.966 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 16:23:56] iteration   373900/  500000 | consumed samples:      2991200 | elapsed time per iteration (ms): 320.4 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.944870E+00 | loss scale: 524288.0 | grad norm: 0.921 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 16:24:28] iteration   374000/  500000 | consumed samples:      2992000 | elapsed time per iteration (ms): 322.0 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.982542E+00 | loss scale: 524288.0 | grad norm: 0.972 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1062.82, 1062.82)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 374000 | lm loss value: 3.632269E+00 | lm loss PPL: 3.779850E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 16:25:02] iteration   374100/  500000 | consumed samples:      2992800 | elapsed time per iteration (ms): 320.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.914682E+00 | loss scale: 524288.0 | grad norm: 1.010 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 16:25:33] iteration   374200/  500000 | consumed samples:      2993600 | elapsed time per iteration (ms): 319.4 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.926885E+00 | loss scale: 524288.0 | grad norm: 0.925 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 16:26:05] iteration   374300/  500000 | consumed samples:      2994400 | elapsed time per iteration (ms): 320.0 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.915808E+00 | loss scale: 524288.0 | grad norm: 0.966 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-22 16:26:37] iteration   374400/  500000 | consumed samples:      2995200 | elapsed time per iteration (ms): 318.9 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.939912E+00 | loss scale: 524288.0 | grad norm: 1.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 16:27:09] iteration   374500/  500000 | consumed samples:      2996000 | elapsed time per iteration (ms): 320.6 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.928071E+00 | loss scale: 524288.0 | grad norm: 0.955 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 16:27:41] iteration   374600/  500000 | consumed samples:      2996800 | elapsed time per iteration (ms): 320.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.983298E+00 | loss scale: 524288.0 | grad norm: 0.975 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 16:28:14] iteration   374700/  500000 | consumed samples:      2997600 | elapsed time per iteration (ms): 321.6 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.929285E+00 | loss scale: 524288.0 | grad norm: 0.935 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 16:28:46] iteration   374800/  500000 | consumed samples:      2998400 | elapsed time per iteration (ms): 324.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.937287E+00 | loss scale: 524288.0 | grad norm: 0.967 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 16:29:18] iteration   374900/  500000 | consumed samples:      2999200 | elapsed time per iteration (ms): 321.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.954929E+00 | loss scale: 524288.0 | grad norm: 0.955 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 16:29:50] iteration   375000/  500000 | consumed samples:      3000000 | elapsed time per iteration (ms): 321.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.944291E+00 | loss scale: 262144.0 | grad norm: 0.993 | number of skipped iterations:   1 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1062.70, 1062.70)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 375000 | lm loss value: 3.658701E+00 | lm loss PPL: 3.881088E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 16:30:24] iteration   375100/  500000 | consumed samples:      3000800 | elapsed time per iteration (ms): 323.9 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.920388E+00 | loss scale: 262144.0 | grad norm: 1.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 16:30:56] iteration   375200/  500000 | consumed samples:      3001600 | elapsed time per iteration (ms): 323.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.968042E+00 | loss scale: 262144.0 | grad norm: 0.974 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 16:31:28] iteration   375300/  500000 | consumed samples:      3002400 | elapsed time per iteration (ms): 321.0 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.938005E+00 | loss scale: 262144.0 | grad norm: 0.930 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 16:32:01] iteration   375400/  500000 | consumed samples:      3003200 | elapsed time per iteration (ms): 322.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.933885E+00 | loss scale: 262144.0 | grad norm: 0.971 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 16:32:33] iteration   375500/  500000 | consumed samples:      3004000 | elapsed time per iteration (ms): 323.6 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.922158E+00 | loss scale: 262144.0 | grad norm: 0.971 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 16:33:05] iteration   375600/  500000 | consumed samples:      3004800 | elapsed time per iteration (ms): 324.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.941557E+00 | loss scale: 262144.0 | grad norm: 0.951 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 16:33:38] iteration   375700/  500000 | consumed samples:      3005600 | elapsed time per iteration (ms): 323.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.937646E+00 | loss scale: 262144.0 | grad norm: 0.962 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 16:34:10] iteration   375800/  500000 | consumed samples:      3006400 | elapsed time per iteration (ms): 321.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.915289E+00 | loss scale: 262144.0 | grad norm: 0.864 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 16:34:42] iteration   375900/  500000 | consumed samples:      3007200 | elapsed time per iteration (ms): 324.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.956867E+00 | loss scale: 262144.0 | grad norm: 0.951 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 16:35:15] iteration   376000/  500000 | consumed samples:      3008000 | elapsed time per iteration (ms): 324.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.939855E+00 | loss scale: 524288.0 | grad norm: 0.940 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1062.94, 1062.94)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 376000 | lm loss value: 3.817862E+00 | lm loss PPL: 4.550682E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 16:35:48] iteration   376100/  500000 | consumed samples:      3008800 | elapsed time per iteration (ms): 324.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.924334E+00 | loss scale: 524288.0 | grad norm: 0.973 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 16:36:20] iteration   376200/  500000 | consumed samples:      3009600 | elapsed time per iteration (ms): 320.9 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.956543E+00 | loss scale: 524288.0 | grad norm: 0.980 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 16:36:53] iteration   376300/  500000 | consumed samples:      3010400 | elapsed time per iteration (ms): 322.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.915490E+00 | loss scale: 524288.0 | grad norm: 0.930 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 16:37:25] iteration   376400/  500000 | consumed samples:      3011200 | elapsed time per iteration (ms): 324.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.907060E+00 | loss scale: 524288.0 | grad norm: 0.875 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 16:37:57] iteration   376500/  500000 | consumed samples:      3012000 | elapsed time per iteration (ms): 323.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.944654E+00 | loss scale: 524288.0 | grad norm: 0.952 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-22 16:38:30] iteration   376600/  500000 | consumed samples:      3012800 | elapsed time per iteration (ms): 321.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.935596E+00 | loss scale: 524288.0 | grad norm: 0.965 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 16:39:02] iteration   376700/  500000 | consumed samples:      3013600 | elapsed time per iteration (ms): 324.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.934315E+00 | loss scale: 524288.0 | grad norm: 0.993 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 16:39:34] iteration   376800/  500000 | consumed samples:      3014400 | elapsed time per iteration (ms): 322.9 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.970374E+00 | loss scale: 524288.0 | grad norm: 0.987 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 16:40:07] iteration   376900/  500000 | consumed samples:      3015200 | elapsed time per iteration (ms): 323.0 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.945395E+00 | loss scale: 524288.0 | grad norm: 0.963 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 16:40:39] iteration   377000/  500000 | consumed samples:      3016000 | elapsed time per iteration (ms): 324.0 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.942225E+00 | loss scale: 524288.0 | grad norm: 0.926 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1064.76, 1064.76)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 377000 | lm loss value: 3.468748E+00 | lm loss PPL: 3.209654E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 16:41:12] iteration   377100/  500000 | consumed samples:      3016800 | elapsed time per iteration (ms): 323.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.918400E+00 | loss scale: 524288.0 | grad norm: 0.950 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 16:41:45] iteration   377200/  500000 | consumed samples:      3017600 | elapsed time per iteration (ms): 322.9 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.969525E+00 | loss scale: 524288.0 | grad norm: 1.004 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 16:42:17] iteration   377300/  500000 | consumed samples:      3018400 | elapsed time per iteration (ms): 322.6 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.944982E+00 | loss scale: 262144.0 | grad norm: 0.950 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-22 16:42:49] iteration   377400/  500000 | consumed samples:      3019200 | elapsed time per iteration (ms): 321.0 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.909027E+00 | loss scale: 262144.0 | grad norm: 0.895 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 16:43:21] iteration   377500/  500000 | consumed samples:      3020000 | elapsed time per iteration (ms): 322.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.933561E+00 | loss scale: 262144.0 | grad norm: 0.906 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 16:43:54] iteration   377600/  500000 | consumed samples:      3020800 | elapsed time per iteration (ms): 322.9 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.930972E+00 | loss scale: 262144.0 | grad norm: 0.949 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 16:44:26] iteration   377700/  500000 | consumed samples:      3021600 | elapsed time per iteration (ms): 323.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.902022E+00 | loss scale: 262144.0 | grad norm: 0.974 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 16:44:58] iteration   377800/  500000 | consumed samples:      3022400 | elapsed time per iteration (ms): 321.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.920069E+00 | loss scale: 262144.0 | grad norm: 0.946 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 16:45:30] iteration   377900/  500000 | consumed samples:      3023200 | elapsed time per iteration (ms): 320.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.917690E+00 | loss scale: 262144.0 | grad norm: 0.949 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 16:46:02] iteration   378000/  500000 | consumed samples:      3024000 | elapsed time per iteration (ms): 320.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.970316E+00 | loss scale: 262144.0 | grad norm: 0.980 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1063.45, 1063.45)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 378000 | lm loss value: 3.679219E+00 | lm loss PPL: 3.961543E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 16:46:36] iteration   378100/  500000 | consumed samples:      3024800 | elapsed time per iteration (ms): 324.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.928651E+00 | loss scale: 262144.0 | grad norm: 0.994 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 16:47:08] iteration   378200/  500000 | consumed samples:      3025600 | elapsed time per iteration (ms): 322.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.915342E+00 | loss scale: 262144.0 | grad norm: 0.958 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 16:47:40] iteration   378300/  500000 | consumed samples:      3026400 | elapsed time per iteration (ms): 322.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.940438E+00 | loss scale: 524288.0 | grad norm: 0.959 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 16:48:13] iteration   378400/  500000 | consumed samples:      3027200 | elapsed time per iteration (ms): 322.9 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.954461E+00 | loss scale: 524288.0 | grad norm: 0.936 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 16:48:45] iteration   378500/  500000 | consumed samples:      3028000 | elapsed time per iteration (ms): 323.1 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.930219E+00 | loss scale: 524288.0 | grad norm: 0.975 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 16:49:17] iteration   378600/  500000 | consumed samples:      3028800 | elapsed time per iteration (ms): 319.1 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.951895E+00 | loss scale: 524288.0 | grad norm: 0.999 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 16:49:49] iteration   378700/  500000 | consumed samples:      3029600 | elapsed time per iteration (ms): 322.4 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.943338E+00 | loss scale: 524288.0 | grad norm: 0.987 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 16:50:21] iteration   378800/  500000 | consumed samples:      3030400 | elapsed time per iteration (ms): 321.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.952727E+00 | loss scale: 524288.0 | grad norm: 0.984 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 16:50:53] iteration   378900/  500000 | consumed samples:      3031200 | elapsed time per iteration (ms): 322.0 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.942862E+00 | loss scale: 524288.0 | grad norm: 0.947 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-22 16:51:26] iteration   379000/  500000 | consumed samples:      3032000 | elapsed time per iteration (ms): 322.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.969062E+00 | loss scale: 262144.0 | grad norm: 1.022 | number of skipped iterations:   1 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1063.55, 1063.55)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 379000 | lm loss value: 3.679456E+00 | lm loss PPL: 3.962481E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 16:51:59] iteration   379100/  500000 | consumed samples:      3032800 | elapsed time per iteration (ms): 321.4 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.962789E+00 | loss scale: 262144.0 | grad norm: 0.931 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 16:52:31] iteration   379200/  500000 | consumed samples:      3033600 | elapsed time per iteration (ms): 320.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.908289E+00 | loss scale: 262144.0 | grad norm: 0.937 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 16:53:03] iteration   379300/  500000 | consumed samples:      3034400 | elapsed time per iteration (ms): 322.0 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.960404E+00 | loss scale: 262144.0 | grad norm: 0.991 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 16:53:35] iteration   379400/  500000 | consumed samples:      3035200 | elapsed time per iteration (ms): 322.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.951176E+00 | loss scale: 262144.0 | grad norm: 0.918 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 16:54:07] iteration   379500/  500000 | consumed samples:      3036000 | elapsed time per iteration (ms): 321.9 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.951140E+00 | loss scale: 262144.0 | grad norm: 0.963 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 16:54:40] iteration   379600/  500000 | consumed samples:      3036800 | elapsed time per iteration (ms): 323.1 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.979460E+00 | loss scale: 262144.0 | grad norm: 0.950 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 16:55:12] iteration   379700/  500000 | consumed samples:      3037600 | elapsed time per iteration (ms): 321.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.939820E+00 | loss scale: 262144.0 | grad norm: 0.918 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 16:55:45] iteration   379800/  500000 | consumed samples:      3038400 | elapsed time per iteration (ms): 325.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.983718E+00 | loss scale: 262144.0 | grad norm: 0.922 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 16:56:17] iteration   379900/  500000 | consumed samples:      3039200 | elapsed time per iteration (ms): 321.1 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.958292E+00 | loss scale: 262144.0 | grad norm: 0.947 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 16:56:49] iteration   380000/  500000 | consumed samples:      3040000 | elapsed time per iteration (ms): 323.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.929818E+00 | loss scale: 524288.0 | grad norm: 0.990 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1074.75, 1074.75)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 380000 | lm loss value: 3.596720E+00 | lm loss PPL: 3.647840E+01 | 
--------------------------------------------------------------------------------------------------
saving checkpoint at iteration  380000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-max in torch format
  successfully saved checkpoint at iteration  380000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-max
(min, max) time across ranks (ms):
    save-checkpoint ................................: (5724.18, 5724.18)
 [2024-06-22 16:57:28] iteration   380100/  500000 | consumed samples:      3040800 | elapsed time per iteration (ms): 320.1 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.957820E+00 | loss scale: 524288.0 | grad norm: 0.907 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 16:58:00] iteration   380200/  500000 | consumed samples:      3041600 | elapsed time per iteration (ms): 322.6 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.906254E+00 | loss scale: 524288.0 | grad norm: 0.961 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 16:58:32] iteration   380300/  500000 | consumed samples:      3042400 | elapsed time per iteration (ms): 322.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.932086E+00 | loss scale: 524288.0 | grad norm: 0.968 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 16:59:04] iteration   380400/  500000 | consumed samples:      3043200 | elapsed time per iteration (ms): 321.6 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.914183E+00 | loss scale: 524288.0 | grad norm: 0.945 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 16:59:37] iteration   380500/  500000 | consumed samples:      3044000 | elapsed time per iteration (ms): 321.4 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.950508E+00 | loss scale: 524288.0 | grad norm: 0.985 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 17:00:09] iteration   380600/  500000 | consumed samples:      3044800 | elapsed time per iteration (ms): 322.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.896002E+00 | loss scale: 524288.0 | grad norm: 1.035 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 17:00:41] iteration   380700/  500000 | consumed samples:      3045600 | elapsed time per iteration (ms): 323.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.948866E+00 | loss scale: 524288.0 | grad norm: 0.945 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-22 17:01:13] iteration   380800/  500000 | consumed samples:      3046400 | elapsed time per iteration (ms): 322.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.914350E+00 | loss scale: 524288.0 | grad norm: 1.015 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 17:01:46] iteration   380900/  500000 | consumed samples:      3047200 | elapsed time per iteration (ms): 322.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.968612E+00 | loss scale: 524288.0 | grad norm: 0.922 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 17:02:18] iteration   381000/  500000 | consumed samples:      3048000 | elapsed time per iteration (ms): 321.6 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.967923E+00 | loss scale: 524288.0 | grad norm: 0.992 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1065.65, 1065.65)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 381000 | lm loss value: 3.791905E+00 | lm loss PPL: 4.434079E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 17:02:51] iteration   381100/  500000 | consumed samples:      3048800 | elapsed time per iteration (ms): 323.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.934199E+00 | loss scale: 262144.0 | grad norm: 0.945 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-22 17:03:24] iteration   381200/  500000 | consumed samples:      3049600 | elapsed time per iteration (ms): 323.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.951439E+00 | loss scale: 262144.0 | grad norm: 0.957 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 17:03:56] iteration   381300/  500000 | consumed samples:      3050400 | elapsed time per iteration (ms): 325.0 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.946745E+00 | loss scale: 262144.0 | grad norm: 1.015 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 17:04:28] iteration   381400/  500000 | consumed samples:      3051200 | elapsed time per iteration (ms): 322.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.974573E+00 | loss scale: 262144.0 | grad norm: 0.958 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 17:05:01] iteration   381500/  500000 | consumed samples:      3052000 | elapsed time per iteration (ms): 322.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.929505E+00 | loss scale: 262144.0 | grad norm: 0.969 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 17:05:33] iteration   381600/  500000 | consumed samples:      3052800 | elapsed time per iteration (ms): 324.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.926031E+00 | loss scale: 262144.0 | grad norm: 0.961 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 17:06:05] iteration   381700/  500000 | consumed samples:      3053600 | elapsed time per iteration (ms): 322.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.943845E+00 | loss scale: 262144.0 | grad norm: 0.966 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 17:06:37] iteration   381800/  500000 | consumed samples:      3054400 | elapsed time per iteration (ms): 321.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.910491E+00 | loss scale: 262144.0 | grad norm: 0.963 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 17:07:10] iteration   381900/  500000 | consumed samples:      3055200 | elapsed time per iteration (ms): 325.0 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.926343E+00 | loss scale: 262144.0 | grad norm: 0.967 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 17:07:42] iteration   382000/  500000 | consumed samples:      3056000 | elapsed time per iteration (ms): 321.6 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.919367E+00 | loss scale: 262144.0 | grad norm: 0.989 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1078.77, 1078.77)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 382000 | lm loss value: 3.730346E+00 | lm loss PPL: 4.169355E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 17:08:15] iteration   382100/  500000 | consumed samples:      3056800 | elapsed time per iteration (ms): 320.9 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.963531E+00 | loss scale: 524288.0 | grad norm: 0.956 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 17:08:47] iteration   382200/  500000 | consumed samples:      3057600 | elapsed time per iteration (ms): 321.9 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.932531E+00 | loss scale: 524288.0 | grad norm: 1.023 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 17:09:20] iteration   382300/  500000 | consumed samples:      3058400 | elapsed time per iteration (ms): 321.0 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.938541E+00 | loss scale: 524288.0 | grad norm: 0.993 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 17:09:52] iteration   382400/  500000 | consumed samples:      3059200 | elapsed time per iteration (ms): 326.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.963192E+00 | loss scale: 524288.0 | grad norm: 0.930 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-22 17:10:24] iteration   382500/  500000 | consumed samples:      3060000 | elapsed time per iteration (ms): 322.4 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.908454E+00 | loss scale: 524288.0 | grad norm: 0.975 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 17:10:57] iteration   382600/  500000 | consumed samples:      3060800 | elapsed time per iteration (ms): 323.1 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.939183E+00 | loss scale: 524288.0 | grad norm: 1.032 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 17:11:29] iteration   382700/  500000 | consumed samples:      3061600 | elapsed time per iteration (ms): 321.4 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.932362E+00 | loss scale: 524288.0 | grad norm: 0.948 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 17:12:01] iteration   382800/  500000 | consumed samples:      3062400 | elapsed time per iteration (ms): 322.0 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.926477E+00 | loss scale: 524288.0 | grad norm: 1.049 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 17:12:33] iteration   382900/  500000 | consumed samples:      3063200 | elapsed time per iteration (ms): 322.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.948282E+00 | loss scale: 262144.0 | grad norm: 0.981 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-22 17:13:05] iteration   383000/  500000 | consumed samples:      3064000 | elapsed time per iteration (ms): 320.6 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.914708E+00 | loss scale: 262144.0 | grad norm: 0.970 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1065.44, 1065.44)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 383000 | lm loss value: 3.662825E+00 | lm loss PPL: 3.897129E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 17:13:39] iteration   383100/  500000 | consumed samples:      3064800 | elapsed time per iteration (ms): 324.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.972372E+00 | loss scale: 262144.0 | grad norm: 0.953 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 17:14:11] iteration   383200/  500000 | consumed samples:      3065600 | elapsed time per iteration (ms): 322.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.966006E+00 | loss scale: 262144.0 | grad norm: 0.971 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 17:14:44] iteration   383300/  500000 | consumed samples:      3066400 | elapsed time per iteration (ms): 324.9 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.890437E+00 | loss scale: 262144.0 | grad norm: 0.962 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 17:15:16] iteration   383400/  500000 | consumed samples:      3067200 | elapsed time per iteration (ms): 322.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.942826E+00 | loss scale: 262144.0 | grad norm: 0.908 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 17:15:48] iteration   383500/  500000 | consumed samples:      3068000 | elapsed time per iteration (ms): 323.9 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.910378E+00 | loss scale: 262144.0 | grad norm: 0.950 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 17:16:20] iteration   383600/  500000 | consumed samples:      3068800 | elapsed time per iteration (ms): 322.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.967041E+00 | loss scale: 262144.0 | grad norm: 0.970 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 17:16:53] iteration   383700/  500000 | consumed samples:      3069600 | elapsed time per iteration (ms): 322.0 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.929267E+00 | loss scale: 262144.0 | grad norm: 0.971 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 17:17:25] iteration   383800/  500000 | consumed samples:      3070400 | elapsed time per iteration (ms): 321.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.966176E+00 | loss scale: 262144.0 | grad norm: 1.004 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 17:17:57] iteration   383900/  500000 | consumed samples:      3071200 | elapsed time per iteration (ms): 324.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.913293E+00 | loss scale: 524288.0 | grad norm: 0.898 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 17:18:29] iteration   384000/  500000 | consumed samples:      3072000 | elapsed time per iteration (ms): 322.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.961610E+00 | loss scale: 524288.0 | grad norm: 0.944 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1075.87, 1075.87)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 384000 | lm loss value: 3.678479E+00 | lm loss PPL: 3.958615E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 17:19:03] iteration   384100/  500000 | consumed samples:      3072800 | elapsed time per iteration (ms): 322.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.920461E+00 | loss scale: 524288.0 | grad norm: 0.979 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 17:19:35] iteration   384200/  500000 | consumed samples:      3073600 | elapsed time per iteration (ms): 321.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.947726E+00 | loss scale: 524288.0 | grad norm: 0.971 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 17:20:07] iteration   384300/  500000 | consumed samples:      3074400 | elapsed time per iteration (ms): 323.4 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.932940E+00 | loss scale: 524288.0 | grad norm: 0.995 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 17:20:40] iteration   384400/  500000 | consumed samples:      3075200 | elapsed time per iteration (ms): 324.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.917174E+00 | loss scale: 524288.0 | grad norm: 0.886 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 17:21:12] iteration   384500/  500000 | consumed samples:      3076000 | elapsed time per iteration (ms): 321.9 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.954635E+00 | loss scale: 524288.0 | grad norm: 0.987 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 17:21:44] iteration   384600/  500000 | consumed samples:      3076800 | elapsed time per iteration (ms): 321.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.902962E+00 | loss scale: 524288.0 | grad norm: 0.927 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 17:22:17] iteration   384700/  500000 | consumed samples:      3077600 | elapsed time per iteration (ms): 323.1 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.936994E+00 | loss scale: 524288.0 | grad norm: 0.956 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 17:22:49] iteration   384800/  500000 | consumed samples:      3078400 | elapsed time per iteration (ms): 322.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.933789E+00 | loss scale: 524288.0 | grad norm: 0.858 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 17:23:21] iteration   384900/  500000 | consumed samples:      3079200 | elapsed time per iteration (ms): 320.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.921762E+00 | loss scale: 524288.0 | grad norm: 0.948 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-22 17:23:53] iteration   385000/  500000 | consumed samples:      3080000 | elapsed time per iteration (ms): 325.4 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.949543E+00 | loss scale: 524288.0 | grad norm: 0.960 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1063.23, 1063.23)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 385000 | lm loss value: 3.616894E+00 | lm loss PPL: 3.722179E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 17:24:27] iteration   385100/  500000 | consumed samples:      3080800 | elapsed time per iteration (ms): 323.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.931081E+00 | loss scale: 524288.0 | grad norm: 0.947 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 17:24:59] iteration   385200/  500000 | consumed samples:      3081600 | elapsed time per iteration (ms): 322.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.978516E+00 | loss scale: 524288.0 | grad norm: 1.025 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 17:25:31] iteration   385300/  500000 | consumed samples:      3082400 | elapsed time per iteration (ms): 322.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.957537E+00 | loss scale: 524288.0 | grad norm: 0.989 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 17:26:03] iteration   385400/  500000 | consumed samples:      3083200 | elapsed time per iteration (ms): 321.9 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.948429E+00 | loss scale: 524288.0 | grad norm: 1.014 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 17:26:36] iteration   385500/  500000 | consumed samples:      3084000 | elapsed time per iteration (ms): 323.1 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.904617E+00 | loss scale: 524288.0 | grad norm: 0.933 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 17:27:08] iteration   385600/  500000 | consumed samples:      3084800 | elapsed time per iteration (ms): 323.0 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.937365E+00 | loss scale: 524288.0 | grad norm: 0.988 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 17:27:40] iteration   385700/  500000 | consumed samples:      3085600 | elapsed time per iteration (ms): 323.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.954059E+00 | loss scale: 524288.0 | grad norm: 0.966 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 17:28:13] iteration   385800/  500000 | consumed samples:      3086400 | elapsed time per iteration (ms): 323.1 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.921041E+00 | loss scale: 524288.0 | grad norm: 0.961 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 17:28:45] iteration   385900/  500000 | consumed samples:      3087200 | elapsed time per iteration (ms): 322.9 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.930959E+00 | loss scale: 524288.0 | grad norm: 0.974 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-22 17:29:17] iteration   386000/  500000 | consumed samples:      3088000 | elapsed time per iteration (ms): 323.1 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.923636E+00 | loss scale: 524288.0 | grad norm: 0.936 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1068.78, 1068.78)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 386000 | lm loss value: 3.720336E+00 | lm loss PPL: 4.127825E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 17:29:51] iteration   386100/  500000 | consumed samples:      3088800 | elapsed time per iteration (ms): 323.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.921371E+00 | loss scale: 524288.0 | grad norm: 0.943 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 17:30:23] iteration   386200/  500000 | consumed samples:      3089600 | elapsed time per iteration (ms): 322.4 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.929376E+00 | loss scale: 262144.0 | grad norm: 0.958 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-22 17:30:55] iteration   386300/  500000 | consumed samples:      3090400 | elapsed time per iteration (ms): 320.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.915118E+00 | loss scale: 262144.0 | grad norm: 0.949 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 17:31:27] iteration   386400/  500000 | consumed samples:      3091200 | elapsed time per iteration (ms): 323.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.934605E+00 | loss scale: 262144.0 | grad norm: 0.978 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 17:32:00] iteration   386500/  500000 | consumed samples:      3092000 | elapsed time per iteration (ms): 322.9 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.921821E+00 | loss scale: 131072.0 | grad norm: 0.943 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-22 17:32:32] iteration   386600/  500000 | consumed samples:      3092800 | elapsed time per iteration (ms): 325.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.985280E+00 | loss scale: 131072.0 | grad norm: 1.005 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 17:33:05] iteration   386700/  500000 | consumed samples:      3093600 | elapsed time per iteration (ms): 325.6 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.948115E+00 | loss scale: 131072.0 | grad norm: 0.939 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 17:33:37] iteration   386800/  500000 | consumed samples:      3094400 | elapsed time per iteration (ms): 322.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.914706E+00 | loss scale: 131072.0 | grad norm: 0.939 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 17:34:09] iteration   386900/  500000 | consumed samples:      3095200 | elapsed time per iteration (ms): 322.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.916163E+00 | loss scale: 131072.0 | grad norm: 0.958 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 17:34:42] iteration   387000/  500000 | consumed samples:      3096000 | elapsed time per iteration (ms): 322.9 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.904980E+00 | loss scale: 131072.0 | grad norm: 0.965 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1068.04, 1068.04)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 387000 | lm loss value: 3.593094E+00 | lm loss PPL: 3.634634E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 17:35:15] iteration   387100/  500000 | consumed samples:      3096800 | elapsed time per iteration (ms): 322.4 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.933716E+00 | loss scale: 131072.0 | grad norm: 0.935 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 17:35:47] iteration   387200/  500000 | consumed samples:      3097600 | elapsed time per iteration (ms): 324.0 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.929244E+00 | loss scale: 131072.0 | grad norm: 1.018 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 17:36:20] iteration   387300/  500000 | consumed samples:      3098400 | elapsed time per iteration (ms): 322.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.922687E+00 | loss scale: 131072.0 | grad norm: 1.013 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 17:36:52] iteration   387400/  500000 | consumed samples:      3099200 | elapsed time per iteration (ms): 321.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.960782E+00 | loss scale: 131072.0 | grad norm: 0.994 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 17:37:24] iteration   387500/  500000 | consumed samples:      3100000 | elapsed time per iteration (ms): 321.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.951308E+00 | loss scale: 262144.0 | grad norm: 0.977 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 17:37:56] iteration   387600/  500000 | consumed samples:      3100800 | elapsed time per iteration (ms): 322.6 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.925331E+00 | loss scale: 262144.0 | grad norm: 0.965 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 17:38:28] iteration   387700/  500000 | consumed samples:      3101600 | elapsed time per iteration (ms): 323.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.927768E+00 | loss scale: 262144.0 | grad norm: 0.960 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 17:39:01] iteration   387800/  500000 | consumed samples:      3102400 | elapsed time per iteration (ms): 324.0 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.955772E+00 | loss scale: 262144.0 | grad norm: 0.975 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 17:39:33] iteration   387900/  500000 | consumed samples:      3103200 | elapsed time per iteration (ms): 323.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.948606E+00 | loss scale: 262144.0 | grad norm: 0.918 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 17:40:06] iteration   388000/  500000 | consumed samples:      3104000 | elapsed time per iteration (ms): 324.4 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.914740E+00 | loss scale: 262144.0 | grad norm: 0.968 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1062.91, 1062.91)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 388000 | lm loss value: 3.670774E+00 | lm loss PPL: 3.928232E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 17:40:39] iteration   388100/  500000 | consumed samples:      3104800 | elapsed time per iteration (ms): 323.4 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.948475E+00 | loss scale: 262144.0 | grad norm: 0.952 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 17:41:11] iteration   388200/  500000 | consumed samples:      3105600 | elapsed time per iteration (ms): 321.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.962666E+00 | loss scale: 262144.0 | grad norm: 0.964 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 17:41:43] iteration   388300/  500000 | consumed samples:      3106400 | elapsed time per iteration (ms): 321.9 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.965292E+00 | loss scale: 262144.0 | grad norm: 0.952 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 17:42:16] iteration   388400/  500000 | consumed samples:      3107200 | elapsed time per iteration (ms): 322.9 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.910588E+00 | loss scale: 262144.0 | grad norm: 0.982 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 17:42:48] iteration   388500/  500000 | consumed samples:      3108000 | elapsed time per iteration (ms): 323.4 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.938685E+00 | loss scale: 524288.0 | grad norm: 0.999 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 17:43:20] iteration   388600/  500000 | consumed samples:      3108800 | elapsed time per iteration (ms): 321.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.902106E+00 | loss scale: 524288.0 | grad norm: 0.985 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 17:43:53] iteration   388700/  500000 | consumed samples:      3109600 | elapsed time per iteration (ms): 324.4 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.899164E+00 | loss scale: 524288.0 | grad norm: 0.951 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 17:44:25] iteration   388800/  500000 | consumed samples:      3110400 | elapsed time per iteration (ms): 323.0 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.966224E+00 | loss scale: 524288.0 | grad norm: 0.961 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 17:44:57] iteration   388900/  500000 | consumed samples:      3111200 | elapsed time per iteration (ms): 319.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.928721E+00 | loss scale: 524288.0 | grad norm: 0.915 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 17:45:29] iteration   389000/  500000 | consumed samples:      3112000 | elapsed time per iteration (ms): 322.9 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.948419E+00 | loss scale: 524288.0 | grad norm: 0.966 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1065.81, 1065.81)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 389000 | lm loss value: 3.656881E+00 | lm loss PPL: 3.874031E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 17:46:02] iteration   389100/  500000 | consumed samples:      3112800 | elapsed time per iteration (ms): 322.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.895786E+00 | loss scale: 524288.0 | grad norm: 0.925 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 17:46:35] iteration   389200/  500000 | consumed samples:      3113600 | elapsed time per iteration (ms): 324.1 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.934026E+00 | loss scale: 524288.0 | grad norm: 0.971 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 17:47:07] iteration   389300/  500000 | consumed samples:      3114400 | elapsed time per iteration (ms): 322.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.919287E+00 | loss scale: 524288.0 | grad norm: 1.032 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 17:47:39] iteration   389400/  500000 | consumed samples:      3115200 | elapsed time per iteration (ms): 322.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.957675E+00 | loss scale: 524288.0 | grad norm: 0.916 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 17:48:12] iteration   389500/  500000 | consumed samples:      3116000 | elapsed time per iteration (ms): 323.6 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.971842E+00 | loss scale: 524288.0 | grad norm: 1.002 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-22 17:48:44] iteration   389600/  500000 | consumed samples:      3116800 | elapsed time per iteration (ms): 323.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.905021E+00 | loss scale: 524288.0 | grad norm: 0.976 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 17:49:16] iteration   389700/  500000 | consumed samples:      3117600 | elapsed time per iteration (ms): 320.9 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.945369E+00 | loss scale: 524288.0 | grad norm: 0.928 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 17:49:49] iteration   389800/  500000 | consumed samples:      3118400 | elapsed time per iteration (ms): 325.0 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.925139E+00 | loss scale: 524288.0 | grad norm: 0.917 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 17:50:21] iteration   389900/  500000 | consumed samples:      3119200 | elapsed time per iteration (ms): 320.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.940626E+00 | loss scale: 262144.0 | grad norm: 0.923 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-22 17:50:53] iteration   390000/  500000 | consumed samples:      3120000 | elapsed time per iteration (ms): 324.6 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.940653E+00 | loss scale: 262144.0 | grad norm: 0.972 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1064.48, 1064.48)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 390000 | lm loss value: 3.759556E+00 | lm loss PPL: 4.292937E+01 | 
--------------------------------------------------------------------------------------------------
saving checkpoint at iteration  390000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-max in torch format
  successfully saved checkpoint at iteration  390000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-max
(min, max) time across ranks (ms):
    save-checkpoint ................................: (5648.72, 5648.72)
 [2024-06-22 17:51:32] iteration   390100/  500000 | consumed samples:      3120800 | elapsed time per iteration (ms): 321.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.943370E+00 | loss scale: 262144.0 | grad norm: 0.967 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 17:52:04] iteration   390200/  500000 | consumed samples:      3121600 | elapsed time per iteration (ms): 323.6 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.899689E+00 | loss scale: 262144.0 | grad norm: 0.979 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 17:52:36] iteration   390300/  500000 | consumed samples:      3122400 | elapsed time per iteration (ms): 321.9 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.946292E+00 | loss scale: 262144.0 | grad norm: 0.974 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 17:53:09] iteration   390400/  500000 | consumed samples:      3123200 | elapsed time per iteration (ms): 323.6 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.867850E+00 | loss scale: 262144.0 | grad norm: 0.959 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 17:53:41] iteration   390500/  500000 | consumed samples:      3124000 | elapsed time per iteration (ms): 325.1 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.960652E+00 | loss scale: 262144.0 | grad norm: 0.951 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 17:54:14] iteration   390600/  500000 | consumed samples:      3124800 | elapsed time per iteration (ms): 322.1 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.974162E+00 | loss scale: 262144.0 | grad norm: 0.971 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 17:54:46] iteration   390700/  500000 | consumed samples:      3125600 | elapsed time per iteration (ms): 323.4 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.935173E+00 | loss scale: 262144.0 | grad norm: 0.962 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 17:55:18] iteration   390800/  500000 | consumed samples:      3126400 | elapsed time per iteration (ms): 322.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.954520E+00 | loss scale: 262144.0 | grad norm: 1.014 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 17:55:50] iteration   390900/  500000 | consumed samples:      3127200 | elapsed time per iteration (ms): 323.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.944280E+00 | loss scale: 524288.0 | grad norm: 0.973 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 17:56:23] iteration   391000/  500000 | consumed samples:      3128000 | elapsed time per iteration (ms): 323.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.961694E+00 | loss scale: 524288.0 | grad norm: 0.983 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1064.28, 1064.28)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 391000 | lm loss value: 3.630502E+00 | lm loss PPL: 3.773177E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 17:56:56] iteration   391100/  500000 | consumed samples:      3128800 | elapsed time per iteration (ms): 323.6 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.920774E+00 | loss scale: 524288.0 | grad norm: 0.984 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 17:57:28] iteration   391200/  500000 | consumed samples:      3129600 | elapsed time per iteration (ms): 320.9 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.929771E+00 | loss scale: 524288.0 | grad norm: 1.055 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 17:58:00] iteration   391300/  500000 | consumed samples:      3130400 | elapsed time per iteration (ms): 320.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.958524E+00 | loss scale: 524288.0 | grad norm: 1.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 17:58:33] iteration   391400/  500000 | consumed samples:      3131200 | elapsed time per iteration (ms): 322.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.923854E+00 | loss scale: 524288.0 | grad norm: 1.009 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 17:59:05] iteration   391500/  500000 | consumed samples:      3132000 | elapsed time per iteration (ms): 320.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.902859E+00 | loss scale: 524288.0 | grad norm: 0.921 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 17:59:37] iteration   391600/  500000 | consumed samples:      3132800 | elapsed time per iteration (ms): 323.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.911776E+00 | loss scale: 524288.0 | grad norm: 0.963 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 18:00:09] iteration   391700/  500000 | consumed samples:      3133600 | elapsed time per iteration (ms): 322.1 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.954062E+00 | loss scale: 524288.0 | grad norm: 1.039 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 18:00:42] iteration   391800/  500000 | consumed samples:      3134400 | elapsed time per iteration (ms): 323.9 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.902745E+00 | loss scale: 524288.0 | grad norm: 0.973 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 18:01:14] iteration   391900/  500000 | consumed samples:      3135200 | elapsed time per iteration (ms): 321.4 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.948576E+00 | loss scale: 524288.0 | grad norm: 0.982 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-22 18:01:46] iteration   392000/  500000 | consumed samples:      3136000 | elapsed time per iteration (ms): 324.1 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.928776E+00 | loss scale: 524288.0 | grad norm: 0.982 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1063.86, 1063.86)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 392000 | lm loss value: 3.828258E+00 | lm loss PPL: 4.598236E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 18:02:19] iteration   392100/  500000 | consumed samples:      3136800 | elapsed time per iteration (ms): 322.0 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.926053E+00 | loss scale: 524288.0 | grad norm: 1.015 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 18:02:52] iteration   392200/  500000 | consumed samples:      3137600 | elapsed time per iteration (ms): 323.1 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.964301E+00 | loss scale: 524288.0 | grad norm: 0.966 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 18:03:24] iteration   392300/  500000 | consumed samples:      3138400 | elapsed time per iteration (ms): 319.9 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.918954E+00 | loss scale: 524288.0 | grad norm: 0.966 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 18:03:56] iteration   392400/  500000 | consumed samples:      3139200 | elapsed time per iteration (ms): 322.4 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.947129E+00 | loss scale: 262144.0 | grad norm: 0.972 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-22 18:04:28] iteration   392500/  500000 | consumed samples:      3140000 | elapsed time per iteration (ms): 322.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.955909E+00 | loss scale: 262144.0 | grad norm: 0.964 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 18:05:01] iteration   392600/  500000 | consumed samples:      3140800 | elapsed time per iteration (ms): 322.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.950499E+00 | loss scale: 262144.0 | grad norm: 0.934 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 18:05:33] iteration   392700/  500000 | consumed samples:      3141600 | elapsed time per iteration (ms): 321.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.942813E+00 | loss scale: 262144.0 | grad norm: 0.968 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 18:06:05] iteration   392800/  500000 | consumed samples:      3142400 | elapsed time per iteration (ms): 321.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.950323E+00 | loss scale: 262144.0 | grad norm: 0.977 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 18:06:37] iteration   392900/  500000 | consumed samples:      3143200 | elapsed time per iteration (ms): 322.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.913430E+00 | loss scale: 262144.0 | grad norm: 0.969 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 18:07:09] iteration   393000/  500000 | consumed samples:      3144000 | elapsed time per iteration (ms): 322.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.919104E+00 | loss scale: 262144.0 | grad norm: 0.947 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1066.05, 1066.05)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 393000 | lm loss value: 3.714875E+00 | lm loss PPL: 4.105345E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 18:07:43] iteration   393100/  500000 | consumed samples:      3144800 | elapsed time per iteration (ms): 325.6 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.920381E+00 | loss scale: 262144.0 | grad norm: 1.016 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 18:08:15] iteration   393200/  500000 | consumed samples:      3145600 | elapsed time per iteration (ms): 320.9 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.918279E+00 | loss scale: 262144.0 | grad norm: 1.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 18:08:47] iteration   393300/  500000 | consumed samples:      3146400 | elapsed time per iteration (ms): 320.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.934876E+00 | loss scale: 262144.0 | grad norm: 1.040 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 18:09:19] iteration   393400/  500000 | consumed samples:      3147200 | elapsed time per iteration (ms): 320.9 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.947847E+00 | loss scale: 524288.0 | grad norm: 0.911 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-22 18:09:51] iteration   393500/  500000 | consumed samples:      3148000 | elapsed time per iteration (ms): 320.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.921287E+00 | loss scale: 524288.0 | grad norm: 0.998 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 18:10:23] iteration   393600/  500000 | consumed samples:      3148800 | elapsed time per iteration (ms): 320.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.915150E+00 | loss scale: 524288.0 | grad norm: 1.005 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 18:10:56] iteration   393700/  500000 | consumed samples:      3149600 | elapsed time per iteration (ms): 323.9 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.986620E+00 | loss scale: 524288.0 | grad norm: 0.955 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 18:11:28] iteration   393800/  500000 | consumed samples:      3150400 | elapsed time per iteration (ms): 324.4 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.955419E+00 | loss scale: 524288.0 | grad norm: 0.939 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 18:12:01] iteration   393900/  500000 | consumed samples:      3151200 | elapsed time per iteration (ms): 324.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.955840E+00 | loss scale: 524288.0 | grad norm: 0.985 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 18:12:33] iteration   394000/  500000 | consumed samples:      3152000 | elapsed time per iteration (ms): 323.1 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.920787E+00 | loss scale: 524288.0 | grad norm: 0.961 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1063.42, 1063.42)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 394000 | lm loss value: 3.716179E+00 | lm loss PPL: 4.110702E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 18:13:06] iteration   394100/  500000 | consumed samples:      3152800 | elapsed time per iteration (ms): 322.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.958037E+00 | loss scale: 524288.0 | grad norm: 0.977 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 18:13:39] iteration   394200/  500000 | consumed samples:      3153600 | elapsed time per iteration (ms): 323.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.956261E+00 | loss scale: 262144.0 | grad norm: 0.965 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-22 18:14:11] iteration   394300/  500000 | consumed samples:      3154400 | elapsed time per iteration (ms): 321.9 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.976682E+00 | loss scale: 262144.0 | grad norm: 0.933 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 18:14:43] iteration   394400/  500000 | consumed samples:      3155200 | elapsed time per iteration (ms): 318.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.929728E+00 | loss scale: 262144.0 | grad norm: 0.995 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 18:15:14] iteration   394500/  500000 | consumed samples:      3156000 | elapsed time per iteration (ms): 318.4 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.932402E+00 | loss scale: 131072.0 | grad norm: 0.930 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-22 18:15:47] iteration   394600/  500000 | consumed samples:      3156800 | elapsed time per iteration (ms): 323.6 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.909616E+00 | loss scale: 131072.0 | grad norm: 1.010 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 18:16:19] iteration   394700/  500000 | consumed samples:      3157600 | elapsed time per iteration (ms): 323.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.959998E+00 | loss scale: 131072.0 | grad norm: 1.051 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 18:16:52] iteration   394800/  500000 | consumed samples:      3158400 | elapsed time per iteration (ms): 324.9 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.947847E+00 | loss scale: 131072.0 | grad norm: 1.006 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 18:17:24] iteration   394900/  500000 | consumed samples:      3159200 | elapsed time per iteration (ms): 325.0 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.954304E+00 | loss scale: 131072.0 | grad norm: 0.970 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 18:17:56] iteration   395000/  500000 | consumed samples:      3160000 | elapsed time per iteration (ms): 323.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.949561E+00 | loss scale: 131072.0 | grad norm: 0.944 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1067.65, 1067.65)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 395000 | lm loss value: 3.743090E+00 | lm loss PPL: 4.222829E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 18:18:30] iteration   395100/  500000 | consumed samples:      3160800 | elapsed time per iteration (ms): 322.4 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.909392E+00 | loss scale: 131072.0 | grad norm: 0.970 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 18:19:02] iteration   395200/  500000 | consumed samples:      3161600 | elapsed time per iteration (ms): 321.1 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.901386E+00 | loss scale: 131072.0 | grad norm: 0.968 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 18:19:34] iteration   395300/  500000 | consumed samples:      3162400 | elapsed time per iteration (ms): 323.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.926316E+00 | loss scale: 131072.0 | grad norm: 0.977 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 18:20:06] iteration   395400/  500000 | consumed samples:      3163200 | elapsed time per iteration (ms): 321.0 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.987972E+00 | loss scale: 131072.0 | grad norm: 1.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 18:20:39] iteration   395500/  500000 | consumed samples:      3164000 | elapsed time per iteration (ms): 325.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.912263E+00 | loss scale: 262144.0 | grad norm: 0.979 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 18:21:11] iteration   395600/  500000 | consumed samples:      3164800 | elapsed time per iteration (ms): 321.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.869066E+00 | loss scale: 262144.0 | grad norm: 0.962 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 18:21:43] iteration   395700/  500000 | consumed samples:      3165600 | elapsed time per iteration (ms): 321.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.954135E+00 | loss scale: 262144.0 | grad norm: 1.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 18:22:15] iteration   395800/  500000 | consumed samples:      3166400 | elapsed time per iteration (ms): 321.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.926071E+00 | loss scale: 262144.0 | grad norm: 1.005 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 18:22:48] iteration   395900/  500000 | consumed samples:      3167200 | elapsed time per iteration (ms): 321.4 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.951679E+00 | loss scale: 262144.0 | grad norm: 0.931 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 18:23:20] iteration   396000/  500000 | consumed samples:      3168000 | elapsed time per iteration (ms): 320.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.932180E+00 | loss scale: 262144.0 | grad norm: 0.946 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1064.72, 1064.72)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 396000 | lm loss value: 3.751263E+00 | lm loss PPL: 4.257481E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 18:23:53] iteration   396100/  500000 | consumed samples:      3168800 | elapsed time per iteration (ms): 322.9 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.958499E+00 | loss scale: 262144.0 | grad norm: 1.011 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 18:24:25] iteration   396200/  500000 | consumed samples:      3169600 | elapsed time per iteration (ms): 321.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.948241E+00 | loss scale: 262144.0 | grad norm: 0.983 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 18:24:57] iteration   396300/  500000 | consumed samples:      3170400 | elapsed time per iteration (ms): 321.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.962141E+00 | loss scale: 262144.0 | grad norm: 0.958 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 18:25:30] iteration   396400/  500000 | consumed samples:      3171200 | elapsed time per iteration (ms): 322.1 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.914446E+00 | loss scale: 262144.0 | grad norm: 1.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 18:26:02] iteration   396500/  500000 | consumed samples:      3172000 | elapsed time per iteration (ms): 324.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.938405E+00 | loss scale: 524288.0 | grad norm: 1.174 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 18:26:34] iteration   396600/  500000 | consumed samples:      3172800 | elapsed time per iteration (ms): 323.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.934579E+00 | loss scale: 524288.0 | grad norm: 0.970 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-22 18:27:06] iteration   396700/  500000 | consumed samples:      3173600 | elapsed time per iteration (ms): 320.9 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.952719E+00 | loss scale: 524288.0 | grad norm: 0.941 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 18:27:39] iteration   396800/  500000 | consumed samples:      3174400 | elapsed time per iteration (ms): 324.1 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.915741E+00 | loss scale: 524288.0 | grad norm: 1.028 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 18:28:11] iteration   396900/  500000 | consumed samples:      3175200 | elapsed time per iteration (ms): 323.4 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.930994E+00 | loss scale: 524288.0 | grad norm: 1.042 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 18:28:44] iteration   397000/  500000 | consumed samples:      3176000 | elapsed time per iteration (ms): 324.6 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.968180E+00 | loss scale: 524288.0 | grad norm: 0.968 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1064.75, 1064.75)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 397000 | lm loss value: 3.714792E+00 | lm loss PPL: 4.105005E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 18:29:17] iteration   397100/  500000 | consumed samples:      3176800 | elapsed time per iteration (ms): 323.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.939136E+00 | loss scale: 524288.0 | grad norm: 0.979 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 18:29:49] iteration   397200/  500000 | consumed samples:      3177600 | elapsed time per iteration (ms): 322.0 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.978372E+00 | loss scale: 524288.0 | grad norm: 1.024 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 18:30:22] iteration   397300/  500000 | consumed samples:      3178400 | elapsed time per iteration (ms): 323.9 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.932344E+00 | loss scale: 524288.0 | grad norm: 1.020 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 18:30:54] iteration   397400/  500000 | consumed samples:      3179200 | elapsed time per iteration (ms): 322.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.909731E+00 | loss scale: 524288.0 | grad norm: 0.961 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 18:31:26] iteration   397500/  500000 | consumed samples:      3180000 | elapsed time per iteration (ms): 320.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.885795E+00 | loss scale: 524288.0 | grad norm: 0.966 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 18:31:58] iteration   397600/  500000 | consumed samples:      3180800 | elapsed time per iteration (ms): 322.9 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.938926E+00 | loss scale: 1048576.0 | grad norm: 1.009 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-22 18:32:31] iteration   397700/  500000 | consumed samples:      3181600 | elapsed time per iteration (ms): 322.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.954932E+00 | loss scale: 524288.0 | grad norm: 0.892 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-22 18:33:03] iteration   397800/  500000 | consumed samples:      3182400 | elapsed time per iteration (ms): 324.4 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.947011E+00 | loss scale: 524288.0 | grad norm: 1.010 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 18:33:35] iteration   397900/  500000 | consumed samples:      3183200 | elapsed time per iteration (ms): 325.1 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.976030E+00 | loss scale: 524288.0 | grad norm: 0.979 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 18:34:08] iteration   398000/  500000 | consumed samples:      3184000 | elapsed time per iteration (ms): 322.0 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.966827E+00 | loss scale: 524288.0 | grad norm: 0.961 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1066.69, 1066.69)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 398000 | lm loss value: 3.573079E+00 | lm loss PPL: 3.562610E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 18:34:41] iteration   398100/  500000 | consumed samples:      3184800 | elapsed time per iteration (ms): 322.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.954226E+00 | loss scale: 524288.0 | grad norm: 0.917 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 18:35:13] iteration   398200/  500000 | consumed samples:      3185600 | elapsed time per iteration (ms): 324.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.927119E+00 | loss scale: 524288.0 | grad norm: 0.962 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 18:35:46] iteration   398300/  500000 | consumed samples:      3186400 | elapsed time per iteration (ms): 324.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.932405E+00 | loss scale: 524288.0 | grad norm: 0.947 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 18:36:18] iteration   398400/  500000 | consumed samples:      3187200 | elapsed time per iteration (ms): 324.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.929729E+00 | loss scale: 524288.0 | grad norm: 1.006 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 18:36:51] iteration   398500/  500000 | consumed samples:      3188000 | elapsed time per iteration (ms): 322.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.961528E+00 | loss scale: 524288.0 | grad norm: 1.054 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 18:37:23] iteration   398600/  500000 | consumed samples:      3188800 | elapsed time per iteration (ms): 321.1 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.932258E+00 | loss scale: 262144.0 | grad norm: 0.981 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-22 18:37:55] iteration   398700/  500000 | consumed samples:      3189600 | elapsed time per iteration (ms): 323.4 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.948938E+00 | loss scale: 262144.0 | grad norm: 0.969 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 18:38:27] iteration   398800/  500000 | consumed samples:      3190400 | elapsed time per iteration (ms): 321.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.947166E+00 | loss scale: 262144.0 | grad norm: 0.968 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 18:38:59] iteration   398900/  500000 | consumed samples:      3191200 | elapsed time per iteration (ms): 322.9 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.928235E+00 | loss scale: 262144.0 | grad norm: 0.951 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 18:39:32] iteration   399000/  500000 | consumed samples:      3192000 | elapsed time per iteration (ms): 320.9 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.935556E+00 | loss scale: 262144.0 | grad norm: 1.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1065.82, 1065.82)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 399000 | lm loss value: 3.687293E+00 | lm loss PPL: 3.993658E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 18:40:05] iteration   399100/  500000 | consumed samples:      3192800 | elapsed time per iteration (ms): 321.9 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.920883E+00 | loss scale: 262144.0 | grad norm: 0.981 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 18:40:37] iteration   399200/  500000 | consumed samples:      3193600 | elapsed time per iteration (ms): 321.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.950484E+00 | loss scale: 262144.0 | grad norm: 0.978 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 18:41:09] iteration   399300/  500000 | consumed samples:      3194400 | elapsed time per iteration (ms): 321.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.925140E+00 | loss scale: 262144.0 | grad norm: 0.924 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 18:41:41] iteration   399400/  500000 | consumed samples:      3195200 | elapsed time per iteration (ms): 321.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.953148E+00 | loss scale: 262144.0 | grad norm: 1.008 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 18:42:14] iteration   399500/  500000 | consumed samples:      3196000 | elapsed time per iteration (ms): 323.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.895518E+00 | loss scale: 262144.0 | grad norm: 0.945 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 18:42:46] iteration   399600/  500000 | consumed samples:      3196800 | elapsed time per iteration (ms): 322.6 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.920372E+00 | loss scale: 524288.0 | grad norm: 0.992 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 18:43:18] iteration   399700/  500000 | consumed samples:      3197600 | elapsed time per iteration (ms): 323.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.951073E+00 | loss scale: 524288.0 | grad norm: 1.048 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 18:43:51] iteration   399800/  500000 | consumed samples:      3198400 | elapsed time per iteration (ms): 325.1 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.929913E+00 | loss scale: 524288.0 | grad norm: 0.968 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 18:44:23] iteration   399900/  500000 | consumed samples:      3199200 | elapsed time per iteration (ms): 323.4 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.927089E+00 | loss scale: 524288.0 | grad norm: 0.981 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 18:44:56] iteration   400000/  500000 | consumed samples:      3200000 | elapsed time per iteration (ms): 324.0 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.961682E+00 | loss scale: 524288.0 | grad norm: 0.971 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1066.54, 1066.54)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 400000 | lm loss value: 3.655256E+00 | lm loss PPL: 3.867740E+01 | 
--------------------------------------------------------------------------------------------------
saving checkpoint at iteration  400000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-max in torch format
  successfully saved checkpoint at iteration  400000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-max
(min, max) time across ranks (ms):
    save-checkpoint ................................: (5710.79, 5710.79)
 [2024-06-22 18:45:34] iteration   400100/  500000 | consumed samples:      3200800 | elapsed time per iteration (ms): 321.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.918402E+00 | loss scale: 524288.0 | grad norm: 0.996 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 18:46:07] iteration   400200/  500000 | consumed samples:      3201600 | elapsed time per iteration (ms): 322.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.943360E+00 | loss scale: 524288.0 | grad norm: 0.971 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 18:46:39] iteration   400300/  500000 | consumed samples:      3202400 | elapsed time per iteration (ms): 322.6 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.893340E+00 | loss scale: 524288.0 | grad norm: 1.012 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 18:47:11] iteration   400400/  500000 | consumed samples:      3203200 | elapsed time per iteration (ms): 321.1 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.948832E+00 | loss scale: 524288.0 | grad norm: 0.967 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 18:47:43] iteration   400500/  500000 | consumed samples:      3204000 | elapsed time per iteration (ms): 323.4 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.929592E+00 | loss scale: 524288.0 | grad norm: 0.975 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 18:48:16] iteration   400600/  500000 | consumed samples:      3204800 | elapsed time per iteration (ms): 322.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.865587E+00 | loss scale: 524288.0 | grad norm: 0.918 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-22 18:48:48] iteration   400700/  500000 | consumed samples:      3205600 | elapsed time per iteration (ms): 324.1 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.977959E+00 | loss scale: 524288.0 | grad norm: 1.021 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 18:49:21] iteration   400800/  500000 | consumed samples:      3206400 | elapsed time per iteration (ms): 324.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.943953E+00 | loss scale: 524288.0 | grad norm: 0.974 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 18:49:53] iteration   400900/  500000 | consumed samples:      3207200 | elapsed time per iteration (ms): 323.9 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.897853E+00 | loss scale: 524288.0 | grad norm: 0.999 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 18:50:25] iteration   401000/  500000 | consumed samples:      3208000 | elapsed time per iteration (ms): 323.0 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.943761E+00 | loss scale: 524288.0 | grad norm: 0.964 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1064.37, 1064.37)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 401000 | lm loss value: 3.775408E+00 | lm loss PPL: 4.361531E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 18:50:58] iteration   401100/  500000 | consumed samples:      3208800 | elapsed time per iteration (ms): 319.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.939282E+00 | loss scale: 524288.0 | grad norm: 0.973 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 18:51:30] iteration   401200/  500000 | consumed samples:      3209600 | elapsed time per iteration (ms): 322.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.937680E+00 | loss scale: 524288.0 | grad norm: 0.997 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 18:52:03] iteration   401300/  500000 | consumed samples:      3210400 | elapsed time per iteration (ms): 323.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.988362E+00 | loss scale: 524288.0 | grad norm: 1.020 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 18:52:35] iteration   401400/  500000 | consumed samples:      3211200 | elapsed time per iteration (ms): 322.1 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.948123E+00 | loss scale: 524288.0 | grad norm: 0.992 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 18:53:07] iteration   401500/  500000 | consumed samples:      3212000 | elapsed time per iteration (ms): 321.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.955096E+00 | loss scale: 524288.0 | grad norm: 0.988 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 18:53:39] iteration   401600/  500000 | consumed samples:      3212800 | elapsed time per iteration (ms): 323.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.951862E+00 | loss scale: 524288.0 | grad norm: 0.926 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-22 18:54:12] iteration   401700/  500000 | consumed samples:      3213600 | elapsed time per iteration (ms): 322.9 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.917794E+00 | loss scale: 524288.0 | grad norm: 0.994 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 18:54:44] iteration   401800/  500000 | consumed samples:      3214400 | elapsed time per iteration (ms): 323.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.926388E+00 | loss scale: 524288.0 | grad norm: 0.969 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 18:55:16] iteration   401900/  500000 | consumed samples:      3215200 | elapsed time per iteration (ms): 321.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.940741E+00 | loss scale: 524288.0 | grad norm: 0.930 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 18:55:49] iteration   402000/  500000 | consumed samples:      3216000 | elapsed time per iteration (ms): 322.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.905827E+00 | loss scale: 524288.0 | grad norm: 0.996 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1064.19, 1064.19)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 402000 | lm loss value: 3.708498E+00 | lm loss PPL: 4.079251E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 18:56:22] iteration   402100/  500000 | consumed samples:      3216800 | elapsed time per iteration (ms): 320.1 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.950604E+00 | loss scale: 524288.0 | grad norm: 0.979 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 18:56:54] iteration   402200/  500000 | consumed samples:      3217600 | elapsed time per iteration (ms): 323.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.915431E+00 | loss scale: 524288.0 | grad norm: 1.012 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 18:57:26] iteration   402300/  500000 | consumed samples:      3218400 | elapsed time per iteration (ms): 323.4 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.930130E+00 | loss scale: 262144.0 | grad norm: 0.964 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-22 18:57:59] iteration   402400/  500000 | consumed samples:      3219200 | elapsed time per iteration (ms): 324.4 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.949702E+00 | loss scale: 262144.0 | grad norm: 0.976 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 18:58:31] iteration   402500/  500000 | consumed samples:      3220000 | elapsed time per iteration (ms): 321.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.926339E+00 | loss scale: 262144.0 | grad norm: 1.006 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 18:59:03] iteration   402600/  500000 | consumed samples:      3220800 | elapsed time per iteration (ms): 324.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.937967E+00 | loss scale: 262144.0 | grad norm: 0.975 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 18:59:36] iteration   402700/  500000 | consumed samples:      3221600 | elapsed time per iteration (ms): 322.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.981700E+00 | loss scale: 262144.0 | grad norm: 0.996 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 19:00:08] iteration   402800/  500000 | consumed samples:      3222400 | elapsed time per iteration (ms): 322.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.930604E+00 | loss scale: 262144.0 | grad norm: 1.059 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 19:00:40] iteration   402900/  500000 | consumed samples:      3223200 | elapsed time per iteration (ms): 323.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.917659E+00 | loss scale: 262144.0 | grad norm: 0.894 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 19:01:13] iteration   403000/  500000 | consumed samples:      3224000 | elapsed time per iteration (ms): 323.4 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.943029E+00 | loss scale: 262144.0 | grad norm: 0.981 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1065.27, 1065.27)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 403000 | lm loss value: 3.639692E+00 | lm loss PPL: 3.808009E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 19:01:46] iteration   403100/  500000 | consumed samples:      3224800 | elapsed time per iteration (ms): 323.4 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.914937E+00 | loss scale: 262144.0 | grad norm: 1.009 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 19:02:18] iteration   403200/  500000 | consumed samples:      3225600 | elapsed time per iteration (ms): 323.0 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.922346E+00 | loss scale: 262144.0 | grad norm: 1.010 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 19:02:51] iteration   403300/  500000 | consumed samples:      3226400 | elapsed time per iteration (ms): 323.6 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.933046E+00 | loss scale: 524288.0 | grad norm: 0.975 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 19:03:23] iteration   403400/  500000 | consumed samples:      3227200 | elapsed time per iteration (ms): 322.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.901660E+00 | loss scale: 524288.0 | grad norm: 0.962 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-22 19:03:55] iteration   403500/  500000 | consumed samples:      3228000 | elapsed time per iteration (ms): 322.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.897760E+00 | loss scale: 524288.0 | grad norm: 0.960 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 19:04:27] iteration   403600/  500000 | consumed samples:      3228800 | elapsed time per iteration (ms): 323.1 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.934167E+00 | loss scale: 262144.0 | grad norm: 0.952 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-22 19:05:00] iteration   403700/  500000 | consumed samples:      3229600 | elapsed time per iteration (ms): 321.9 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.957164E+00 | loss scale: 262144.0 | grad norm: 0.986 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 19:05:32] iteration   403800/  500000 | consumed samples:      3230400 | elapsed time per iteration (ms): 320.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.928569E+00 | loss scale: 262144.0 | grad norm: 1.004 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 19:06:04] iteration   403900/  500000 | consumed samples:      3231200 | elapsed time per iteration (ms): 324.1 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.868838E+00 | loss scale: 262144.0 | grad norm: 0.974 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 19:06:36] iteration   404000/  500000 | consumed samples:      3232000 | elapsed time per iteration (ms): 323.0 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.920895E+00 | loss scale: 262144.0 | grad norm: 0.978 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1065.38, 1065.38)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 404000 | lm loss value: 3.720916E+00 | lm loss PPL: 4.130221E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 19:07:10] iteration   404100/  500000 | consumed samples:      3232800 | elapsed time per iteration (ms): 323.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.941202E+00 | loss scale: 262144.0 | grad norm: 0.979 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 19:07:42] iteration   404200/  500000 | consumed samples:      3233600 | elapsed time per iteration (ms): 324.6 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.958266E+00 | loss scale: 262144.0 | grad norm: 1.010 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 19:08:15] iteration   404300/  500000 | consumed samples:      3234400 | elapsed time per iteration (ms): 322.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.940836E+00 | loss scale: 262144.0 | grad norm: 0.948 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 19:08:47] iteration   404400/  500000 | consumed samples:      3235200 | elapsed time per iteration (ms): 323.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.929709E+00 | loss scale: 262144.0 | grad norm: 0.987 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 19:09:19] iteration   404500/  500000 | consumed samples:      3236000 | elapsed time per iteration (ms): 322.1 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.909819E+00 | loss scale: 262144.0 | grad norm: 1.031 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 19:09:52] iteration   404600/  500000 | consumed samples:      3236800 | elapsed time per iteration (ms): 324.4 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.894546E+00 | loss scale: 524288.0 | grad norm: 0.976 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 19:10:24] iteration   404700/  500000 | consumed samples:      3237600 | elapsed time per iteration (ms): 321.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.930859E+00 | loss scale: 524288.0 | grad norm: 0.920 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 19:10:56] iteration   404800/  500000 | consumed samples:      3238400 | elapsed time per iteration (ms): 323.1 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.942983E+00 | loss scale: 524288.0 | grad norm: 0.979 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 19:11:29] iteration   404900/  500000 | consumed samples:      3239200 | elapsed time per iteration (ms): 325.6 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.895893E+00 | loss scale: 524288.0 | grad norm: 0.975 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 19:12:01] iteration   405000/  500000 | consumed samples:      3240000 | elapsed time per iteration (ms): 323.1 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.971387E+00 | loss scale: 524288.0 | grad norm: 0.945 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1063.52, 1063.52)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 405000 | lm loss value: 3.727483E+00 | lm loss PPL: 4.157434E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 19:12:34] iteration   405100/  500000 | consumed samples:      3240800 | elapsed time per iteration (ms): 321.9 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.892878E+00 | loss scale: 524288.0 | grad norm: 0.959 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 19:13:06] iteration   405200/  500000 | consumed samples:      3241600 | elapsed time per iteration (ms): 321.0 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.906188E+00 | loss scale: 524288.0 | grad norm: 0.974 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 19:13:38] iteration   405300/  500000 | consumed samples:      3242400 | elapsed time per iteration (ms): 321.0 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.913599E+00 | loss scale: 524288.0 | grad norm: 1.011 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-22 19:14:11] iteration   405400/  500000 | consumed samples:      3243200 | elapsed time per iteration (ms): 322.0 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.914608E+00 | loss scale: 262144.0 | grad norm: 1.011 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-22 19:14:43] iteration   405500/  500000 | consumed samples:      3244000 | elapsed time per iteration (ms): 324.4 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.931561E+00 | loss scale: 262144.0 | grad norm: 1.009 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 19:15:15] iteration   405600/  500000 | consumed samples:      3244800 | elapsed time per iteration (ms): 322.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.966880E+00 | loss scale: 262144.0 | grad norm: 0.973 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 19:15:47] iteration   405700/  500000 | consumed samples:      3245600 | elapsed time per iteration (ms): 322.0 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.955197E+00 | loss scale: 262144.0 | grad norm: 1.006 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 19:16:20] iteration   405800/  500000 | consumed samples:      3246400 | elapsed time per iteration (ms): 322.1 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.923228E+00 | loss scale: 262144.0 | grad norm: 0.974 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 19:16:52] iteration   405900/  500000 | consumed samples:      3247200 | elapsed time per iteration (ms): 322.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.898641E+00 | loss scale: 262144.0 | grad norm: 1.008 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 19:17:24] iteration   406000/  500000 | consumed samples:      3248000 | elapsed time per iteration (ms): 322.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.948620E+00 | loss scale: 262144.0 | grad norm: 0.978 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1066.45, 1066.45)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 406000 | lm loss value: 3.624374E+00 | lm loss PPL: 3.750125E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 19:17:58] iteration   406100/  500000 | consumed samples:      3248800 | elapsed time per iteration (ms): 323.0 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.934212E+00 | loss scale: 262144.0 | grad norm: 0.959 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 19:18:30] iteration   406200/  500000 | consumed samples:      3249600 | elapsed time per iteration (ms): 321.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.938203E+00 | loss scale: 262144.0 | grad norm: 0.957 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 19:19:02] iteration   406300/  500000 | consumed samples:      3250400 | elapsed time per iteration (ms): 322.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.937282E+00 | loss scale: 262144.0 | grad norm: 0.981 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 19:19:34] iteration   406400/  500000 | consumed samples:      3251200 | elapsed time per iteration (ms): 323.0 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.957206E+00 | loss scale: 524288.0 | grad norm: 1.017 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 19:20:06] iteration   406500/  500000 | consumed samples:      3252000 | elapsed time per iteration (ms): 322.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.907117E+00 | loss scale: 524288.0 | grad norm: 0.939 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 19:20:39] iteration   406600/  500000 | consumed samples:      3252800 | elapsed time per iteration (ms): 322.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.943392E+00 | loss scale: 524288.0 | grad norm: 1.007 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 19:21:11] iteration   406700/  500000 | consumed samples:      3253600 | elapsed time per iteration (ms): 322.0 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.918526E+00 | loss scale: 524288.0 | grad norm: 0.980 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 19:21:43] iteration   406800/  500000 | consumed samples:      3254400 | elapsed time per iteration (ms): 323.9 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.939812E+00 | loss scale: 524288.0 | grad norm: 0.995 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 19:22:16] iteration   406900/  500000 | consumed samples:      3255200 | elapsed time per iteration (ms): 322.1 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.920480E+00 | loss scale: 524288.0 | grad norm: 1.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 19:22:48] iteration   407000/  500000 | consumed samples:      3256000 | elapsed time per iteration (ms): 323.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.907484E+00 | loss scale: 524288.0 | grad norm: 0.967 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1064.44, 1064.44)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 407000 | lm loss value: 3.739818E+00 | lm loss PPL: 4.209034E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 19:23:21] iteration   407100/  500000 | consumed samples:      3256800 | elapsed time per iteration (ms): 321.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.914051E+00 | loss scale: 524288.0 | grad norm: 1.018 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 19:23:54] iteration   407200/  500000 | consumed samples:      3257600 | elapsed time per iteration (ms): 323.6 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.942465E+00 | loss scale: 524288.0 | grad norm: 1.029 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 19:24:26] iteration   407300/  500000 | consumed samples:      3258400 | elapsed time per iteration (ms): 324.1 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.935234E+00 | loss scale: 524288.0 | grad norm: 0.967 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 19:24:58] iteration   407400/  500000 | consumed samples:      3259200 | elapsed time per iteration (ms): 323.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.961007E+00 | loss scale: 524288.0 | grad norm: 0.987 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-22 19:25:31] iteration   407500/  500000 | consumed samples:      3260000 | elapsed time per iteration (ms): 322.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.943257E+00 | loss scale: 524288.0 | grad norm: 0.988 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 19:26:03] iteration   407600/  500000 | consumed samples:      3260800 | elapsed time per iteration (ms): 323.4 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.969837E+00 | loss scale: 524288.0 | grad norm: 0.955 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 19:26:35] iteration   407700/  500000 | consumed samples:      3261600 | elapsed time per iteration (ms): 323.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.938026E+00 | loss scale: 524288.0 | grad norm: 0.982 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 19:27:07] iteration   407800/  500000 | consumed samples:      3262400 | elapsed time per iteration (ms): 322.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.942651E+00 | loss scale: 524288.0 | grad norm: 1.020 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 19:27:40] iteration   407900/  500000 | consumed samples:      3263200 | elapsed time per iteration (ms): 322.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.916595E+00 | loss scale: 524288.0 | grad norm: 1.025 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 19:28:12] iteration   408000/  500000 | consumed samples:      3264000 | elapsed time per iteration (ms): 322.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.949907E+00 | loss scale: 524288.0 | grad norm: 0.996 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1065.54, 1065.54)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 408000 | lm loss value: 3.630727E+00 | lm loss PPL: 3.774023E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 19:28:45] iteration   408100/  500000 | consumed samples:      3264800 | elapsed time per iteration (ms): 320.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.919334E+00 | loss scale: 262144.0 | grad norm: 1.262 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-22 19:29:17] iteration   408200/  500000 | consumed samples:      3265600 | elapsed time per iteration (ms): 321.0 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.965183E+00 | loss scale: 262144.0 | grad norm: 0.977 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 19:29:49] iteration   408300/  500000 | consumed samples:      3266400 | elapsed time per iteration (ms): 322.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.929557E+00 | loss scale: 262144.0 | grad norm: 0.977 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 19:30:21] iteration   408400/  500000 | consumed samples:      3267200 | elapsed time per iteration (ms): 319.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.942786E+00 | loss scale: 262144.0 | grad norm: 1.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 19:30:54] iteration   408500/  500000 | consumed samples:      3268000 | elapsed time per iteration (ms): 321.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.959982E+00 | loss scale: 262144.0 | grad norm: 0.963 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 19:31:26] iteration   408600/  500000 | consumed samples:      3268800 | elapsed time per iteration (ms): 323.1 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.924057E+00 | loss scale: 262144.0 | grad norm: 0.974 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 19:31:58] iteration   408700/  500000 | consumed samples:      3269600 | elapsed time per iteration (ms): 324.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.937541E+00 | loss scale: 262144.0 | grad norm: 0.980 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 19:32:31] iteration   408800/  500000 | consumed samples:      3270400 | elapsed time per iteration (ms): 323.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.958851E+00 | loss scale: 262144.0 | grad norm: 0.988 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 19:33:03] iteration   408900/  500000 | consumed samples:      3271200 | elapsed time per iteration (ms): 324.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.908925E+00 | loss scale: 262144.0 | grad norm: 1.020 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 19:33:35] iteration   409000/  500000 | consumed samples:      3272000 | elapsed time per iteration (ms): 321.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.931623E+00 | loss scale: 262144.0 | grad norm: 0.934 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1063.16, 1063.16)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 409000 | lm loss value: 3.873676E+00 | lm loss PPL: 4.811895E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 19:34:09] iteration   409100/  500000 | consumed samples:      3272800 | elapsed time per iteration (ms): 321.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.948784E+00 | loss scale: 524288.0 | grad norm: 1.046 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 19:34:41] iteration   409200/  500000 | consumed samples:      3273600 | elapsed time per iteration (ms): 322.6 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.936836E+00 | loss scale: 524288.0 | grad norm: 0.958 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 19:35:13] iteration   409300/  500000 | consumed samples:      3274400 | elapsed time per iteration (ms): 324.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.953737E+00 | loss scale: 524288.0 | grad norm: 1.011 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 19:35:46] iteration   409400/  500000 | consumed samples:      3275200 | elapsed time per iteration (ms): 324.4 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.906735E+00 | loss scale: 524288.0 | grad norm: 1.021 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 19:36:18] iteration   409500/  500000 | consumed samples:      3276000 | elapsed time per iteration (ms): 321.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.961174E+00 | loss scale: 524288.0 | grad norm: 0.988 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 19:36:50] iteration   409600/  500000 | consumed samples:      3276800 | elapsed time per iteration (ms): 323.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.965900E+00 | loss scale: 524288.0 | grad norm: 0.942 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 19:37:23] iteration   409700/  500000 | consumed samples:      3277600 | elapsed time per iteration (ms): 324.9 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.960773E+00 | loss scale: 524288.0 | grad norm: 0.932 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 19:37:55] iteration   409800/  500000 | consumed samples:      3278400 | elapsed time per iteration (ms): 321.6 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.935338E+00 | loss scale: 524288.0 | grad norm: 1.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 19:38:27] iteration   409900/  500000 | consumed samples:      3279200 | elapsed time per iteration (ms): 322.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.959723E+00 | loss scale: 524288.0 | grad norm: 0.940 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 19:38:59] iteration   410000/  500000 | consumed samples:      3280000 | elapsed time per iteration (ms): 324.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.915537E+00 | loss scale: 524288.0 | grad norm: 0.959 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1066.87, 1066.87)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 410000 | lm loss value: 3.697966E+00 | lm loss PPL: 4.036513E+01 | 
--------------------------------------------------------------------------------------------------
saving checkpoint at iteration  410000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-max in torch format
  successfully saved checkpoint at iteration  410000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-max
(min, max) time across ranks (ms):
    save-checkpoint ................................: (5806.71, 5806.71)
 [2024-06-22 19:39:39] iteration   410100/  500000 | consumed samples:      3280800 | elapsed time per iteration (ms): 323.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.873297E+00 | loss scale: 524288.0 | grad norm: 0.950 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-22 19:40:11] iteration   410200/  500000 | consumed samples:      3281600 | elapsed time per iteration (ms): 324.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.948047E+00 | loss scale: 524288.0 | grad norm: 1.022 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 19:40:44] iteration   410300/  500000 | consumed samples:      3282400 | elapsed time per iteration (ms): 324.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.910866E+00 | loss scale: 524288.0 | grad norm: 1.006 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 19:41:16] iteration   410400/  500000 | consumed samples:      3283200 | elapsed time per iteration (ms): 322.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.886248E+00 | loss scale: 524288.0 | grad norm: 0.942 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 19:41:48] iteration   410500/  500000 | consumed samples:      3284000 | elapsed time per iteration (ms): 323.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.970321E+00 | loss scale: 524288.0 | grad norm: 0.961 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 19:42:20] iteration   410600/  500000 | consumed samples:      3284800 | elapsed time per iteration (ms): 321.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.946704E+00 | loss scale: 524288.0 | grad norm: 0.933 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 19:42:53] iteration   410700/  500000 | consumed samples:      3285600 | elapsed time per iteration (ms): 323.0 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.950614E+00 | loss scale: 524288.0 | grad norm: 0.952 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 19:43:25] iteration   410800/  500000 | consumed samples:      3286400 | elapsed time per iteration (ms): 321.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.933933E+00 | loss scale: 524288.0 | grad norm: 1.061 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 19:43:57] iteration   410900/  500000 | consumed samples:      3287200 | elapsed time per iteration (ms): 323.0 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.918845E+00 | loss scale: 524288.0 | grad norm: 0.980 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 19:44:29] iteration   411000/  500000 | consumed samples:      3288000 | elapsed time per iteration (ms): 322.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.936340E+00 | loss scale: 524288.0 | grad norm: 0.977 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1065.26, 1065.26)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 411000 | lm loss value: 3.758743E+00 | lm loss PPL: 4.289446E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 19:45:03] iteration   411100/  500000 | consumed samples:      3288800 | elapsed time per iteration (ms): 324.0 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.926802E+00 | loss scale: 1048576.0 | grad norm: 0.955 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 19:45:35] iteration   411200/  500000 | consumed samples:      3289600 | elapsed time per iteration (ms): 322.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.899737E+00 | loss scale: 524288.0 | grad norm: 0.951 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-22 19:46:07] iteration   411300/  500000 | consumed samples:      3290400 | elapsed time per iteration (ms): 322.9 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.923557E+00 | loss scale: 524288.0 | grad norm: 1.010 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 19:46:40] iteration   411400/  500000 | consumed samples:      3291200 | elapsed time per iteration (ms): 323.6 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.925800E+00 | loss scale: 524288.0 | grad norm: 0.969 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 19:47:12] iteration   411500/  500000 | consumed samples:      3292000 | elapsed time per iteration (ms): 323.1 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.963624E+00 | loss scale: 524288.0 | grad norm: 0.993 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 19:47:44] iteration   411600/  500000 | consumed samples:      3292800 | elapsed time per iteration (ms): 323.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.941198E+00 | loss scale: 524288.0 | grad norm: 1.004 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 19:48:17] iteration   411700/  500000 | consumed samples:      3293600 | elapsed time per iteration (ms): 321.0 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.924164E+00 | loss scale: 524288.0 | grad norm: 0.959 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 19:48:49] iteration   411800/  500000 | consumed samples:      3294400 | elapsed time per iteration (ms): 324.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.929182E+00 | loss scale: 524288.0 | grad norm: 0.936 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 19:49:21] iteration   411900/  500000 | consumed samples:      3295200 | elapsed time per iteration (ms): 323.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.926591E+00 | loss scale: 524288.0 | grad norm: 1.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 19:49:54] iteration   412000/  500000 | consumed samples:      3296000 | elapsed time per iteration (ms): 322.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.960356E+00 | loss scale: 524288.0 | grad norm: 0.994 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1064.07, 1064.07)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 412000 | lm loss value: 3.881842E+00 | lm loss PPL: 4.851348E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 19:50:27] iteration   412100/  500000 | consumed samples:      3296800 | elapsed time per iteration (ms): 323.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.927038E+00 | loss scale: 524288.0 | grad norm: 0.943 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 19:50:59] iteration   412200/  500000 | consumed samples:      3297600 | elapsed time per iteration (ms): 321.9 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.950137E+00 | loss scale: 524288.0 | grad norm: 1.126 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-22 19:51:32] iteration   412300/  500000 | consumed samples:      3298400 | elapsed time per iteration (ms): 324.0 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.923282E+00 | loss scale: 524288.0 | grad norm: 0.977 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 19:52:04] iteration   412400/  500000 | consumed samples:      3299200 | elapsed time per iteration (ms): 321.1 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.923205E+00 | loss scale: 524288.0 | grad norm: 1.012 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 19:52:36] iteration   412500/  500000 | consumed samples:      3300000 | elapsed time per iteration (ms): 323.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.895205E+00 | loss scale: 524288.0 | grad norm: 0.974 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 19:53:08] iteration   412600/  500000 | consumed samples:      3300800 | elapsed time per iteration (ms): 323.6 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.946129E+00 | loss scale: 524288.0 | grad norm: 0.975 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 19:53:41] iteration   412700/  500000 | consumed samples:      3301600 | elapsed time per iteration (ms): 323.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.920179E+00 | loss scale: 524288.0 | grad norm: 0.962 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 19:54:13] iteration   412800/  500000 | consumed samples:      3302400 | elapsed time per iteration (ms): 323.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.916980E+00 | loss scale: 524288.0 | grad norm: 0.999 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 19:54:45] iteration   412900/  500000 | consumed samples:      3303200 | elapsed time per iteration (ms): 323.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.948212E+00 | loss scale: 524288.0 | grad norm: 0.968 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 19:55:18] iteration   413000/  500000 | consumed samples:      3304000 | elapsed time per iteration (ms): 323.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.941485E+00 | loss scale: 524288.0 | grad norm: 0.932 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1064.79, 1064.79)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 413000 | lm loss value: 3.826550E+00 | lm loss PPL: 4.590391E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 19:55:51] iteration   413100/  500000 | consumed samples:      3304800 | elapsed time per iteration (ms): 324.1 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.976530E+00 | loss scale: 524288.0 | grad norm: 0.964 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 19:56:24] iteration   413200/  500000 | consumed samples:      3305600 | elapsed time per iteration (ms): 322.9 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.875053E+00 | loss scale: 524288.0 | grad norm: 0.960 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-22 19:56:56] iteration   413300/  500000 | consumed samples:      3306400 | elapsed time per iteration (ms): 322.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.952864E+00 | loss scale: 524288.0 | grad norm: 0.950 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 19:57:28] iteration   413400/  500000 | consumed samples:      3307200 | elapsed time per iteration (ms): 323.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.943409E+00 | loss scale: 524288.0 | grad norm: 0.953 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 19:58:01] iteration   413500/  500000 | consumed samples:      3308000 | elapsed time per iteration (ms): 323.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.922847E+00 | loss scale: 524288.0 | grad norm: 0.942 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 19:58:33] iteration   413600/  500000 | consumed samples:      3308800 | elapsed time per iteration (ms): 322.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.938351E+00 | loss scale: 524288.0 | grad norm: 0.977 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 19:59:05] iteration   413700/  500000 | consumed samples:      3309600 | elapsed time per iteration (ms): 321.9 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.910636E+00 | loss scale: 524288.0 | grad norm: 0.991 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 19:59:37] iteration   413800/  500000 | consumed samples:      3310400 | elapsed time per iteration (ms): 323.1 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.954374E+00 | loss scale: 262144.0 | grad norm: 0.979 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-22 20:00:10] iteration   413900/  500000 | consumed samples:      3311200 | elapsed time per iteration (ms): 322.4 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.920278E+00 | loss scale: 262144.0 | grad norm: 0.971 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 20:00:42] iteration   414000/  500000 | consumed samples:      3312000 | elapsed time per iteration (ms): 323.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.926711E+00 | loss scale: 262144.0 | grad norm: 0.965 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1064.21, 1064.21)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 414000 | lm loss value: 3.721116E+00 | lm loss PPL: 4.131045E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 20:01:15] iteration   414100/  500000 | consumed samples:      3312800 | elapsed time per iteration (ms): 324.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.932693E+00 | loss scale: 262144.0 | grad norm: 0.964 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 20:01:48] iteration   414200/  500000 | consumed samples:      3313600 | elapsed time per iteration (ms): 323.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.908263E+00 | loss scale: 262144.0 | grad norm: 0.973 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 20:02:20] iteration   414300/  500000 | consumed samples:      3314400 | elapsed time per iteration (ms): 323.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.902560E+00 | loss scale: 262144.0 | grad norm: 1.009 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 20:02:53] iteration   414400/  500000 | consumed samples:      3315200 | elapsed time per iteration (ms): 324.6 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.919650E+00 | loss scale: 262144.0 | grad norm: 1.019 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 20:03:25] iteration   414500/  500000 | consumed samples:      3316000 | elapsed time per iteration (ms): 321.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.944627E+00 | loss scale: 262144.0 | grad norm: 0.966 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 20:03:57] iteration   414600/  500000 | consumed samples:      3316800 | elapsed time per iteration (ms): 323.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.914577E+00 | loss scale: 262144.0 | grad norm: 1.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 20:04:29] iteration   414700/  500000 | consumed samples:      3317600 | elapsed time per iteration (ms): 323.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.897301E+00 | loss scale: 262144.0 | grad norm: 0.948 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 20:05:02] iteration   414800/  500000 | consumed samples:      3318400 | elapsed time per iteration (ms): 323.0 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.944308E+00 | loss scale: 524288.0 | grad norm: 0.988 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 20:05:34] iteration   414900/  500000 | consumed samples:      3319200 | elapsed time per iteration (ms): 321.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.963314E+00 | loss scale: 524288.0 | grad norm: 0.953 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 20:06:06] iteration   415000/  500000 | consumed samples:      3320000 | elapsed time per iteration (ms): 321.6 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.954409E+00 | loss scale: 524288.0 | grad norm: 0.990 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1062.97, 1062.97)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 415000 | lm loss value: 3.693352E+00 | lm loss PPL: 4.017929E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 20:06:39] iteration   415100/  500000 | consumed samples:      3320800 | elapsed time per iteration (ms): 319.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.929948E+00 | loss scale: 524288.0 | grad norm: 0.977 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 20:07:11] iteration   415200/  500000 | consumed samples:      3321600 | elapsed time per iteration (ms): 321.9 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.899642E+00 | loss scale: 524288.0 | grad norm: 0.975 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 20:07:43] iteration   415300/  500000 | consumed samples:      3322400 | elapsed time per iteration (ms): 320.1 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.912422E+00 | loss scale: 524288.0 | grad norm: 1.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 20:08:15] iteration   415400/  500000 | consumed samples:      3323200 | elapsed time per iteration (ms): 322.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.920709E+00 | loss scale: 524288.0 | grad norm: 0.982 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 20:08:48] iteration   415500/  500000 | consumed samples:      3324000 | elapsed time per iteration (ms): 322.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.923544E+00 | loss scale: 524288.0 | grad norm: 0.969 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 20:09:20] iteration   415600/  500000 | consumed samples:      3324800 | elapsed time per iteration (ms): 323.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.908667E+00 | loss scale: 524288.0 | grad norm: 0.997 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 20:09:52] iteration   415700/  500000 | consumed samples:      3325600 | elapsed time per iteration (ms): 322.6 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.954670E+00 | loss scale: 524288.0 | grad norm: 1.007 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 20:10:25] iteration   415800/  500000 | consumed samples:      3326400 | elapsed time per iteration (ms): 321.1 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.951059E+00 | loss scale: 524288.0 | grad norm: 0.981 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-22 20:10:57] iteration   415900/  500000 | consumed samples:      3327200 | elapsed time per iteration (ms): 325.1 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.926402E+00 | loss scale: 524288.0 | grad norm: 0.976 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 20:11:29] iteration   416000/  500000 | consumed samples:      3328000 | elapsed time per iteration (ms): 323.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.925755E+00 | loss scale: 524288.0 | grad norm: 0.964 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1065.36, 1065.36)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 416000 | lm loss value: 3.668028E+00 | lm loss PPL: 3.917456E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 20:12:03] iteration   416100/  500000 | consumed samples:      3328800 | elapsed time per iteration (ms): 322.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.927590E+00 | loss scale: 262144.0 | grad norm: 0.989 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-22 20:12:35] iteration   416200/  500000 | consumed samples:      3329600 | elapsed time per iteration (ms): 322.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.936664E+00 | loss scale: 262144.0 | grad norm: 0.990 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 20:13:07] iteration   416300/  500000 | consumed samples:      3330400 | elapsed time per iteration (ms): 322.1 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.912077E+00 | loss scale: 262144.0 | grad norm: 1.012 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 20:13:39] iteration   416400/  500000 | consumed samples:      3331200 | elapsed time per iteration (ms): 322.4 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.922057E+00 | loss scale: 262144.0 | grad norm: 0.977 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 20:14:12] iteration   416500/  500000 | consumed samples:      3332000 | elapsed time per iteration (ms): 322.6 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.957027E+00 | loss scale: 262144.0 | grad norm: 0.986 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 20:14:44] iteration   416600/  500000 | consumed samples:      3332800 | elapsed time per iteration (ms): 323.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.893429E+00 | loss scale: 262144.0 | grad norm: 0.949 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 20:15:16] iteration   416700/  500000 | consumed samples:      3333600 | elapsed time per iteration (ms): 321.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.885391E+00 | loss scale: 262144.0 | grad norm: 1.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 20:15:49] iteration   416800/  500000 | consumed samples:      3334400 | elapsed time per iteration (ms): 324.6 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.927159E+00 | loss scale: 262144.0 | grad norm: 1.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 20:16:21] iteration   416900/  500000 | consumed samples:      3335200 | elapsed time per iteration (ms): 324.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.940083E+00 | loss scale: 262144.0 | grad norm: 1.017 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 20:16:53] iteration   417000/  500000 | consumed samples:      3336000 | elapsed time per iteration (ms): 323.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.954741E+00 | loss scale: 262144.0 | grad norm: 0.994 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1062.58, 1062.58)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 417000 | lm loss value: 3.699687E+00 | lm loss PPL: 4.043466E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 20:17:27] iteration   417100/  500000 | consumed samples:      3336800 | elapsed time per iteration (ms): 321.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.926353E+00 | loss scale: 524288.0 | grad norm: 1.016 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 20:17:59] iteration   417200/  500000 | consumed samples:      3337600 | elapsed time per iteration (ms): 322.6 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.904014E+00 | loss scale: 524288.0 | grad norm: 0.985 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 20:18:31] iteration   417300/  500000 | consumed samples:      3338400 | elapsed time per iteration (ms): 321.9 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.960892E+00 | loss scale: 524288.0 | grad norm: 0.981 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 20:19:03] iteration   417400/  500000 | consumed samples:      3339200 | elapsed time per iteration (ms): 321.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.928438E+00 | loss scale: 524288.0 | grad norm: 1.038 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 20:19:36] iteration   417500/  500000 | consumed samples:      3340000 | elapsed time per iteration (ms): 324.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.944373E+00 | loss scale: 524288.0 | grad norm: 0.974 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 20:20:08] iteration   417600/  500000 | consumed samples:      3340800 | elapsed time per iteration (ms): 322.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.916924E+00 | loss scale: 524288.0 | grad norm: 0.989 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-22 20:20:40] iteration   417700/  500000 | consumed samples:      3341600 | elapsed time per iteration (ms): 324.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.913356E+00 | loss scale: 524288.0 | grad norm: 1.029 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 20:21:13] iteration   417800/  500000 | consumed samples:      3342400 | elapsed time per iteration (ms): 323.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.962653E+00 | loss scale: 524288.0 | grad norm: 0.967 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 20:21:45] iteration   417900/  500000 | consumed samples:      3343200 | elapsed time per iteration (ms): 325.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.886613E+00 | loss scale: 524288.0 | grad norm: 0.957 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 20:22:18] iteration   418000/  500000 | consumed samples:      3344000 | elapsed time per iteration (ms): 324.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.908378E+00 | loss scale: 524288.0 | grad norm: 1.046 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1068.37, 1068.37)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 418000 | lm loss value: 3.705637E+00 | lm loss PPL: 4.067597E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 20:22:51] iteration   418100/  500000 | consumed samples:      3344800 | elapsed time per iteration (ms): 324.1 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.907919E+00 | loss scale: 524288.0 | grad norm: 1.010 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 20:23:24] iteration   418200/  500000 | consumed samples:      3345600 | elapsed time per iteration (ms): 322.9 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.897058E+00 | loss scale: 524288.0 | grad norm: 1.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 20:23:56] iteration   418300/  500000 | consumed samples:      3346400 | elapsed time per iteration (ms): 321.1 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.941674E+00 | loss scale: 524288.0 | grad norm: 0.967 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 20:24:28] iteration   418400/  500000 | consumed samples:      3347200 | elapsed time per iteration (ms): 322.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.912904E+00 | loss scale: 524288.0 | grad norm: 0.997 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 20:25:00] iteration   418500/  500000 | consumed samples:      3348000 | elapsed time per iteration (ms): 321.0 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.964518E+00 | loss scale: 524288.0 | grad norm: 0.983 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 20:25:32] iteration   418600/  500000 | consumed samples:      3348800 | elapsed time per iteration (ms): 321.9 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.956468E+00 | loss scale: 524288.0 | grad norm: 0.961 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-22 20:26:04] iteration   418700/  500000 | consumed samples:      3349600 | elapsed time per iteration (ms): 320.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.893238E+00 | loss scale: 524288.0 | grad norm: 1.015 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 20:26:36] iteration   418800/  500000 | consumed samples:      3350400 | elapsed time per iteration (ms): 321.9 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.914069E+00 | loss scale: 524288.0 | grad norm: 0.976 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 20:27:09] iteration   418900/  500000 | consumed samples:      3351200 | elapsed time per iteration (ms): 322.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.935007E+00 | loss scale: 524288.0 | grad norm: 1.027 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 20:27:41] iteration   419000/  500000 | consumed samples:      3352000 | elapsed time per iteration (ms): 325.4 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.954686E+00 | loss scale: 524288.0 | grad norm: 0.967 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1063.52, 1063.52)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 419000 | lm loss value: 3.889304E+00 | lm loss PPL: 4.887685E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 20:28:14] iteration   419100/  500000 | consumed samples:      3352800 | elapsed time per iteration (ms): 322.1 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.909856E+00 | loss scale: 524288.0 | grad norm: 0.962 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 20:28:47] iteration   419200/  500000 | consumed samples:      3353600 | elapsed time per iteration (ms): 321.6 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.893580E+00 | loss scale: 524288.0 | grad norm: 0.959 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 20:29:19] iteration   419300/  500000 | consumed samples:      3354400 | elapsed time per iteration (ms): 322.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.934065E+00 | loss scale: 524288.0 | grad norm: 0.974 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 20:29:51] iteration   419400/  500000 | consumed samples:      3355200 | elapsed time per iteration (ms): 322.6 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.896779E+00 | loss scale: 524288.0 | grad norm: 0.982 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 20:30:23] iteration   419500/  500000 | consumed samples:      3356000 | elapsed time per iteration (ms): 322.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.912003E+00 | loss scale: 524288.0 | grad norm: 1.004 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 20:30:56] iteration   419600/  500000 | consumed samples:      3356800 | elapsed time per iteration (ms): 323.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.934108E+00 | loss scale: 1048576.0 | grad norm: 0.992 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 20:31:28] iteration   419700/  500000 | consumed samples:      3357600 | elapsed time per iteration (ms): 323.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.934930E+00 | loss scale: 524288.0 | grad norm: 0.995 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-22 20:32:00] iteration   419800/  500000 | consumed samples:      3358400 | elapsed time per iteration (ms): 322.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.924151E+00 | loss scale: 524288.0 | grad norm: 0.973 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 20:32:32] iteration   419900/  500000 | consumed samples:      3359200 | elapsed time per iteration (ms): 320.9 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.937541E+00 | loss scale: 524288.0 | grad norm: 0.978 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 20:33:05] iteration   420000/  500000 | consumed samples:      3360000 | elapsed time per iteration (ms): 323.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.938633E+00 | loss scale: 524288.0 | grad norm: 0.957 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1064.14, 1064.14)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 420000 | lm loss value: 3.631107E+00 | lm loss PPL: 3.775460E+01 | 
--------------------------------------------------------------------------------------------------
saving checkpoint at iteration  420000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-max in torch format
  successfully saved checkpoint at iteration  420000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-max
(min, max) time across ranks (ms):
    save-checkpoint ................................: (5556.20, 5556.20)
 [2024-06-22 20:33:44] iteration   420100/  500000 | consumed samples:      3360800 | elapsed time per iteration (ms): 323.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.944923E+00 | loss scale: 262144.0 | grad norm: 1.024 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-22 20:34:16] iteration   420200/  500000 | consumed samples:      3361600 | elapsed time per iteration (ms): 323.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.897484E+00 | loss scale: 262144.0 | grad norm: 0.971 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 20:34:49] iteration   420300/  500000 | consumed samples:      3362400 | elapsed time per iteration (ms): 324.6 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.944198E+00 | loss scale: 262144.0 | grad norm: 1.035 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 20:35:21] iteration   420400/  500000 | consumed samples:      3363200 | elapsed time per iteration (ms): 321.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.918745E+00 | loss scale: 262144.0 | grad norm: 1.019 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 20:35:53] iteration   420500/  500000 | consumed samples:      3364000 | elapsed time per iteration (ms): 322.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.947302E+00 | loss scale: 262144.0 | grad norm: 1.033 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 20:36:25] iteration   420600/  500000 | consumed samples:      3364800 | elapsed time per iteration (ms): 322.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.895663E+00 | loss scale: 262144.0 | grad norm: 1.093 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 20:36:58] iteration   420700/  500000 | consumed samples:      3365600 | elapsed time per iteration (ms): 323.4 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.936964E+00 | loss scale: 262144.0 | grad norm: 0.989 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 20:37:30] iteration   420800/  500000 | consumed samples:      3366400 | elapsed time per iteration (ms): 322.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.921677E+00 | loss scale: 262144.0 | grad norm: 1.049 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 20:38:02] iteration   420900/  500000 | consumed samples:      3367200 | elapsed time per iteration (ms): 321.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.933787E+00 | loss scale: 262144.0 | grad norm: 0.989 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 20:38:34] iteration   421000/  500000 | consumed samples:      3368000 | elapsed time per iteration (ms): 323.0 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.889517E+00 | loss scale: 262144.0 | grad norm: 0.966 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1068.74, 1068.74)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 421000 | lm loss value: 3.822016E+00 | lm loss PPL: 4.569625E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 20:39:08] iteration   421100/  500000 | consumed samples:      3368800 | elapsed time per iteration (ms): 323.4 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.952571E+00 | loss scale: 524288.0 | grad norm: 0.992 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 20:39:40] iteration   421200/  500000 | consumed samples:      3369600 | elapsed time per iteration (ms): 321.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.907567E+00 | loss scale: 524288.0 | grad norm: 0.997 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-22 20:40:12] iteration   421300/  500000 | consumed samples:      3370400 | elapsed time per iteration (ms): 324.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.957522E+00 | loss scale: 262144.0 | grad norm: 0.990 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-22 20:40:45] iteration   421400/  500000 | consumed samples:      3371200 | elapsed time per iteration (ms): 325.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.936259E+00 | loss scale: 262144.0 | grad norm: 0.956 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 20:41:17] iteration   421500/  500000 | consumed samples:      3372000 | elapsed time per iteration (ms): 323.6 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.931960E+00 | loss scale: 262144.0 | grad norm: 1.005 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 20:41:50] iteration   421600/  500000 | consumed samples:      3372800 | elapsed time per iteration (ms): 325.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.952271E+00 | loss scale: 262144.0 | grad norm: 0.995 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 20:42:22] iteration   421700/  500000 | consumed samples:      3373600 | elapsed time per iteration (ms): 324.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.937914E+00 | loss scale: 262144.0 | grad norm: 0.969 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 20:42:55] iteration   421800/  500000 | consumed samples:      3374400 | elapsed time per iteration (ms): 324.0 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.935717E+00 | loss scale: 262144.0 | grad norm: 1.004 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 20:43:27] iteration   421900/  500000 | consumed samples:      3375200 | elapsed time per iteration (ms): 325.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.917345E+00 | loss scale: 262144.0 | grad norm: 0.976 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 20:44:00] iteration   422000/  500000 | consumed samples:      3376000 | elapsed time per iteration (ms): 325.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.913453E+00 | loss scale: 262144.0 | grad norm: 0.961 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1065.00, 1065.00)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 422000 | lm loss value: 3.668391E+00 | lm loss PPL: 3.918880E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 20:44:33] iteration   422100/  500000 | consumed samples:      3376800 | elapsed time per iteration (ms): 325.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.920355E+00 | loss scale: 262144.0 | grad norm: 1.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 20:45:06] iteration   422200/  500000 | consumed samples:      3377600 | elapsed time per iteration (ms): 324.4 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.928415E+00 | loss scale: 262144.0 | grad norm: 0.984 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 20:45:38] iteration   422300/  500000 | consumed samples:      3378400 | elapsed time per iteration (ms): 327.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.905184E+00 | loss scale: 524288.0 | grad norm: 0.994 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 20:46:11] iteration   422400/  500000 | consumed samples:      3379200 | elapsed time per iteration (ms): 323.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.897063E+00 | loss scale: 524288.0 | grad norm: 1.040 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 20:46:43] iteration   422500/  500000 | consumed samples:      3380000 | elapsed time per iteration (ms): 323.6 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.918412E+00 | loss scale: 524288.0 | grad norm: 0.970 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 20:47:15] iteration   422600/  500000 | consumed samples:      3380800 | elapsed time per iteration (ms): 322.9 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.922863E+00 | loss scale: 524288.0 | grad norm: 0.964 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 20:47:47] iteration   422700/  500000 | consumed samples:      3381600 | elapsed time per iteration (ms): 319.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.917056E+00 | loss scale: 524288.0 | grad norm: 0.980 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 20:48:20] iteration   422800/  500000 | consumed samples:      3382400 | elapsed time per iteration (ms): 322.0 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.918513E+00 | loss scale: 524288.0 | grad norm: 0.986 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 20:48:52] iteration   422900/  500000 | consumed samples:      3383200 | elapsed time per iteration (ms): 322.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.939021E+00 | loss scale: 524288.0 | grad norm: 0.976 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-22 20:49:25] iteration   423000/  500000 | consumed samples:      3384000 | elapsed time per iteration (ms): 327.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.942676E+00 | loss scale: 524288.0 | grad norm: 0.966 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1066.09, 1066.09)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 423000 | lm loss value: 3.748557E+00 | lm loss PPL: 4.245976E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 20:49:58] iteration   423100/  500000 | consumed samples:      3384800 | elapsed time per iteration (ms): 322.9 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.945042E+00 | loss scale: 524288.0 | grad norm: 0.982 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 20:50:30] iteration   423200/  500000 | consumed samples:      3385600 | elapsed time per iteration (ms): 324.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.927452E+00 | loss scale: 524288.0 | grad norm: 1.012 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 20:51:03] iteration   423300/  500000 | consumed samples:      3386400 | elapsed time per iteration (ms): 325.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.925327E+00 | loss scale: 524288.0 | grad norm: 1.020 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 20:51:36] iteration   423400/  500000 | consumed samples:      3387200 | elapsed time per iteration (ms): 325.6 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.943595E+00 | loss scale: 524288.0 | grad norm: 1.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 20:52:08] iteration   423500/  500000 | consumed samples:      3388000 | elapsed time per iteration (ms): 325.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.925470E+00 | loss scale: 524288.0 | grad norm: 0.982 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 20:52:41] iteration   423600/  500000 | consumed samples:      3388800 | elapsed time per iteration (ms): 324.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.920580E+00 | loss scale: 524288.0 | grad norm: 0.984 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 20:53:13] iteration   423700/  500000 | consumed samples:      3389600 | elapsed time per iteration (ms): 322.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.919369E+00 | loss scale: 524288.0 | grad norm: 1.010 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 20:53:45] iteration   423800/  500000 | consumed samples:      3390400 | elapsed time per iteration (ms): 323.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.930807E+00 | loss scale: 524288.0 | grad norm: 0.994 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 20:54:17] iteration   423900/  500000 | consumed samples:      3391200 | elapsed time per iteration (ms): 322.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.904459E+00 | loss scale: 524288.0 | grad norm: 1.012 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-22 20:54:50] iteration   424000/  500000 | consumed samples:      3392000 | elapsed time per iteration (ms): 324.1 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.944081E+00 | loss scale: 524288.0 | grad norm: 1.015 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1064.56, 1064.56)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 424000 | lm loss value: 3.583539E+00 | lm loss PPL: 3.600071E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 20:55:23] iteration   424100/  500000 | consumed samples:      3392800 | elapsed time per iteration (ms): 323.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.947815E+00 | loss scale: 524288.0 | grad norm: 0.903 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 20:55:55] iteration   424200/  500000 | consumed samples:      3393600 | elapsed time per iteration (ms): 323.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.970284E+00 | loss scale: 524288.0 | grad norm: 0.973 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 20:56:28] iteration   424300/  500000 | consumed samples:      3394400 | elapsed time per iteration (ms): 324.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.907284E+00 | loss scale: 524288.0 | grad norm: 1.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 20:57:00] iteration   424400/  500000 | consumed samples:      3395200 | elapsed time per iteration (ms): 320.9 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.923398E+00 | loss scale: 524288.0 | grad norm: 0.995 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 20:57:32] iteration   424500/  500000 | consumed samples:      3396000 | elapsed time per iteration (ms): 320.9 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.963896E+00 | loss scale: 524288.0 | grad norm: 1.028 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 20:58:04] iteration   424600/  500000 | consumed samples:      3396800 | elapsed time per iteration (ms): 323.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.912856E+00 | loss scale: 524288.0 | grad norm: 1.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 20:58:37] iteration   424700/  500000 | consumed samples:      3397600 | elapsed time per iteration (ms): 322.9 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.941300E+00 | loss scale: 524288.0 | grad norm: 0.989 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 20:59:09] iteration   424800/  500000 | consumed samples:      3398400 | elapsed time per iteration (ms): 323.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.967609E+00 | loss scale: 524288.0 | grad norm: 1.028 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 20:59:41] iteration   424900/  500000 | consumed samples:      3399200 | elapsed time per iteration (ms): 324.0 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.959221E+00 | loss scale: 1048576.0 | grad norm: 0.974 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 21:00:14] iteration   425000/  500000 | consumed samples:      3400000 | elapsed time per iteration (ms): 323.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.923945E+00 | loss scale: 524288.0 | grad norm: 1.028 | number of skipped iterations:   2 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1068.39, 1068.39)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 425000 | lm loss value: 3.770186E+00 | lm loss PPL: 4.338813E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 21:00:47] iteration   425100/  500000 | consumed samples:      3400800 | elapsed time per iteration (ms): 324.0 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.965016E+00 | loss scale: 262144.0 | grad norm: 0.961 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-22 21:01:20] iteration   425200/  500000 | consumed samples:      3401600 | elapsed time per iteration (ms): 323.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.882561E+00 | loss scale: 262144.0 | grad norm: 0.978 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 21:01:52] iteration   425300/  500000 | consumed samples:      3402400 | elapsed time per iteration (ms): 324.0 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.933563E+00 | loss scale: 262144.0 | grad norm: 0.972 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 21:02:24] iteration   425400/  500000 | consumed samples:      3403200 | elapsed time per iteration (ms): 323.0 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.917570E+00 | loss scale: 262144.0 | grad norm: 1.039 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 21:02:57] iteration   425500/  500000 | consumed samples:      3404000 | elapsed time per iteration (ms): 322.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.899911E+00 | loss scale: 262144.0 | grad norm: 0.967 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 21:03:29] iteration   425600/  500000 | consumed samples:      3404800 | elapsed time per iteration (ms): 322.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.954039E+00 | loss scale: 262144.0 | grad norm: 0.984 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 21:04:01] iteration   425700/  500000 | consumed samples:      3405600 | elapsed time per iteration (ms): 324.1 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.925309E+00 | loss scale: 262144.0 | grad norm: 1.096 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 21:04:34] iteration   425800/  500000 | consumed samples:      3406400 | elapsed time per iteration (ms): 322.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.920112E+00 | loss scale: 262144.0 | grad norm: 0.976 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 21:05:06] iteration   425900/  500000 | consumed samples:      3407200 | elapsed time per iteration (ms): 324.9 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.971203E+00 | loss scale: 262144.0 | grad norm: 0.984 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 21:05:38] iteration   426000/  500000 | consumed samples:      3408000 | elapsed time per iteration (ms): 323.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.932698E+00 | loss scale: 262144.0 | grad norm: 0.990 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1067.68, 1067.68)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 426000 | lm loss value: 3.546057E+00 | lm loss PPL: 3.467633E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 21:06:12] iteration   426100/  500000 | consumed samples:      3408800 | elapsed time per iteration (ms): 320.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.920423E+00 | loss scale: 524288.0 | grad norm: 1.018 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 21:06:44] iteration   426200/  500000 | consumed samples:      3409600 | elapsed time per iteration (ms): 323.4 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.941942E+00 | loss scale: 524288.0 | grad norm: 1.015 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 21:07:16] iteration   426300/  500000 | consumed samples:      3410400 | elapsed time per iteration (ms): 323.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.917432E+00 | loss scale: 524288.0 | grad norm: 0.971 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 21:07:49] iteration   426400/  500000 | consumed samples:      3411200 | elapsed time per iteration (ms): 324.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.925987E+00 | loss scale: 524288.0 | grad norm: 1.043 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 21:08:21] iteration   426500/  500000 | consumed samples:      3412000 | elapsed time per iteration (ms): 323.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.918488E+00 | loss scale: 524288.0 | grad norm: 1.012 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 21:08:53] iteration   426600/  500000 | consumed samples:      3412800 | elapsed time per iteration (ms): 324.1 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.931618E+00 | loss scale: 524288.0 | grad norm: 1.022 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 21:09:25] iteration   426700/  500000 | consumed samples:      3413600 | elapsed time per iteration (ms): 320.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.911339E+00 | loss scale: 524288.0 | grad norm: 1.009 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 21:09:58] iteration   426800/  500000 | consumed samples:      3414400 | elapsed time per iteration (ms): 322.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.907232E+00 | loss scale: 524288.0 | grad norm: 0.996 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 21:10:30] iteration   426900/  500000 | consumed samples:      3415200 | elapsed time per iteration (ms): 322.6 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.891378E+00 | loss scale: 524288.0 | grad norm: 0.897 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 21:11:02] iteration   427000/  500000 | consumed samples:      3416000 | elapsed time per iteration (ms): 323.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.883524E+00 | loss scale: 524288.0 | grad norm: 0.921 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1064.21, 1064.21)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 427000 | lm loss value: 3.756083E+00 | lm loss PPL: 4.278053E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 21:11:36] iteration   427100/  500000 | consumed samples:      3416800 | elapsed time per iteration (ms): 323.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.934688E+00 | loss scale: 524288.0 | grad norm: 0.952 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-22 21:12:08] iteration   427200/  500000 | consumed samples:      3417600 | elapsed time per iteration (ms): 324.6 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.915938E+00 | loss scale: 524288.0 | grad norm: 0.986 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 21:12:40] iteration   427300/  500000 | consumed samples:      3418400 | elapsed time per iteration (ms): 322.4 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.926315E+00 | loss scale: 524288.0 | grad norm: 1.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 21:13:13] iteration   427400/  500000 | consumed samples:      3419200 | elapsed time per iteration (ms): 322.1 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.913659E+00 | loss scale: 524288.0 | grad norm: 1.013 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 21:13:45] iteration   427500/  500000 | consumed samples:      3420000 | elapsed time per iteration (ms): 324.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.937573E+00 | loss scale: 524288.0 | grad norm: 0.996 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 21:14:17] iteration   427600/  500000 | consumed samples:      3420800 | elapsed time per iteration (ms): 323.6 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.906196E+00 | loss scale: 524288.0 | grad norm: 0.998 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 21:14:50] iteration   427700/  500000 | consumed samples:      3421600 | elapsed time per iteration (ms): 324.9 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.942888E+00 | loss scale: 524288.0 | grad norm: 0.996 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 21:15:22] iteration   427800/  500000 | consumed samples:      3422400 | elapsed time per iteration (ms): 323.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.941100E+00 | loss scale: 524288.0 | grad norm: 1.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 21:15:55] iteration   427900/  500000 | consumed samples:      3423200 | elapsed time per iteration (ms): 323.9 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.908624E+00 | loss scale: 524288.0 | grad norm: 0.982 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 21:16:27] iteration   428000/  500000 | consumed samples:      3424000 | elapsed time per iteration (ms): 325.0 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.941541E+00 | loss scale: 524288.0 | grad norm: 0.992 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1066.45, 1066.45)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 428000 | lm loss value: 3.586757E+00 | lm loss PPL: 3.611677E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 21:17:00] iteration   428100/  500000 | consumed samples:      3424800 | elapsed time per iteration (ms): 321.6 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.952070E+00 | loss scale: 1048576.0 | grad norm: 0.988 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 21:17:33] iteration   428200/  500000 | consumed samples:      3425600 | elapsed time per iteration (ms): 321.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.895825E+00 | loss scale: 524288.0 | grad norm: 0.992 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-22 21:18:05] iteration   428300/  500000 | consumed samples:      3426400 | elapsed time per iteration (ms): 323.0 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.914695E+00 | loss scale: 524288.0 | grad norm: 0.962 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 21:18:37] iteration   428400/  500000 | consumed samples:      3427200 | elapsed time per iteration (ms): 323.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.877420E+00 | loss scale: 524288.0 | grad norm: 0.979 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 21:19:10] iteration   428500/  500000 | consumed samples:      3428000 | elapsed time per iteration (ms): 325.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.925192E+00 | loss scale: 524288.0 | grad norm: 0.978 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 21:19:42] iteration   428600/  500000 | consumed samples:      3428800 | elapsed time per iteration (ms): 321.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.905875E+00 | loss scale: 524288.0 | grad norm: 1.013 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 21:20:14] iteration   428700/  500000 | consumed samples:      3429600 | elapsed time per iteration (ms): 322.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.939795E+00 | loss scale: 262144.0 | grad norm: 1.011 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-22 21:20:47] iteration   428800/  500000 | consumed samples:      3430400 | elapsed time per iteration (ms): 326.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.902881E+00 | loss scale: 262144.0 | grad norm: 0.988 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 21:21:19] iteration   428900/  500000 | consumed samples:      3431200 | elapsed time per iteration (ms): 323.0 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.913293E+00 | loss scale: 262144.0 | grad norm: 0.996 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 21:21:51] iteration   429000/  500000 | consumed samples:      3432000 | elapsed time per iteration (ms): 323.6 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.925095E+00 | loss scale: 262144.0 | grad norm: 0.998 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1064.49, 1064.49)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 429000 | lm loss value: 3.697226E+00 | lm loss PPL: 4.033526E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 21:22:25] iteration   429100/  500000 | consumed samples:      3432800 | elapsed time per iteration (ms): 323.1 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.898028E+00 | loss scale: 262144.0 | grad norm: 1.013 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 21:22:57] iteration   429200/  500000 | consumed samples:      3433600 | elapsed time per iteration (ms): 324.6 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.917384E+00 | loss scale: 262144.0 | grad norm: 0.964 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 21:23:30] iteration   429300/  500000 | consumed samples:      3434400 | elapsed time per iteration (ms): 327.6 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.905458E+00 | loss scale: 262144.0 | grad norm: 1.051 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 21:24:02] iteration   429400/  500000 | consumed samples:      3435200 | elapsed time per iteration (ms): 323.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.940924E+00 | loss scale: 262144.0 | grad norm: 1.038 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 21:24:35] iteration   429500/  500000 | consumed samples:      3436000 | elapsed time per iteration (ms): 324.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.936347E+00 | loss scale: 262144.0 | grad norm: 1.049 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 21:25:07] iteration   429600/  500000 | consumed samples:      3436800 | elapsed time per iteration (ms): 322.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.894438E+00 | loss scale: 262144.0 | grad norm: 0.970 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 21:25:39] iteration   429700/  500000 | consumed samples:      3437600 | elapsed time per iteration (ms): 323.1 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.901880E+00 | loss scale: 524288.0 | grad norm: 0.996 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-22 21:26:12] iteration   429800/  500000 | consumed samples:      3438400 | elapsed time per iteration (ms): 324.1 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.912783E+00 | loss scale: 524288.0 | grad norm: 0.950 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 21:26:44] iteration   429900/  500000 | consumed samples:      3439200 | elapsed time per iteration (ms): 321.4 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.939925E+00 | loss scale: 524288.0 | grad norm: 1.005 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 21:27:16] iteration   430000/  500000 | consumed samples:      3440000 | elapsed time per iteration (ms): 321.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.916423E+00 | loss scale: 524288.0 | grad norm: 1.053 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1063.36, 1063.36)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 430000 | lm loss value: 3.767487E+00 | lm loss PPL: 4.327119E+01 | 
--------------------------------------------------------------------------------------------------
saving checkpoint at iteration  430000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-max in torch format
  successfully saved checkpoint at iteration  430000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-max
(min, max) time across ranks (ms):
    save-checkpoint ................................: (5552.24, 5552.24)
 [2024-06-22 21:27:55] iteration   430100/  500000 | consumed samples:      3440800 | elapsed time per iteration (ms): 321.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 3.009706E+00 | loss scale: 524288.0 | grad norm: 1.034 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 21:28:27] iteration   430200/  500000 | consumed samples:      3441600 | elapsed time per iteration (ms): 323.1 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.918834E+00 | loss scale: 524288.0 | grad norm: 1.011 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 21:29:00] iteration   430300/  500000 | consumed samples:      3442400 | elapsed time per iteration (ms): 324.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.921486E+00 | loss scale: 524288.0 | grad norm: 1.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 21:29:32] iteration   430400/  500000 | consumed samples:      3443200 | elapsed time per iteration (ms): 325.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.938748E+00 | loss scale: 524288.0 | grad norm: 0.962 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 21:30:04] iteration   430500/  500000 | consumed samples:      3444000 | elapsed time per iteration (ms): 323.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.918247E+00 | loss scale: 524288.0 | grad norm: 0.988 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 21:30:37] iteration   430600/  500000 | consumed samples:      3444800 | elapsed time per iteration (ms): 325.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.948896E+00 | loss scale: 524288.0 | grad norm: 1.009 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 21:31:10] iteration   430700/  500000 | consumed samples:      3445600 | elapsed time per iteration (ms): 325.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.953151E+00 | loss scale: 1048576.0 | grad norm: 1.066 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-22 21:31:42] iteration   430800/  500000 | consumed samples:      3446400 | elapsed time per iteration (ms): 323.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.961433E+00 | loss scale: 524288.0 | grad norm: 1.006 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-22 21:32:14] iteration   430900/  500000 | consumed samples:      3447200 | elapsed time per iteration (ms): 325.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.915956E+00 | loss scale: 524288.0 | grad norm: 1.007 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 21:32:47] iteration   431000/  500000 | consumed samples:      3448000 | elapsed time per iteration (ms): 324.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.923247E+00 | loss scale: 524288.0 | grad norm: 1.007 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1064.43, 1064.43)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 431000 | lm loss value: 3.750992E+00 | lm loss PPL: 4.256330E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 21:33:20] iteration   431100/  500000 | consumed samples:      3448800 | elapsed time per iteration (ms): 322.0 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.909347E+00 | loss scale: 262144.0 | grad norm: 0.967 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-22 21:33:53] iteration   431200/  500000 | consumed samples:      3449600 | elapsed time per iteration (ms): 324.1 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.927426E+00 | loss scale: 262144.0 | grad norm: 1.033 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 21:34:25] iteration   431300/  500000 | consumed samples:      3450400 | elapsed time per iteration (ms): 325.0 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.909021E+00 | loss scale: 262144.0 | grad norm: 0.981 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 21:34:57] iteration   431400/  500000 | consumed samples:      3451200 | elapsed time per iteration (ms): 323.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.908057E+00 | loss scale: 262144.0 | grad norm: 0.970 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 21:35:30] iteration   431500/  500000 | consumed samples:      3452000 | elapsed time per iteration (ms): 325.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.938018E+00 | loss scale: 262144.0 | grad norm: 1.011 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 21:36:02] iteration   431600/  500000 | consumed samples:      3452800 | elapsed time per iteration (ms): 323.0 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.932516E+00 | loss scale: 262144.0 | grad norm: 1.039 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 21:36:34] iteration   431700/  500000 | consumed samples:      3453600 | elapsed time per iteration (ms): 322.4 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.930600E+00 | loss scale: 262144.0 | grad norm: 0.969 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 21:37:07] iteration   431800/  500000 | consumed samples:      3454400 | elapsed time per iteration (ms): 322.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.883952E+00 | loss scale: 262144.0 | grad norm: 0.967 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 21:37:39] iteration   431900/  500000 | consumed samples:      3455200 | elapsed time per iteration (ms): 324.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.912713E+00 | loss scale: 262144.0 | grad norm: 0.994 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 21:38:12] iteration   432000/  500000 | consumed samples:      3456000 | elapsed time per iteration (ms): 324.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.905816E+00 | loss scale: 262144.0 | grad norm: 0.989 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1064.01, 1064.01)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 432000 | lm loss value: 3.707626E+00 | lm loss PPL: 4.075692E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 21:38:45] iteration   432100/  500000 | consumed samples:      3456800 | elapsed time per iteration (ms): 322.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.915167E+00 | loss scale: 524288.0 | grad norm: 0.983 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 21:39:17] iteration   432200/  500000 | consumed samples:      3457600 | elapsed time per iteration (ms): 324.6 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.910565E+00 | loss scale: 524288.0 | grad norm: 0.949 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 21:39:50] iteration   432300/  500000 | consumed samples:      3458400 | elapsed time per iteration (ms): 325.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.921985E+00 | loss scale: 524288.0 | grad norm: 0.983 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 21:40:22] iteration   432400/  500000 | consumed samples:      3459200 | elapsed time per iteration (ms): 323.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.936926E+00 | loss scale: 524288.0 | grad norm: 0.977 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 21:40:54] iteration   432500/  500000 | consumed samples:      3460000 | elapsed time per iteration (ms): 321.0 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.920676E+00 | loss scale: 524288.0 | grad norm: 0.966 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-22 21:41:27] iteration   432600/  500000 | consumed samples:      3460800 | elapsed time per iteration (ms): 323.6 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.936093E+00 | loss scale: 524288.0 | grad norm: 1.026 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 21:41:59] iteration   432700/  500000 | consumed samples:      3461600 | elapsed time per iteration (ms): 323.1 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.898850E+00 | loss scale: 524288.0 | grad norm: 0.978 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 21:42:31] iteration   432800/  500000 | consumed samples:      3462400 | elapsed time per iteration (ms): 321.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.883061E+00 | loss scale: 524288.0 | grad norm: 1.021 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 21:43:04] iteration   432900/  500000 | consumed samples:      3463200 | elapsed time per iteration (ms): 324.4 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.910127E+00 | loss scale: 524288.0 | grad norm: 1.011 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 21:43:36] iteration   433000/  500000 | consumed samples:      3464000 | elapsed time per iteration (ms): 321.4 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.903482E+00 | loss scale: 524288.0 | grad norm: 1.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1064.15, 1064.15)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 433000 | lm loss value: 3.586982E+00 | lm loss PPL: 3.612490E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 21:44:09] iteration   433100/  500000 | consumed samples:      3464800 | elapsed time per iteration (ms): 322.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.965626E+00 | loss scale: 524288.0 | grad norm: 1.016 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 21:44:42] iteration   433200/  500000 | consumed samples:      3465600 | elapsed time per iteration (ms): 324.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.926986E+00 | loss scale: 262144.0 | grad norm: 0.939 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-22 21:45:14] iteration   433300/  500000 | consumed samples:      3466400 | elapsed time per iteration (ms): 322.1 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.898284E+00 | loss scale: 262144.0 | grad norm: 0.984 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 21:45:46] iteration   433400/  500000 | consumed samples:      3467200 | elapsed time per iteration (ms): 323.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.892898E+00 | loss scale: 262144.0 | grad norm: 0.964 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 21:46:19] iteration   433500/  500000 | consumed samples:      3468000 | elapsed time per iteration (ms): 324.4 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.936156E+00 | loss scale: 262144.0 | grad norm: 0.980 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 21:46:51] iteration   433600/  500000 | consumed samples:      3468800 | elapsed time per iteration (ms): 323.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.912927E+00 | loss scale: 262144.0 | grad norm: 1.021 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 21:47:24] iteration   433700/  500000 | consumed samples:      3469600 | elapsed time per iteration (ms): 325.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.912468E+00 | loss scale: 262144.0 | grad norm: 0.991 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 21:47:56] iteration   433800/  500000 | consumed samples:      3470400 | elapsed time per iteration (ms): 323.0 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.917830E+00 | loss scale: 262144.0 | grad norm: 0.989 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 21:48:28] iteration   433900/  500000 | consumed samples:      3471200 | elapsed time per iteration (ms): 323.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.960390E+00 | loss scale: 262144.0 | grad norm: 0.974 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 21:49:01] iteration   434000/  500000 | consumed samples:      3472000 | elapsed time per iteration (ms): 324.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.919603E+00 | loss scale: 262144.0 | grad norm: 0.971 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1064.46, 1064.46)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 434000 | lm loss value: 3.598893E+00 | lm loss PPL: 3.655774E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 21:49:34] iteration   434100/  500000 | consumed samples:      3472800 | elapsed time per iteration (ms): 324.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.912302E+00 | loss scale: 262144.0 | grad norm: 0.986 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 21:50:06] iteration   434200/  500000 | consumed samples:      3473600 | elapsed time per iteration (ms): 322.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.957320E+00 | loss scale: 524288.0 | grad norm: 1.006 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 21:50:39] iteration   434300/  500000 | consumed samples:      3474400 | elapsed time per iteration (ms): 325.9 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.898251E+00 | loss scale: 524288.0 | grad norm: 0.996 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 21:51:11] iteration   434400/  500000 | consumed samples:      3475200 | elapsed time per iteration (ms): 322.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.940512E+00 | loss scale: 524288.0 | grad norm: 0.992 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-22 21:51:44] iteration   434500/  500000 | consumed samples:      3476000 | elapsed time per iteration (ms): 325.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.924142E+00 | loss scale: 524288.0 | grad norm: 1.094 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 21:52:16] iteration   434600/  500000 | consumed samples:      3476800 | elapsed time per iteration (ms): 323.6 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.920878E+00 | loss scale: 524288.0 | grad norm: 0.992 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 21:52:48] iteration   434700/  500000 | consumed samples:      3477600 | elapsed time per iteration (ms): 321.9 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.900446E+00 | loss scale: 524288.0 | grad norm: 0.972 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 21:53:20] iteration   434800/  500000 | consumed samples:      3478400 | elapsed time per iteration (ms): 320.4 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.900486E+00 | loss scale: 524288.0 | grad norm: 0.997 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 21:53:52] iteration   434900/  500000 | consumed samples:      3479200 | elapsed time per iteration (ms): 320.1 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.941457E+00 | loss scale: 524288.0 | grad norm: 0.956 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 21:54:25] iteration   435000/  500000 | consumed samples:      3480000 | elapsed time per iteration (ms): 323.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.933081E+00 | loss scale: 524288.0 | grad norm: 0.992 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1064.87, 1064.87)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 435000 | lm loss value: 3.726650E+00 | lm loss PPL: 4.153972E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 21:54:58] iteration   435100/  500000 | consumed samples:      3480800 | elapsed time per iteration (ms): 322.4 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.942893E+00 | loss scale: 524288.0 | grad norm: 1.043 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 21:55:30] iteration   435200/  500000 | consumed samples:      3481600 | elapsed time per iteration (ms): 322.9 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.953173E+00 | loss scale: 524288.0 | grad norm: 1.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 21:56:03] iteration   435300/  500000 | consumed samples:      3482400 | elapsed time per iteration (ms): 324.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.903982E+00 | loss scale: 524288.0 | grad norm: 1.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 21:56:35] iteration   435400/  500000 | consumed samples:      3483200 | elapsed time per iteration (ms): 324.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.919474E+00 | loss scale: 524288.0 | grad norm: 0.978 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-22 21:57:07] iteration   435500/  500000 | consumed samples:      3484000 | elapsed time per iteration (ms): 322.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.913816E+00 | loss scale: 524288.0 | grad norm: 1.007 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 21:57:40] iteration   435600/  500000 | consumed samples:      3484800 | elapsed time per iteration (ms): 322.6 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.928454E+00 | loss scale: 262144.0 | grad norm: 0.979 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-22 21:58:12] iteration   435700/  500000 | consumed samples:      3485600 | elapsed time per iteration (ms): 322.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.911042E+00 | loss scale: 262144.0 | grad norm: 1.028 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 21:58:44] iteration   435800/  500000 | consumed samples:      3486400 | elapsed time per iteration (ms): 324.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.887918E+00 | loss scale: 262144.0 | grad norm: 0.979 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 21:59:17] iteration   435900/  500000 | consumed samples:      3487200 | elapsed time per iteration (ms): 322.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.911932E+00 | loss scale: 262144.0 | grad norm: 0.940 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 21:59:49] iteration   436000/  500000 | consumed samples:      3488000 | elapsed time per iteration (ms): 326.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.924624E+00 | loss scale: 262144.0 | grad norm: 1.011 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1069.78, 1069.78)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 436000 | lm loss value: 3.756845E+00 | lm loss PPL: 4.281315E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 22:00:23] iteration   436100/  500000 | consumed samples:      3488800 | elapsed time per iteration (ms): 323.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.941183E+00 | loss scale: 262144.0 | grad norm: 0.983 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 22:00:55] iteration   436200/  500000 | consumed samples:      3489600 | elapsed time per iteration (ms): 322.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.861071E+00 | loss scale: 262144.0 | grad norm: 0.994 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 22:01:27] iteration   436300/  500000 | consumed samples:      3490400 | elapsed time per iteration (ms): 323.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.897719E+00 | loss scale: 262144.0 | grad norm: 0.987 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 22:02:00] iteration   436400/  500000 | consumed samples:      3491200 | elapsed time per iteration (ms): 324.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.896804E+00 | loss scale: 262144.0 | grad norm: 1.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 22:02:32] iteration   436500/  500000 | consumed samples:      3492000 | elapsed time per iteration (ms): 323.6 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.921805E+00 | loss scale: 262144.0 | grad norm: 0.956 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 22:03:04] iteration   436600/  500000 | consumed samples:      3492800 | elapsed time per iteration (ms): 324.0 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.952015E+00 | loss scale: 524288.0 | grad norm: 0.993 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 22:03:37] iteration   436700/  500000 | consumed samples:      3493600 | elapsed time per iteration (ms): 324.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.891841E+00 | loss scale: 524288.0 | grad norm: 1.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 22:04:09] iteration   436800/  500000 | consumed samples:      3494400 | elapsed time per iteration (ms): 324.0 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.926322E+00 | loss scale: 524288.0 | grad norm: 0.968 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 22:04:42] iteration   436900/  500000 | consumed samples:      3495200 | elapsed time per iteration (ms): 326.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.923775E+00 | loss scale: 524288.0 | grad norm: 1.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 22:05:14] iteration   437000/  500000 | consumed samples:      3496000 | elapsed time per iteration (ms): 325.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.905668E+00 | loss scale: 524288.0 | grad norm: 0.996 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1064.52, 1064.52)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 437000 | lm loss value: 3.630736E+00 | lm loss PPL: 3.774058E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 22:05:48] iteration   437100/  500000 | consumed samples:      3496800 | elapsed time per iteration (ms): 326.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.929291E+00 | loss scale: 524288.0 | grad norm: 0.997 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 22:06:20] iteration   437200/  500000 | consumed samples:      3497600 | elapsed time per iteration (ms): 322.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.933080E+00 | loss scale: 524288.0 | grad norm: 1.007 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 22:06:53] iteration   437300/  500000 | consumed samples:      3498400 | elapsed time per iteration (ms): 323.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.928979E+00 | loss scale: 524288.0 | grad norm: 0.989 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 22:07:25] iteration   437400/  500000 | consumed samples:      3499200 | elapsed time per iteration (ms): 323.4 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.910620E+00 | loss scale: 524288.0 | grad norm: 1.030 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 22:07:57] iteration   437500/  500000 | consumed samples:      3500000 | elapsed time per iteration (ms): 323.4 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.970883E+00 | loss scale: 524288.0 | grad norm: 0.960 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 22:08:30] iteration   437600/  500000 | consumed samples:      3500800 | elapsed time per iteration (ms): 323.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.880772E+00 | loss scale: 524288.0 | grad norm: 0.969 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-22 22:09:02] iteration   437700/  500000 | consumed samples:      3501600 | elapsed time per iteration (ms): 325.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.948201E+00 | loss scale: 524288.0 | grad norm: 0.962 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 22:09:35] iteration   437800/  500000 | consumed samples:      3502400 | elapsed time per iteration (ms): 323.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.947487E+00 | loss scale: 524288.0 | grad norm: 0.988 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 22:10:07] iteration   437900/  500000 | consumed samples:      3503200 | elapsed time per iteration (ms): 325.4 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.960169E+00 | loss scale: 524288.0 | grad norm: 1.032 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 22:10:40] iteration   438000/  500000 | consumed samples:      3504000 | elapsed time per iteration (ms): 324.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.899001E+00 | loss scale: 524288.0 | grad norm: 0.988 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1063.95, 1063.95)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 438000 | lm loss value: 3.702531E+00 | lm loss PPL: 4.054981E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 22:11:13] iteration   438100/  500000 | consumed samples:      3504800 | elapsed time per iteration (ms): 323.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.917065E+00 | loss scale: 524288.0 | grad norm: 0.998 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 22:11:45] iteration   438200/  500000 | consumed samples:      3505600 | elapsed time per iteration (ms): 323.0 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.903881E+00 | loss scale: 524288.0 | grad norm: 1.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 22:12:18] iteration   438300/  500000 | consumed samples:      3506400 | elapsed time per iteration (ms): 322.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.934475E+00 | loss scale: 524288.0 | grad norm: 1.018 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 22:12:50] iteration   438400/  500000 | consumed samples:      3507200 | elapsed time per iteration (ms): 325.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.901382E+00 | loss scale: 524288.0 | grad norm: 0.973 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 22:13:23] iteration   438500/  500000 | consumed samples:      3508000 | elapsed time per iteration (ms): 324.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.930136E+00 | loss scale: 524288.0 | grad norm: 0.953 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 22:13:55] iteration   438600/  500000 | consumed samples:      3508800 | elapsed time per iteration (ms): 323.0 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.916945E+00 | loss scale: 524288.0 | grad norm: 1.027 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-22 22:14:27] iteration   438700/  500000 | consumed samples:      3509600 | elapsed time per iteration (ms): 324.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.856798E+00 | loss scale: 524288.0 | grad norm: 1.060 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 22:15:00] iteration   438800/  500000 | consumed samples:      3510400 | elapsed time per iteration (ms): 325.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.883653E+00 | loss scale: 524288.0 | grad norm: 1.032 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 22:15:32] iteration   438900/  500000 | consumed samples:      3511200 | elapsed time per iteration (ms): 323.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.905148E+00 | loss scale: 524288.0 | grad norm: 1.020 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 22:16:05] iteration   439000/  500000 | consumed samples:      3512000 | elapsed time per iteration (ms): 324.9 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.921117E+00 | loss scale: 524288.0 | grad norm: 0.979 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1064.10, 1064.10)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 439000 | lm loss value: 3.665612E+00 | lm loss PPL: 3.908006E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 22:16:38] iteration   439100/  500000 | consumed samples:      3512800 | elapsed time per iteration (ms): 324.9 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.922831E+00 | loss scale: 524288.0 | grad norm: 0.954 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 22:17:11] iteration   439200/  500000 | consumed samples:      3513600 | elapsed time per iteration (ms): 323.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.946243E+00 | loss scale: 524288.0 | grad norm: 1.014 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 22:17:43] iteration   439300/  500000 | consumed samples:      3514400 | elapsed time per iteration (ms): 325.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.940859E+00 | loss scale: 524288.0 | grad norm: 1.010 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 22:18:15] iteration   439400/  500000 | consumed samples:      3515200 | elapsed time per iteration (ms): 322.9 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.930767E+00 | loss scale: 524288.0 | grad norm: 1.011 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 22:18:48] iteration   439500/  500000 | consumed samples:      3516000 | elapsed time per iteration (ms): 325.6 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.910947E+00 | loss scale: 524288.0 | grad norm: 0.966 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 22:19:20] iteration   439600/  500000 | consumed samples:      3516800 | elapsed time per iteration (ms): 322.9 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.890423E+00 | loss scale: 524288.0 | grad norm: 1.003 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-22 22:19:52] iteration   439700/  500000 | consumed samples:      3517600 | elapsed time per iteration (ms): 320.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.934917E+00 | loss scale: 262144.0 | grad norm: 1.011 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-22 22:20:25] iteration   439800/  500000 | consumed samples:      3518400 | elapsed time per iteration (ms): 325.4 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.900765E+00 | loss scale: 262144.0 | grad norm: 1.108 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 22:20:57] iteration   439900/  500000 | consumed samples:      3519200 | elapsed time per iteration (ms): 323.1 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.909156E+00 | loss scale: 262144.0 | grad norm: 1.038 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 22:21:30] iteration   440000/  500000 | consumed samples:      3520000 | elapsed time per iteration (ms): 324.9 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.911292E+00 | loss scale: 262144.0 | grad norm: 1.005 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1063.71, 1063.71)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 440000 | lm loss value: 3.702496E+00 | lm loss PPL: 4.054840E+01 | 
--------------------------------------------------------------------------------------------------
saving checkpoint at iteration  440000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-max in torch format
  successfully saved checkpoint at iteration  440000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-max
(min, max) time across ranks (ms):
    save-checkpoint ................................: (5862.27, 5862.27)
 [2024-06-22 22:22:09] iteration   440100/  500000 | consumed samples:      3520800 | elapsed time per iteration (ms): 322.6 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.950147E+00 | loss scale: 262144.0 | grad norm: 0.969 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 22:22:41] iteration   440200/  500000 | consumed samples:      3521600 | elapsed time per iteration (ms): 322.6 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.904530E+00 | loss scale: 262144.0 | grad norm: 1.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 22:23:13] iteration   440300/  500000 | consumed samples:      3522400 | elapsed time per iteration (ms): 322.6 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.926335E+00 | loss scale: 262144.0 | grad norm: 0.998 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 22:23:46] iteration   440400/  500000 | consumed samples:      3523200 | elapsed time per iteration (ms): 323.4 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.920451E+00 | loss scale: 262144.0 | grad norm: 0.993 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 22:24:18] iteration   440500/  500000 | consumed samples:      3524000 | elapsed time per iteration (ms): 320.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.935616E+00 | loss scale: 262144.0 | grad norm: 1.040 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 22:24:50] iteration   440600/  500000 | consumed samples:      3524800 | elapsed time per iteration (ms): 324.1 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.869674E+00 | loss scale: 262144.0 | grad norm: 1.006 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 22:25:23] iteration   440700/  500000 | consumed samples:      3525600 | elapsed time per iteration (ms): 322.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.903051E+00 | loss scale: 524288.0 | grad norm: 1.005 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 22:25:55] iteration   440800/  500000 | consumed samples:      3526400 | elapsed time per iteration (ms): 324.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.926639E+00 | loss scale: 524288.0 | grad norm: 0.992 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 22:26:28] iteration   440900/  500000 | consumed samples:      3527200 | elapsed time per iteration (ms): 325.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.921561E+00 | loss scale: 524288.0 | grad norm: 0.992 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 22:27:00] iteration   441000/  500000 | consumed samples:      3528000 | elapsed time per iteration (ms): 322.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.971464E+00 | loss scale: 524288.0 | grad norm: 1.088 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1065.32, 1065.32)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 441000 | lm loss value: 3.689859E+00 | lm loss PPL: 4.003921E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 22:27:33] iteration   441100/  500000 | consumed samples:      3528800 | elapsed time per iteration (ms): 321.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.917249E+00 | loss scale: 524288.0 | grad norm: 0.986 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 22:28:05] iteration   441200/  500000 | consumed samples:      3529600 | elapsed time per iteration (ms): 323.0 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.915757E+00 | loss scale: 524288.0 | grad norm: 0.977 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 22:28:38] iteration   441300/  500000 | consumed samples:      3530400 | elapsed time per iteration (ms): 325.1 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.908936E+00 | loss scale: 524288.0 | grad norm: 0.987 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 22:29:10] iteration   441400/  500000 | consumed samples:      3531200 | elapsed time per iteration (ms): 323.1 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.915591E+00 | loss scale: 524288.0 | grad norm: 0.970 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-22 22:29:43] iteration   441500/  500000 | consumed samples:      3532000 | elapsed time per iteration (ms): 324.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.919616E+00 | loss scale: 524288.0 | grad norm: 1.011 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 22:30:15] iteration   441600/  500000 | consumed samples:      3532800 | elapsed time per iteration (ms): 324.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.911078E+00 | loss scale: 524288.0 | grad norm: 1.009 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 22:30:48] iteration   441700/  500000 | consumed samples:      3533600 | elapsed time per iteration (ms): 325.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.919474E+00 | loss scale: 262144.0 | grad norm: 1.005 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-22 22:31:20] iteration   441800/  500000 | consumed samples:      3534400 | elapsed time per iteration (ms): 324.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.939026E+00 | loss scale: 262144.0 | grad norm: 0.956 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 22:31:52] iteration   441900/  500000 | consumed samples:      3535200 | elapsed time per iteration (ms): 324.1 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.936695E+00 | loss scale: 262144.0 | grad norm: 1.027 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 22:32:25] iteration   442000/  500000 | consumed samples:      3536000 | elapsed time per iteration (ms): 324.6 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.937464E+00 | loss scale: 262144.0 | grad norm: 0.942 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1063.42, 1063.42)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 442000 | lm loss value: 3.670503E+00 | lm loss PPL: 3.927167E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 22:32:58] iteration   442100/  500000 | consumed samples:      3536800 | elapsed time per iteration (ms): 324.0 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.910210E+00 | loss scale: 262144.0 | grad norm: 1.005 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 22:33:31] iteration   442200/  500000 | consumed samples:      3537600 | elapsed time per iteration (ms): 324.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.928891E+00 | loss scale: 262144.0 | grad norm: 1.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 22:34:03] iteration   442300/  500000 | consumed samples:      3538400 | elapsed time per iteration (ms): 321.6 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.904106E+00 | loss scale: 262144.0 | grad norm: 1.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 22:34:35] iteration   442400/  500000 | consumed samples:      3539200 | elapsed time per iteration (ms): 325.4 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.861972E+00 | loss scale: 262144.0 | grad norm: 1.005 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 22:35:08] iteration   442500/  500000 | consumed samples:      3540000 | elapsed time per iteration (ms): 323.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.904752E+00 | loss scale: 262144.0 | grad norm: 1.014 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 22:35:40] iteration   442600/  500000 | consumed samples:      3540800 | elapsed time per iteration (ms): 323.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.939875E+00 | loss scale: 262144.0 | grad norm: 1.034 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 22:36:12] iteration   442700/  500000 | consumed samples:      3541600 | elapsed time per iteration (ms): 320.6 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.927144E+00 | loss scale: 524288.0 | grad norm: 0.988 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 22:36:45] iteration   442800/  500000 | consumed samples:      3542400 | elapsed time per iteration (ms): 324.9 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.910505E+00 | loss scale: 524288.0 | grad norm: 1.042 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 22:37:17] iteration   442900/  500000 | consumed samples:      3543200 | elapsed time per iteration (ms): 323.6 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.926822E+00 | loss scale: 524288.0 | grad norm: 1.004 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 22:37:50] iteration   443000/  500000 | consumed samples:      3544000 | elapsed time per iteration (ms): 325.4 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.925703E+00 | loss scale: 524288.0 | grad norm: 0.993 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1063.89, 1063.89)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 443000 | lm loss value: 3.722799E+00 | lm loss PPL: 4.138004E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 22:38:23] iteration   443100/  500000 | consumed samples:      3544800 | elapsed time per iteration (ms): 322.9 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.867320E+00 | loss scale: 524288.0 | grad norm: 0.998 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 22:38:55] iteration   443200/  500000 | consumed samples:      3545600 | elapsed time per iteration (ms): 323.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.910334E+00 | loss scale: 524288.0 | grad norm: 1.064 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 22:39:28] iteration   443300/  500000 | consumed samples:      3546400 | elapsed time per iteration (ms): 323.4 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.915069E+00 | loss scale: 524288.0 | grad norm: 0.970 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 22:40:00] iteration   443400/  500000 | consumed samples:      3547200 | elapsed time per iteration (ms): 324.4 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.898820E+00 | loss scale: 524288.0 | grad norm: 1.024 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 22:40:33] iteration   443500/  500000 | consumed samples:      3548000 | elapsed time per iteration (ms): 324.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.958883E+00 | loss scale: 524288.0 | grad norm: 1.010 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 22:41:05] iteration   443600/  500000 | consumed samples:      3548800 | elapsed time per iteration (ms): 323.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.945349E+00 | loss scale: 524288.0 | grad norm: 0.991 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 22:41:37] iteration   443700/  500000 | consumed samples:      3549600 | elapsed time per iteration (ms): 324.6 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.929660E+00 | loss scale: 1048576.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-22 22:42:10] iteration   443800/  500000 | consumed samples:      3550400 | elapsed time per iteration (ms): 322.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.891471E+00 | loss scale: 524288.0 | grad norm: 0.993 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-22 22:42:42] iteration   443900/  500000 | consumed samples:      3551200 | elapsed time per iteration (ms): 324.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.902124E+00 | loss scale: 524288.0 | grad norm: 0.972 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 22:43:14] iteration   444000/  500000 | consumed samples:      3552000 | elapsed time per iteration (ms): 321.4 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.857994E+00 | loss scale: 524288.0 | grad norm: 0.991 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1065.34, 1065.34)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 444000 | lm loss value: 3.563761E+00 | lm loss PPL: 3.529571E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 22:43:47] iteration   444100/  500000 | consumed samples:      3552800 | elapsed time per iteration (ms): 321.6 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.932807E+00 | loss scale: 524288.0 | grad norm: 1.030 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 22:44:20] iteration   444200/  500000 | consumed samples:      3553600 | elapsed time per iteration (ms): 322.6 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.900910E+00 | loss scale: 524288.0 | grad norm: 0.939 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 22:44:52] iteration   444300/  500000 | consumed samples:      3554400 | elapsed time per iteration (ms): 323.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.922441E+00 | loss scale: 524288.0 | grad norm: 0.991 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 22:45:24] iteration   444400/  500000 | consumed samples:      3555200 | elapsed time per iteration (ms): 322.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.940355E+00 | loss scale: 524288.0 | grad norm: 1.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 22:45:56] iteration   444500/  500000 | consumed samples:      3556000 | elapsed time per iteration (ms): 322.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.920767E+00 | loss scale: 524288.0 | grad norm: 0.990 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 22:46:29] iteration   444600/  500000 | consumed samples:      3556800 | elapsed time per iteration (ms): 323.9 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.927727E+00 | loss scale: 524288.0 | grad norm: 0.980 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 22:47:01] iteration   444700/  500000 | consumed samples:      3557600 | elapsed time per iteration (ms): 323.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.890089E+00 | loss scale: 524288.0 | grad norm: 1.028 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 22:47:34] iteration   444800/  500000 | consumed samples:      3558400 | elapsed time per iteration (ms): 323.9 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.912047E+00 | loss scale: 524288.0 | grad norm: 0.978 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-22 22:48:06] iteration   444900/  500000 | consumed samples:      3559200 | elapsed time per iteration (ms): 324.1 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.892950E+00 | loss scale: 524288.0 | grad norm: 1.008 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 22:48:39] iteration   445000/  500000 | consumed samples:      3560000 | elapsed time per iteration (ms): 325.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.866704E+00 | loss scale: 524288.0 | grad norm: 0.996 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1063.00, 1063.00)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 445000 | lm loss value: 3.651255E+00 | lm loss PPL: 3.852299E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 22:49:12] iteration   445100/  500000 | consumed samples:      3560800 | elapsed time per iteration (ms): 321.9 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.885331E+00 | loss scale: 524288.0 | grad norm: 1.026 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 22:49:44] iteration   445200/  500000 | consumed samples:      3561600 | elapsed time per iteration (ms): 323.6 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.899700E+00 | loss scale: 262144.0 | grad norm: 0.977 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-22 22:50:17] iteration   445300/  500000 | consumed samples:      3562400 | elapsed time per iteration (ms): 324.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.949102E+00 | loss scale: 262144.0 | grad norm: 1.005 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 22:50:49] iteration   445400/  500000 | consumed samples:      3563200 | elapsed time per iteration (ms): 325.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.887257E+00 | loss scale: 262144.0 | grad norm: 0.977 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 22:51:21] iteration   445500/  500000 | consumed samples:      3564000 | elapsed time per iteration (ms): 323.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.918217E+00 | loss scale: 262144.0 | grad norm: 0.982 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 22:51:54] iteration   445600/  500000 | consumed samples:      3564800 | elapsed time per iteration (ms): 322.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.945262E+00 | loss scale: 262144.0 | grad norm: 1.033 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 22:52:26] iteration   445700/  500000 | consumed samples:      3565600 | elapsed time per iteration (ms): 324.4 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.927010E+00 | loss scale: 262144.0 | grad norm: 1.055 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 22:52:59] iteration   445800/  500000 | consumed samples:      3566400 | elapsed time per iteration (ms): 325.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.871145E+00 | loss scale: 262144.0 | grad norm: 0.997 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 22:53:31] iteration   445900/  500000 | consumed samples:      3567200 | elapsed time per iteration (ms): 323.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.882593E+00 | loss scale: 262144.0 | grad norm: 0.984 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 22:54:03] iteration   446000/  500000 | consumed samples:      3568000 | elapsed time per iteration (ms): 322.1 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.941619E+00 | loss scale: 262144.0 | grad norm: 0.984 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1063.82, 1063.82)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 446000 | lm loss value: 3.775252E+00 | lm loss PPL: 4.360849E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 22:54:37] iteration   446100/  500000 | consumed samples:      3568800 | elapsed time per iteration (ms): 324.0 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.890473E+00 | loss scale: 262144.0 | grad norm: 0.991 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 22:55:09] iteration   446200/  500000 | consumed samples:      3569600 | elapsed time per iteration (ms): 324.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.921492E+00 | loss scale: 524288.0 | grad norm: 0.971 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 22:55:42] iteration   446300/  500000 | consumed samples:      3570400 | elapsed time per iteration (ms): 325.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.874281E+00 | loss scale: 524288.0 | grad norm: 0.949 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 22:56:14] iteration   446400/  500000 | consumed samples:      3571200 | elapsed time per iteration (ms): 322.9 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.908163E+00 | loss scale: 524288.0 | grad norm: 1.014 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 22:56:46] iteration   446500/  500000 | consumed samples:      3572000 | elapsed time per iteration (ms): 323.4 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.923135E+00 | loss scale: 524288.0 | grad norm: 1.035 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 22:57:18] iteration   446600/  500000 | consumed samples:      3572800 | elapsed time per iteration (ms): 321.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.917019E+00 | loss scale: 524288.0 | grad norm: 1.063 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-22 22:57:51] iteration   446700/  500000 | consumed samples:      3573600 | elapsed time per iteration (ms): 324.0 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.934166E+00 | loss scale: 524288.0 | grad norm: 0.991 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 22:58:23] iteration   446800/  500000 | consumed samples:      3574400 | elapsed time per iteration (ms): 324.1 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.935697E+00 | loss scale: 524288.0 | grad norm: 0.989 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 22:58:56] iteration   446900/  500000 | consumed samples:      3575200 | elapsed time per iteration (ms): 325.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.905247E+00 | loss scale: 524288.0 | grad norm: 0.942 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 22:59:28] iteration   447000/  500000 | consumed samples:      3576000 | elapsed time per iteration (ms): 325.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.952578E+00 | loss scale: 524288.0 | grad norm: 0.999 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1063.37, 1063.37)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 447000 | lm loss value: 3.619461E+00 | lm loss PPL: 3.731745E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 23:00:02] iteration   447100/  500000 | consumed samples:      3576800 | elapsed time per iteration (ms): 324.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.917979E+00 | loss scale: 262144.0 | grad norm: 1.062 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-22 23:00:34] iteration   447200/  500000 | consumed samples:      3577600 | elapsed time per iteration (ms): 322.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.909699E+00 | loss scale: 262144.0 | grad norm: 1.020 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 23:01:07] iteration   447300/  500000 | consumed samples:      3578400 | elapsed time per iteration (ms): 324.6 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.958049E+00 | loss scale: 262144.0 | grad norm: 1.011 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 23:01:39] iteration   447400/  500000 | consumed samples:      3579200 | elapsed time per iteration (ms): 326.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.944832E+00 | loss scale: 262144.0 | grad norm: 1.021 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 23:02:12] iteration   447500/  500000 | consumed samples:      3580000 | elapsed time per iteration (ms): 322.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.905291E+00 | loss scale: 262144.0 | grad norm: 1.012 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 23:02:44] iteration   447600/  500000 | consumed samples:      3580800 | elapsed time per iteration (ms): 324.9 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.949270E+00 | loss scale: 262144.0 | grad norm: 0.992 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 23:03:16] iteration   447700/  500000 | consumed samples:      3581600 | elapsed time per iteration (ms): 323.9 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.934225E+00 | loss scale: 262144.0 | grad norm: 0.972 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 23:03:49] iteration   447800/  500000 | consumed samples:      3582400 | elapsed time per iteration (ms): 325.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.900980E+00 | loss scale: 262144.0 | grad norm: 1.018 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 23:04:21] iteration   447900/  500000 | consumed samples:      3583200 | elapsed time per iteration (ms): 323.1 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.930402E+00 | loss scale: 262144.0 | grad norm: 0.937 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 23:04:53] iteration   448000/  500000 | consumed samples:      3584000 | elapsed time per iteration (ms): 321.9 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.915625E+00 | loss scale: 262144.0 | grad norm: 0.991 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1063.23, 1063.23)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 448000 | lm loss value: 3.751053E+00 | lm loss PPL: 4.256586E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 23:05:27] iteration   448100/  500000 | consumed samples:      3584800 | elapsed time per iteration (ms): 322.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.926907E+00 | loss scale: 524288.0 | grad norm: 1.041 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-22 23:05:59] iteration   448200/  500000 | consumed samples:      3585600 | elapsed time per iteration (ms): 323.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.919922E+00 | loss scale: 524288.0 | grad norm: 1.016 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 23:06:31] iteration   448300/  500000 | consumed samples:      3586400 | elapsed time per iteration (ms): 322.6 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.914149E+00 | loss scale: 524288.0 | grad norm: 0.987 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 23:07:04] iteration   448400/  500000 | consumed samples:      3587200 | elapsed time per iteration (ms): 325.1 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.966220E+00 | loss scale: 524288.0 | grad norm: 1.065 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 23:07:36] iteration   448500/  500000 | consumed samples:      3588000 | elapsed time per iteration (ms): 324.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.928665E+00 | loss scale: 524288.0 | grad norm: 0.981 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 23:08:09] iteration   448600/  500000 | consumed samples:      3588800 | elapsed time per iteration (ms): 325.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.876941E+00 | loss scale: 524288.0 | grad norm: 1.066 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 23:08:41] iteration   448700/  500000 | consumed samples:      3589600 | elapsed time per iteration (ms): 321.4 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.945585E+00 | loss scale: 524288.0 | grad norm: 0.972 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 23:09:14] iteration   448800/  500000 | consumed samples:      3590400 | elapsed time per iteration (ms): 324.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.931450E+00 | loss scale: 524288.0 | grad norm: 0.988 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 23:09:46] iteration   448900/  500000 | consumed samples:      3591200 | elapsed time per iteration (ms): 323.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.872373E+00 | loss scale: 524288.0 | grad norm: 1.028 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 23:10:18] iteration   449000/  500000 | consumed samples:      3592000 | elapsed time per iteration (ms): 323.9 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.890093E+00 | loss scale: 524288.0 | grad norm: 1.017 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1065.24, 1065.24)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 449000 | lm loss value: 3.679873E+00 | lm loss PPL: 3.964136E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 23:10:52] iteration   449100/  500000 | consumed samples:      3592800 | elapsed time per iteration (ms): 324.6 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.899363E+00 | loss scale: 1048576.0 | grad norm: 1.028 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-22 23:11:24] iteration   449200/  500000 | consumed samples:      3593600 | elapsed time per iteration (ms): 322.1 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.911702E+00 | loss scale: 262144.0 | grad norm: 0.953 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-22 23:11:56] iteration   449300/  500000 | consumed samples:      3594400 | elapsed time per iteration (ms): 324.1 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.940367E+00 | loss scale: 262144.0 | grad norm: 1.023 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 23:12:29] iteration   449400/  500000 | consumed samples:      3595200 | elapsed time per iteration (ms): 321.9 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.890897E+00 | loss scale: 262144.0 | grad norm: 0.997 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 23:13:01] iteration   449500/  500000 | consumed samples:      3596000 | elapsed time per iteration (ms): 324.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.885850E+00 | loss scale: 262144.0 | grad norm: 0.971 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 23:13:34] iteration   449600/  500000 | consumed samples:      3596800 | elapsed time per iteration (ms): 326.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.892903E+00 | loss scale: 262144.0 | grad norm: 0.998 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 23:14:06] iteration   449700/  500000 | consumed samples:      3597600 | elapsed time per iteration (ms): 322.9 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.911313E+00 | loss scale: 262144.0 | grad norm: 1.007 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 23:14:39] iteration   449800/  500000 | consumed samples:      3598400 | elapsed time per iteration (ms): 326.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.939487E+00 | loss scale: 262144.0 | grad norm: 1.029 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 23:15:11] iteration   449900/  500000 | consumed samples:      3599200 | elapsed time per iteration (ms): 321.6 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.893204E+00 | loss scale: 262144.0 | grad norm: 1.027 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 23:15:43] iteration   450000/  500000 | consumed samples:      3600000 | elapsed time per iteration (ms): 326.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.933414E+00 | loss scale: 262144.0 | grad norm: 0.980 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1062.91, 1062.91)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 450000 | lm loss value: 3.595849E+00 | lm loss PPL: 3.644662E+01 | 
--------------------------------------------------------------------------------------------------
saving checkpoint at iteration  450000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-max in torch format
  successfully saved checkpoint at iteration  450000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-max
(min, max) time across ranks (ms):
    save-checkpoint ................................: (5721.75, 5721.75)
 [2024-06-22 23:16:23] iteration   450100/  500000 | consumed samples:      3600800 | elapsed time per iteration (ms): 323.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.950161E+00 | loss scale: 262144.0 | grad norm: 1.066 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 23:16:55] iteration   450200/  500000 | consumed samples:      3601600 | elapsed time per iteration (ms): 322.9 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.916380E+00 | loss scale: 524288.0 | grad norm: 1.033 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 23:17:27] iteration   450300/  500000 | consumed samples:      3602400 | elapsed time per iteration (ms): 325.4 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.914205E+00 | loss scale: 524288.0 | grad norm: 1.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 23:18:00] iteration   450400/  500000 | consumed samples:      3603200 | elapsed time per iteration (ms): 323.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.936822E+00 | loss scale: 524288.0 | grad norm: 1.015 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 23:18:32] iteration   450500/  500000 | consumed samples:      3604000 | elapsed time per iteration (ms): 321.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.894828E+00 | loss scale: 524288.0 | grad norm: 0.988 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 23:19:04] iteration   450600/  500000 | consumed samples:      3604800 | elapsed time per iteration (ms): 323.0 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.923698E+00 | loss scale: 524288.0 | grad norm: 1.007 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 23:19:37] iteration   450700/  500000 | consumed samples:      3605600 | elapsed time per iteration (ms): 325.6 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.925115E+00 | loss scale: 524288.0 | grad norm: 0.994 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 23:20:09] iteration   450800/  500000 | consumed samples:      3606400 | elapsed time per iteration (ms): 325.1 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.881904E+00 | loss scale: 524288.0 | grad norm: 0.997 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 23:20:42] iteration   450900/  500000 | consumed samples:      3607200 | elapsed time per iteration (ms): 325.0 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.932072E+00 | loss scale: 524288.0 | grad norm: 0.980 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 23:21:14] iteration   451000/  500000 | consumed samples:      3608000 | elapsed time per iteration (ms): 324.1 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.930900E+00 | loss scale: 524288.0 | grad norm: 0.977 | number of skipped iterations:   1 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1065.72, 1065.72)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 451000 | lm loss value: 3.804067E+00 | lm loss PPL: 4.488337E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 23:21:48] iteration   451100/  500000 | consumed samples:      3608800 | elapsed time per iteration (ms): 324.1 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.952705E+00 | loss scale: 524288.0 | grad norm: 1.026 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 23:22:20] iteration   451200/  500000 | consumed samples:      3609600 | elapsed time per iteration (ms): 322.9 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.943551E+00 | loss scale: 524288.0 | grad norm: 1.026 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 23:22:52] iteration   451300/  500000 | consumed samples:      3610400 | elapsed time per iteration (ms): 322.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.904702E+00 | loss scale: 524288.0 | grad norm: 1.006 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 23:23:25] iteration   451400/  500000 | consumed samples:      3611200 | elapsed time per iteration (ms): 323.4 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.877671E+00 | loss scale: 524288.0 | grad norm: 1.004 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 23:23:57] iteration   451500/  500000 | consumed samples:      3612000 | elapsed time per iteration (ms): 324.4 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.920641E+00 | loss scale: 524288.0 | grad norm: 0.935 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 23:24:29] iteration   451600/  500000 | consumed samples:      3612800 | elapsed time per iteration (ms): 323.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.896780E+00 | loss scale: 524288.0 | grad norm: 1.058 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 23:25:02] iteration   451700/  500000 | consumed samples:      3613600 | elapsed time per iteration (ms): 324.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.935952E+00 | loss scale: 524288.0 | grad norm: 1.027 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 23:25:34] iteration   451800/  500000 | consumed samples:      3614400 | elapsed time per iteration (ms): 325.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.871819E+00 | loss scale: 262144.0 | grad norm: 1.042 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-22 23:26:07] iteration   451900/  500000 | consumed samples:      3615200 | elapsed time per iteration (ms): 323.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.931246E+00 | loss scale: 262144.0 | grad norm: 0.996 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 23:26:39] iteration   452000/  500000 | consumed samples:      3616000 | elapsed time per iteration (ms): 323.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.942988E+00 | loss scale: 262144.0 | grad norm: 1.058 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1066.06, 1066.06)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 452000 | lm loss value: 3.615780E+00 | lm loss PPL: 3.718035E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 23:27:12] iteration   452100/  500000 | consumed samples:      3616800 | elapsed time per iteration (ms): 322.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.926249E+00 | loss scale: 262144.0 | grad norm: 0.994 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 23:27:45] iteration   452200/  500000 | consumed samples:      3617600 | elapsed time per iteration (ms): 323.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.894213E+00 | loss scale: 262144.0 | grad norm: 1.032 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 23:28:17] iteration   452300/  500000 | consumed samples:      3618400 | elapsed time per iteration (ms): 324.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.911451E+00 | loss scale: 262144.0 | grad norm: 0.974 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 23:28:50] iteration   452400/  500000 | consumed samples:      3619200 | elapsed time per iteration (ms): 325.0 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.936362E+00 | loss scale: 262144.0 | grad norm: 0.946 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 23:29:22] iteration   452500/  500000 | consumed samples:      3620000 | elapsed time per iteration (ms): 322.6 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.883694E+00 | loss scale: 262144.0 | grad norm: 1.042 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 23:29:54] iteration   452600/  500000 | consumed samples:      3620800 | elapsed time per iteration (ms): 322.9 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.889790E+00 | loss scale: 262144.0 | grad norm: 1.018 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 23:30:27] iteration   452700/  500000 | consumed samples:      3621600 | elapsed time per iteration (ms): 323.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.923208E+00 | loss scale: 262144.0 | grad norm: 1.048 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 23:30:59] iteration   452800/  500000 | consumed samples:      3622400 | elapsed time per iteration (ms): 324.4 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.928132E+00 | loss scale: 524288.0 | grad norm: 0.996 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 23:31:32] iteration   452900/  500000 | consumed samples:      3623200 | elapsed time per iteration (ms): 324.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.976157E+00 | loss scale: 524288.0 | grad norm: 0.974 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 23:32:04] iteration   453000/  500000 | consumed samples:      3624000 | elapsed time per iteration (ms): 324.1 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.901092E+00 | loss scale: 524288.0 | grad norm: 0.979 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1063.27, 1063.27)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 453000 | lm loss value: 3.752551E+00 | lm loss PPL: 4.262968E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 23:32:37] iteration   453100/  500000 | consumed samples:      3624800 | elapsed time per iteration (ms): 323.9 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.874044E+00 | loss scale: 524288.0 | grad norm: 0.905 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 23:33:10] iteration   453200/  500000 | consumed samples:      3625600 | elapsed time per iteration (ms): 325.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.921857E+00 | loss scale: 524288.0 | grad norm: 1.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 23:33:42] iteration   453300/  500000 | consumed samples:      3626400 | elapsed time per iteration (ms): 325.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.902345E+00 | loss scale: 524288.0 | grad norm: 0.992 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 23:34:15] iteration   453400/  500000 | consumed samples:      3627200 | elapsed time per iteration (ms): 324.0 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.908200E+00 | loss scale: 524288.0 | grad norm: 0.986 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 23:34:48] iteration   453500/  500000 | consumed samples:      3628000 | elapsed time per iteration (ms): 326.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.934153E+00 | loss scale: 524288.0 | grad norm: 1.009 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 23:35:20] iteration   453600/  500000 | consumed samples:      3628800 | elapsed time per iteration (ms): 323.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.879673E+00 | loss scale: 524288.0 | grad norm: 1.016 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-22 23:35:52] iteration   453700/  500000 | consumed samples:      3629600 | elapsed time per iteration (ms): 323.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.928176E+00 | loss scale: 524288.0 | grad norm: 1.029 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 23:36:25] iteration   453800/  500000 | consumed samples:      3630400 | elapsed time per iteration (ms): 324.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.961064E+00 | loss scale: 524288.0 | grad norm: 0.902 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 23:36:57] iteration   453900/  500000 | consumed samples:      3631200 | elapsed time per iteration (ms): 326.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.925322E+00 | loss scale: 524288.0 | grad norm: 1.027 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 23:37:30] iteration   454000/  500000 | consumed samples:      3632000 | elapsed time per iteration (ms): 323.1 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.914612E+00 | loss scale: 524288.0 | grad norm: 0.949 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1065.15, 1065.15)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 454000 | lm loss value: 3.846623E+00 | lm loss PPL: 4.683463E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 23:38:03] iteration   454100/  500000 | consumed samples:      3632800 | elapsed time per iteration (ms): 323.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.912209E+00 | loss scale: 524288.0 | grad norm: 1.009 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 23:38:35] iteration   454200/  500000 | consumed samples:      3633600 | elapsed time per iteration (ms): 322.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.914334E+00 | loss scale: 524288.0 | grad norm: 1.046 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 23:39:07] iteration   454300/  500000 | consumed samples:      3634400 | elapsed time per iteration (ms): 322.1 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.932198E+00 | loss scale: 524288.0 | grad norm: 1.065 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 23:39:40] iteration   454400/  500000 | consumed samples:      3635200 | elapsed time per iteration (ms): 320.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.954218E+00 | loss scale: 524288.0 | grad norm: 1.009 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 23:40:12] iteration   454500/  500000 | consumed samples:      3636000 | elapsed time per iteration (ms): 322.6 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.941597E+00 | loss scale: 524288.0 | grad norm: 1.031 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 23:40:44] iteration   454600/  500000 | consumed samples:      3636800 | elapsed time per iteration (ms): 323.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.889273E+00 | loss scale: 524288.0 | grad norm: 0.997 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-22 23:41:16] iteration   454700/  500000 | consumed samples:      3637600 | elapsed time per iteration (ms): 323.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.920166E+00 | loss scale: 524288.0 | grad norm: 0.973 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 23:41:49] iteration   454800/  500000 | consumed samples:      3638400 | elapsed time per iteration (ms): 325.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.924615E+00 | loss scale: 524288.0 | grad norm: 0.994 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 23:42:21] iteration   454900/  500000 | consumed samples:      3639200 | elapsed time per iteration (ms): 322.6 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.925962E+00 | loss scale: 524288.0 | grad norm: 0.934 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 23:42:53] iteration   455000/  500000 | consumed samples:      3640000 | elapsed time per iteration (ms): 322.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.905334E+00 | loss scale: 524288.0 | grad norm: 1.037 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1063.08, 1063.08)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 455000 | lm loss value: 3.903270E+00 | lm loss PPL: 4.956424E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 23:43:27] iteration   455100/  500000 | consumed samples:      3640800 | elapsed time per iteration (ms): 323.6 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.921398E+00 | loss scale: 524288.0 | grad norm: 1.016 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 23:43:59] iteration   455200/  500000 | consumed samples:      3641600 | elapsed time per iteration (ms): 325.1 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.865243E+00 | loss scale: 524288.0 | grad norm: 0.989 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 23:44:32] iteration   455300/  500000 | consumed samples:      3642400 | elapsed time per iteration (ms): 323.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.949976E+00 | loss scale: 262144.0 | grad norm: 1.022 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-22 23:45:04] iteration   455400/  500000 | consumed samples:      3643200 | elapsed time per iteration (ms): 324.1 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.900613E+00 | loss scale: 262144.0 | grad norm: 1.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 23:45:37] iteration   455500/  500000 | consumed samples:      3644000 | elapsed time per iteration (ms): 326.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.910044E+00 | loss scale: 262144.0 | grad norm: 1.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 23:46:09] iteration   455600/  500000 | consumed samples:      3644800 | elapsed time per iteration (ms): 324.4 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.907901E+00 | loss scale: 262144.0 | grad norm: 1.043 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 23:46:42] iteration   455700/  500000 | consumed samples:      3645600 | elapsed time per iteration (ms): 323.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.936288E+00 | loss scale: 262144.0 | grad norm: 0.990 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 23:47:14] iteration   455800/  500000 | consumed samples:      3646400 | elapsed time per iteration (ms): 322.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.917162E+00 | loss scale: 262144.0 | grad norm: 0.978 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 23:47:46] iteration   455900/  500000 | consumed samples:      3647200 | elapsed time per iteration (ms): 322.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.919807E+00 | loss scale: 262144.0 | grad norm: 0.995 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 23:48:18] iteration   456000/  500000 | consumed samples:      3648000 | elapsed time per iteration (ms): 322.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.906073E+00 | loss scale: 262144.0 | grad norm: 1.015 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1063.70, 1063.70)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 456000 | lm loss value: 3.638721E+00 | lm loss PPL: 3.804316E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 23:48:52] iteration   456100/  500000 | consumed samples:      3648800 | elapsed time per iteration (ms): 323.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.907178E+00 | loss scale: 262144.0 | grad norm: 1.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 23:49:24] iteration   456200/  500000 | consumed samples:      3649600 | elapsed time per iteration (ms): 323.1 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.967939E+00 | loss scale: 262144.0 | grad norm: 0.994 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 23:49:56] iteration   456300/  500000 | consumed samples:      3650400 | elapsed time per iteration (ms): 323.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.916995E+00 | loss scale: 524288.0 | grad norm: 1.017 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 23:50:29] iteration   456400/  500000 | consumed samples:      3651200 | elapsed time per iteration (ms): 322.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.898675E+00 | loss scale: 524288.0 | grad norm: 0.967 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 23:51:01] iteration   456500/  500000 | consumed samples:      3652000 | elapsed time per iteration (ms): 324.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.918586E+00 | loss scale: 524288.0 | grad norm: 0.999 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 23:51:33] iteration   456600/  500000 | consumed samples:      3652800 | elapsed time per iteration (ms): 322.6 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.924872E+00 | loss scale: 524288.0 | grad norm: 1.015 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 23:52:06] iteration   456700/  500000 | consumed samples:      3653600 | elapsed time per iteration (ms): 323.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.923257E+00 | loss scale: 524288.0 | grad norm: 0.967 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 23:52:38] iteration   456800/  500000 | consumed samples:      3654400 | elapsed time per iteration (ms): 323.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.903257E+00 | loss scale: 524288.0 | grad norm: 1.041 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 23:53:11] iteration   456900/  500000 | consumed samples:      3655200 | elapsed time per iteration (ms): 326.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.935591E+00 | loss scale: 524288.0 | grad norm: 1.214 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 23:53:43] iteration   457000/  500000 | consumed samples:      3656000 | elapsed time per iteration (ms): 325.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.901098E+00 | loss scale: 524288.0 | grad norm: 0.995 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1076.87, 1076.87)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 457000 | lm loss value: 3.499557E+00 | lm loss PPL: 3.310078E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 23:54:17] iteration   457100/  500000 | consumed samples:      3656800 | elapsed time per iteration (ms): 324.1 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.883905E+00 | loss scale: 524288.0 | grad norm: 1.053 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 23:54:49] iteration   457200/  500000 | consumed samples:      3657600 | elapsed time per iteration (ms): 324.6 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.926615E+00 | loss scale: 524288.0 | grad norm: 0.998 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 23:55:22] iteration   457300/  500000 | consumed samples:      3658400 | elapsed time per iteration (ms): 323.4 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.949517E+00 | loss scale: 524288.0 | grad norm: 0.976 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-22 23:55:54] iteration   457400/  500000 | consumed samples:      3659200 | elapsed time per iteration (ms): 324.9 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.869366E+00 | loss scale: 524288.0 | grad norm: 0.999 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 23:56:26] iteration   457500/  500000 | consumed samples:      3660000 | elapsed time per iteration (ms): 322.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.922769E+00 | loss scale: 524288.0 | grad norm: 0.965 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 23:56:59] iteration   457600/  500000 | consumed samples:      3660800 | elapsed time per iteration (ms): 324.9 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.876358E+00 | loss scale: 524288.0 | grad norm: 0.983 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 23:57:31] iteration   457700/  500000 | consumed samples:      3661600 | elapsed time per iteration (ms): 325.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.893323E+00 | loss scale: 524288.0 | grad norm: 0.982 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 23:58:04] iteration   457800/  500000 | consumed samples:      3662400 | elapsed time per iteration (ms): 323.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.903821E+00 | loss scale: 524288.0 | grad norm: 1.023 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 23:58:36] iteration   457900/  500000 | consumed samples:      3663200 | elapsed time per iteration (ms): 326.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.892805E+00 | loss scale: 524288.0 | grad norm: 1.008 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-22 23:59:09] iteration   458000/  500000 | consumed samples:      3664000 | elapsed time per iteration (ms): 324.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.926119E+00 | loss scale: 524288.0 | grad norm: 1.018 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1065.16, 1065.16)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 458000 | lm loss value: 3.638115E+00 | lm loss PPL: 3.802012E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-22 23:59:42] iteration   458100/  500000 | consumed samples:      3664800 | elapsed time per iteration (ms): 324.1 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.959664E+00 | loss scale: 524288.0 | grad norm: 1.021 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 00:00:15] iteration   458200/  500000 | consumed samples:      3665600 | elapsed time per iteration (ms): 324.6 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.909569E+00 | loss scale: 524288.0 | grad norm: 0.997 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 00:00:47] iteration   458300/  500000 | consumed samples:      3666400 | elapsed time per iteration (ms): 323.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.931164E+00 | loss scale: 524288.0 | grad norm: 1.047 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-23 00:01:20] iteration   458400/  500000 | consumed samples:      3667200 | elapsed time per iteration (ms): 323.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.931013E+00 | loss scale: 524288.0 | grad norm: 1.023 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 00:01:52] iteration   458500/  500000 | consumed samples:      3668000 | elapsed time per iteration (ms): 325.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.922927E+00 | loss scale: 524288.0 | grad norm: 1.004 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 00:02:24] iteration   458600/  500000 | consumed samples:      3668800 | elapsed time per iteration (ms): 322.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.899839E+00 | loss scale: 524288.0 | grad norm: 1.011 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 00:02:57] iteration   458700/  500000 | consumed samples:      3669600 | elapsed time per iteration (ms): 324.0 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.948188E+00 | loss scale: 524288.0 | grad norm: 1.012 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 00:03:29] iteration   458800/  500000 | consumed samples:      3670400 | elapsed time per iteration (ms): 323.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.933986E+00 | loss scale: 524288.0 | grad norm: 0.997 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 00:04:02] iteration   458900/  500000 | consumed samples:      3671200 | elapsed time per iteration (ms): 325.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.894389E+00 | loss scale: 524288.0 | grad norm: 1.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 00:04:34] iteration   459000/  500000 | consumed samples:      3672000 | elapsed time per iteration (ms): 324.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.882646E+00 | loss scale: 524288.0 | grad norm: 1.006 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1063.95, 1063.95)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 459000 | lm loss value: 3.734432E+00 | lm loss PPL: 4.186425E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-23 00:05:08] iteration   459100/  500000 | consumed samples:      3672800 | elapsed time per iteration (ms): 323.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.917548E+00 | loss scale: 524288.0 | grad norm: 1.013 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 00:05:40] iteration   459200/  500000 | consumed samples:      3673600 | elapsed time per iteration (ms): 325.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.912048E+00 | loss scale: 524288.0 | grad norm: 1.014 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 00:06:12] iteration   459300/  500000 | consumed samples:      3674400 | elapsed time per iteration (ms): 324.4 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.893503E+00 | loss scale: 1048576.0 | grad norm: 1.040 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 00:06:45] iteration   459400/  500000 | consumed samples:      3675200 | elapsed time per iteration (ms): 323.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.912186E+00 | loss scale: 524288.0 | grad norm: 1.007 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-23 00:07:17] iteration   459500/  500000 | consumed samples:      3676000 | elapsed time per iteration (ms): 324.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.937098E+00 | loss scale: 524288.0 | grad norm: 0.999 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 00:07:50] iteration   459600/  500000 | consumed samples:      3676800 | elapsed time per iteration (ms): 323.0 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.905038E+00 | loss scale: 524288.0 | grad norm: 1.020 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 00:08:22] iteration   459700/  500000 | consumed samples:      3677600 | elapsed time per iteration (ms): 322.0 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.948893E+00 | loss scale: 524288.0 | grad norm: 1.022 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 00:08:54] iteration   459800/  500000 | consumed samples:      3678400 | elapsed time per iteration (ms): 323.6 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.942597E+00 | loss scale: 524288.0 | grad norm: 1.017 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 00:09:27] iteration   459900/  500000 | consumed samples:      3679200 | elapsed time per iteration (ms): 324.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.890443E+00 | loss scale: 524288.0 | grad norm: 1.017 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 00:09:59] iteration   460000/  500000 | consumed samples:      3680000 | elapsed time per iteration (ms): 322.4 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.907279E+00 | loss scale: 524288.0 | grad norm: 0.941 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1064.99, 1064.99)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 460000 | lm loss value: 3.732254E+00 | lm loss PPL: 4.177315E+01 | 
--------------------------------------------------------------------------------------------------
saving checkpoint at iteration  460000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-max in torch format
  successfully saved checkpoint at iteration  460000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-max
(min, max) time across ranks (ms):
    save-checkpoint ................................: (5800.38, 5800.38)
 [2024-06-23 00:10:38] iteration   460100/  500000 | consumed samples:      3680800 | elapsed time per iteration (ms): 325.1 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.933976E+00 | loss scale: 524288.0 | grad norm: 0.969 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 00:11:11] iteration   460200/  500000 | consumed samples:      3681600 | elapsed time per iteration (ms): 324.9 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.934659E+00 | loss scale: 524288.0 | grad norm: 1.041 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 00:11:43] iteration   460300/  500000 | consumed samples:      3682400 | elapsed time per iteration (ms): 321.9 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.910026E+00 | loss scale: 524288.0 | grad norm: 1.019 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 00:12:15] iteration   460400/  500000 | consumed samples:      3683200 | elapsed time per iteration (ms): 323.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.883751E+00 | loss scale: 524288.0 | grad norm: 1.018 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-23 00:12:47] iteration   460500/  500000 | consumed samples:      3684000 | elapsed time per iteration (ms): 322.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.922728E+00 | loss scale: 524288.0 | grad norm: 1.029 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 00:13:20] iteration   460600/  500000 | consumed samples:      3684800 | elapsed time per iteration (ms): 321.1 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.929707E+00 | loss scale: 524288.0 | grad norm: 1.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 00:13:52] iteration   460700/  500000 | consumed samples:      3685600 | elapsed time per iteration (ms): 324.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.942432E+00 | loss scale: 524288.0 | grad norm: 1.029 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 00:14:24] iteration   460800/  500000 | consumed samples:      3686400 | elapsed time per iteration (ms): 323.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.911541E+00 | loss scale: 524288.0 | grad norm: 1.030 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 00:14:57] iteration   460900/  500000 | consumed samples:      3687200 | elapsed time per iteration (ms): 323.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.907261E+00 | loss scale: 524288.0 | grad norm: 1.025 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 00:15:29] iteration   461000/  500000 | consumed samples:      3688000 | elapsed time per iteration (ms): 324.0 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.918316E+00 | loss scale: 262144.0 | grad norm: 1.023 | number of skipped iterations:   1 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1063.27, 1063.27)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 461000 | lm loss value: 3.801794E+00 | lm loss PPL: 4.478145E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-23 00:16:03] iteration   461100/  500000 | consumed samples:      3688800 | elapsed time per iteration (ms): 325.0 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.910792E+00 | loss scale: 262144.0 | grad norm: 1.028 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 00:16:35] iteration   461200/  500000 | consumed samples:      3689600 | elapsed time per iteration (ms): 322.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.898965E+00 | loss scale: 262144.0 | grad norm: 1.035 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 00:17:07] iteration   461300/  500000 | consumed samples:      3690400 | elapsed time per iteration (ms): 321.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.878670E+00 | loss scale: 262144.0 | grad norm: 1.030 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 00:17:40] iteration   461400/  500000 | consumed samples:      3691200 | elapsed time per iteration (ms): 324.9 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.947556E+00 | loss scale: 262144.0 | grad norm: 1.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 00:18:12] iteration   461500/  500000 | consumed samples:      3692000 | elapsed time per iteration (ms): 322.9 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.874753E+00 | loss scale: 262144.0 | grad norm: 1.041 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 00:18:44] iteration   461600/  500000 | consumed samples:      3692800 | elapsed time per iteration (ms): 324.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.860107E+00 | loss scale: 262144.0 | grad norm: 0.928 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 00:19:17] iteration   461700/  500000 | consumed samples:      3693600 | elapsed time per iteration (ms): 323.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.911418E+00 | loss scale: 262144.0 | grad norm: 1.028 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 00:19:49] iteration   461800/  500000 | consumed samples:      3694400 | elapsed time per iteration (ms): 324.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.929116E+00 | loss scale: 262144.0 | grad norm: 1.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 00:20:21] iteration   461900/  500000 | consumed samples:      3695200 | elapsed time per iteration (ms): 323.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.903972E+00 | loss scale: 262144.0 | grad norm: 0.965 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 00:20:54] iteration   462000/  500000 | consumed samples:      3696000 | elapsed time per iteration (ms): 324.0 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.908187E+00 | loss scale: 524288.0 | grad norm: 1.056 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1062.87, 1062.87)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 462000 | lm loss value: 3.593173E+00 | lm loss PPL: 3.634924E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-23 00:21:27] iteration   462100/  500000 | consumed samples:      3696800 | elapsed time per iteration (ms): 324.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.911634E+00 | loss scale: 524288.0 | grad norm: 0.955 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 00:22:00] iteration   462200/  500000 | consumed samples:      3697600 | elapsed time per iteration (ms): 324.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.938115E+00 | loss scale: 524288.0 | grad norm: 0.987 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-23 00:22:32] iteration   462300/  500000 | consumed samples:      3698400 | elapsed time per iteration (ms): 325.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.897076E+00 | loss scale: 524288.0 | grad norm: 0.956 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 00:23:05] iteration   462400/  500000 | consumed samples:      3699200 | elapsed time per iteration (ms): 323.1 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.904166E+00 | loss scale: 524288.0 | grad norm: 0.991 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 00:23:37] iteration   462500/  500000 | consumed samples:      3700000 | elapsed time per iteration (ms): 324.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.884678E+00 | loss scale: 524288.0 | grad norm: 1.004 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 00:24:09] iteration   462600/  500000 | consumed samples:      3700800 | elapsed time per iteration (ms): 322.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.903991E+00 | loss scale: 524288.0 | grad norm: 1.038 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 00:24:42] iteration   462700/  500000 | consumed samples:      3701600 | elapsed time per iteration (ms): 325.0 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.892398E+00 | loss scale: 524288.0 | grad norm: 1.005 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 00:25:14] iteration   462800/  500000 | consumed samples:      3702400 | elapsed time per iteration (ms): 323.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.904912E+00 | loss scale: 524288.0 | grad norm: 1.046 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 00:25:47] iteration   462900/  500000 | consumed samples:      3703200 | elapsed time per iteration (ms): 322.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.884847E+00 | loss scale: 524288.0 | grad norm: 0.934 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 00:26:19] iteration   463000/  500000 | consumed samples:      3704000 | elapsed time per iteration (ms): 322.0 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.915147E+00 | loss scale: 524288.0 | grad norm: 1.018 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1064.88, 1064.88)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 463000 | lm loss value: 3.617243E+00 | lm loss PPL: 3.723478E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-23 00:26:52] iteration   463100/  500000 | consumed samples:      3704800 | elapsed time per iteration (ms): 324.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.871354E+00 | loss scale: 524288.0 | grad norm: 1.005 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 00:27:25] iteration   463200/  500000 | consumed samples:      3705600 | elapsed time per iteration (ms): 325.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.930007E+00 | loss scale: 524288.0 | grad norm: 1.000 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-23 00:27:57] iteration   463300/  500000 | consumed samples:      3706400 | elapsed time per iteration (ms): 322.1 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.916029E+00 | loss scale: 524288.0 | grad norm: 1.032 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 00:28:29] iteration   463400/  500000 | consumed samples:      3707200 | elapsed time per iteration (ms): 323.9 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.906462E+00 | loss scale: 524288.0 | grad norm: 1.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 00:29:02] iteration   463500/  500000 | consumed samples:      3708000 | elapsed time per iteration (ms): 324.1 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.914061E+00 | loss scale: 524288.0 | grad norm: 0.986 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 00:29:34] iteration   463600/  500000 | consumed samples:      3708800 | elapsed time per iteration (ms): 324.9 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.912099E+00 | loss scale: 524288.0 | grad norm: 0.921 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 00:30:07] iteration   463700/  500000 | consumed samples:      3709600 | elapsed time per iteration (ms): 323.9 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.922336E+00 | loss scale: 524288.0 | grad norm: 1.009 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 00:30:39] iteration   463800/  500000 | consumed samples:      3710400 | elapsed time per iteration (ms): 323.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.912717E+00 | loss scale: 524288.0 | grad norm: 1.020 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 00:31:12] iteration   463900/  500000 | consumed samples:      3711200 | elapsed time per iteration (ms): 325.0 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.893759E+00 | loss scale: 524288.0 | grad norm: 0.992 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 00:31:44] iteration   464000/  500000 | consumed samples:      3712000 | elapsed time per iteration (ms): 325.4 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.900375E+00 | loss scale: 524288.0 | grad norm: 1.026 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1062.91, 1062.91)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 464000 | lm loss value: 3.618261E+00 | lm loss PPL: 3.727271E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-23 00:32:17] iteration   464100/  500000 | consumed samples:      3712800 | elapsed time per iteration (ms): 323.0 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.919874E+00 | loss scale: 262144.0 | grad norm: 1.008 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-23 00:32:50] iteration   464200/  500000 | consumed samples:      3713600 | elapsed time per iteration (ms): 324.4 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.916693E+00 | loss scale: 262144.0 | grad norm: 0.971 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 00:33:22] iteration   464300/  500000 | consumed samples:      3714400 | elapsed time per iteration (ms): 322.6 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.916612E+00 | loss scale: 262144.0 | grad norm: 0.950 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 00:33:55] iteration   464400/  500000 | consumed samples:      3715200 | elapsed time per iteration (ms): 325.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.923092E+00 | loss scale: 262144.0 | grad norm: 1.015 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 00:34:27] iteration   464500/  500000 | consumed samples:      3716000 | elapsed time per iteration (ms): 323.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.919767E+00 | loss scale: 262144.0 | grad norm: 1.053 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 00:35:00] iteration   464600/  500000 | consumed samples:      3716800 | elapsed time per iteration (ms): 324.9 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.935399E+00 | loss scale: 262144.0 | grad norm: 1.057 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 00:35:32] iteration   464700/  500000 | consumed samples:      3717600 | elapsed time per iteration (ms): 324.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.922200E+00 | loss scale: 262144.0 | grad norm: 1.022 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 00:36:04] iteration   464800/  500000 | consumed samples:      3718400 | elapsed time per iteration (ms): 324.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.908767E+00 | loss scale: 262144.0 | grad norm: 0.924 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 00:36:37] iteration   464900/  500000 | consumed samples:      3719200 | elapsed time per iteration (ms): 324.4 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.919568E+00 | loss scale: 262144.0 | grad norm: 1.007 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 00:37:09] iteration   465000/  500000 | consumed samples:      3720000 | elapsed time per iteration (ms): 325.1 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.928062E+00 | loss scale: 262144.0 | grad norm: 0.990 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1064.43, 1064.43)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 465000 | lm loss value: 3.689638E+00 | lm loss PPL: 4.003035E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-23 00:37:43] iteration   465100/  500000 | consumed samples:      3720800 | elapsed time per iteration (ms): 325.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.915932E+00 | loss scale: 524288.0 | grad norm: 1.031 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 00:38:15] iteration   465200/  500000 | consumed samples:      3721600 | elapsed time per iteration (ms): 323.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.912650E+00 | loss scale: 524288.0 | grad norm: 0.942 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 00:38:48] iteration   465300/  500000 | consumed samples:      3722400 | elapsed time per iteration (ms): 326.4 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.895092E+00 | loss scale: 524288.0 | grad norm: 1.018 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 00:39:20] iteration   465400/  500000 | consumed samples:      3723200 | elapsed time per iteration (ms): 324.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.877816E+00 | loss scale: 524288.0 | grad norm: 1.007 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 00:39:53] iteration   465500/  500000 | consumed samples:      3724000 | elapsed time per iteration (ms): 326.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.885487E+00 | loss scale: 524288.0 | grad norm: 1.023 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 00:40:25] iteration   465600/  500000 | consumed samples:      3724800 | elapsed time per iteration (ms): 323.4 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.911703E+00 | loss scale: 524288.0 | grad norm: 1.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 00:40:58] iteration   465700/  500000 | consumed samples:      3725600 | elapsed time per iteration (ms): 325.9 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.880949E+00 | loss scale: 524288.0 | grad norm: 1.017 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 00:41:30] iteration   465800/  500000 | consumed samples:      3726400 | elapsed time per iteration (ms): 324.0 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.922496E+00 | loss scale: 524288.0 | grad norm: 0.975 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 00:42:03] iteration   465900/  500000 | consumed samples:      3727200 | elapsed time per iteration (ms): 325.1 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.910781E+00 | loss scale: 524288.0 | grad norm: 0.994 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 00:42:35] iteration   466000/  500000 | consumed samples:      3728000 | elapsed time per iteration (ms): 324.9 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.876829E+00 | loss scale: 524288.0 | grad norm: 1.056 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1062.67, 1062.67)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 466000 | lm loss value: 3.863236E+00 | lm loss PPL: 4.761920E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-23 00:43:09] iteration   466100/  500000 | consumed samples:      3728800 | elapsed time per iteration (ms): 322.9 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.905151E+00 | loss scale: 524288.0 | grad norm: 1.001 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-23 00:43:41] iteration   466200/  500000 | consumed samples:      3729600 | elapsed time per iteration (ms): 324.1 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.943105E+00 | loss scale: 524288.0 | grad norm: 1.015 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 00:44:14] iteration   466300/  500000 | consumed samples:      3730400 | elapsed time per iteration (ms): 324.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.950238E+00 | loss scale: 524288.0 | grad norm: 0.991 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 00:44:46] iteration   466400/  500000 | consumed samples:      3731200 | elapsed time per iteration (ms): 324.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.921693E+00 | loss scale: 262144.0 | grad norm: 1.003 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-23 00:45:19] iteration   466500/  500000 | consumed samples:      3732000 | elapsed time per iteration (ms): 325.9 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.917689E+00 | loss scale: 262144.0 | grad norm: 0.932 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 00:45:51] iteration   466600/  500000 | consumed samples:      3732800 | elapsed time per iteration (ms): 324.6 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.887750E+00 | loss scale: 262144.0 | grad norm: 1.043 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 00:46:23] iteration   466700/  500000 | consumed samples:      3733600 | elapsed time per iteration (ms): 324.4 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.917432E+00 | loss scale: 262144.0 | grad norm: 1.044 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 00:46:56] iteration   466800/  500000 | consumed samples:      3734400 | elapsed time per iteration (ms): 324.0 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.922176E+00 | loss scale: 262144.0 | grad norm: 0.981 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 00:47:28] iteration   466900/  500000 | consumed samples:      3735200 | elapsed time per iteration (ms): 323.1 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.943503E+00 | loss scale: 262144.0 | grad norm: 1.015 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 00:48:01] iteration   467000/  500000 | consumed samples:      3736000 | elapsed time per iteration (ms): 325.0 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.885909E+00 | loss scale: 262144.0 | grad norm: 0.989 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1063.49, 1063.49)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 467000 | lm loss value: 3.904502E+00 | lm loss PPL: 4.962534E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-23 00:48:34] iteration   467100/  500000 | consumed samples:      3736800 | elapsed time per iteration (ms): 322.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.923703E+00 | loss scale: 262144.0 | grad norm: 1.025 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 00:49:06] iteration   467200/  500000 | consumed samples:      3737600 | elapsed time per iteration (ms): 323.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.915086E+00 | loss scale: 262144.0 | grad norm: 1.013 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 00:49:38] iteration   467300/  500000 | consumed samples:      3738400 | elapsed time per iteration (ms): 321.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.928652E+00 | loss scale: 262144.0 | grad norm: 1.048 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 00:50:11] iteration   467400/  500000 | consumed samples:      3739200 | elapsed time per iteration (ms): 323.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.930822E+00 | loss scale: 524288.0 | grad norm: 1.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 00:50:43] iteration   467500/  500000 | consumed samples:      3740000 | elapsed time per iteration (ms): 323.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.914838E+00 | loss scale: 524288.0 | grad norm: 1.045 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 00:51:16] iteration   467600/  500000 | consumed samples:      3740800 | elapsed time per iteration (ms): 323.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.899771E+00 | loss scale: 524288.0 | grad norm: 0.995 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-23 00:51:48] iteration   467700/  500000 | consumed samples:      3741600 | elapsed time per iteration (ms): 325.6 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.927541E+00 | loss scale: 524288.0 | grad norm: 0.999 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 00:52:20] iteration   467800/  500000 | consumed samples:      3742400 | elapsed time per iteration (ms): 323.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.915937E+00 | loss scale: 524288.0 | grad norm: 0.990 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 00:52:53] iteration   467900/  500000 | consumed samples:      3743200 | elapsed time per iteration (ms): 325.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.906032E+00 | loss scale: 524288.0 | grad norm: 0.973 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 00:53:25] iteration   468000/  500000 | consumed samples:      3744000 | elapsed time per iteration (ms): 322.6 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.925915E+00 | loss scale: 524288.0 | grad norm: 1.007 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1062.56, 1062.56)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 468000 | lm loss value: 3.792949E+00 | lm loss PPL: 4.438712E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-23 00:53:59] iteration   468100/  500000 | consumed samples:      3744800 | elapsed time per iteration (ms): 323.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.854513E+00 | loss scale: 524288.0 | grad norm: 1.008 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 00:54:31] iteration   468200/  500000 | consumed samples:      3745600 | elapsed time per iteration (ms): 321.4 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.886400E+00 | loss scale: 524288.0 | grad norm: 0.960 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 00:55:03] iteration   468300/  500000 | consumed samples:      3746400 | elapsed time per iteration (ms): 323.9 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.898367E+00 | loss scale: 524288.0 | grad norm: 1.065 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 00:55:36] iteration   468400/  500000 | consumed samples:      3747200 | elapsed time per iteration (ms): 325.0 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.892183E+00 | loss scale: 524288.0 | grad norm: 1.062 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 00:56:08] iteration   468500/  500000 | consumed samples:      3748000 | elapsed time per iteration (ms): 325.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.935135E+00 | loss scale: 524288.0 | grad norm: 0.994 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 00:56:40] iteration   468600/  500000 | consumed samples:      3748800 | elapsed time per iteration (ms): 322.6 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.888139E+00 | loss scale: 524288.0 | grad norm: 1.020 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-23 00:57:13] iteration   468700/  500000 | consumed samples:      3749600 | elapsed time per iteration (ms): 324.1 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.962787E+00 | loss scale: 524288.0 | grad norm: 1.016 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 00:57:45] iteration   468800/  500000 | consumed samples:      3750400 | elapsed time per iteration (ms): 323.6 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.892496E+00 | loss scale: 524288.0 | grad norm: 1.015 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 00:58:18] iteration   468900/  500000 | consumed samples:      3751200 | elapsed time per iteration (ms): 325.1 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.961057E+00 | loss scale: 524288.0 | grad norm: 1.008 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 00:58:50] iteration   469000/  500000 | consumed samples:      3752000 | elapsed time per iteration (ms): 327.0 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.895046E+00 | loss scale: 524288.0 | grad norm: 1.033 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1062.44, 1062.44)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 469000 | lm loss value: 3.858826E+00 | lm loss PPL: 4.740964E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-23 00:59:24] iteration   469100/  500000 | consumed samples:      3752800 | elapsed time per iteration (ms): 323.1 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.872120E+00 | loss scale: 524288.0 | grad norm: 1.056 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 00:59:56] iteration   469200/  500000 | consumed samples:      3753600 | elapsed time per iteration (ms): 325.6 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.891581E+00 | loss scale: 524288.0 | grad norm: 1.013 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 01:00:29] iteration   469300/  500000 | consumed samples:      3754400 | elapsed time per iteration (ms): 322.9 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.908359E+00 | loss scale: 524288.0 | grad norm: 1.022 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 01:01:01] iteration   469400/  500000 | consumed samples:      3755200 | elapsed time per iteration (ms): 325.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.933244E+00 | loss scale: 524288.0 | grad norm: 1.095 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 01:01:34] iteration   469500/  500000 | consumed samples:      3756000 | elapsed time per iteration (ms): 323.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.908906E+00 | loss scale: 524288.0 | grad norm: 1.032 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 01:02:06] iteration   469600/  500000 | consumed samples:      3756800 | elapsed time per iteration (ms): 322.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.895013E+00 | loss scale: 262144.0 | grad norm: 0.988 | number of skipped iterations:   3 | number of nan iterations:   0 |
 [2024-06-23 01:02:39] iteration   469700/  500000 | consumed samples:      3757600 | elapsed time per iteration (ms): 326.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.912947E+00 | loss scale: 262144.0 | grad norm: 1.034 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 01:03:11] iteration   469800/  500000 | consumed samples:      3758400 | elapsed time per iteration (ms): 323.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.929653E+00 | loss scale: 262144.0 | grad norm: 1.063 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 01:03:44] iteration   469900/  500000 | consumed samples:      3759200 | elapsed time per iteration (ms): 327.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.983289E+00 | loss scale: 262144.0 | grad norm: 0.973 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 01:04:16] iteration   470000/  500000 | consumed samples:      3760000 | elapsed time per iteration (ms): 323.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.932317E+00 | loss scale: 262144.0 | grad norm: 0.975 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1062.88, 1062.88)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 470000 | lm loss value: 3.721889E+00 | lm loss PPL: 4.134241E+01 | 
--------------------------------------------------------------------------------------------------
saving checkpoint at iteration  470000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-max in torch format
  successfully saved checkpoint at iteration  470000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-max
(min, max) time across ranks (ms):
    save-checkpoint ................................: (5609.78, 5609.78)
 [2024-06-23 01:04:55] iteration   470100/  500000 | consumed samples:      3760800 | elapsed time per iteration (ms): 323.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.955956E+00 | loss scale: 262144.0 | grad norm: 1.093 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 01:05:28] iteration   470200/  500000 | consumed samples:      3761600 | elapsed time per iteration (ms): 325.6 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.940650E+00 | loss scale: 262144.0 | grad norm: 1.034 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 01:06:00] iteration   470300/  500000 | consumed samples:      3762400 | elapsed time per iteration (ms): 323.4 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.887632E+00 | loss scale: 262144.0 | grad norm: 1.046 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 01:06:32] iteration   470400/  500000 | consumed samples:      3763200 | elapsed time per iteration (ms): 323.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.874943E+00 | loss scale: 262144.0 | grad norm: 0.965 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 01:07:05] iteration   470500/  500000 | consumed samples:      3764000 | elapsed time per iteration (ms): 324.6 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.933281E+00 | loss scale: 262144.0 | grad norm: 1.028 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 01:07:37] iteration   470600/  500000 | consumed samples:      3764800 | elapsed time per iteration (ms): 325.1 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.847298E+00 | loss scale: 524288.0 | grad norm: 0.971 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 01:08:09] iteration   470700/  500000 | consumed samples:      3765600 | elapsed time per iteration (ms): 322.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.911502E+00 | loss scale: 524288.0 | grad norm: 1.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 01:08:42] iteration   470800/  500000 | consumed samples:      3766400 | elapsed time per iteration (ms): 325.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.928926E+00 | loss scale: 524288.0 | grad norm: 1.032 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 01:09:15] iteration   470900/  500000 | consumed samples:      3767200 | elapsed time per iteration (ms): 325.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.919865E+00 | loss scale: 524288.0 | grad norm: 1.101 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 01:09:47] iteration   471000/  500000 | consumed samples:      3768000 | elapsed time per iteration (ms): 323.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.927168E+00 | loss scale: 524288.0 | grad norm: 1.035 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1065.92, 1065.92)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 471000 | lm loss value: 3.707438E+00 | lm loss PPL: 4.074927E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-23 01:10:20] iteration   471100/  500000 | consumed samples:      3768800 | elapsed time per iteration (ms): 323.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.908034E+00 | loss scale: 524288.0 | grad norm: 0.987 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 01:10:53] iteration   471200/  500000 | consumed samples:      3769600 | elapsed time per iteration (ms): 324.4 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.919224E+00 | loss scale: 524288.0 | grad norm: 1.048 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 01:11:25] iteration   471300/  500000 | consumed samples:      3770400 | elapsed time per iteration (ms): 324.0 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.932043E+00 | loss scale: 524288.0 | grad norm: 1.029 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 01:11:58] iteration   471400/  500000 | consumed samples:      3771200 | elapsed time per iteration (ms): 323.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.915285E+00 | loss scale: 524288.0 | grad norm: 0.965 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 01:12:30] iteration   471500/  500000 | consumed samples:      3772000 | elapsed time per iteration (ms): 323.1 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.900061E+00 | loss scale: 524288.0 | grad norm: 1.006 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 01:13:02] iteration   471600/  500000 | consumed samples:      3772800 | elapsed time per iteration (ms): 321.4 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.941186E+00 | loss scale: 524288.0 | grad norm: 1.062 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-23 01:13:34] iteration   471700/  500000 | consumed samples:      3773600 | elapsed time per iteration (ms): 321.4 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.901138E+00 | loss scale: 524288.0 | grad norm: 0.990 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 01:14:07] iteration   471800/  500000 | consumed samples:      3774400 | elapsed time per iteration (ms): 324.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.923157E+00 | loss scale: 524288.0 | grad norm: 0.983 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 01:14:39] iteration   471900/  500000 | consumed samples:      3775200 | elapsed time per iteration (ms): 324.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.917729E+00 | loss scale: 524288.0 | grad norm: 0.956 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 01:15:11] iteration   472000/  500000 | consumed samples:      3776000 | elapsed time per iteration (ms): 321.0 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.897072E+00 | loss scale: 524288.0 | grad norm: 0.983 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1062.76, 1062.76)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 472000 | lm loss value: 3.807930E+00 | lm loss PPL: 4.505707E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-23 01:15:45] iteration   472100/  500000 | consumed samples:      3776800 | elapsed time per iteration (ms): 324.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.940312E+00 | loss scale: 524288.0 | grad norm: 1.009 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 01:16:17] iteration   472200/  500000 | consumed samples:      3777600 | elapsed time per iteration (ms): 322.4 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.894887E+00 | loss scale: 524288.0 | grad norm: 1.063 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 01:16:49] iteration   472300/  500000 | consumed samples:      3778400 | elapsed time per iteration (ms): 323.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.902632E+00 | loss scale: 524288.0 | grad norm: 1.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 01:17:22] iteration   472400/  500000 | consumed samples:      3779200 | elapsed time per iteration (ms): 323.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.879636E+00 | loss scale: 524288.0 | grad norm: 0.985 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 01:17:54] iteration   472500/  500000 | consumed samples:      3780000 | elapsed time per iteration (ms): 325.4 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.907013E+00 | loss scale: 262144.0 | grad norm: 1.032 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-23 01:18:27] iteration   472600/  500000 | consumed samples:      3780800 | elapsed time per iteration (ms): 324.9 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.925324E+00 | loss scale: 262144.0 | grad norm: 1.019 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 01:18:59] iteration   472700/  500000 | consumed samples:      3781600 | elapsed time per iteration (ms): 324.1 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.904798E+00 | loss scale: 262144.0 | grad norm: 1.006 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 01:19:31] iteration   472800/  500000 | consumed samples:      3782400 | elapsed time per iteration (ms): 324.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.923831E+00 | loss scale: 262144.0 | grad norm: 1.007 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 01:20:04] iteration   472900/  500000 | consumed samples:      3783200 | elapsed time per iteration (ms): 325.6 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.941292E+00 | loss scale: 262144.0 | grad norm: 0.980 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 01:20:37] iteration   473000/  500000 | consumed samples:      3784000 | elapsed time per iteration (ms): 325.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.941029E+00 | loss scale: 262144.0 | grad norm: 1.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1067.72, 1067.72)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 473000 | lm loss value: 3.694645E+00 | lm loss PPL: 4.023129E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-23 01:21:10] iteration   473100/  500000 | consumed samples:      3784800 | elapsed time per iteration (ms): 324.4 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.889814E+00 | loss scale: 262144.0 | grad norm: 1.032 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 01:21:43] iteration   473200/  500000 | consumed samples:      3785600 | elapsed time per iteration (ms): 327.4 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.907199E+00 | loss scale: 262144.0 | grad norm: 0.986 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 01:22:15] iteration   473300/  500000 | consumed samples:      3786400 | elapsed time per iteration (ms): 325.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.924508E+00 | loss scale: 262144.0 | grad norm: 0.988 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 01:22:48] iteration   473400/  500000 | consumed samples:      3787200 | elapsed time per iteration (ms): 325.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.935618E+00 | loss scale: 262144.0 | grad norm: 0.997 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 01:23:20] iteration   473500/  500000 | consumed samples:      3788000 | elapsed time per iteration (ms): 322.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.867670E+00 | loss scale: 524288.0 | grad norm: 0.981 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 01:23:53] iteration   473600/  500000 | consumed samples:      3788800 | elapsed time per iteration (ms): 324.9 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.894128E+00 | loss scale: 524288.0 | grad norm: 1.017 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 01:24:25] iteration   473700/  500000 | consumed samples:      3789600 | elapsed time per iteration (ms): 322.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.937326E+00 | loss scale: 524288.0 | grad norm: 1.024 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 01:24:57] iteration   473800/  500000 | consumed samples:      3790400 | elapsed time per iteration (ms): 324.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.948665E+00 | loss scale: 524288.0 | grad norm: 1.013 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 01:25:30] iteration   473900/  500000 | consumed samples:      3791200 | elapsed time per iteration (ms): 324.6 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.959155E+00 | loss scale: 524288.0 | grad norm: 1.014 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 01:26:02] iteration   474000/  500000 | consumed samples:      3792000 | elapsed time per iteration (ms): 326.0 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.930042E+00 | loss scale: 524288.0 | grad norm: 1.009 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1062.82, 1062.82)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 474000 | lm loss value: 3.694355E+00 | lm loss PPL: 4.021964E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-23 01:26:36] iteration   474100/  500000 | consumed samples:      3792800 | elapsed time per iteration (ms): 325.1 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.919273E+00 | loss scale: 524288.0 | grad norm: 1.005 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 01:27:08] iteration   474200/  500000 | consumed samples:      3793600 | elapsed time per iteration (ms): 325.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.906654E+00 | loss scale: 524288.0 | grad norm: 1.037 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 01:27:41] iteration   474300/  500000 | consumed samples:      3794400 | elapsed time per iteration (ms): 325.4 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.868725E+00 | loss scale: 524288.0 | grad norm: 1.033 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-23 01:28:13] iteration   474400/  500000 | consumed samples:      3795200 | elapsed time per iteration (ms): 323.9 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.879647E+00 | loss scale: 524288.0 | grad norm: 0.979 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 01:28:46] iteration   474500/  500000 | consumed samples:      3796000 | elapsed time per iteration (ms): 323.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.892177E+00 | loss scale: 524288.0 | grad norm: 1.020 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 01:29:18] iteration   474600/  500000 | consumed samples:      3796800 | elapsed time per iteration (ms): 323.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.901611E+00 | loss scale: 524288.0 | grad norm: 1.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 01:29:50] iteration   474700/  500000 | consumed samples:      3797600 | elapsed time per iteration (ms): 320.6 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.958936E+00 | loss scale: 524288.0 | grad norm: 1.058 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 01:30:22] iteration   474800/  500000 | consumed samples:      3798400 | elapsed time per iteration (ms): 323.0 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.905651E+00 | loss scale: 524288.0 | grad norm: 1.031 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 01:30:55] iteration   474900/  500000 | consumed samples:      3799200 | elapsed time per iteration (ms): 325.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.867816E+00 | loss scale: 524288.0 | grad norm: 1.005 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 01:31:28] iteration   475000/  500000 | consumed samples:      3800000 | elapsed time per iteration (ms): 324.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.911840E+00 | loss scale: 262144.0 | grad norm: 1.018 | number of skipped iterations:   1 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1062.58, 1062.58)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 475000 | lm loss value: 3.735364E+00 | lm loss PPL: 4.190326E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-23 01:32:01] iteration   475100/  500000 | consumed samples:      3800800 | elapsed time per iteration (ms): 325.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.918213E+00 | loss scale: 262144.0 | grad norm: 1.024 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 01:32:33] iteration   475200/  500000 | consumed samples:      3801600 | elapsed time per iteration (ms): 323.4 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.899441E+00 | loss scale: 262144.0 | grad norm: 0.942 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 01:33:06] iteration   475300/  500000 | consumed samples:      3802400 | elapsed time per iteration (ms): 325.9 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.901494E+00 | loss scale: 262144.0 | grad norm: 1.036 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 01:33:39] iteration   475400/  500000 | consumed samples:      3803200 | elapsed time per iteration (ms): 325.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.932390E+00 | loss scale: 262144.0 | grad norm: 1.043 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 01:34:11] iteration   475500/  500000 | consumed samples:      3804000 | elapsed time per iteration (ms): 324.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.881157E+00 | loss scale: 262144.0 | grad norm: 1.016 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 01:34:44] iteration   475600/  500000 | consumed samples:      3804800 | elapsed time per iteration (ms): 325.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.923472E+00 | loss scale: 262144.0 | grad norm: 1.005 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 01:35:16] iteration   475700/  500000 | consumed samples:      3805600 | elapsed time per iteration (ms): 323.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.962389E+00 | loss scale: 262144.0 | grad norm: 1.051 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 01:35:49] iteration   475800/  500000 | consumed samples:      3806400 | elapsed time per iteration (ms): 325.6 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.921718E+00 | loss scale: 262144.0 | grad norm: 1.036 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 01:36:21] iteration   475900/  500000 | consumed samples:      3807200 | elapsed time per iteration (ms): 324.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.913828E+00 | loss scale: 262144.0 | grad norm: 0.959 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 01:36:53] iteration   476000/  500000 | consumed samples:      3808000 | elapsed time per iteration (ms): 325.1 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.910403E+00 | loss scale: 524288.0 | grad norm: 1.056 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1064.88, 1064.88)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 476000 | lm loss value: 3.647877E+00 | lm loss PPL: 3.839306E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-23 01:37:27] iteration   476100/  500000 | consumed samples:      3808800 | elapsed time per iteration (ms): 324.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.913629E+00 | loss scale: 524288.0 | grad norm: 1.033 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 01:38:00] iteration   476200/  500000 | consumed samples:      3809600 | elapsed time per iteration (ms): 325.4 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.893342E+00 | loss scale: 524288.0 | grad norm: 1.051 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 01:38:32] iteration   476300/  500000 | consumed samples:      3810400 | elapsed time per iteration (ms): 323.1 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.935356E+00 | loss scale: 524288.0 | grad norm: 1.045 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 01:39:04] iteration   476400/  500000 | consumed samples:      3811200 | elapsed time per iteration (ms): 323.4 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.918994E+00 | loss scale: 524288.0 | grad norm: 0.962 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 01:39:36] iteration   476500/  500000 | consumed samples:      3812000 | elapsed time per iteration (ms): 323.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.923566E+00 | loss scale: 524288.0 | grad norm: 1.009 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 01:40:09] iteration   476600/  500000 | consumed samples:      3812800 | elapsed time per iteration (ms): 323.1 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.934061E+00 | loss scale: 524288.0 | grad norm: 1.012 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 01:40:41] iteration   476700/  500000 | consumed samples:      3813600 | elapsed time per iteration (ms): 324.6 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.895742E+00 | loss scale: 524288.0 | grad norm: 1.020 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 01:41:14] iteration   476800/  500000 | consumed samples:      3814400 | elapsed time per iteration (ms): 324.0 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.899458E+00 | loss scale: 524288.0 | grad norm: 1.011 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 01:41:46] iteration   476900/  500000 | consumed samples:      3815200 | elapsed time per iteration (ms): 323.6 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.875794E+00 | loss scale: 524288.0 | grad norm: 1.054 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 01:42:18] iteration   477000/  500000 | consumed samples:      3816000 | elapsed time per iteration (ms): 324.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.942472E+00 | loss scale: 524288.0 | grad norm: 0.982 | number of skipped iterations:   1 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1067.86, 1067.86)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 477000 | lm loss value: 3.765600E+00 | lm loss PPL: 4.318962E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-23 01:42:52] iteration   477100/  500000 | consumed samples:      3816800 | elapsed time per iteration (ms): 325.9 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.895371E+00 | loss scale: 262144.0 | grad norm: 1.032 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-23 01:43:25] iteration   477200/  500000 | consumed samples:      3817600 | elapsed time per iteration (ms): 324.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.926810E+00 | loss scale: 262144.0 | grad norm: 1.056 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 01:43:57] iteration   477300/  500000 | consumed samples:      3818400 | elapsed time per iteration (ms): 324.6 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.920339E+00 | loss scale: 262144.0 | grad norm: 1.025 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 01:44:29] iteration   477400/  500000 | consumed samples:      3819200 | elapsed time per iteration (ms): 324.1 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.881446E+00 | loss scale: 262144.0 | grad norm: 1.011 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 01:45:02] iteration   477500/  500000 | consumed samples:      3820000 | elapsed time per iteration (ms): 327.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.896774E+00 | loss scale: 262144.0 | grad norm: 1.044 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 01:45:35] iteration   477600/  500000 | consumed samples:      3820800 | elapsed time per iteration (ms): 324.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.916510E+00 | loss scale: 262144.0 | grad norm: 1.043 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 01:46:07] iteration   477700/  500000 | consumed samples:      3821600 | elapsed time per iteration (ms): 325.0 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.939265E+00 | loss scale: 262144.0 | grad norm: 1.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 01:46:39] iteration   477800/  500000 | consumed samples:      3822400 | elapsed time per iteration (ms): 323.6 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.921797E+00 | loss scale: 262144.0 | grad norm: 0.994 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 01:47:12] iteration   477900/  500000 | consumed samples:      3823200 | elapsed time per iteration (ms): 324.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.931467E+00 | loss scale: 262144.0 | grad norm: 0.998 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 01:47:44] iteration   478000/  500000 | consumed samples:      3824000 | elapsed time per iteration (ms): 324.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.924950E+00 | loss scale: 262144.0 | grad norm: 1.053 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1064.64, 1064.64)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 478000 | lm loss value: 3.762032E+00 | lm loss PPL: 4.303580E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-23 01:48:18] iteration   478100/  500000 | consumed samples:      3824800 | elapsed time per iteration (ms): 324.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.916092E+00 | loss scale: 524288.0 | grad norm: 1.018 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 01:48:50] iteration   478200/  500000 | consumed samples:      3825600 | elapsed time per iteration (ms): 326.4 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.883008E+00 | loss scale: 524288.0 | grad norm: 0.970 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 01:49:23] iteration   478300/  500000 | consumed samples:      3826400 | elapsed time per iteration (ms): 324.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.921062E+00 | loss scale: 524288.0 | grad norm: 0.994 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 01:49:56] iteration   478400/  500000 | consumed samples:      3827200 | elapsed time per iteration (ms): 326.0 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.898893E+00 | loss scale: 524288.0 | grad norm: 1.015 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 01:50:28] iteration   478500/  500000 | consumed samples:      3828000 | elapsed time per iteration (ms): 325.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.892138E+00 | loss scale: 524288.0 | grad norm: 1.043 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 01:51:00] iteration   478600/  500000 | consumed samples:      3828800 | elapsed time per iteration (ms): 323.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.914795E+00 | loss scale: 524288.0 | grad norm: 1.023 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 01:51:33] iteration   478700/  500000 | consumed samples:      3829600 | elapsed time per iteration (ms): 324.6 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.889264E+00 | loss scale: 524288.0 | grad norm: 1.030 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 01:52:05] iteration   478800/  500000 | consumed samples:      3830400 | elapsed time per iteration (ms): 324.4 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.881984E+00 | loss scale: 524288.0 | grad norm: 1.030 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 01:52:38] iteration   478900/  500000 | consumed samples:      3831200 | elapsed time per iteration (ms): 326.4 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.883678E+00 | loss scale: 524288.0 | grad norm: 0.965 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 01:53:10] iteration   479000/  500000 | consumed samples:      3832000 | elapsed time per iteration (ms): 324.0 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.905778E+00 | loss scale: 524288.0 | grad norm: 1.021 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1063.33, 1063.33)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 479000 | lm loss value: 3.749964E+00 | lm loss PPL: 4.251953E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-23 01:53:44] iteration   479100/  500000 | consumed samples:      3832800 | elapsed time per iteration (ms): 325.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.850857E+00 | loss scale: 524288.0 | grad norm: 1.001 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-23 01:54:16] iteration   479200/  500000 | consumed samples:      3833600 | elapsed time per iteration (ms): 324.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.937171E+00 | loss scale: 524288.0 | grad norm: 0.983 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 01:54:49] iteration   479300/  500000 | consumed samples:      3834400 | elapsed time per iteration (ms): 324.9 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.907468E+00 | loss scale: 524288.0 | grad norm: 1.059 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 01:55:21] iteration   479400/  500000 | consumed samples:      3835200 | elapsed time per iteration (ms): 323.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.901569E+00 | loss scale: 262144.0 | grad norm: 0.976 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-23 01:55:54] iteration   479500/  500000 | consumed samples:      3836000 | elapsed time per iteration (ms): 325.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.939613E+00 | loss scale: 262144.0 | grad norm: 1.051 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 01:56:26] iteration   479600/  500000 | consumed samples:      3836800 | elapsed time per iteration (ms): 325.9 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.869601E+00 | loss scale: 262144.0 | grad norm: 1.049 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 01:56:59] iteration   479700/  500000 | consumed samples:      3837600 | elapsed time per iteration (ms): 325.4 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.909160E+00 | loss scale: 262144.0 | grad norm: 1.006 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 01:57:31] iteration   479800/  500000 | consumed samples:      3838400 | elapsed time per iteration (ms): 324.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.894060E+00 | loss scale: 262144.0 | grad norm: 1.046 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 01:58:04] iteration   479900/  500000 | consumed samples:      3839200 | elapsed time per iteration (ms): 324.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.908763E+00 | loss scale: 262144.0 | grad norm: 1.054 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 01:58:36] iteration   480000/  500000 | consumed samples:      3840000 | elapsed time per iteration (ms): 323.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.914438E+00 | loss scale: 262144.0 | grad norm: 1.012 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1064.62, 1064.62)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 480000 | lm loss value: 3.627995E+00 | lm loss PPL: 3.763726E+01 | 
--------------------------------------------------------------------------------------------------
saving checkpoint at iteration  480000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-max in torch format
  successfully saved checkpoint at iteration  480000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-max
(min, max) time across ranks (ms):
    save-checkpoint ................................: (5698.52, 5698.52)
 [2024-06-23 01:59:16] iteration   480100/  500000 | consumed samples:      3840800 | elapsed time per iteration (ms): 325.0 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.901534E+00 | loss scale: 262144.0 | grad norm: 1.017 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 01:59:48] iteration   480200/  500000 | consumed samples:      3841600 | elapsed time per iteration (ms): 324.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.898753E+00 | loss scale: 262144.0 | grad norm: 1.045 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 02:00:20] iteration   480300/  500000 | consumed samples:      3842400 | elapsed time per iteration (ms): 324.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.891733E+00 | loss scale: 262144.0 | grad norm: 1.045 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 02:00:53] iteration   480400/  500000 | consumed samples:      3843200 | elapsed time per iteration (ms): 327.0 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.917976E+00 | loss scale: 524288.0 | grad norm: 1.035 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 02:01:26] iteration   480500/  500000 | consumed samples:      3844000 | elapsed time per iteration (ms): 323.9 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.937339E+00 | loss scale: 524288.0 | grad norm: 1.029 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 02:01:58] iteration   480600/  500000 | consumed samples:      3844800 | elapsed time per iteration (ms): 324.9 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.884604E+00 | loss scale: 524288.0 | grad norm: 1.054 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 02:02:30] iteration   480700/  500000 | consumed samples:      3845600 | elapsed time per iteration (ms): 324.6 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.933954E+00 | loss scale: 524288.0 | grad norm: 1.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 02:03:03] iteration   480800/  500000 | consumed samples:      3846400 | elapsed time per iteration (ms): 324.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.919421E+00 | loss scale: 524288.0 | grad norm: 1.045 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 02:03:35] iteration   480900/  500000 | consumed samples:      3847200 | elapsed time per iteration (ms): 324.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.844139E+00 | loss scale: 524288.0 | grad norm: 1.018 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 02:04:08] iteration   481000/  500000 | consumed samples:      3848000 | elapsed time per iteration (ms): 324.9 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.932513E+00 | loss scale: 524288.0 | grad norm: 0.999 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1066.02, 1066.02)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 481000 | lm loss value: 3.751871E+00 | lm loss PPL: 4.260071E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-23 02:04:41] iteration   481100/  500000 | consumed samples:      3848800 | elapsed time per iteration (ms): 323.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.922611E+00 | loss scale: 524288.0 | grad norm: 1.018 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 02:05:14] iteration   481200/  500000 | consumed samples:      3849600 | elapsed time per iteration (ms): 325.6 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.889935E+00 | loss scale: 524288.0 | grad norm: 1.011 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 02:05:46] iteration   481300/  500000 | consumed samples:      3850400 | elapsed time per iteration (ms): 324.9 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.900032E+00 | loss scale: 524288.0 | grad norm: 1.007 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 02:06:19] iteration   481400/  500000 | consumed samples:      3851200 | elapsed time per iteration (ms): 324.0 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.920678E+00 | loss scale: 524288.0 | grad norm: 1.061 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-23 02:06:51] iteration   481500/  500000 | consumed samples:      3852000 | elapsed time per iteration (ms): 326.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.908167E+00 | loss scale: 524288.0 | grad norm: 0.999 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 02:07:24] iteration   481600/  500000 | consumed samples:      3852800 | elapsed time per iteration (ms): 325.6 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.923976E+00 | loss scale: 262144.0 | grad norm: 1.041 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-23 02:07:57] iteration   481700/  500000 | consumed samples:      3853600 | elapsed time per iteration (ms): 326.1 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.886976E+00 | loss scale: 262144.0 | grad norm: 1.091 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 02:08:29] iteration   481800/  500000 | consumed samples:      3854400 | elapsed time per iteration (ms): 323.4 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.880039E+00 | loss scale: 262144.0 | grad norm: 1.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 02:09:01] iteration   481900/  500000 | consumed samples:      3855200 | elapsed time per iteration (ms): 325.0 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.945536E+00 | loss scale: 262144.0 | grad norm: 1.023 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 02:09:34] iteration   482000/  500000 | consumed samples:      3856000 | elapsed time per iteration (ms): 325.0 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.908835E+00 | loss scale: 262144.0 | grad norm: 1.034 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1063.06, 1063.06)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 482000 | lm loss value: 3.819067E+00 | lm loss PPL: 4.556168E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-23 02:10:07] iteration   482100/  500000 | consumed samples:      3856800 | elapsed time per iteration (ms): 324.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.952035E+00 | loss scale: 262144.0 | grad norm: 1.058 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 02:10:40] iteration   482200/  500000 | consumed samples:      3857600 | elapsed time per iteration (ms): 325.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.909768E+00 | loss scale: 262144.0 | grad norm: 1.030 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 02:11:13] iteration   482300/  500000 | consumed samples:      3858400 | elapsed time per iteration (ms): 326.0 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.899845E+00 | loss scale: 262144.0 | grad norm: 0.975 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 02:11:45] iteration   482400/  500000 | consumed samples:      3859200 | elapsed time per iteration (ms): 325.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.912057E+00 | loss scale: 262144.0 | grad norm: 0.982 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 02:12:17] iteration   482500/  500000 | consumed samples:      3860000 | elapsed time per iteration (ms): 323.0 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.871889E+00 | loss scale: 262144.0 | grad norm: 1.046 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 02:12:50] iteration   482600/  500000 | consumed samples:      3860800 | elapsed time per iteration (ms): 323.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.888177E+00 | loss scale: 524288.0 | grad norm: 1.016 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 02:13:22] iteration   482700/  500000 | consumed samples:      3861600 | elapsed time per iteration (ms): 324.0 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.883590E+00 | loss scale: 524288.0 | grad norm: 1.040 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 02:13:55] iteration   482800/  500000 | consumed samples:      3862400 | elapsed time per iteration (ms): 324.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.904153E+00 | loss scale: 524288.0 | grad norm: 1.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 02:14:27] iteration   482900/  500000 | consumed samples:      3863200 | elapsed time per iteration (ms): 322.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.939777E+00 | loss scale: 524288.0 | grad norm: 1.063 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-23 02:15:00] iteration   483000/  500000 | consumed samples:      3864000 | elapsed time per iteration (ms): 326.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.857111E+00 | loss scale: 524288.0 | grad norm: 0.966 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1070.88, 1070.88)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 483000 | lm loss value: 3.757710E+00 | lm loss PPL: 4.285019E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-23 02:15:33] iteration   483100/  500000 | consumed samples:      3864800 | elapsed time per iteration (ms): 324.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.915916E+00 | loss scale: 524288.0 | grad norm: 1.053 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 02:16:05] iteration   483200/  500000 | consumed samples:      3865600 | elapsed time per iteration (ms): 323.9 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.916789E+00 | loss scale: 524288.0 | grad norm: 1.063 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 02:16:38] iteration   483300/  500000 | consumed samples:      3866400 | elapsed time per iteration (ms): 325.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.934530E+00 | loss scale: 524288.0 | grad norm: 0.991 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 02:17:10] iteration   483400/  500000 | consumed samples:      3867200 | elapsed time per iteration (ms): 323.4 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.862597E+00 | loss scale: 524288.0 | grad norm: 1.021 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 02:17:43] iteration   483500/  500000 | consumed samples:      3868000 | elapsed time per iteration (ms): 324.4 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.927704E+00 | loss scale: 262144.0 | grad norm: 1.053 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-23 02:18:15] iteration   483600/  500000 | consumed samples:      3868800 | elapsed time per iteration (ms): 325.9 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.912722E+00 | loss scale: 262144.0 | grad norm: 1.013 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 02:18:48] iteration   483700/  500000 | consumed samples:      3869600 | elapsed time per iteration (ms): 325.9 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.892381E+00 | loss scale: 262144.0 | grad norm: 1.104 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 02:19:20] iteration   483800/  500000 | consumed samples:      3870400 | elapsed time per iteration (ms): 324.1 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.900947E+00 | loss scale: 262144.0 | grad norm: 1.041 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 02:19:53] iteration   483900/  500000 | consumed samples:      3871200 | elapsed time per iteration (ms): 323.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.877773E+00 | loss scale: 262144.0 | grad norm: 1.038 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 02:20:25] iteration   484000/  500000 | consumed samples:      3872000 | elapsed time per iteration (ms): 324.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.894311E+00 | loss scale: 262144.0 | grad norm: 1.029 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1062.21, 1062.21)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 484000 | lm loss value: 3.685932E+00 | lm loss PPL: 3.988228E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-23 02:20:59] iteration   484100/  500000 | consumed samples:      3872800 | elapsed time per iteration (ms): 323.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.889671E+00 | loss scale: 262144.0 | grad norm: 1.019 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 02:21:31] iteration   484200/  500000 | consumed samples:      3873600 | elapsed time per iteration (ms): 323.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.919615E+00 | loss scale: 262144.0 | grad norm: 1.008 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 02:22:03] iteration   484300/  500000 | consumed samples:      3874400 | elapsed time per iteration (ms): 324.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.928357E+00 | loss scale: 262144.0 | grad norm: 1.028 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 02:22:36] iteration   484400/  500000 | consumed samples:      3875200 | elapsed time per iteration (ms): 323.9 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.891801E+00 | loss scale: 262144.0 | grad norm: 1.008 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 02:23:08] iteration   484500/  500000 | consumed samples:      3876000 | elapsed time per iteration (ms): 325.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.915475E+00 | loss scale: 524288.0 | grad norm: 0.999 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 02:23:41] iteration   484600/  500000 | consumed samples:      3876800 | elapsed time per iteration (ms): 322.9 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.877039E+00 | loss scale: 524288.0 | grad norm: 1.009 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 02:24:13] iteration   484700/  500000 | consumed samples:      3877600 | elapsed time per iteration (ms): 322.1 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.939254E+00 | loss scale: 524288.0 | grad norm: 1.051 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 02:24:45] iteration   484800/  500000 | consumed samples:      3878400 | elapsed time per iteration (ms): 322.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.897444E+00 | loss scale: 524288.0 | grad norm: 1.041 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 02:25:17] iteration   484900/  500000 | consumed samples:      3879200 | elapsed time per iteration (ms): 323.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.894868E+00 | loss scale: 524288.0 | grad norm: 1.035 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 02:25:50] iteration   485000/  500000 | consumed samples:      3880000 | elapsed time per iteration (ms): 324.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.912768E+00 | loss scale: 524288.0 | grad norm: 0.995 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1063.08, 1063.08)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 485000 | lm loss value: 3.688028E+00 | lm loss PPL: 3.996596E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-23 02:26:24] iteration   485100/  500000 | consumed samples:      3880800 | elapsed time per iteration (ms): 326.4 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.890695E+00 | loss scale: 524288.0 | grad norm: 1.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 02:26:56] iteration   485200/  500000 | consumed samples:      3881600 | elapsed time per iteration (ms): 325.1 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.928537E+00 | loss scale: 524288.0 | grad norm: 1.021 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 02:27:29] iteration   485300/  500000 | consumed samples:      3882400 | elapsed time per iteration (ms): 325.4 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.903739E+00 | loss scale: 524288.0 | grad norm: 1.039 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 02:28:01] iteration   485400/  500000 | consumed samples:      3883200 | elapsed time per iteration (ms): 326.9 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.912895E+00 | loss scale: 524288.0 | grad norm: 0.980 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 02:28:34] iteration   485500/  500000 | consumed samples:      3884000 | elapsed time per iteration (ms): 323.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.916047E+00 | loss scale: 524288.0 | grad norm: 1.053 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-23 02:29:06] iteration   485600/  500000 | consumed samples:      3884800 | elapsed time per iteration (ms): 322.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.908269E+00 | loss scale: 524288.0 | grad norm: 1.052 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 02:29:39] iteration   485700/  500000 | consumed samples:      3885600 | elapsed time per iteration (ms): 325.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.909044E+00 | loss scale: 524288.0 | grad norm: 1.034 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 02:30:11] iteration   485800/  500000 | consumed samples:      3886400 | elapsed time per iteration (ms): 324.9 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.911099E+00 | loss scale: 524288.0 | grad norm: 1.004 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 02:30:44] iteration   485900/  500000 | consumed samples:      3887200 | elapsed time per iteration (ms): 326.1 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.904490E+00 | loss scale: 524288.0 | grad norm: 0.954 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 02:31:16] iteration   486000/  500000 | consumed samples:      3888000 | elapsed time per iteration (ms): 323.9 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.895907E+00 | loss scale: 524288.0 | grad norm: 1.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1063.10, 1063.10)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 486000 | lm loss value: 3.727029E+00 | lm loss PPL: 4.155547E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-23 02:31:49] iteration   486100/  500000 | consumed samples:      3888800 | elapsed time per iteration (ms): 323.6 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.902045E+00 | loss scale: 524288.0 | grad norm: 1.028 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 02:32:22] iteration   486200/  500000 | consumed samples:      3889600 | elapsed time per iteration (ms): 321.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.882543E+00 | loss scale: 262144.0 | grad norm: 1.031 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-23 02:32:54] iteration   486300/  500000 | consumed samples:      3890400 | elapsed time per iteration (ms): 324.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.900363E+00 | loss scale: 262144.0 | grad norm: 0.966 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 02:33:26] iteration   486400/  500000 | consumed samples:      3891200 | elapsed time per iteration (ms): 322.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.924727E+00 | loss scale: 262144.0 | grad norm: 1.031 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 02:33:59] iteration   486500/  500000 | consumed samples:      3892000 | elapsed time per iteration (ms): 323.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.904961E+00 | loss scale: 262144.0 | grad norm: 1.107 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 02:34:31] iteration   486600/  500000 | consumed samples:      3892800 | elapsed time per iteration (ms): 322.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.954591E+00 | loss scale: 262144.0 | grad norm: 1.133 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 02:35:03] iteration   486700/  500000 | consumed samples:      3893600 | elapsed time per iteration (ms): 322.0 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.879680E+00 | loss scale: 262144.0 | grad norm: 1.043 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 02:35:36] iteration   486800/  500000 | consumed samples:      3894400 | elapsed time per iteration (ms): 325.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.891455E+00 | loss scale: 262144.0 | grad norm: 1.025 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 02:36:08] iteration   486900/  500000 | consumed samples:      3895200 | elapsed time per iteration (ms): 324.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.888681E+00 | loss scale: 262144.0 | grad norm: 1.017 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 02:36:41] iteration   487000/  500000 | consumed samples:      3896000 | elapsed time per iteration (ms): 326.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.931998E+00 | loss scale: 262144.0 | grad norm: 1.033 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1063.54, 1063.54)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 487000 | lm loss value: 3.689831E+00 | lm loss PPL: 4.003807E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-23 02:37:14] iteration   487100/  500000 | consumed samples:      3896800 | elapsed time per iteration (ms): 324.4 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.884251E+00 | loss scale: 262144.0 | grad norm: 0.965 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 02:37:47] iteration   487200/  500000 | consumed samples:      3897600 | elapsed time per iteration (ms): 326.4 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.911991E+00 | loss scale: 524288.0 | grad norm: 1.033 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 02:38:19] iteration   487300/  500000 | consumed samples:      3898400 | elapsed time per iteration (ms): 325.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.883663E+00 | loss scale: 524288.0 | grad norm: 1.025 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 02:38:52] iteration   487400/  500000 | consumed samples:      3899200 | elapsed time per iteration (ms): 325.4 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.906068E+00 | loss scale: 524288.0 | grad norm: 1.063 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 02:39:24] iteration   487500/  500000 | consumed samples:      3900000 | elapsed time per iteration (ms): 324.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.920451E+00 | loss scale: 524288.0 | grad norm: 1.018 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 02:39:57] iteration   487600/  500000 | consumed samples:      3900800 | elapsed time per iteration (ms): 322.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.875022E+00 | loss scale: 524288.0 | grad norm: 1.040 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-23 02:40:29] iteration   487700/  500000 | consumed samples:      3901600 | elapsed time per iteration (ms): 324.1 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.914085E+00 | loss scale: 524288.0 | grad norm: 0.989 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 02:41:01] iteration   487800/  500000 | consumed samples:      3902400 | elapsed time per iteration (ms): 323.4 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.916406E+00 | loss scale: 524288.0 | grad norm: 1.021 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 02:41:34] iteration   487900/  500000 | consumed samples:      3903200 | elapsed time per iteration (ms): 324.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.869655E+00 | loss scale: 524288.0 | grad norm: 1.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 02:42:06] iteration   488000/  500000 | consumed samples:      3904000 | elapsed time per iteration (ms): 325.4 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.918840E+00 | loss scale: 524288.0 | grad norm: 0.990 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1064.31, 1064.31)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 488000 | lm loss value: 3.786012E+00 | lm loss PPL: 4.408025E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-23 02:42:40] iteration   488100/  500000 | consumed samples:      3904800 | elapsed time per iteration (ms): 326.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.860892E+00 | loss scale: 524288.0 | grad norm: 1.038 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 02:43:13] iteration   488200/  500000 | consumed samples:      3905600 | elapsed time per iteration (ms): 324.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.854471E+00 | loss scale: 262144.0 | grad norm: 0.980 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-23 02:43:45] iteration   488300/  500000 | consumed samples:      3906400 | elapsed time per iteration (ms): 325.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.855229E+00 | loss scale: 262144.0 | grad norm: 1.063 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 02:44:18] iteration   488400/  500000 | consumed samples:      3907200 | elapsed time per iteration (ms): 324.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.868297E+00 | loss scale: 262144.0 | grad norm: 1.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 02:44:50] iteration   488500/  500000 | consumed samples:      3908000 | elapsed time per iteration (ms): 328.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.871501E+00 | loss scale: 262144.0 | grad norm: 1.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 02:45:23] iteration   488600/  500000 | consumed samples:      3908800 | elapsed time per iteration (ms): 324.9 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.862328E+00 | loss scale: 262144.0 | grad norm: 1.035 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 02:45:55] iteration   488700/  500000 | consumed samples:      3909600 | elapsed time per iteration (ms): 323.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.857117E+00 | loss scale: 262144.0 | grad norm: 1.060 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 02:46:28] iteration   488800/  500000 | consumed samples:      3910400 | elapsed time per iteration (ms): 324.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.893165E+00 | loss scale: 262144.0 | grad norm: 1.052 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 02:47:00] iteration   488900/  500000 | consumed samples:      3911200 | elapsed time per iteration (ms): 325.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.895658E+00 | loss scale: 262144.0 | grad norm: 1.123 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 02:47:33] iteration   489000/  500000 | consumed samples:      3912000 | elapsed time per iteration (ms): 323.4 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.882935E+00 | loss scale: 262144.0 | grad norm: 1.058 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1062.85, 1062.85)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 489000 | lm loss value: 3.728078E+00 | lm loss PPL: 4.159908E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-23 02:48:06] iteration   489100/  500000 | consumed samples:      3912800 | elapsed time per iteration (ms): 324.1 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.902858E+00 | loss scale: 262144.0 | grad norm: 1.027 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 02:48:39] iteration   489200/  500000 | consumed samples:      3913600 | elapsed time per iteration (ms): 325.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.881153E+00 | loss scale: 524288.0 | grad norm: 0.982 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 02:49:11] iteration   489300/  500000 | consumed samples:      3914400 | elapsed time per iteration (ms): 324.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.845547E+00 | loss scale: 524288.0 | grad norm: 1.163 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 02:49:44] iteration   489400/  500000 | consumed samples:      3915200 | elapsed time per iteration (ms): 324.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.861361E+00 | loss scale: 524288.0 | grad norm: 1.066 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 02:50:16] iteration   489500/  500000 | consumed samples:      3916000 | elapsed time per iteration (ms): 325.4 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.859590E+00 | loss scale: 524288.0 | grad norm: 1.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 02:50:49] iteration   489600/  500000 | consumed samples:      3916800 | elapsed time per iteration (ms): 325.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.894632E+00 | loss scale: 524288.0 | grad norm: 1.014 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-23 02:51:21] iteration   489700/  500000 | consumed samples:      3917600 | elapsed time per iteration (ms): 324.9 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.873800E+00 | loss scale: 524288.0 | grad norm: 1.059 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 02:51:54] iteration   489800/  500000 | consumed samples:      3918400 | elapsed time per iteration (ms): 325.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.885358E+00 | loss scale: 262144.0 | grad norm: 1.020 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-23 02:52:26] iteration   489900/  500000 | consumed samples:      3919200 | elapsed time per iteration (ms): 324.6 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.866259E+00 | loss scale: 262144.0 | grad norm: 1.036 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 02:52:59] iteration   490000/  500000 | consumed samples:      3920000 | elapsed time per iteration (ms): 324.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.874761E+00 | loss scale: 262144.0 | grad norm: 1.039 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1064.96, 1064.96)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 490000 | lm loss value: 3.825052E+00 | lm loss PPL: 4.583520E+01 | 
--------------------------------------------------------------------------------------------------
saving checkpoint at iteration  490000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-max in torch format
  successfully saved checkpoint at iteration  490000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-max
(min, max) time across ranks (ms):
    save-checkpoint ................................: (5706.15, 5706.15)
 [2024-06-23 02:53:38] iteration   490100/  500000 | consumed samples:      3920800 | elapsed time per iteration (ms): 323.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.909027E+00 | loss scale: 262144.0 | grad norm: 1.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 02:54:10] iteration   490200/  500000 | consumed samples:      3921600 | elapsed time per iteration (ms): 324.0 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.856847E+00 | loss scale: 262144.0 | grad norm: 0.997 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 02:54:43] iteration   490300/  500000 | consumed samples:      3922400 | elapsed time per iteration (ms): 325.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.879587E+00 | loss scale: 262144.0 | grad norm: 1.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 02:55:15] iteration   490400/  500000 | consumed samples:      3923200 | elapsed time per iteration (ms): 322.9 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.809581E+00 | loss scale: 262144.0 | grad norm: 1.041 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 02:55:47] iteration   490500/  500000 | consumed samples:      3924000 | elapsed time per iteration (ms): 326.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.868568E+00 | loss scale: 262144.0 | grad norm: 1.029 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 02:56:20] iteration   490600/  500000 | consumed samples:      3924800 | elapsed time per iteration (ms): 322.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.865673E+00 | loss scale: 262144.0 | grad norm: 1.099 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 02:56:52] iteration   490700/  500000 | consumed samples:      3925600 | elapsed time per iteration (ms): 321.4 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.872897E+00 | loss scale: 262144.0 | grad norm: 1.057 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 02:57:24] iteration   490800/  500000 | consumed samples:      3926400 | elapsed time per iteration (ms): 323.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.878113E+00 | loss scale: 524288.0 | grad norm: 1.037 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 02:57:57] iteration   490900/  500000 | consumed samples:      3927200 | elapsed time per iteration (ms): 324.9 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.874130E+00 | loss scale: 524288.0 | grad norm: 1.060 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 02:58:29] iteration   491000/  500000 | consumed samples:      3928000 | elapsed time per iteration (ms): 325.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.873557E+00 | loss scale: 524288.0 | grad norm: 1.009 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1065.09, 1065.09)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 491000 | lm loss value: 3.732615E+00 | lm loss PPL: 4.178824E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-23 02:59:03] iteration   491100/  500000 | consumed samples:      3928800 | elapsed time per iteration (ms): 324.4 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.874005E+00 | loss scale: 524288.0 | grad norm: 0.968 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-23 02:59:35] iteration   491200/  500000 | consumed samples:      3929600 | elapsed time per iteration (ms): 326.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.912393E+00 | loss scale: 524288.0 | grad norm: 1.030 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 03:00:08] iteration   491300/  500000 | consumed samples:      3930400 | elapsed time per iteration (ms): 323.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.906302E+00 | loss scale: 524288.0 | grad norm: 0.965 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 03:00:40] iteration   491400/  500000 | consumed samples:      3931200 | elapsed time per iteration (ms): 326.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.876135E+00 | loss scale: 524288.0 | grad norm: 1.012 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 03:01:13] iteration   491500/  500000 | consumed samples:      3932000 | elapsed time per iteration (ms): 324.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.912079E+00 | loss scale: 524288.0 | grad norm: 1.004 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 03:01:45] iteration   491600/  500000 | consumed samples:      3932800 | elapsed time per iteration (ms): 323.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.870304E+00 | loss scale: 524288.0 | grad norm: 0.992 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 03:02:18] iteration   491700/  500000 | consumed samples:      3933600 | elapsed time per iteration (ms): 325.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.867024E+00 | loss scale: 524288.0 | grad norm: 1.014 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 03:02:50] iteration   491800/  500000 | consumed samples:      3934400 | elapsed time per iteration (ms): 322.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.834675E+00 | loss scale: 262144.0 | grad norm: 0.981 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-23 03:03:22] iteration   491900/  500000 | consumed samples:      3935200 | elapsed time per iteration (ms): 324.1 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.832225E+00 | loss scale: 262144.0 | grad norm: 1.030 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 03:03:55] iteration   492000/  500000 | consumed samples:      3936000 | elapsed time per iteration (ms): 325.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.880476E+00 | loss scale: 262144.0 | grad norm: 1.017 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1062.30, 1062.30)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 492000 | lm loss value: 3.779029E+00 | lm loss PPL: 4.377350E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-23 03:04:28] iteration   492100/  500000 | consumed samples:      3936800 | elapsed time per iteration (ms): 323.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.901980E+00 | loss scale: 262144.0 | grad norm: 1.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 03:05:01] iteration   492200/  500000 | consumed samples:      3937600 | elapsed time per iteration (ms): 324.0 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.908949E+00 | loss scale: 262144.0 | grad norm: 1.049 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 03:05:33] iteration   492300/  500000 | consumed samples:      3938400 | elapsed time per iteration (ms): 324.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.886633E+00 | loss scale: 262144.0 | grad norm: 1.055 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 03:06:06] iteration   492400/  500000 | consumed samples:      3939200 | elapsed time per iteration (ms): 326.1 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.862018E+00 | loss scale: 262144.0 | grad norm: 1.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 03:06:38] iteration   492500/  500000 | consumed samples:      3940000 | elapsed time per iteration (ms): 324.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.833733E+00 | loss scale: 131072.0 | grad norm: 1.022 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-23 03:07:11] iteration   492600/  500000 | consumed samples:      3940800 | elapsed time per iteration (ms): 325.0 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.870031E+00 | loss scale: 131072.0 | grad norm: 1.030 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 03:07:43] iteration   492700/  500000 | consumed samples:      3941600 | elapsed time per iteration (ms): 327.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.882292E+00 | loss scale: 131072.0 | grad norm: 1.010 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 03:08:16] iteration   492800/  500000 | consumed samples:      3942400 | elapsed time per iteration (ms): 323.9 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.856005E+00 | loss scale: 131072.0 | grad norm: 1.016 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 03:08:48] iteration   492900/  500000 | consumed samples:      3943200 | elapsed time per iteration (ms): 323.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.898958E+00 | loss scale: 131072.0 | grad norm: 1.058 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 03:09:21] iteration   493000/  500000 | consumed samples:      3944000 | elapsed time per iteration (ms): 322.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.873970E+00 | loss scale: 131072.0 | grad norm: 1.052 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1062.35, 1062.35)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 493000 | lm loss value: 3.716263E+00 | lm loss PPL: 4.111047E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-23 03:09:54] iteration   493100/  500000 | consumed samples:      3944800 | elapsed time per iteration (ms): 324.1 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.847633E+00 | loss scale: 131072.0 | grad norm: 1.013 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 03:10:26] iteration   493200/  500000 | consumed samples:      3945600 | elapsed time per iteration (ms): 322.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.908513E+00 | loss scale: 131072.0 | grad norm: 1.036 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 03:10:59] iteration   493300/  500000 | consumed samples:      3946400 | elapsed time per iteration (ms): 322.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.915003E+00 | loss scale: 131072.0 | grad norm: 1.053 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 03:11:31] iteration   493400/  500000 | consumed samples:      3947200 | elapsed time per iteration (ms): 324.4 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.906089E+00 | loss scale: 131072.0 | grad norm: 1.030 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 03:12:03] iteration   493500/  500000 | consumed samples:      3948000 | elapsed time per iteration (ms): 323.6 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.838862E+00 | loss scale: 262144.0 | grad norm: 1.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 03:12:36] iteration   493600/  500000 | consumed samples:      3948800 | elapsed time per iteration (ms): 325.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.835462E+00 | loss scale: 262144.0 | grad norm: 1.034 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 03:13:08] iteration   493700/  500000 | consumed samples:      3949600 | elapsed time per iteration (ms): 324.0 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.895718E+00 | loss scale: 262144.0 | grad norm: 1.039 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 03:13:41] iteration   493800/  500000 | consumed samples:      3950400 | elapsed time per iteration (ms): 326.0 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.855298E+00 | loss scale: 262144.0 | grad norm: 1.040 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-23 03:14:13] iteration   493900/  500000 | consumed samples:      3951200 | elapsed time per iteration (ms): 322.6 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.864986E+00 | loss scale: 262144.0 | grad norm: 0.961 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 03:14:46] iteration   494000/  500000 | consumed samples:      3952000 | elapsed time per iteration (ms): 325.4 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.873878E+00 | loss scale: 262144.0 | grad norm: 1.009 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1063.46, 1063.46)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 494000 | lm loss value: 3.754883E+00 | lm loss PPL: 4.272923E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-23 03:15:19] iteration   494100/  500000 | consumed samples:      3952800 | elapsed time per iteration (ms): 326.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.889685E+00 | loss scale: 262144.0 | grad norm: 1.022 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 03:15:52] iteration   494200/  500000 | consumed samples:      3953600 | elapsed time per iteration (ms): 324.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.890545E+00 | loss scale: 262144.0 | grad norm: 1.047 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 03:16:24] iteration   494300/  500000 | consumed samples:      3954400 | elapsed time per iteration (ms): 323.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.871625E+00 | loss scale: 262144.0 | grad norm: 0.999 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 03:16:57] iteration   494400/  500000 | consumed samples:      3955200 | elapsed time per iteration (ms): 325.0 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.909659E+00 | loss scale: 262144.0 | grad norm: 1.064 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 03:17:29] iteration   494500/  500000 | consumed samples:      3956000 | elapsed time per iteration (ms): 323.9 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.850811E+00 | loss scale: 262144.0 | grad norm: 1.041 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 03:18:02] iteration   494600/  500000 | consumed samples:      3956800 | elapsed time per iteration (ms): 325.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.876278E+00 | loss scale: 262144.0 | grad norm: 1.030 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 03:18:34] iteration   494700/  500000 | consumed samples:      3957600 | elapsed time per iteration (ms): 325.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.875715E+00 | loss scale: 262144.0 | grad norm: 1.029 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 03:19:07] iteration   494800/  500000 | consumed samples:      3958400 | elapsed time per iteration (ms): 325.0 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.902003E+00 | loss scale: 524288.0 | grad norm: 1.042 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 03:19:39] iteration   494900/  500000 | consumed samples:      3959200 | elapsed time per iteration (ms): 325.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.826303E+00 | loss scale: 524288.0 | grad norm: 1.025 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 03:20:11] iteration   495000/  500000 | consumed samples:      3960000 | elapsed time per iteration (ms): 323.6 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.872674E+00 | loss scale: 524288.0 | grad norm: 1.053 | number of skipped iterations:   1 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1063.86, 1063.86)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 495000 | lm loss value: 3.586756E+00 | lm loss PPL: 3.611671E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-23 03:20:45] iteration   495100/  500000 | consumed samples:      3960800 | elapsed time per iteration (ms): 326.0 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.866725E+00 | loss scale: 262144.0 | grad norm: 1.054 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-23 03:21:18] iteration   495200/  500000 | consumed samples:      3961600 | elapsed time per iteration (ms): 325.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.933260E+00 | loss scale: 262144.0 | grad norm: 1.064 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 03:21:50] iteration   495300/  500000 | consumed samples:      3962400 | elapsed time per iteration (ms): 326.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.874336E+00 | loss scale: 262144.0 | grad norm: 1.025 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 03:22:23] iteration   495400/  500000 | consumed samples:      3963200 | elapsed time per iteration (ms): 325.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.869109E+00 | loss scale: 262144.0 | grad norm: 1.032 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 03:22:55] iteration   495500/  500000 | consumed samples:      3964000 | elapsed time per iteration (ms): 324.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.891804E+00 | loss scale: 262144.0 | grad norm: 1.065 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 03:23:28] iteration   495600/  500000 | consumed samples:      3964800 | elapsed time per iteration (ms): 324.6 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.906721E+00 | loss scale: 262144.0 | grad norm: 1.030 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 03:24:00] iteration   495700/  500000 | consumed samples:      3965600 | elapsed time per iteration (ms): 324.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.892412E+00 | loss scale: 262144.0 | grad norm: 1.063 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 03:24:33] iteration   495800/  500000 | consumed samples:      3966400 | elapsed time per iteration (ms): 325.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.886111E+00 | loss scale: 262144.0 | grad norm: 1.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 03:25:05] iteration   495900/  500000 | consumed samples:      3967200 | elapsed time per iteration (ms): 323.9 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.876899E+00 | loss scale: 262144.0 | grad norm: 1.048 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 03:25:38] iteration   496000/  500000 | consumed samples:      3968000 | elapsed time per iteration (ms): 324.1 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.908442E+00 | loss scale: 262144.0 | grad norm: 1.028 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1063.76, 1063.76)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 496000 | lm loss value: 3.813882E+00 | lm loss PPL: 4.532604E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-23 03:26:11] iteration   496100/  500000 | consumed samples:      3968800 | elapsed time per iteration (ms): 323.4 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.866255E+00 | loss scale: 524288.0 | grad norm: 1.085 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 03:26:44] iteration   496200/  500000 | consumed samples:      3969600 | elapsed time per iteration (ms): 327.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.902980E+00 | loss scale: 524288.0 | grad norm: 1.017 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 03:27:16] iteration   496300/  500000 | consumed samples:      3970400 | elapsed time per iteration (ms): 326.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.876399E+00 | loss scale: 524288.0 | grad norm: 1.109 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 03:27:49] iteration   496400/  500000 | consumed samples:      3971200 | elapsed time per iteration (ms): 324.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.839468E+00 | loss scale: 524288.0 | grad norm: 1.121 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 03:28:21] iteration   496500/  500000 | consumed samples:      3972000 | elapsed time per iteration (ms): 323.1 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.879698E+00 | loss scale: 524288.0 | grad norm: 1.009 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-23 03:28:54] iteration   496600/  500000 | consumed samples:      3972800 | elapsed time per iteration (ms): 325.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.877335E+00 | loss scale: 524288.0 | grad norm: 1.055 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 03:29:26] iteration   496700/  500000 | consumed samples:      3973600 | elapsed time per iteration (ms): 324.1 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.878849E+00 | loss scale: 524288.0 | grad norm: 1.049 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 03:29:59] iteration   496800/  500000 | consumed samples:      3974400 | elapsed time per iteration (ms): 325.1 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.849676E+00 | loss scale: 524288.0 | grad norm: 0.985 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 03:30:31] iteration   496900/  500000 | consumed samples:      3975200 | elapsed time per iteration (ms): 326.4 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.840457E+00 | loss scale: 524288.0 | grad norm: 1.007 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 03:31:04] iteration   497000/  500000 | consumed samples:      3976000 | elapsed time per iteration (ms): 324.0 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.859919E+00 | loss scale: 524288.0 | grad norm: 1.093 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1063.63, 1063.63)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 497000 | lm loss value: 3.684943E+00 | lm loss PPL: 3.984284E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-23 03:31:37] iteration   497100/  500000 | consumed samples:      3976800 | elapsed time per iteration (ms): 323.1 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.871264E+00 | loss scale: 524288.0 | grad norm: 1.009 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 03:32:10] iteration   497200/  500000 | consumed samples:      3977600 | elapsed time per iteration (ms): 325.0 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.856456E+00 | loss scale: 524288.0 | grad norm: 1.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 03:32:42] iteration   497300/  500000 | consumed samples:      3978400 | elapsed time per iteration (ms): 326.0 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.887031E+00 | loss scale: 524288.0 | grad norm: 1.112 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 03:33:15] iteration   497400/  500000 | consumed samples:      3979200 | elapsed time per iteration (ms): 325.6 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.876549E+00 | loss scale: 524288.0 | grad norm: 1.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 03:33:47] iteration   497500/  500000 | consumed samples:      3980000 | elapsed time per iteration (ms): 324.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.882510E+00 | loss scale: 524288.0 | grad norm: 1.000 | number of skipped iterations:   2 | number of nan iterations:   0 |
 [2024-06-23 03:34:20] iteration   497600/  500000 | consumed samples:      3980800 | elapsed time per iteration (ms): 324.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.895827E+00 | loss scale: 524288.0 | grad norm: 1.035 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 03:34:52] iteration   497700/  500000 | consumed samples:      3981600 | elapsed time per iteration (ms): 324.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.872473E+00 | loss scale: 524288.0 | grad norm: 1.013 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 03:35:25] iteration   497800/  500000 | consumed samples:      3982400 | elapsed time per iteration (ms): 325.1 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.866457E+00 | loss scale: 524288.0 | grad norm: 0.996 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 03:35:57] iteration   497900/  500000 | consumed samples:      3983200 | elapsed time per iteration (ms): 324.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.882909E+00 | loss scale: 524288.0 | grad norm: 1.037 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 03:36:30] iteration   498000/  500000 | consumed samples:      3984000 | elapsed time per iteration (ms): 325.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.879839E+00 | loss scale: 262144.0 | grad norm: 1.090 | number of skipped iterations:   1 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1063.44, 1063.44)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 498000 | lm loss value: 3.780263E+00 | lm loss PPL: 4.382755E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-23 03:37:03] iteration   498100/  500000 | consumed samples:      3984800 | elapsed time per iteration (ms): 323.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.888658E+00 | loss scale: 262144.0 | grad norm: 1.045 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 03:37:36] iteration   498200/  500000 | consumed samples:      3985600 | elapsed time per iteration (ms): 325.9 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.923142E+00 | loss scale: 262144.0 | grad norm: 0.966 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 03:38:08] iteration   498300/  500000 | consumed samples:      3986400 | elapsed time per iteration (ms): 325.1 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.872525E+00 | loss scale: 262144.0 | grad norm: 1.047 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 03:38:41] iteration   498400/  500000 | consumed samples:      3987200 | elapsed time per iteration (ms): 327.1 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.876315E+00 | loss scale: 262144.0 | grad norm: 1.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 03:39:13] iteration   498500/  500000 | consumed samples:      3988000 | elapsed time per iteration (ms): 324.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.831460E+00 | loss scale: 262144.0 | grad norm: 0.998 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 03:39:46] iteration   498600/  500000 | consumed samples:      3988800 | elapsed time per iteration (ms): 325.4 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.902481E+00 | loss scale: 262144.0 | grad norm: 0.988 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 03:40:18] iteration   498700/  500000 | consumed samples:      3989600 | elapsed time per iteration (ms): 323.8 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.894548E+00 | loss scale: 262144.0 | grad norm: 0.995 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 03:40:51] iteration   498800/  500000 | consumed samples:      3990400 | elapsed time per iteration (ms): 325.4 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.874966E+00 | loss scale: 262144.0 | grad norm: 1.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 03:41:23] iteration   498900/  500000 | consumed samples:      3991200 | elapsed time per iteration (ms): 326.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.904288E+00 | loss scale: 262144.0 | grad norm: 1.021 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 03:41:56] iteration   499000/  500000 | consumed samples:      3992000 | elapsed time per iteration (ms): 324.9 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.843426E+00 | loss scale: 524288.0 | grad norm: 1.004 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1062.89, 1062.89)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 499000 | lm loss value: 3.766815E+00 | lm loss PPL: 4.324213E+01 | 
--------------------------------------------------------------------------------------------------
 [2024-06-23 03:42:29] iteration   499100/  500000 | consumed samples:      3992800 | elapsed time per iteration (ms): 323.7 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.906026E+00 | loss scale: 524288.0 | grad norm: 1.064 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 03:43:02] iteration   499200/  500000 | consumed samples:      3993600 | elapsed time per iteration (ms): 324.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.851591E+00 | loss scale: 524288.0 | grad norm: 1.038 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 03:43:34] iteration   499300/  500000 | consumed samples:      3994400 | elapsed time per iteration (ms): 326.0 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.852250E+00 | loss scale: 524288.0 | grad norm: 1.023 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 03:44:07] iteration   499400/  500000 | consumed samples:      3995200 | elapsed time per iteration (ms): 325.1 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.896485E+00 | loss scale: 524288.0 | grad norm: 1.028 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 03:44:39] iteration   499500/  500000 | consumed samples:      3996000 | elapsed time per iteration (ms): 323.1 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.852610E+00 | loss scale: 524288.0 | grad norm: 1.063 | number of skipped iterations:   1 | number of nan iterations:   0 |
 [2024-06-23 03:45:12] iteration   499600/  500000 | consumed samples:      3996800 | elapsed time per iteration (ms): 324.3 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.893204E+00 | loss scale: 524288.0 | grad norm: 1.050 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 03:45:44] iteration   499700/  500000 | consumed samples:      3997600 | elapsed time per iteration (ms): 324.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.827336E+00 | loss scale: 524288.0 | grad norm: 1.026 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 03:46:17] iteration   499800/  500000 | consumed samples:      3998400 | elapsed time per iteration (ms): 324.5 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.909985E+00 | loss scale: 524288.0 | grad norm: 0.924 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 03:46:49] iteration   499900/  500000 | consumed samples:      3999200 | elapsed time per iteration (ms): 325.2 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.855024E+00 | loss scale: 524288.0 | grad norm: 1.062 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2024-06-23 03:47:21] iteration   500000/  500000 | consumed samples:      4000000 | elapsed time per iteration (ms): 323.9 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.842911E+00 | loss scale: 524288.0 | grad norm: 1.034 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    evaluate .......................................: (1064.81, 1064.81)
--------------------------------------------------------------------------------------------------
 validation loss at iteration 500000 | lm loss value: 3.725705E+00 | lm loss PPL: 4.150050E+01 | 
--------------------------------------------------------------------------------------------------
saving checkpoint at iteration  500000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-max in torch format
  successfully saved checkpoint at iteration  500000 to /Zhushitong/workspace/Models/gpt-2/checkpoints/gpt-2-max
(min, max) time across ranks (ms):
    save-checkpoint ................................: (5675.57, 5675.57)
[after training is done] datetime: 2024-06-23 03:47:28 
Evaluating on 80 samples
Evaluating iter 1/10
Evaluating iter 2/10
Evaluating iter 3/10
Evaluating iter 4/10
Evaluating iter 5/10
Evaluating iter 6/10
Evaluating iter 7/10
Evaluating iter 8/10
Evaluating iter 9/10
Evaluating iter 10/10
(min, max) time across ranks (ms):
    evaluate .......................................: (1071.26, 1071.26)
--------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 500000 on validation set | lm loss value: 3.695049E+00 | lm loss PPL: 4.024753E+01 | 
--------------------------------------------------------------------------------------------------------------------
Evaluating on 80 samples
Evaluating iter 1/10
Evaluating iter 2/10
Evaluating iter 3/10
Evaluating iter 4/10
Evaluating iter 5/10
Evaluating iter 6/10
Evaluating iter 7/10
Evaluating iter 8/10
Evaluating iter 9/10
Evaluating iter 10/10
(min, max) time across ranks (ms):
    evaluate .......................................: (1064.48, 1064.48)
--------------------------------------------------------------------------------------------------------------
 validation loss at iteration 500000 on test set | lm loss value: 3.592971E+00 | lm loss PPL: 3.634189E+01 | 
--------------------------------------------------------------------------------------------------------------
